<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción | The Probability Engine</title>
<meta name=keywords content="mlops,machine-learning,python,gcp,mlflow,wandb,fastapi,docker"><meta name=description content="Un análisis profundo de un pipeline MLOps completo: desde el download de datos hasta el deployment en producción, con código real y decisiones arquitectónicas explicadas."><meta name=author content="Carlos Daniel Jiménez"><link rel=canonical href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-completo/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=16x16 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=32x32 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=apple-touch-icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=mask-icon href=https://carlosdanieljimenez.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-completo/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=icon type=image/png href=/img/icon.jpeg><link rel=apple-touch-icon href=/img/icon.jpeg><link rel="shortcut icon" href=/img/icon.jpeg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-completo/"><meta property="og:site_name" content="The Probability Engine"><meta property="og:title" content="Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción"><meta property="og:description" content="Un análisis profundo de un pipeline MLOps completo: desde el download de datos hasta el deployment en producción, con código real y decisiones arquitectónicas explicadas."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="mlops"><meta property="article:published_time" content="2026-01-13T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-13T00:00:00+00:00"><meta property="article:tag" content="Mlops"><meta property="article:tag" content="Machine-Learning"><meta property="article:tag" content="Python"><meta property="article:tag" content="Gcp"><meta property="article:tag" content="Mlflow"><meta property="article:tag" content="Wandb"><meta name=twitter:card content="summary"><meta name=twitter:title content="Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción"><meta name=twitter:description content="Un análisis profundo de un pipeline MLOps completo: desde el download de datos hasta el deployment en producción, con código real y decisiones arquitectónicas explicadas."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"MLOps Guides","item":"https://carlosdanieljimenez.com/mlops/"},{"@type":"ListItem","position":2,"name":"Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción","item":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-completo/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción","name":"Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción","description":"Un análisis profundo de un pipeline MLOps completo: desde el download de datos hasta el deployment en producción, con código real y decisiones arquitectónicas explicadas.","keywords":["mlops","machine-learning","python","gcp","mlflow","wandb","fastapi","docker"],"articleBody":"Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción Por Qué Este Post No Es Otro Tutorial de Scikit-Learn La mayoría de los posts sobre MLOps te enseñan a entrenar un Random Forest en un notebook y te dicen “ahora ponlo en producción”. Este post asume que ya sabes entrenar modelos. Lo que probablemente no sabes es cómo construir un sistema donde:\nUn commit a GitHub dispara un pipeline completo de 7 steps Cada decisión de preprocesamiento está respaldada por métricas cuantificables Los modelos se versionan con metadata rica, no con nombres de archivo tipo model_final_v3_REAL.pkl El deployment no requiere SSH a un servidor para copiar un pickle Rollback de una versión defectuosa toma 30 segundos, no 3 horas de panic debugging Este post disecciona un pipeline real que implementa todo eso. No es teoría, es código que corre en producción. Basado en el capítulo 2 de “Hands-On Machine Learning” de Aurélien Géron, pero con la infraestructura que el libro no cubre.\nRepositorio completo: github\nTabla de Contenidos La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente Estructura del Proyecto: Arquitectura Que Escala Orquestación con Hydra + MLflow Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering Step 06: Hyperparameter Sweep - Optimización Bayesiana con W\u0026B Step 07: Model Registry - Versionamiento en MLflow CI/CD con GitHub Actions: Automatización del Pipeline Completo El Valor de MLOps: Por Qué Esto Importa W\u0026B vs MLflow: Por Qué Ambos, No Uno u Otro (#wandb-vs-mlflow) Docker y MLflow: Containerización del Ecosistema Completo Pipeline Container con MLflow Tracking API Container para Inference Streamlit Container para Frontend Docker Compose: Orquestación de los Tres Containers Arquitectura del API: FastAPI en Producción (#api-architecture) Estrategias de Selección de Modelos y Parámetros Model Selection: Comparación de 5 Algoritmos Parameter Grids y GridSearch Métricas de Evaluación: MAPE, SMAPE, wMAPE Testing: Fixtures, Mocking y Coverage Real Patrones de Producción Que Nadie Te Cuenta El Transform Pattern: El Truco del KMeans Sintético Training/Serving Skew: El Asesino Silencioso Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea Model Monitoring: Más Allá de Accuracy The Cascade Pattern: Fallback Resilience Feature Store Anti-Pattern: Cuándo NO Necesitas Uno Production Readiness: Un Checklist Honesto Conclusiones: MLOps Como Disciplina de Ingeniería 1. La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente El Problema Real del MLOps Ser un MLOps engineer tiene dos cosas importantes en su quehacer:\nPrimero, y lo que siento que es lo más importante: ser ordenado. Suena redundante, pero cada cosa debe ir en su lugar. Un notebook con 50 celdas ejecutadas en orden aleatorio no es un pipeline—es una bomba de tiempo. Cuando ese modelo necesita reentrenarse a las 3 AM porque el data drift disparó una alerta, ¿quién se acuerda del orden correcto de las celdas?\nSegundo: lo que no se prueba, no deja de ser un mock o un prototipo. Lejos de pensar en usar solamente patrones de diseño, el foco y lo que intentaré sembrar como idea central de este post es la usabilidad de los productos y ver esto como software design.\nEl Mindset Correcto Este proyecto trata Machine Learning como lo que realmente es: software con componentes probabilísticos. No es magia, es ingeniería. Y como ingeniería, necesita:\nVersionamiento: De datos, código, modelos y configuración Testing: Unit, integration y end-to-end Observabilidad: Logs, métricas y traces Reproducibilidad: Ejecutar hoy y en 6 meses debe dar el mismo resultado Deployment: Automatizado, no manual Referencia: Hands-On Machine Learning de Géron Este post se basa en el Capítulo 2 del libro de Géron, un clásico que todos deberíamos leer. Pero el libro se enfoca en el modelo—cómo entrenar un buen predictor. Este post se enfoca en el sistema alrededor del modelo—cómo hacer que ese predictor llegue a producción de manera confiable.\nLo que Géron enseña: Imputación de datos, feature engineering, selección de modelos, evaluación.\nLo que este post agrega: GCS para almacenamiento, W\u0026B para experimentación, MLflow para model registry, FastAPI para serving, Docker para deployment, GitHub Actions para CI/CD.\n2. Estructura del Proyecto: Arquitectura Que Escala El Árbol Completo (200+ Archivos) cap2-end_to_end/ ├── main.py # Orquestador Hydra + MLflow ├── config.yaml # Single source of truth ├── pyproject.toml # Dependencias con UV ├── Makefile # CLI para operaciones comunes ├── Dockerfile # Pipeline containerizado ├── docker-compose.yaml # API + Streamlit + MLflow ├── pytest.ini # Configuración de tests ├── .env.example # Template de secrets │ ├── src/ │ ├── data/ # Steps de procesamiento (01-04) │ │ ├── 01_download_data/ │ │ │ ├── main.py # Download desde URL → GCS │ │ │ ├── downloader.py # Lógica de descarga │ │ │ ├── models.py # Pydantic schemas │ │ │ ├── MLproject # Entry point MLflow │ │ │ └── conda.yaml # Dependencias aisladas │ │ │ │ │ ├── 02_preprocessing_and_imputation/ │ │ │ ├── main.py │ │ │ ├── preprocessor.py │ │ │ ├── imputation_analyzer.py # (crítico) Comparación de estrategias │ │ │ └── utils.py │ │ │ │ │ ├── 03_feature_engineering/ │ │ │ ├── main.py │ │ │ ├── feature_engineer.py # (crítico) KMeans clustering │ │ │ └── utils.py # Optimización n_clusters │ │ │ │ │ └── 04_segregation/ │ │ ├── main.py │ │ ├── segregator.py # Train/test split │ │ └── models.py │ │ │ ├── model/ # Steps de modelado (05-07) │ │ ├── 05_model_selection/ │ │ │ ├── main.py # Comparación de 5 algoritmos │ │ │ ├── model_selector.py # (crítico) GridSearch por modelo │ │ │ └── utils.py │ │ │ │ │ ├── 06_sweep/ │ │ │ ├── main.py # (crítico) W\u0026B Bayesian optimization │ │ │ ├── sweep_config.yaml # Espacio de búsqueda │ │ │ └── best_params.yaml # Output (generado) │ │ │ │ │ └── 07_registration/ │ │ ├── main.py # (crítico) Registro en MLflow │ │ └── configs/ │ │ └── model_config.yaml # Metadata (generado) │ │ │ └── utils/ │ └── colored_logger.py # Logging estructurado │ ├── api/ # FastAPI REST API │ ├── app/ │ │ ├── main.py # FastAPI + lifespan │ │ ├── core/ │ │ │ ├── config.py # Pydantic Settings │ │ │ ├── model_loader.py # Load desde MLflow/GCS/Local │ │ │ └── wandb_logger.py # Logging predicciones │ │ ├── models/ │ │ │ └── schemas.py # Request/Response schemas │ │ └── routers/ │ │ └── predict.py # POST /api/v1/predict │ ├── Dockerfile # Imagen del API (port 8080) │ └── requirements.txt │ ├── streamlit_app/ # Frontend interactivo │ ├── app.py # Aplicación Streamlit (450+ líneas) │ ├── Dockerfile # Imagen Streamlit (port 8501) │ └── requirements.txt │ ├── tests/ # Suite de tests │ ├── conftest.py # Fixtures compartidas │ ├── fixtures/ │ │ └── test_data_generator.py # Datos sintéticos │ ├── test_pipeline.py # Test de orquestación │ ├── test_downloader.py │ ├── test_preprocessor.py │ ├── test_imputation_analyzer.py # (crítico) Tests de imputación │ ├── test_feature_engineering.py │ ├── test_segregation.py │ └── test_integration_simple.py # End-to-end │ └── docs/ ├── API_ARCHITECTURE_POST.md ├── QUICKSTART_GUIDE.md └── TESTING_IMPROVEMENTS.md Los archivos marcados con (crítico) son los más críticos para entender la arquitectura.\nDecisiones Arquitectónicas Fundamentales 1. Separación src/data vs src/model Por qué: Los steps de datos (01-04) producen artifacts reutilizables—preprocesamiento, features, splits. Los steps de modelo (05-07) los consumen pero pueden reentrenarse sin reejecutar todo upstream.\nBeneficio: Si cambias hiperparámetros, reejecutas solo 06-07. Si cambias feature engineering, reejecutas 03-07. No re-descargas datos cada vez.\nCosto: Más verbosidad, más archivos. Pero en pipelines reales con múltiples data scientists, el aislamiento vale oro.\n2. MLproject + conda.yaml por Step Cada subdirectorio es un proyecto MLflow independiente:\n# src/data/02_preprocessing/MLproject name: preprocessing_and_imputation conda_env: conda.yaml entry_points: main: parameters: gcs_input_path: {type: string} gcs_output_path: {type: string} command: \"python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}\" Ventajas:\nDependencias aisladas (step 03 usa scikit-learn 1.3, step 06 podría usar 1.4) Ejecución independiente: mlflow run src/data/02_preprocessing Tracking granular: cada step es un run separado Desventaja: Overhead de archivos. Pero es el mismo overhead que tener microservicios—cada uno con su Dockerfile.\n3. api/ Como Proyecto Separado El API no está en src/api/. Es un proyecto hermano con su propio requirements.txt, Dockerfile y tests.\nRazón: El API se deploya independientemente del pipeline. No necesita pandas completo, scikit-learn full o W\u0026B client. Solo FastAPI, pydantic y el pickle del modelo.\nResultado: Imagen Docker de 200MB vs 1.5GB si incluyeras todo el pipeline.\n4. Tests en la Raíz Los tests prueban el sistema completo, no módulos aislados. test_integration_simple.py corre el pipeline end-to-end. No encaja conceptualmente en src/.\n5. Ausencia de notebooks/ Decisión deliberada. Los notebooks son excelentes para exploración, terribles para producción. Este proyecto prioriza reproducibilidad sobre iteración rápida.\nSi necesitas explorar, úsalos localmente pero no los comitees. Los notebooks en git son:\nDifíciles de revisar (diffs incomprensibles) Imposibles de testear Propensos a ejecutarse fuera de orden 3. Orquestación con Hydra + MLflow Por Qué No Scripts Bash Simples Ejecutar comandos Python secuenciales funciona para pipelines simples:\npython src/data/01_download_data/main.py python src/data/02_preprocessing/main.py python src/data/03_feature_engineering/main.py # ... Este enfoque falla cuando necesitas:\nEjecutar solo steps específicos (debugging) Cambiar parámetros sin editar código Versionar configuración junto al código Logs estructurados de qué corrió con qué params Rastrear dependencias entre steps Hydra + MLflow resuelve todos estos problemas.\nEl Orquestador: main.py \"\"\" MLOps Pipeline Orchestrator Ejecuta steps secuencialmente usando MLflow + Hydra \"\"\" import os import sys import mlflow import hydra from omegaconf import DictConfig from pathlib import Path import time def validate_environment_variables() -\u003e None: \"\"\"Fail fast si faltan secrets críticos.\"\"\" required_vars = { \"GCP_PROJECT_ID\": \"Google Cloud Project ID\", \"GCS_BUCKET_NAME\": \"GCS Bucket name\", \"WANDB_API_KEY\": \"Weights \u0026 Biases API Key\", } missing = [] for var, description in required_vars.items(): value = os.getenv(var) if not value or value in [\"your-project-id\", \"your-key\"]: missing.append(f\" ERROR: {var}: {description}\") if missing: print(\"\\n\" + \"=\"*70) print(\"ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES\") print(\"=\"*70) print(\"\\n\".join(missing)) print(\"\\nCreate .env file with:\") print(\" GCP_PROJECT_ID=your-project-id\") print(\" GCS_BUCKET_NAME=your-bucket\") print(\" WANDB_API_KEY=your-key\") sys.exit(1) def get_steps_to_execute(config: DictConfig) -\u003e list[str]: \"\"\"Convierte execute_steps de config a lista.\"\"\" steps = config['main']['execute_steps'] if isinstance(steps, str): return [s.strip() for s in steps.split(',')] return list(steps) def run_step(step_name: str, step_path: Path, entry_point: str, parameters: dict): \"\"\"Ejecuta un step como MLflow project.\"\"\" print(f\"\\n{'='*70}\") print(f\"EXECUTING: {step_name}\") print(f\"{'='*70}\") mlflow.run( uri=str(step_path), entry_point=entry_point, env_manager=\"local\", parameters=parameters ) @hydra.main(config_path='.', config_name=\"config\", version_base=\"1.3\") def go(config: DictConfig) -\u003e None: \"\"\"Entry point principal del pipeline.\"\"\" validate_environment_variables() mlflow.set_experiment(config['main']['experiment_name']) steps_to_execute = get_steps_to_execute(config) root_path = Path(__file__).parent start_time = time.time() try: # Step 01: Download Data if \"01_download_data\" in steps_to_execute: run_step( \"01 - Download Data\", root_path / \"src\" / \"data\" / \"01_download_data\", \"main\", { \"file_url\": config[\"download_data\"][\"file_url\"], \"gcs_output_path\": config[\"download_data\"][\"gcs_output_path\"], } ) # ... Steps 02-07 similar pattern ... elapsed = time.time() - start_time print(f\"\\nSUCCESS: PIPELINE COMPLETED ({elapsed:.1f}s)\") except Exception as e: print(f\"\\nERROR: PIPELINE FAILED: {e}\") raise if __name__ == \"__main__\": go() config.yaml: Single Source of Truth main: project_name: \"housing-mlops-gcp\" experiment_name: \"end_to_end_pipeline\" execute_steps: - \"01_download_data\" - \"02_preprocessing_and_imputation\" - \"03_feature_engineering\" - \"04_segregation\" - \"05_model_selection\" - \"06_sweep\" - \"07_registration\" download_data: file_url: \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\" gcs_output_path: \"data/01-raw/housing.parquet\" preprocessing: gcs_input_path: \"data/01-raw/housing.parquet\" gcs_output_path: \"data/02-processed/housing_processed.parquet\" imputation_strategy: \"auto\" # Comparará 4 estrategias feature_engineering: gcs_input_path: \"data/02-processed/housing_processed.parquet\" gcs_output_path: \"data/03-features/housing_features.parquet\" n_clusters: 10 optimize_hyperparams: true # Busca mejor K segregation: gcs_input_path: \"data/03-features/housing_features.parquet\" gcs_train_output_path: \"data/04-split/train/train.parquet\" gcs_test_output_path: \"data/04-split/test/test.parquet\" test_size: 0.2 target_column: \"median_house_value\" model_selection: gcs_train_path: \"data/04-split/train/train.parquet\" gcs_test_path: \"data/04-split/test/test.parquet\" sweep: sweep_count: 50 # 50 runs de Bayesian optimization metric_name: \"mape\" metric_goal: \"minimize\" registration: registered_model_name: \"housing_price_model\" model_stage: \"Staging\" # O \"Production\" Lo Que Este Código Hace Bien 1. Fail Fast con Validación de Environment\nAntes de gastar CPU, verifica que todas las secrets existen. El mensaje de error incluye instrucciones de cómo conseguir cada valor.\nERROR: MISSING REQUIRED ENVIRONMENT VARIABLES =============================================== ERROR: WANDB_API_KEY: Weights \u0026 Biases API Key Create .env file with: WANDB_API_KEY=your-key Esto ahorra frustración—especialmente para nuevos colaboradores.\n2. Ejecución Selectiva Sin Comentar Código\nCambias config.yaml:\nexecute_steps: [\"03_feature_engineering\", \"05_model_selection\"] Y solo esos steps corren. No editas Python, no comentas imports.\n3. Separación Entre Orchestration y Logic\nmain.py no sabe cómo descargar datos o entrenar modelos. Solo sabe cómo invocar scripts que lo hacen. Cada step puede desarrollarse/testearse independientemente.\n4. Logging Estructurado con Visual Hierarchy\nLos separadores (\"=\"*70) y emojis no son cosmética—en un pipeline que corre 2 horas, las secciones visuales permiten escanear rápido para encontrar qué step falló.\n4. Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos El Problema Real California Housing tiene ~1% de total_bedrooms faltantes. Opciones obvias:\nDrop rows → pierdes datos Fill con median → asumes distribución sin verificar Fill con KNN → asumes similitud en feature space Fill con IterativeImputer → asumes relaciones modelables Pregunta: ¿Cuál es mejor?\nRespuesta incorrecta: “KNN siempre funciona”\nRespuesta correcta: “Probé las 4, median tuvo RMSE de 0.8, KNN de 0.6, Iterative de 0.5. Uso Iterative porque minimiza error de reconstrucción. Aquí está el plot en W\u0026B.”\nimputation_analyzer.py: El Core \"\"\" Imputation Analyzer - Compara estrategias automáticamente Autor: Carlos Daniel Jiménez \"\"\" from dataclasses import dataclass from typing import Dict, Tuple import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer from sklearn.ensemble import RandomForestRegressor from sklearn.preprocessing import StandardScaler import matplotlib.pyplot as plt @dataclass class ImputationResult: \"\"\"Resultado de una estrategia de imputación.\"\"\" method_name: str rmse: float imputed_values: np.ndarray imputer: object class ImputationAnalyzer: \"\"\" Analiza y compara estrategias de imputación. Selecciona automáticamente la mejor basándose en RMSE. \"\"\" def __init__( self, df: pd.DataFrame, target_column: str = \"total_bedrooms\", test_size: float = 0.2, random_state: int = 42 ): self.df = df self.target_column = target_column self.test_size = test_size self.random_state = random_state self.results: Dict[str, ImputationResult] = {} self.best_method: str = None self.best_imputer: object = None def prepare_validation_set(self) -\u003e Tuple[pd.DataFrame, pd.DataFrame, pd.Series]: \"\"\" Crea validation set masked para comparar estrategias. Strategy: 1. Remove rows con target faltante (no podemos validar contra NaN) 2. Split en train/val 3. Maskear target en val set (simular missing values) 4. Guardar ground truth Returns: (train_set, val_set_missing, y_val_true) \"\"\" housing_numeric = self.df.select_dtypes(include=[np.number]) housing_known = housing_numeric.dropna(subset=[self.target_column]) train_set, val_set = train_test_split( housing_known, test_size=self.test_size, random_state=self.random_state ) # Maskear target en val val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan # Ground truth y_val_true = val_set[self.target_column].copy() return train_set, val_set_missing, y_val_true def evaluate_simple_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, strategy: str = \"median\" ) -\u003e ImputationResult: \"\"\"Evalúa SimpleImputer con strategy dada.\"\"\" imputer = SimpleImputer(strategy=strategy) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"Simple Imputer ({strategy})\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def evaluate_knn_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, n_neighbors: int = 5 ) -\u003e ImputationResult: \"\"\" Evalúa KNNImputer con scaling. CRÍTICO: KNN requiere features escaladas o explota con overflow. \"\"\" import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Scale data scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) val_scaled = scaler.transform(val_set_missing) # KNN imputation imputer = KNNImputer(n_neighbors=n_neighbors) imputer.fit(train_scaled) val_imputed_scaled = imputer.transform(val_scaled) # Inverse scale val_imputed = scaler.inverse_transform(val_imputed_scaled) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"KNN Imputer (k={n_neighbors})\", rmse=rmse, imputed_values=y_val_pred, imputer=(scaler, imputer) # Store tuple! ) def evaluate_iterative_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series ) -\u003e ImputationResult: \"\"\"Evalúa IterativeImputer con RandomForest estimator.\"\"\" estimator = RandomForestRegressor( n_jobs=-1, random_state=self.random_state ) imputer = IterativeImputer( estimator=estimator, random_state=self.random_state ) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=\"Iterative Imputer (RF)\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def compare_all_methods(self) -\u003e Dict[str, ImputationResult]: \"\"\"Compara todas las estrategias y selecciona la mejor.\"\"\" train_set, val_set_missing, y_val_true = self.prepare_validation_set() # Evaluar todos self.results['simple_median'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"median\" ) self.results['simple_mean'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"mean\" ) self.results['knn'] = self.evaluate_knn_imputer( train_set, val_set_missing, y_val_true, n_neighbors=5 ) self.results['iterative_rf'] = self.evaluate_iterative_imputer( train_set, val_set_missing, y_val_true ) # Seleccionar mejor best_key = min(self.results, key=lambda k: self.results[k].rmse) self.best_method = best_key self.best_imputer = self.results[best_key].imputer # Print summary print(\"\\n\" + \"=\"*70) print(\"IMPUTATION METHODS COMPARISON\") print(\"=\"*70) for key, result in sorted(self.results.items(), key=lambda x: x[1].rmse): status = \"[BEST]\" if key == best_key else \"\" print(f\" {result.method_name:30s} RMSE: {result.rmse:8.4f} {status}\") print(\"=\"*70) return self.results def apply_best_imputer(self, df: pd.DataFrame) -\u003e pd.DataFrame: \"\"\"Aplica el mejor imputer al dataset completo.\"\"\" if self.best_imputer is None: raise ValueError(\"Run compare_all_methods() first\") df_out = df.copy() numeric_df = df_out.select_dtypes(include=[np.number]) import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Check si es tuple (KNN con scaler) if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer numeric_scaled = scaler.transform(numeric_df) imputed_scaled = imputer.transform(numeric_scaled) imputed_array = scaler.inverse_transform(imputed_scaled) else: imputed_array = self.best_imputer.transform(numeric_df) target_col_idx = numeric_df.columns.get_loc(self.target_column) df_out[self.target_column] = imputed_array[:, target_col_idx] return df_out def create_comparison_plot(self) -\u003e plt.Figure: \"\"\"Crea bar plot comparando RMSE de métodos.\"\"\" methods = [r.method_name for r in self.results.values()] rmses = [r.rmse for r in self.results.values()] fig, ax = plt.subplots(figsize=(10, 6)) colors = ['green' if i == np.argmin(rmses) else 'skyblue' for i in range(len(rmses))] bars = ax.bar(methods, rmses, color=colors) ax.set_xlabel('Imputation Method', fontweight='bold') ax.set_ylabel('RMSE', fontweight='bold') ax.set_title('Comparison of Imputation Strategies', fontsize=14) ax.grid(axis='y', alpha=0.3) # Value labels for bar, rmse in zip(bars, rmses): height = bar.get_height() ax.text( bar.get_x() + bar.get_width()/2., height, f'{rmse:.4f}', ha='center', va='bottom' ) plt.xticks(rotation=45, ha='right') plt.tight_layout() return fig Decisiones Técnicas Críticas 1. La Métrica: RMSE de Reconstrucción ¿Por qué RMSE y no MAE?\nMAE trata todos los errores igual. RMSE penaliza errores grandes más fuertemente.\nSi un método imputa 100 bedrooms cuando la verdad es 3, eso es problemático. RMSE lo castiga más que MAE. En imputación, errores grandes distorsionan el dataset más que muchos errores pequeños.\n2. El Validation Set Masked train_set, val_set = train_test_split(housing_known, test_size=0.2) val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan y_val_true = val_set[self.target_column].copy() Este trick es crítico. No puedes evaluar imputation strategies en los missing values reales—no sabes la verdad. Entonces:\nTomas filas donde el target NO falta Splits en train/val Artificialmente maskeas el target en val Comparas qué tan bien cada imputer reconstruye los valores que conocías Es validación cruzada para preprocesamiento, no solo para modelos.\n3. Por Qué KNN Necesita Scaling scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) KNN calcula distancias euclidianas entre observaciones. Si una feature está en rango [0, 1] y otra en [0, 10000], la segunda domina completamente.\nStandardScaler normaliza todo a media 0, std 1. Ahora todas las features contribuyen equitativamente.\nIterativeImputer con RandomForest NO necesita scaling—los árboles son invariantes a escala.\n4. El Imputer Como Tuple if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer # ... apply both Si KNN ganó, necesitas guardar tanto el scaler como el imputer. En producción, cuando llegan datos nuevos:\nEscalar con el mismo scaler fitted en training Aplicar KNN imputer Inverse transform para volver a escala original Guardar solo el imputer sin el scaler rompería todo.\nUso en el Pipeline # En main.py del Step 02 import wandb import mlflow analyzer = ImputationAnalyzer(df, target_column=\"total_bedrooms\") results = analyzer.compare_all_methods() # Log a W\u0026B comparison_plot = analyzer.create_comparison_plot() wandb.log({ \"imputation/comparison\": wandb.Image(comparison_plot), \"imputation/best_method\": analyzer.best_method, \"imputation/best_rmse\": results[analyzer.best_method].rmse, }) # Aplicar al dataset completo housing_clean = analyzer.apply_best_imputer(housing_df) # Guardar imputer import joblib joblib.dump(analyzer.best_imputer, \"artifacts/imputer.pkl\") mlflow.log_artifact(\"artifacts/imputer.pkl\") Lo Que Esto Logra Sin esto: “Usé median porque es lo que hace todo el mundo.”\nCon esto: “Comparé 4 estrategias. IterativeImputer con RandomForest tuvo 15% menor RMSE que median. Aquí está el plot en W\u0026B dashboard run abc123. El imputer está serializado en MLflow.”\nAhora tienes evidencia cuantificable de por qué elegiste lo que elegiste. Seis meses después, cuando alguien pregunta, los datos están ahí.\n5. Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering El Problema Real California tiene patrones geográficos fuertes. Casas en San Francisco se comportan diferente que casas en el valle central. Pero latitude/longitude como features crudas no capturan esto bien—un modelo lineal no puede aprender “esta área es cara”.\nSolución: Clustering geográfico. Pero no para segmentar datos, sino para crear una feature categórica: cluster_label.\nClusterSimilarity: Custom Transformer from sklearn.base import BaseEstimator, TransformerMixin from sklearn.cluster import KMeans import numpy as np class ClusterSimilarity(BaseEstimator, TransformerMixin): \"\"\" Custom transformer para clustering geográfico. Design: Transformer de scikit-learn para integrarse en Pipeline. \"\"\" def __init__(self, n_clusters=10, gamma=1.0, random_state=None): self.n_clusters = n_clusters self.gamma = gamma # Placeholder para RBF kernel (no usado actualmente) self.random_state = random_state def fit(self, X, y=None, sample_weight=None): \"\"\"Fit KMeans en coordenadas geográficas.\"\"\" self.kmeans_ = KMeans( self.n_clusters, n_init=10, random_state=self.random_state ) self.kmeans_.fit(X, sample_weight=sample_weight) return self def transform(self, X): \"\"\"Transforma coordenadas a cluster labels.\"\"\" cluster_labels = self.kmeans_.predict(X) return np.expand_dims(cluster_labels, axis=1) def get_feature_names_out(self, names=None): \"\"\"Retorna nombres de features para Pipeline.\"\"\" return [\"cluster_label\"] El Pipeline de Preprocessing Completo from sklearn.pipeline import Pipeline from sklearn.compose import ColumnTransformer from sklearn.impute import SimpleImputer from sklearn.preprocessing import OneHotEncoder, StandardScaler def create_preprocessing_pipeline(n_clusters=10): \"\"\" Crea pipeline que procesa: - Numéricas: impute + scale - Categóricas: impute + one-hot - Geo: clustering \"\"\" num_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"median\")), (\"standardize\", StandardScaler()), ]) cat_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")), ]) num_attribs = [ \"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\" ] cat_attribs = [\"ocean_proximity\"] preprocessing = ColumnTransformer([ (\"num\", num_pipeline, num_attribs), (\"cat\", cat_pipeline, cat_attribs), (\"geo\", ClusterSimilarity(n_clusters=n_clusters), [\"latitude\", \"longitude\"]), ]) return preprocessing Optimización Automática de n_clusters from sklearn.metrics import silhouette_score, davies_bouldin_score def optimize_n_clusters( df: pd.DataFrame, min_clusters=2, max_clusters=20 ) -\u003e Tuple[int, Dict]: \"\"\" Busca el mejor K para KMeans usando silhouette score. Métricas: - Silhouette score (0 a 1): Separación de clusters. Maximizar. - Davies-Bouldin index: Dispersión interna vs separación. Minimizar. \"\"\" geo_features = df[[\"latitude\", \"longitude\"]].values cluster_range = range(min_clusters, max_clusters + 1) silhouette_scores = [] davies_bouldin_scores = [] inertias = [] for n in cluster_range: kmeans = KMeans(n_clusters=n, n_init=10, random_state=42) labels = kmeans.fit_predict(geo_features) silhouette_scores.append(silhouette_score(geo_features, labels)) davies_bouldin_scores.append(davies_bouldin_score(geo_features, labels)) inertias.append(kmeans.inertia_) # Seleccionar K con mejor silhouette optimal_n = cluster_range[np.argmax(silhouette_scores)] metrics = { \"optimal_n_clusters\": optimal_n, \"best_silhouette\": max(silhouette_scores), \"cluster_range\": list(cluster_range), \"silhouette_scores\": silhouette_scores, \"davies_bouldin_scores\": davies_bouldin_scores, \"inertias\": inertias, } return optimal_n, metrics Visualización: Elbow Method + Silhouette def create_optimization_plots(metrics: Dict) -\u003e Dict[str, plt.Figure]: \"\"\"Crea plots de optimización de K.\"\"\" # Plot 1: Elbow Method (Inertia) fig1, ax1 = plt.subplots(figsize=(10, 6)) ax1.plot(metrics[\"cluster_range\"], metrics[\"inertias\"], 'bo-') ax1.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--', label=f'Optimal K={metrics[\"optimal_n_clusters\"]}' ) ax1.set_xlabel('Number of Clusters (K)') ax1.set_ylabel('Inertia') ax1.set_title('Elbow Method - KMeans Optimization') ax1.legend() ax1.grid(True) # Plot 2: Silhouette Score fig2, ax2 = plt.subplots(figsize=(10, 6)) ax2.plot(metrics[\"cluster_range\"], metrics[\"silhouette_scores\"], 'go-') ax2.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--' ) ax2.set_xlabel('Number of Clusters (K)') ax2.set_ylabel('Silhouette Score') ax2.set_title('Silhouette Score vs K') ax2.grid(True) return {\"elbow_method\": fig1, \"silhouette_scores\": fig2} Uso en el Pipeline # En main.py del Step 03 import wandb import mlflow import joblib # Descargar datos desde GCS df = download_from_gcs(bucket, \"data/02-processed/housing_processed.parquet\") # Optimizar K optimal_k, metrics = optimize_n_clusters(df, min_clusters=5, max_clusters=15) print(f\"Optimal K: {optimal_k}\") print(f\" Silhouette: {metrics['best_silhouette']:.4f}\") # Crear plots plots = create_optimization_plots(metrics) # Log a W\u0026B wandb.log({ \"optimization/optimal_k\": optimal_k, \"optimization/silhouette\": metrics[\"best_silhouette\"], \"optimization/elbow_plot\": wandb.Image(plots[\"elbow_method\"]), \"optimization/silhouette_plot\": wandb.Image(plots[\"silhouette_scores\"]), }) # Crear pipeline con K óptimo preprocessing_pipeline = create_preprocessing_pipeline(n_clusters=optimal_k) # Fit pipeline target_column = \"median_house_value\" y = df[target_column] X = df.drop(columns=[target_column]) preprocessing_pipeline.fit(X, y) # Transform data X_transformed = preprocessing_pipeline.transform(X) # Reconstruir DataFrame con target df_transformed = pd.DataFrame( X_transformed, columns=preprocessing_pipeline.get_feature_names_out() ) df_transformed[target_column] = y.values # Upload a GCS upload_to_gcs(df_transformed, bucket, \"data/03-features/housing_features.parquet\") # Guardar pipeline joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") mlflow.log_artifact(\"artifacts/preprocessing_pipeline.pkl\") Decisiones Técnicas Críticas 1. Por Qué Silhouette Score Silhouette score (rango 0 a 1) mide qué tan bien separados están los clusters:\n1.0: Clusters perfectamente separados 0.5: Overlap moderado 0.0: Clusters aleatorios Es interpretable y generalmente correlaciona bien con calidad visual de clusters.\nDavies-Bouldin index: También lo calculamos pero no lo usamos para decisión—es más sensible a outliers.\n2. La Crítica Obvia Este código optimiza n_clusters basándose en métricas de clustering, no en performance del modelo final.\nUn approach más riguroso sería:\nfor k in range(5, 15): pipeline = create_preprocessing_pipeline(n_clusters=k) X_train_transformed = pipeline.fit_transform(X_train, y_train) X_test_transformed = pipeline.transform(X_test) model = RandomForestRegressor() model.fit(X_train_transformed, y_train) mape = calculate_mape(model, X_test_transformed, y_test) # Seleccionar K con mejor MAPE Esto tomaría 10x más tiempo pero sería más riguroso.\nTrade-off: Este pipeline prioriza velocidad sobre rigor absoluto. Para California Housing, silhouette score es suficientemente bueno. Para datasets más complejos, considera el approach de cross-validation completo.\n3. handle_unknown=“ignore” en OneHotEncoder OneHotEncoder(handle_unknown=\"ignore\") Crítico para producción. Si en training tienes categorías [\"\u003c1H OCEAN\", \"INLAND\", \"NEAR BAY\"] pero en producción llega \"ISLAND\" (que no viste), el encoder:\nSin handle_unknown: Explota con ValueError Con handle_unknown=\"ignore\": Genera vector de ceros para esa observación Pierdes información de esa observación, pero el API no devuelve HTTP 500.\n4. Por Qué Guardar el Pipeline, No Solo el Modelo joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") En producción, necesitas:\nCargar el pipeline Transform datos nuevos Predecir con el modelo Si solo guardas el modelo, no sabes:\nQué features espera En qué orden Qué transformaciones aplicar El pipeline encapsula todo eso.\nLo Que Esto Logra Sin esto: “Usé KMeans con K=10 porque leí que 10 clusters es bueno.”\nCon esto: “Probé K de 5 a 15. K=8 maximizó silhouette score (0.64). Aquí están los plots de elbow method y silhouette. El pipeline con K=8 está serializado en MLflow.”\nEvidencia cuantificable + artifact reproducible.\n6. Step 06: Hyperparameter Sweep - Optimización Bayesiana con W\u0026B El Problema de Model Selection vs Hyperparameter Tuning La mayoría de los proyectos de ML cometen este error: entrenan un Random Forest en un notebook, ajustan algunos hiperparámetros hasta que R² se ve “bien” y declaran victoria. Tres meses después, cuando alguien pregunta “¿por qué Random Forest y no XGBoost?”, la respuesta es silencio incómodo.\nEste pipeline separa dos fases:\nModel Selection (Step 05): Compara algoritmos con GridSearch rápido (5-10 combos por modelo) Hyperparameter Sweep (Step 06): Optimiza el ganador con Bayesian search exhaustivo (50+ runs) Razón: No tienes tiempo ni cómputo para hacer sweep exhaustivo de 5 algoritmos. Primero decides estrategia (qué algoritmo), luego tácticas (qué hiperparámetros).\nsweep_config.yaml: El Espacio de Búsqueda # ================================================================= # W\u0026B Sweep Configuration for Random Forest # Autor: Carlos Daniel Jiménez # ================================================================= program: main.py method: bayes # Bayesian optimization, no random, no grid metric: name: wmape # Weighted MAPE (menos sesgado que MAPE) goal: minimize parameters: n_estimators: min: 50 max: 500 max_depth: min: 5 max: 30 min_samples_split: min: 2 max: 20 min_samples_leaf: min: 1 max: 10 max_features: values: ['sqrt', 'log2'] # Early stopping: elimina runs pobres temprano early_terminate: type: hyperband min_iter: 10 # Mínimo 10 runs antes de terminar eta: 3 # Elimina 1/3 de runs pobres s: 2 name: housing-rf-sweep-improved description: \"Optimize Random Forest with wmape + feature tracking\" main.py del Step 06: El Sweep Real \"\"\" W\u0026B Sweep for Random Forest Hyperparameter Optimization. Autor: Carlos Daniel Jiménez \"\"\" import argparse import yaml import wandb import logging from pathlib import Path from utils import ( download_data_from_gcs, prepare_data, train_random_forest, evaluate_model, log_feature_importances ) logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) # Module-level data cache (cargado una vez, reusado en todos los runs) _data_cache = { \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None, \"feature_names\": None } def train(): \"\"\" Training function llamada por W\u0026B Sweep agent. Ejecutada para cada combinación de hiperparámetros. Usa module-level cache para evitar recargar datos en cada run. \"\"\" run = wandb.init() config = wandb.config logger.info(\"=\"*70) logger.info(f\"SWEEP RUN: {run.name}\") logger.info(\"=\"*70) try: # Preparar parámetros params = { 'n_estimators': int(config.n_estimators), 'max_depth': int(config.max_depth) if config.max_depth else None, 'min_samples_split': int(config.min_samples_split), 'min_samples_leaf': int(config.min_samples_leaf), 'max_features': config.max_features, 'random_state': 42 } # Train model usando cached data model = train_random_forest( _data_cache[\"X_train\"], _data_cache[\"y_train\"], params ) # Evaluate model metrics = evaluate_model( model, _data_cache[\"X_test\"], _data_cache[\"y_test\"] ) # Log feature importances feature_importances = log_feature_importances( model, _data_cache[\"feature_names\"] ) # Log todo a W\u0026B wandb.log({ **params, **metrics, **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) logger.info(f\"SUCCESS: MAPE={metrics['mape']:.2f}% | \" f\"WMAPE={metrics['wmape']:.2f}%\") except Exception as e: logger.error(f\"ERROR: Run failed: {str(e)}\") wandb.log({ \"error\": str(e), \"mape\": 999.9, \"wmape\": 999.9 }) raise finally: run.finish() def main(): \"\"\"Main function para inicializar y ejecutar el sweep.\"\"\" parser = argparse.ArgumentParser() parser.add_argument(\"--gcs_train_path\", type=str, required=True) parser.add_argument(\"--gcs_test_path\", type=str, required=True) parser.add_argument(\"--bucket_name\", type=str, required=True) parser.add_argument(\"--wandb_project\", type=str, required=True) parser.add_argument(\"--target_column\", type=str, default=\"median_house_value\") parser.add_argument(\"--sweep_count\", type=int, default=50) parser.add_argument(\"--sweep_config\", type=str, default=\"sweep_config.yaml\") args = parser.parse_args() logger.info(\"=\"*70) logger.info(\"W\u0026B SWEEP - HYPERPARAMETER OPTIMIZATION\") logger.info(\"=\"*70) # Cargar datos UNA VEZ en module-level cache logger.info(\"\\nLoading data into cache...\") train_df = download_data_from_gcs(args.bucket_name, args.gcs_train_path) X_train, y_train = prepare_data(train_df, args.target_column) test_df = download_data_from_gcs(args.bucket_name, args.gcs_test_path) X_test, y_test = prepare_data(test_df, args.target_column) # Store in cache _data_cache[\"X_train\"] = X_train _data_cache[\"X_test\"] = X_test _data_cache[\"y_train\"] = y_train _data_cache[\"y_test\"] = y_test _data_cache[\"feature_names\"] = X_train.columns.tolist() logger.info(f\"Data cached: Train {X_train.shape}, Test {X_test.shape}\") # Load sweep configuration sweep_config_path = Path(__file__).parent / args.sweep_config with open(sweep_config_path, 'r') as f: sweep_config = yaml.safe_load(f) logger.info(f\"\\nSweep config:\") logger.info(f\" Method: {sweep_config['method']}\") logger.info(f\" Metric: {sweep_config['metric']['name']} ({sweep_config['metric']['goal']})\") # Initialize sweep sweep_id = wandb.sweep( sweep=sweep_config, project=args.wandb_project ) logger.info(f\"\\nSweep created: {sweep_id}\") logger.info(f\" View at: https://wandb.ai/{args.wandb_project}/sweeps/{sweep_id}\") # Run sweep agent logger.info(f\"\\nStarting sweep agent ({args.sweep_count} runs)...\") wandb.agent( sweep_id, function=train, count=args.sweep_count, project=args.wandb_project ) logger.info(\"\\n\" + \"=\"*70) logger.info(\"SWEEP COMPLETED\") logger.info(\"=\"*70) # Guardar best params api = wandb.Api() sweep = api.sweep(f\"{args.wandb_project}/{sweep_id}\") best_run = sweep.best_run() best_params = { \"hyperparameters\": { \"n_estimators\": int(best_run.config.get('n_estimators')), \"max_depth\": int(best_run.config.get('max_depth')) if best_run.config.get('max_depth') else None, \"min_samples_split\": int(best_run.config.get('min_samples_split')), \"min_samples_leaf\": int(best_run.config.get('min_samples_leaf')), \"max_features\": best_run.config.get('max_features'), }, \"metrics\": { \"mape\": float(best_run.summary.get('mape')), \"wmape\": float(best_run.summary.get('wmape')), \"r2\": float(best_run.summary.get('r2')), }, \"sweep_id\": sweep_id, \"best_run_id\": best_run.id } # Guardar a YAML best_params_path = Path(__file__).parent / \"best_params.yaml\" with open(best_params_path, 'w') as f: yaml.dump(best_params, f) logger.info(f\"\\nBest params saved to: {best_params_path}\") logger.info(f\" MAPE: {best_params['metrics']['mape']:.2f}%\") if __name__ == \"__main__\": main() Decisiones Técnicas Críticas 1. Bayesian Optimization, No Random Search method: bayes # No random, no grid Random search: Prueba combinaciones aleatorias. No aprende de runs anteriores.\nGrid search: Prueba todas las combinaciones. Exhaustivo pero carísimo (5 × 4 × 3 × 3 × 2 = 360 combos).\nBayesian optimization: Construye un modelo probabilístico de la función que optimizas (MAPE en función de hiperparámetros) y usa ese modelo para decidir qué probar siguiente.\nSi detecta que max_depth=None consistentemente da mejor MAPE, explora más en esa región del espacio.\n50 runs es \u003c15% del espacio total, pero capturan el 80% del beneficio posible.\n2. wMAPE, No MAPE metric: name: wmape # Weighted MAPE MAPE estándar: Penaliza errores en casas baratas más que en casas caras.\nSi una casa vale $10,000 y predices $12,000, error = 20%. Si una casa vale $500,000 y predices $510,000, error = 2%.\nAmbos errores son $10,000, pero MAPE los ve radicalmente diferentes.\nwMAPE (Weighted MAPE): Pondera por el valor real. Menos sesgado hacia valores bajos.\nPor qué funciona aquí: California Housing no tiene casas de $0. Rango está entre $15k y $500k—razonablemente acotado.\n3. Variables Globales Para Data Cache _data_cache = { \"X_train\": None, \"X_test\": None, # ... } Las variables globales son generalmente código sucio. Aquí son la decisión correcta.\nCada run del sweep necesita los mismos datos. Sin cache, cargarías desde GCS 50 veces. Con California Housing (20k filas), eso son segundos desperdiciados. Con datasets más grandes, son minutos u horas.\nAlternativa “limpia”: Pasar datos como argumento a cada función. Pero W\u0026B Sweeps tiene interfaz fija—la función que pasas a wandb.agent() no puede recibir argumentos adicionales.\nLas variables globales aquí tienen scope limitado—solo existen durante el proceso del sweep.\n4. Early Stopping con Hyperband early_terminate: type: hyperband min_iter: 10 eta: 3 Hyperband elimina runs pobres temprano. Si después de 10 runs un set de hiperparámetros muestra MAPE de 25% mientras otros están en 8%, Hyperband lo detiene.\neta=3: Elimina el peor tercio de runs en cada iteración.\nBeneficio: Ahorras cómputo en hiperparámetros obviamente malos.\n5. Feature Importances Loggeadas feature_importances = log_feature_importances(model, feature_names) wandb.log({ **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) Random Forest calcula feature importances gratis. Sería valioso loggearlo para entender qué features dominan el modelo.\nEn W\u0026B dashboard, puedes comparar runs y ver “en el mejor run, median_income tuvo importance de 0.45”.\nEl Output Crítico: best_params.yaml hyperparameters: n_estimators: 200 max_depth: 20 min_samples_split: 2 min_samples_leaf: 1 max_features: sqrt metrics: mape: 7.82 wmape: 7.65 r2: 0.87 sweep_id: abc123xyz best_run_id: run_456 Los hiperparámetros óptimos se guardan en YAML, not pickle. Razón:\nYAML es legible y git-friendly. Si en el próximo retraining cambias de n_estimators=200 a n_estimators=300, un git diff lo muestra claramente.\nCon pickle, es un blob binario opaco.\nLo Que Esto Logra Sin esto: “Usé n_estimators=100 porque es el default de scikit-learn.”\nCon esto: “Corrí sweep bayesiano de 50 runs. Optimal config: n_estimators=200, max_depth=20. MAPE mejoró de 8.5% a 7.8%. Aquí está el sweep en W\u0026B: wandb.ai/project/sweeps/abc123.”\nEvidencia cuantificable de por qué elegiste cada hiperparámetro.\n7. Step 07: Model Registry - Versionamiento en MLflow Por Qué No Basta con Guardar el Pickle La tentación es:\nimport joblib joblib.dump(model, \"best_model.pkl\") Esto funciona hasta que necesitas responder:\n¿Qué hiperparámetros usó? ¿Con qué datos se entrenó? ¿Qué métricas logró? ¿Cómo rollback a la versión anterior? MLflow Model Registry resuelve esto.\nregister_model_to_mlflow(): El Core \"\"\" Registro de modelo en MLflow Model Registry. Autor: Carlos Daniel Jiménez \"\"\" import mlflow import mlflow.sklearn from mlflow.tracking import MlflowClient def register_model_to_mlflow( model, model_name: str, model_stage: str, params: dict, metrics: dict, feature_columns: list, target_column: str, gcs_train_path: str, gcs_test_path: str ) -\u003e tuple: \"\"\" Registra modelo en MLflow Model Registry con metadata rica. Args: model: Trained sklearn model model_name: Nombre para registered model model_stage: Stage (Staging/Production) params: Hyperparameters metrics: Métricas de evaluación feature_columns: Lista de features target_column: Target column name gcs_train_path: Path a training data gcs_test_path: Path a test data Returns: (model_uri, model_version, run_id) \"\"\" logger.info(\"=\"*70) logger.info(\"REGISTERING MODEL TO MLFLOW\") logger.info(\"=\"*70) client = MlflowClient() run_id = mlflow.active_run().info.run_id model_uri = f\"runs:/{run_id}/model\" # Log model to MLflow mlflow.sklearn.log_model(model, \"model\") logger.info(f\"Model logged: {model_uri}\") # Create or get registered model try: client.create_registered_model( name=model_name, description=\"Housing price prediction - Random Forest\" ) logger.info(f\"Created new registered model: {model_name}\") except Exception as e: if \"already exists\" in str(e): logger.info(f\"Model already exists: {model_name}\") else: raise # Create model version model_version = client.create_model_version( name=model_name, source=model_uri, run_id=run_id ) logger.info(f\"Version created: {model_version.version}\") # Transition to stage client.transition_model_version_stage( name=model_name, version=model_version.version, stage=model_stage # \"Staging\" or \"Production\" ) logger.info(f\"Transitioned to: {model_stage}\") # Create comprehensive description (MARKDOWN) description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest Regressor ## Hyperparameters - n_estimators: {params['n_estimators']} - max_depth: {params.get('max_depth', 'None')} - min_samples_split: {params['min_samples_split']} - min_samples_leaf: {params['min_samples_leaf']} - max_features: {params.get('max_features', 'sqrt')} ## Performance Metrics - MAPE: {metrics['mape']:.2f}% - Median APE: {metrics['median_ape']:.2f}% - Within 10%: {metrics['within_10pct']:.1f}% - RMSE: {metrics['rmse']:.2f} - R²: {metrics['r2']:.4f} ## Features - Number of features: {len(feature_columns)} - Target: {target_column} ## Data Sources - Training: {gcs_train_path} - Testing: {gcs_test_path} \"\"\" client.update_model_version( name=model_name, version=model_version.version, description=description ) # Add searchable tags tags = { \"algorithm\": \"RandomForest\", \"framework\": \"sklearn\", \"mape\": f\"{metrics['mape']:.2f}\", \"within_10pct\": f\"{metrics['within_10pct']:.1f}\", \"rmse\": f\"{metrics['rmse']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", \"n_features\": str(len(feature_columns)), \"target\": target_column, } for key, value in tags.items(): client.set_model_version_tag( model_name, model_version.version, key, value ) logger.info(\"Tags added to model version\") logger.info(\"=\"*70) return model_uri, model_version.version, run_id Decisiones Técnicas Críticas 1. Artifact vs Registered Model Artifact: Pickle guardado en un run específico. Para usarlo, necesitas el run_id.\nmlflow.sklearn.log_model(model, \"model\") # Solo artifact # Uso: mlflow.sklearn.load_model(f\"runs://{run_id}/model\") Registered Model: Versionado con nombre semántico, stages y metadata.\nclient.create_model_version(name=\"housing_price_model\", source=model_uri) # Uso: mlflow.pyfunc.load_model(\"models:/housing_price_model/Production\") En producción, tu API carga models:/housing_price_model/Production, no runs:/abc123/model.\nCuando registras una nueva versión, la transicionas a Production y el deployment automáticamente toma la nueva versión.\n2. Metadata Rica en Markdown description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest ## Hyperparameters - n_estimators: {params['n_estimators']} ... ## Performance Metrics - MAPE: {metrics['mape']:.2f}% ... \"\"\" Esto guarda markdown en la descripción del modelo. Cuando abres MLflow UI y navegas a housing_price_model v3, ves:\nQué hiperparámetros usó Qué métricas logró De dónde vinieron los datos Por qué es oro: Seis meses después, cuando alguien pregunta “¿por qué el modelo v3 tiene mejor MAPE que v2?”, abres MLflow y la respuesta está ahí.\nNo necesitas buscar en logs ni preguntar a quien lo entrenó.\n3. Tags Para Búsqueda tags = { \"algorithm\": \"RandomForest\", \"mape\": f\"{metrics['mape']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", } for key, value in tags.items(): client.set_model_version_tag(model_name, model_version.version, key, value) En MLflow puedes filtrar modelos por tags. “Muéstrame todos los modelos con MAPE \u003c 8%” es una query que funciona si taggeaste consistentemente.\n4. Model Config File: Single Source of Truth model_config = { 'model': { 'name': model_name, 'version': str(model_version), 'stage': model_stage, 'parameters': params, 'metrics': metrics, 'feature_columns': feature_columns, 'mlflow_run_id': run_id, 'sweep_id': sweep_id } } config_path = Path(\"configs/model_config.yaml\") with open(config_path, 'w') as f: yaml.dump(model_config, f) mlflow.log_artifact(str(config_path), artifact_path=\"config\") Este YAML se loggea a MLflow Y se guarda en el repo (en configs/model_config.yaml).\nPor qué YAML y no solo MLflow: Tu FastAPI app necesita leer configuración al iniciar. Puede hacer mlflow.load_model() para el pickle, pero necesita saber los feature names para validación de input.\nEl YAML es esa single source of truth.\n5. Versionado en Git Cuando commiteas model_config.yaml, el diff muestra:\n- version: 2 + version: 3 - mape: 8.5 + mape: 7.8 - n_estimators: 100 + n_estimators: 200 Es auditable. Sabes exactamente qué cambió entre versiones.\nEl Flujo Completo: Sweep → Registration → Production # 1. Model Selection (Step 05) python src/model/05_model_selection/main.py # Output: \"Best: RandomForestRegressor (MAPE: 8.2%)\" # 2. Hyperparameter Sweep (Step 06) python src/model/06_sweep/main.py --sweep_count=50 # Output: best_params.yaml con hiperparámetros óptimos # 3. Model Registration (Step 07) python src/model/07_registration/main.py --params_file=best_params.yaml # Output: Modelo registrado en MLflow Registry # 4. Transition to Production (manual) mlflow models transition \\ --name housing_price_model \\ --version 3 \\ --stage Production Lo Que Este Approach Soluciona Sin Model Registry:\nPickles en carpetas: model_v3_final_FINAL_2.pkl No sabes qué hiperparámetros usa cada uno Rollback = buscar el pickle correcto en GCS Con Model Registry:\nModelos con versiones semánticas: v1, v2, v3 Metadata embebida: params, metrics, data sources Rollback = transition v3 to Archived + transition v2 to Production 8. CI/CD con GitHub Actions: Automatización del Pipeline Completo Por Qué CI/CD Es Crítico en MLOps Como MLOps engineer, uno de los mayores puntos de fricción es el deployment manual. Has entrenado un modelo excelente en tu laptop, pero llevarlo a producción requiere:\nSSH a un servidor Copiar archivos manualmente Instalar dependencias Cruzar los dedos Debuggear cuando algo explota GitHub Actions elimina esto. Cada commit dispara un pipeline automatizado que:\nEjecuta tests Valida que el código cumple estándares Entrena el modelo (opcional, en pipelines simples) Construye imágenes Docker Deploya a Cloud Run/ECS/Kubernetes La Arquitectura de CI/CD Para Este Proyecto Este proyecto implementa dos workflows separados:\n1. PR Validation Workflow Trigger: Cada pull request a main\nPropósito: Asegurar que el código es production-ready antes de mergear\n# .github/workflows/pr_validation.yaml name: PR Validation - Tests \u0026 Linting on: pull_request: branches: [main, master] paths: - 'src/**' - 'api/**' - 'tests/**' - 'pyproject.toml' - 'requirements.txt' jobs: lint: name: Lint Code runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Set up Python 3.12 uses: actions/setup-python@v5 with: python-version: '3.12' - name: Install uv run: pip install uv - name: Install dependencies run: | uv venv uv pip install -e . uv pip install ruff pytest pytest-cov - name: Run Ruff linter run: | source .venv/bin/activate ruff check src/ tests/ api/ - name: Run Ruff formatter check run: | source .venv/bin/activate ruff format --check src/ tests/ api/ unit-tests: name: Unit Tests runs-on: ubuntu-latest env: GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }} GCS_BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME }} WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }} steps: - uses: actions/checkout@v4 - name: Set up Python 3.12 uses: actions/setup-python@v5 with: python-version: '3.12' - name: Install dependencies run: | pip install uv uv venv uv pip install -e . uv pip install pytest pytest-cov pytest-mock - name: Run unit tests with coverage run: | source .venv/bin/activate pytest tests/ -v \\ --cov=src \\ --cov=api/app \\ --cov-report=xml \\ --cov-report=term-missing \\ --cov-fail-under=70 - name: Upload coverage to Codecov uses: codecov/codecov-action@v4 with: file: ./coverage.xml flags: unittests name: codecov-umbrella integration-tests: name: Integration Tests (Pipeline E2E) runs-on: ubuntu-latest env: GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }} GCS_BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME }} WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }} MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }} steps: - uses: actions/checkout@v4 - name: Set up Python 3.12 uses: actions/setup-python@v5 with: python-version: '3.12' - name: Authenticate to Google Cloud uses: google-github-actions/auth@v2 with: credentials_json: ${{ secrets.GCP_SA_KEY }} - name: Install dependencies run: | pip install uv uv venv uv pip install -e . - name: Run integration test (Steps 01-04) run: | source .venv/bin/activate python main.py main.execute_steps=[01_download_data,02_preprocessing_and_imputation,03_feature_engineering,04_segregation] timeout-minutes: 30 - name: Verify artifacts were created run: | gsutil ls gs://${{ secrets.GCS_BUCKET_NAME }}/data/04-split/train/train.parquet gsutil ls gs://${{ secrets.GCS_BUCKET_NAME }}/data/04-split/test/test.parquet Valor para el MLOps engineer:\nPreviene merges rotos: Si los tests fallan, el PR no puede mergearse Estándares de código: Ruff garantiza consistencia (importa cuando tienes 5+ contributors) Coverage tracking: Codecov muestra qué porcentaje del código está cubierto por tests Fast feedback: Sabes en 5 minutos si tu cambio rompió algo, no 3 horas después 2. Deployment Workflow Trigger: Push a main (después de merge de PR)\nPropósito: Construir y deployar el API a producción\n# .github/workflows/deploy_api.yaml name: Deploy API to Cloud Run on: push: branches: [main] paths: - 'api/**' - 'models/**' - '.github/workflows/deploy_api.yaml' env: PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }} SERVICE_NAME: housing-price-api REGION: us-central1 jobs: build-and-deploy: name: Build Docker Image \u0026 Deploy runs-on: ubuntu-latest permissions: contents: read id-token: write steps: - name: Checkout code uses: actions/checkout@v4 - name: Authenticate to Google Cloud uses: google-github-actions/auth@v2 with: workload_identity_provider: ${{ secrets.WIF_PROVIDER }} service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }} - name: Set up Cloud SDK uses: google-github-actions/setup-gcloud@v2 - name: Configure Docker for GCR run: gcloud auth configure-docker gcr.io - name: Download trained model from GCS run: | mkdir -p api/models/trained gsutil cp gs://${{ secrets.GCS_BUCKET_NAME }}/models/trained/housing_price_model.pkl \\ api/models/trained/housing_price_model.pkl - name: Build Docker image run: | cd api docker build \\ --tag gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \\ --tag gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:latest \\ . - name: Push Docker image to GCR run: | docker push gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} docker push gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:latest - name: Deploy to Cloud Run run: | gcloud run deploy ${{ env.SERVICE_NAME }} \\ --image gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \\ --platform managed \\ --region ${{ env.REGION }} \\ --allow-unauthenticated \\ --set-env-vars=\"GCS_BUCKET=${{ secrets.GCS_BUCKET_NAME }},WANDB_API_KEY=${{ secrets.WANDB_API_KEY }}\" \\ --memory 2Gi \\ --cpu 2 \\ --max-instances 10 \\ --min-instances 1 \\ --timeout 300 - name: Get Cloud Run URL id: deploy-url run: | URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \\ --platform managed \\ --region ${{ env.REGION }} \\ --format 'value(status.url)') echo \"url=$URL\" \u003e\u003e $GITHUB_OUTPUT - name: Run smoke test run: | curl -X POST \"${{ steps.deploy-url.outputs.url }}/api/v1/predict\" \\ -H \"Content-Type: application/json\" \\ -d '{\"instances\":[{\"longitude\":-122.23,\"latitude\":37.88,\"housing_median_age\":41,\"total_rooms\":880,\"total_bedrooms\":129,\"population\":322,\"households\":126,\"median_income\":8.3252,\"ocean_proximity\":\"NEAR BAY\"}]}' - name: Notify deployment success if: success() run: | echo \"Deployment successful! API available at: ${{ steps.deploy-url.outputs.url }}\" Valor para el MLOps engineer:\nZero-downtime deployment: Cloud Run hace rolling updates automáticamente Rollback fácil: Si algo explota, haces gcloud run services update-traffic --to-revisions=PREVIOUS=100 Smoke test automático: Verifica que el API responde después del deploy Versionado de imágenes: Cada commit tiene su propia imagen Docker taggeada con SHA Secretos y Seguridad CRÍTICO: Nunca commitees secrets al repo. GitHub Actions usa GitHub Secrets para guardar:\nGCP_PROJECT_ID: ID del proyecto de GCP GCS_BUCKET_NAME: Nombre del bucket de GCS WANDB_API_KEY: API key de W\u0026B GCP_SA_KEY: Service account key (JSON) para autenticar en GCP WIF_PROVIDER / WIF_SERVICE_ACCOUNT: Workload Identity Federation (más seguro que SA keys) Configuración en GitHub:\nVe a repo → Settings → Secrets and variables → Actions Crea cada secret Los workflows acceden con ${{ secrets.SECRET_NAME }} Monitoreo de Deployments ¿Cómo saber si un deployment falló?\nGitHub Actions envía notificaciones a:\nEmail (configurado en GitHub profile) Slack (con GitHub app) Discord/Teams (con webhooks) Post-deployment monitoring:\n# Agregar step de validación post-deploy - name: Run API health check run: | for i in {1..5}; do STATUS=$(curl -s -o /dev/null -w \"%{http_code}\" \"${{ steps.deploy-url.outputs.url }}/health\") if [ $STATUS -eq 200 ]; then echo \"Health check passed\" exit 0 fi echo \"Attempt $i failed, retrying...\" sleep 10 done echo \"Health check failed after 5 attempts\" exit 1 Estrategias Avanzadas de CI/CD 1. Pipeline de Reentrenamiento Automático Trigger: Cron schedule (ejemplo: semanalmente)\non: schedule: - cron: '0 2 * * 0' # Cada domingo a las 2 AM UTC jobs: retrain-model: runs-on: ubuntu-latest steps: - name: Run full pipeline run: python main.py - name: Compare metrics with production model run: | NEW_MAPE=$(python scripts/get_latest_mape.py) PROD_MAPE=$(python scripts/get_production_mape.py) if (( $(echo \"$NEW_MAPE \u003c $PROD_MAPE\" | bc -l) )); then echo \"New model is better, promoting to Production\" mlflow models transition --name housing_price_model --version latest --stage Production else echo \"New model is worse, keeping current Production model\" fi Valor: El modelo se reentrena automáticamente con datos nuevos. Si mejora, se promociona a Production. Si empeora, se descarta.\n2. Canary Deployments Problema: Un nuevo modelo puede tener bugs sutiles que no aparecen en tests.\nSolución: Deployar el nuevo modelo a solo 10% del tráfico, monitorear por 1 hora, luego migrar 100% si no hay errores.\n- name: Deploy canary (10% traffic) run: | gcloud run services update-traffic ${{ env.SERVICE_NAME }} \\ --to-revisions=LATEST=10,PREVIOUS=90 - name: Wait and monitor run: sleep 3600 # 1 hora - name: Check error rate run: | ERROR_RATE=$(python scripts/check_error_rate.py --minutes=60) if (( $(echo \"$ERROR_RATE \u003e 0.05\" | bc -l) )); then echo \"Error rate too high, rolling back\" gcloud run services update-traffic ${{ env.SERVICE_NAME }} --to-revisions=PREVIOUS=100 exit 1 fi - name: Promote to 100% traffic run: | gcloud run services update-traffic ${{ env.SERVICE_NAME }} --to-revisions=LATEST=100 Lo Que CI/CD Resuelve en MLOps Sin CI/CD:\nDeployment manual propenso a errores “Funciona en mi máquina” syndrome Testing inconsistente Rollback requiere pánico debugging No hay historial de qué se deployó cuándo Con CI/CD:\nDeployment automático en cada merge Tests garantizan que el código funciona Rollback es un comando Historial completo en GitHub Actions UI Cada deployment es reproducible El Valor Real Para el MLOps Engineer No es sobre automatizar por automatizar. Es sobre:\nReducir toil: Gastas tiempo resolviendo problemas interesantes, no copiando archivos manualmente Confianza: Sabes que el código funciona antes de llegar a producción Velocidad: De commit a producción en \u003c10 minutos Auditoría: Cada cambio está loggeado en GitHub Colaboración: Tu equipo puede deployar sin depender de ti Un MLOps engineer sin CI/CD es como un software engineer sin git—técnicamente posible, pero fundamentalmente broken.\n9. El Valor de MLOps: Por Qué Esto Importa La Pregunta Central “¿Por qué debería invertir tiempo en todo esto cuando puedo entrenar un modelo en un notebook en 30 minutos?”\nEsta es la pregunta que todo MLOps engineer ha escuchado. La respuesta corta: porque el notebook no escala.\nLa respuesta larga es lo que cubre esta sección.\nEl Problema Real: Research Code vs Production Code Research Code (Notebook) # notebook.ipynb # Cell 1 import pandas as pd df = pd.read_csv('housing.csv') # Cell 2 df = df.dropna() # Cell 3 from sklearn.ensemble import RandomForestRegressor model = RandomForestRegressor(n_estimators=100) model.fit(X_train, y_train) # Cell 4 import pickle pickle.dump(model, open('model.pkl', 'wb')) # Cell 5 # Wait, did I drop the right columns? # Let me rerun cell 2... oh no, I ran it twice # Now I have 0 rows, what happened? Problemas:\nNo reproducible (orden de ejecución importa) No testeable No versionable (git diffs son ilegibles) No escalable (qué pasa con 100GB de datos?) No auditable (qué params usaste?) Production Code (Este Pipeline) # src/model/05_model_selection/main.py @hydra.main(config_path=\".\", config_name=\"config\") def train(config: DictConfig) -\u003e None: \"\"\"Entrenar modelo con configuración versionada.\"\"\" # Cargar datos desde GCS (single source of truth) df = load_from_gcs(config.gcs_train_path) # Aplicar preprocessing pipeline serializado pipeline = joblib.load('artifacts/preprocessing_pipeline.pkl') X = pipeline.transform(df) # Entrenar con params de config model = RandomForestRegressor(**config.hyperparameters) model.fit(X, y) # Loggear a MLflow mlflow.log_params(config.hyperparameters) mlflow.log_metrics(evaluate(model, X_test, y_test)) mlflow.sklearn.log_model(model, \"model\") return model Beneficios:\nReproducible (mismo config = mismo output) Testeable (funciones puras, mocking) Versionable (git diff legible) Escalable (corre en local o en cluster) Auditable (MLflow tracking) Valor #1: Modularización de Código Por Qué Importa Escenario: Tu modelo tiene bug en preprocessing. En notebook, el preprocessing está mezclado con feature engineering, entrenamiento y evaluación en 300 líneas.\nEn este pipeline:\n# Bug está en preprocessing → solo editas src/data/02_preprocessing/ # Tests fallan → pytest tests/test_preprocessor.py # Fixeas → reejecutas solo step 02-07, no 01 Tiempo ahorrado: Horas por bug.\nSeparation of Concerns Este pipeline separa:\nData steps (01-04): Producen artifacts reutilizables Model steps (05-07): Consumen artifacts, producen modelos API: Consume modelos, produce predicciones Frontend: Consume API, produce UX Beneficio: Equipos pueden trabajar en paralelo. El data scientist modifica feature engineering sin tocar el API. El frontend engineer modifica UI sin entender Random Forests.\nValor #2: Working with Artifacts El Problema: “¿Dónde está el model_final_v3.pkl?” Sin artifact management:\nmodels/ ├── model_v1.pkl ├── model_v2.pkl ├── model_final.pkl ├── model_final_FINAL.pkl ├── model_final_REAL.pkl ├── model_production_2024_01_15.pkl # ¿Este es el de producción? └── model_old_backup.pkl # ¿Puedo borrarlo? Problemas:\nNo sabes qué hiperparámetros usa cada uno No sabes qué métricas logró No sabes con qué datos se entrenó Rollback = buscar el archivo correcto La Solución: Artifact Storage + Metadata 1. Google Cloud Storage para datos:\ngs://bucket-name/ ├── data/ │ ├── 01-raw/housing.parquet # Inmutable │ ├── 02-processed/housing_processed.parquet # Versionado por fecha │ ├── 03-features/housing_features.parquet │ └── 04-split/ │ ├── train/train.parquet │ └── test/test.parquet ├── artifacts/ │ ├── imputer.pkl # Preprocessing artifacts │ ├── preprocessing_pipeline.pkl │ └── scaler.pkl └── models/ └── trained/housing_price_model.pkl # Latest trained Beneficios:\nInmutabilidad: 01-raw/ nunca cambia, siempre puedes reejecutar el pipeline Versionamiento: Cada run tiene timestamp, puedes comparar versiones Compartir: Todo el equipo accede a los mismos datos, no “enviame el CSV por Slack” 2. MLflow para modelos:\n# Registrar modelo mlflow.sklearn.log_model(model, \"model\") # MLflow guarda automáticamente: # - El pickle del modelo # - Los hiperparámetros (n_estimators=200, max_depth=20) # - Las métricas (MAPE=7.8%, R²=0.87) # - Metadata (fecha, duración, usuario) # - Código (git commit SHA) # Cargar modelo en producción model = mlflow.pyfunc.load_model(\"models:/housing_price_model/Production\") Beneficios:\nVersionamiento semántico: v1, v2, v3 con stages (Staging/Production) Metadata rica: Sabes exactamente qué es cada versión Rollback trivial: transition v2 to Production Comparación: MLflow UI muestra tabla comparando todas las versiones 3. W\u0026B para experimentos:\n# Cada run de sweep loggea: wandb.log({ \"hyperparameters/n_estimators\": 200, \"hyperparameters/max_depth\": 20, \"metrics/mape\": 7.8, \"metrics/r2\": 0.87, \"plots/feature_importances\": wandb.Image(fig), \"dataset/train_size\": 16512, }) # W\u0026B dashboard: # - Tabla con 50 runs de sweep # - Filtrar por MAPE \u003c 8% # - Parallel coordinates plot mostrando relación entre hiperparámetros y MAPE # - Comparar top 5 runs side-by-side Beneficios:\nVisualización: Plots interactivos de cómo cada hiperparámetro afecta métricas Colaboración: Tu equipo ve tus experimentos en real-time Reproducibilidad: Cada run tiene link permanente con todo el contexto Valor #3: Pipeline Architecture Por Qué Un Pipeline, No Un Script Script único (run_all.py):\n# run_all.py (500 líneas) def main(): # Download data df = download_data() # Preprocess df = preprocess(df) # Feature engineering df = add_features(df) # Train model model = train_model(df) # Deploy deploy_model(model) Problemas:\nSi falla en train_model(), reejecutas TODO (incluyendo download lento) No puedes ejecutar solo feature engineering para experimentar Cambiar preprocessing requiere reentrenar todo No hay checkpoints intermedios Pipeline modular:\n# Ejecutar todo make run-pipeline # Ejecutar solo preprocessing make run-preprocessing # Ejecutar desde feature engineering en adelante python main.py main.execute_steps=[03_feature_engineering,04_segregation,05_model_selection] # Debugging: ejecutar solo step que falló python src/data/03_feature_engineering/main.py --debug Beneficios:\nEjecución selectiva: Solo reejecutas lo que cambió Debugging rápido: Testeas un step aislado Paralelización: Steps independientes pueden correr en paralelo Checkpointing: Si falla step 05, steps 01-04 ya están hechos El Contrato Entre Steps Cada step:\nInput: Path a artifact en GCS (ejemplo: data/02-processed/housing_processed.parquet) Output: Path a nuevo artifact en GCS (ejemplo: data/03-features/housing_features.parquet) Side effects: Logs a MLflow/W\u0026B # Step 03: Feature Engineering def run(config): # Input df = load_from_gcs(config.gcs_input_path) # Transform df_transformed = apply_feature_engineering(df) # Output save_to_gcs(df_transformed, config.gcs_output_path) # Side effects mlflow.log_artifact(\"preprocessing_pipeline.pkl\") wandb.log({\"optimization/optimal_k\": 8}) Este contrato permite que cada step sea:\nTesteado independientemente Desarrollado por diferentes personas Reemplazado sin afectar otros steps Valor #4: Production-Ready vs Research Code Checklist de Production-Ready Feature Research Code Este Pipeline Versionamiento Git (mal, notebooks) Git + GCS + MLflow Testing Manual (“lo corrí una vez”) pytest + CI Configuración Hardcoded YAML versionado Secretos Expuestos en código .env + GitHub Secrets Logs print() statements Logging estructurado Monitoring “Espero que funcione” W\u0026B + MLflow tracking Deployment Manual CI/CD automático Rollback Panic debugging Transition en MLflow Documentación README desactualizado Código autodocumentado + Markdown en MLflow Colaboración “Ejecuta estas 10 celdas en orden” make run-pipeline El Costo Real de No Hacer MLOps Escenario: Un modelo en producción tiene bug que causa predicciones incorrectas.\nSin MLOps (Research Code):\nDetectar el bug: Usuario reporta → 2 horas Reproducir el bug: Buscar qué código/datos se usaron → 4 horas Fixear: Correr notebook localmente → 1 hora Deployar: SSH, copiar pickle, restart server → 30 min Verificar: Correr tests manuales → 1 hora Total: 8.5 horas de downtime Con MLOps (Este Pipeline):\nDetectar el bug: Monitoring automático alerta → 5 min Rollback: transition v3 to Archived + transition v2 to Production → 2 min Fix: Identificar issue con MLflow metadata, fixear código → 1 hora Deployar: Push to GitHub → CI/CD automático → 10 min Verificar: Smoke tests automáticos pasan → 1 min Total: 1 hora 18 min de downtime (\u003e85% reducción) Ahorro anualizado: Si esto pasa 4 veces al año, ahorras 29 horas de tiempo de ingeniero.\nValor #5: Decisiones Respaldadas por Datos El Anti-Pattern “Usé Random Forest con n_estimators=100 porque eso es lo que hace todo el mundo.”\nProblema: No tienes evidencia de que es la mejor opción.\nEste Pipeline Cada decisión tiene métricas cuantificables:\n1. Imputación:\nComparó 4 estrategias (Simple median, Simple mean, KNN, IterativeImputer) IterativeImputer ganó con RMSE=0.52 (vs 0.78 de median) Plot de comparación en W\u0026B: wandb.ai/project/run/imputation_comparison 2. Feature Engineering:\nOptimizó K de 5 a 15 K=8 maximizó silhouette score (0.64) Plot de elbow method en W\u0026B 3. Hyperparameter Tuning:\nSweep bayesiano de 50 runs Optimal config: n_estimators=200, max_depth=20 MAPE mejoró de 8.5% a 7.8% Link a sweep: wandb.ai/project/sweeps/abc123 Beneficio: Seis meses después, cuando el stakeholder pregunta “¿por qué usamos este modelo?”, abres W\u0026B/MLflow y la respuesta está ahí con plots y métricas.\nEl ROI de MLOps Inversión inicial:\nSetup de GCS, MLflow, W\u0026B, CI/CD: 2-3 días Refactoring de código a pipeline modular: 1-2 semanas Retorno:\nDeployment time: 8 horas → 10 minutos (48x más rápido) Debugging time: 4 horas → 30 min (8x más rápido) Onboarding nuevos engineers: 1 semana → 1 día Confianza del equipo: “Espero que funcione” → “Sé que funciona” Para un equipo de 5 personas, el breakeven es ~1 mes.\nLa Lección Final Para MLOps Engineers No es sobre las herramientas. Puedes reemplazar:\nGCS → S3 → Azure Blob MLflow → Neptune → Comet W\u0026B → TensorBoard → MLflow GitHub Actions → GitLab CI → Jenkins Es sobre los principios:\nModularización: Código en módulos testeables, no notebooks monolíticos Artifact Management: Datos y modelos versionados, no model_final_v3.pkl Automatización: CI/CD elimina toil Observabilidad: Logs, métricas, tracking Reproducibilidad: Mismo input → mismo output Decisiones data-driven: Cada elección respaldada por métricas Cuando entiendes esto, eres un MLOps engineer. Cuando lo implementas, eres un buen MLOps engineer.\n9.5. W\u0026B vs MLflow: Por Qué Ambos, No Uno u Otro La Pregunta Incómoda “¿Por qué tienes Weights \u0026 Biases Y MLflow? ¿No son lo mismo?”\nEsta pregunta revela un malentendido fundamental sobre lo que hace cada herramienta. No son competidores—son aliados con responsabilidades diferentes. Entender esto separa un data scientist que experimenta de un MLOps engineer que construye sistemas.\nLa respuesta corta: W\u0026B es tu laboratorio de investigación. MLflow es tu cadena de producción.\nLa respuesta larga es lo que cubre esta sección, con ejemplos del código real de este proyecto.\nEl Problema Real: Experimentación vs Governance Fase 1: Experimentación (50-100 runs/día) Cuando estás en fase de experimentación:\nCorres 50 sweep runs probando combinaciones de hiperparámetros Necesitas ver en tiempo real cómo evoluciona cada run Quieres comparar visualmente 20 runs simultáneos Necesitas ver plots de convergencia, distribuciones de features, confusion matrices El overhead de logging debe ser mínimo (logging asíncrono) Herramienta correcta: Weights \u0026 Biases\nFase 2: Governance y Deployment (1-2 modelos/semana) Cuando subes un modelo a producción:\nNecesitas versionamiento semántico (v1, v2, v3) Necesitas stages (Staging → Production) Necesitas metadata rica (¿qué hiperparámetros? ¿qué datos? ¿qué commit?) Necesitas un API para cargar modelos (models:/housing_price_model/Production) Necesitas rollback trivial (transition v2 to Production) Herramienta correcta: MLflow Model Registry\nLa verdad incómoda: Ninguna herramienta hace bien ambas cosas.\nCómo Este Proyecto Usa W\u0026B 1. Hyperparameter Sweep (Step 06): Bayesian Optimization # src/model/06_sweep/main.py # Configuración del sweep (Bayesian optimization) sweep_config = { \"method\": \"bayes\", # Bayesian \u003e Grid \u003e Random \"metric\": { \"name\": \"wmape\", \"goal\": \"minimize\" }, \"early_terminate\": { \"type\": \"hyperband\", \"min_iter\": 3 }, \"parameters\": { \"n_estimators\": {\"min\": 50, \"max\": 300}, \"max_depth\": {\"min\": 5, \"max\": 30}, \"min_samples_split\": {\"min\": 2, \"max\": 20}, \"min_samples_leaf\": {\"min\": 1, \"max\": 10} } } # Inicializar sweep sweep_id = wandb.sweep(sweep=sweep_config, project=\"housing-mlops-gcp\") # Función de training que W\u0026B llama 50 veces def train(): run = wandb.init() # W\u0026B asigna hiperparámetros automáticamente # Obtener hiperparámetros sugeridos por Bayesian optimizer config = wandb.config # Entrenar modelo model = RandomForestRegressor( n_estimators=config.n_estimators, max_depth=config.max_depth, # ... ) model.fit(X_train, y_train) # Evaluar metrics = evaluate_model(model, X_test, y_test) # Log a W\u0026B (asíncrono, no bloquea) wandb.log({ \"hyperparameters/n_estimators\": config.n_estimators, \"hyperparameters/max_depth\": config.max_depth, \"metrics/mape\": metrics['mape'], \"metrics/wmape\": metrics['wmape'], # Optimizer usa esto \"metrics/r2\": metrics['r2'], \"plots/feature_importances\": wandb.Image(fig), }) run.finish() # Ejecutar 50 runs con Bayesian optimization wandb.agent(sweep_id, function=train, count=50) Lo que W\u0026B hace aquí que MLflow no puede:\nBayesian Optimization: W\u0026B sugiere los próximos hiperparámetros basándose en runs previos. No es random—usa Gaussian Processes para explorar el espacio eficientemente.\nRun 1: n_estimators=100, max_depth=15 → wMAPE=8.5% Run 2: n_estimators=200, max_depth=20 → wMAPE=7.9% # Mejor Run 3: n_estimators=250, max_depth=22 → wMAPE=7.8% # W\u0026B sugiere valores cercanos a Run 2 Early Termination (Hyperband): Si un run va mal en las primeras 3 iteraciones (epochs), W\u0026B lo mata automáticamente y prueba otros hiperparámetros. Ahorra ~40% de compute.\n\"early_terminate\": { \"type\": \"hyperband\", \"min_iter\": 3 # Mínimo 3 iteraciones antes de terminar } Parallel Coordinates Plot: Visualización interactiva mostrando qué combinación de hiperparámetros produce mejor wMAPE.\nInterpretación: Las líneas azules (runs con wMAPE bajo) convergen en n_estimators=200-250 y max_depth=20-25. Esto te dice visualmente dónde está el óptimo.\nLogging Asíncrono: wandb.log() no bloquea. Mientras el modelo entrena, W\u0026B sube métricas en background. Total overhead: \u003c1% del training time.\nMLflow no tiene:\nBayesian optimization (solo Grid/Random search vía scikit-learn) Early termination inteligente Parallel coordinates plots Logging asíncrono (mlflow.log es síncrono) 2. Real-Time Monitoring: Ver Runs Mientras Corren # En W\u0026B dashboard (web UI): # - Ver 50 runs simultáneos en tabla interactiva # - Filtrar por \"wmape \u003c 8.0%\" → muestra solo 12 runs # - Comparar top 5 runs side-by-side # - Ver plots de convergencia (MAPE vs iteration) Caso de uso real: Inicias un sweep de 50 runs a las 9 AM. A las 10 AM, desde tu laptop en la cafetería:\nAbres W\u0026B dashboard Ves que 30 runs ya terminaron Filtras por wmape \u003c 8.0% → 8 runs cumplen Comparas esos 8 runs → identificas que max_depth=20 aparece en todos Decisión: Cancelas el sweep, ajustas el range de max_depth a [18, 25], reinicias Valor: Retroalimentación inmediata sin SSH al server, sin leer logs en terminal. La experimentación es interactiva, no batch.\n3. Artifact Tracking Ligero (Referencias a GCS) # src/model/05_model_selection/main.py # Upload modelo a GCS model_gcs_uri = upload_model_to_gcs(model, \"models/05-selection/randomforest_best.pkl\") # gs://bucket/models/05-selection/randomforest_best.pkl # Log referencia en W\u0026B (NO sube el pickle, solo el URI) artifact = wandb.Artifact( name=\"best_model_selection\", type=\"model\", description=\"Best model selected: RandomForest\" ) artifact.add_reference(model_gcs_uri, name=\"best_model.pkl\") # Solo el URI run.log_artifact(artifact) W\u0026B no almacena el modelo—solo guarda el URI gs://.... El modelo vive en GCS.\nVentaja: No pagas doble storage (GCS + W\u0026B). W\u0026B es el índice, GCS es el almacén.\nCómo Este Proyecto Usa MLflow 1. Model Registry (Step 07): Versionamiento y Stages # src/model/07_registration/main.py with mlflow.start_run(run_name=\"model_registration\"): # Log modelo mlflow.sklearn.log_model(model, \"model\") # Log params y métricas mlflow.log_params({ \"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 2 }) mlflow.log_metrics({ \"mape\": 7.82, \"r2\": 0.8654 }) # Registrar en Model Registry client = MlflowClient() # Crear modelo registrado (si no existe) client.create_registered_model( name=\"housing_price_model\", description=\"Housing price prediction - Random Forest\" ) # Crear nueva versión model_version = client.create_model_version( name=\"housing_price_model\", source=f\"runs:/{run_id}/model\", run_id=run_id ) # Resultado: housing_price_model/v3 # Transicionar a stage client.transition_model_version_stage( name=\"housing_price_model\", version=model_version.version, stage=\"Staging\" # Staging → Production cuando se valide ) Lo que MLflow hace aquí que W\u0026B no puede:\nVersionamiento Semántico: Cada modelo es housing_price_model/v1, v2, v3. No son IDs aleatorios—son versiones incrementales.\nStages: Un modelo pasa por None → Staging → Production → Archived. Este lifecycle es explícito.\nv1: Production (actual en el API) v2: Staging (validándose) v3: None (recién entrenado) v4: Archived (deprecado) Model-as-Code API: Cargar modelo en el API es trivial:\n# api/app/core/model_loader.py model = mlflow.pyfunc.load_model(\"models:/housing_price_model/Production\") No necesitas saber:\nDónde está el pickle físicamente Qué versión es (MLflow resuelve “Production” → v1) Cómo deserializarlo (mlflow.pyfunc abstrae esto) Rollback en 10 Segundos:\n# Problema: v3 en Production tiene bug # Rollback a v2: mlflow models transition \\ --name housing_price_model \\ --version 2 \\ --stage Production # El API detecta el cambio y recarga v2 automáticamente Metadata Rica con Tags y Description:\n# Agregar tags searchables client.set_model_version_tag( \"housing_price_model\", version, \"training_date\", \"2026-01-13\" ) client.set_model_version_tag( \"housing_price_model\", version, \"sweep_id\", \"abc123xyz\" # Link al W\u0026B sweep ) # Description en Markdown client.update_model_version( name=\"housing_price_model\", version=version, description=\"\"\" # Housing Price Model v3 **Trained:** 2026-01-13 **Algorithm:** Random Forest **Metrics:** MAPE=7.8%, R²=0.865 **Sweep:** [W\u0026B Link](https://wandb.ai/project/sweeps/abc123) \"\"\" ) Resultado: 6 meses después, cuando un stakeholder pregunta “¿qué modelo está en Production?”, abres MLflow UI y toda la info está ahí—no en un Slack thread perdido.\nW\u0026B no tiene:\nModel Registry (solo artifact tracking básico) Stages (Staging/Production) API de carga (models:/name/stage) Transition history (quién cambió v2 a Production, cuándo, por qué) 2. Pipeline Orchestration (main.py) # main.py @hydra.main(config_path=\".\", config_name=\"config\") def go(config: DictConfig) -\u003e None: # MLflow orquesta steps como sub-runs # Step 01: Download mlflow.run( uri=\"src/data/01_download_data\", entry_point=\"main\", parameters={ \"file_url\": config.download_data.file_url, \"gcs_output_path\": config.download_data.gcs_output_path, # ... } ) # Step 02: Preprocessing mlflow.run( uri=\"src/data/02_preprocessing_and_imputation\", entry_point=\"main\", parameters={ \"gcs_input_path\": config.preprocessing.gcs_input_path, # ... } ) # ... Steps 03-07 MLflow crea un run jerárquico:\nParent Run: end_to_end_pipeline ├── Child Run: 01_download_data │ ├── params: file_url, gcs_output_path │ └── artifacts: housing.parquet ├── Child Run: 02_preprocessing_and_imputation │ ├── params: imputation_strategy │ └── artifacts: imputer.pkl, housing_processed.parquet ├── Child Run: 03_feature_engineering │ └── ... └── Child Run: 07_registration └── artifacts: model.pkl, model_config.yaml Valor: En MLflow UI, ves toda la ejecución del pipeline como un árbol. Cada step es auditable—qué params usó, cuánto tardó, qué artifacts produjo.\nW\u0026B no tiene orquestación de pipelines—solo tracking de runs individuales.\nLa División del Trabajo en Este Proyecto Responsabilidad W\u0026B MLflow Razón Bayesian hyperparameter optimization ✓ ✗ W\u0026B tiene sweep inteligente, MLflow solo Grid/Random Real-time dashboards ✓ ✗ W\u0026B UI es interactivo, MLflow UI es estático Parallel coordinates plots ✓ ✗ W\u0026B tiene visualizaciones avanzadas Early termination (Hyperband) ✓ ✗ W\u0026B implementa Hyperband/ASHA/Median stopping Model Registry con stages ✗ ✓ MLflow tiene Staging/Production, W\u0026B no Model-as-code API ✗ ✓ mlflow.pyfunc.load_model() es el estándar Rollback de modelos ✗ ✓ MLflow transition, W\u0026B no tiene concepto de stages Pipeline orchestration ✗ ✓ mlflow.run() ejecuta steps anidados Artifact storage (físico) ✗ ✗ Ambos apuntan a GCS, no duplican storage Logging asíncrono ✓ ✗ W\u0026B no bloquea training, MLflow sí Metadata searchable ✓ ✓ Ambos permiten tags/búsqueda, implementaciones diferentes El Flujo Completo: W\u0026B → MLflow Día 1-3: Experimentación (W\u0026B)\n# Ejecutar sweep de 50 runs make run-sweep # W\u0026B dashboard muestra: # - 50 runs en tabla # - Parallel coordinates plot # - Best run: n_estimators=200, max_depth=20, wMAPE=7.8% # - Sweep ID: abc123xyz Output: src/model/06_sweep/best_params.yaml\nhyperparameters: n_estimators: 200 max_depth: 20 min_samples_split: 2 min_samples_leaf: 1 metrics: mape: 7.82 wmape: 7.76 r2: 0.8654 sweep_id: abc123xyz # Link a W\u0026B best_run_id: def456ghi Día 4: Registration (MLflow)\n# Step 07 lee best_params.yaml python main.py main.execute_steps=[07_registration] # MLflow: # 1. Entrena modelo con best_params # 2. Registra como housing_price_model/v3 # 3. Transiciona a Staging # 4. Guarda metadata (incluyendo sweep_id) Día 5-7: Validación en Staging\n# API corre con modelo en Staging docker run -p 8080:8080 \\ -e MLFLOW_MODEL_NAME=housing_price_model \\ -e MLFLOW_MODEL_STAGE=Staging \\ housing-api:latest # Correr tests, validar métricas, revisar predicciones Día 8: Promoción a Production\nmlflow models transition \\ --name housing_price_model \\ --version 3 \\ --stage Production # API en producción auto-recarga v3 # v2 queda como fallback (stage: Archived) Si algo falla:\n# Rollback en 10 segundos mlflow models transition \\ --name housing_price_model \\ --version 2 \\ --stage Production Por Qué Ambos, Definitivamente Pregunta: “¿Puedo usar solo W\u0026B?”\nRespuesta: Puedes, pero pierdes:\nModel Registry (versionamiento, stages, rollback) API estándar para cargar modelos en producción Pipeline orchestration con runs jerárquicos Resultado: Terminas construyendo tu propio sistema de versionamiento de modelos con scripts custom—reinventando la rueda mal.\nPregunta: “¿Puedo usar solo MLflow?”\nRespuesta: Puedes, pero pierdes:\nBayesian optimization (tendrás que hacer Grid Search lento) Visualizaciones interactivas (parallel coordinates, real-time dashboards) Early termination inteligente (desperdicias compute) Resultado: Tus sweeps toman 3x más tiempo, y no tienes feedback visual de qué funciona.\nEl Costo Real W\u0026B:\nFree tier: 100GB storage, colaboradores ilimitados Team tier: $50/usuario/mes (para equipos \u003e5 personas) MLflow:\nOpen source, gratis Costo: Hosting del tracking server (Cloud Run: ~$20/mes para uso moderado) Storage: GCS (ya lo pagas para datos) Total para equipo de 5: ~$20-50/mes (si usas W\u0026B free tier) o ~$270/mes (si usas W\u0026B Team).\nROI: Si un sweep más eficiente ahorra 30 minutos de compute/día:\nCompute ahorrado: ~15 horas/mes En GCP: 15 horas × $2/hora (GPU) = $30/mes ahorrado solo en compute Más el tiempo de ingeniero (más valioso) Breakeven en \u003c1 mes.\nLa Lección Para MLOps Engineers No elijas herramientas por hype o popularidad. Elige por responsabilidades claras:\nExperimentación rápida e interactiva: W\u0026B, Neptune, Comet Governance y deployment: MLflow, Seldon, BentoML Artifact storage: GCS, S3, Azure Blob (no herramientas de tracking) Este proyecto usa:\nW\u0026B: Porque necesita sweep Bayesiano eficiente MLflow: Porque necesita Model Registry production-ready GCS: Porque necesita storage de alta disponibilidad No hay redundancia—hay especialización.\nCuando entiendes esto, dejas de preguntar “¿W\u0026B o MLflow?” y empiezas a preguntar “¿qué problema estoy resolviendo?”\nEsa es la diferencia entre usar herramientas y construir sistemas.\n10. Docker y MLflow: Containerización del Ecosistema Completo La Arquitectura de Tres Containers Este proyecto utiliza tres Dockerfiles distintos, cada uno optimizado para su propósito específico:\nPipeline Container (Dockerfile): Ejecuta el pipeline completo de entrenamiento con MLflow tracking API Container (api/Dockerfile): Sirve predicciones con FastAPI en producción Streamlit Container (streamlit_app/Dockerfile): Proporciona interfaz web interactiva Esta separación no es accidental—es una decisión arquitectónica que refleja los diferentes requisitos de cada componente. 1. Pipeline Container: Entrenamiento con MLflow Tracking Dockerfile del Pipeline # ================================================================= # Dockerfile for MLOps Pipeline Execution # Purpose: Run the complete training pipeline in containerized environment # ================================================================= FROM python:3.12-slim LABEL maintainer=\"danieljimenez88m@gmail.com\" LABEL description=\"Housing Price Prediction - MLOps Pipeline\" # Set working directory WORKDIR /app # Install system dependencies RUN apt-get update \u0026\u0026 apt-get install -y \\ gcc \\ g++ \\ git \\ curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* # Copy requirements first for better caching COPY pyproject.toml ./ COPY requirements.txt* ./ # Install Python dependencies RUN pip install --no-cache-dir --upgrade pip \u0026\u0026 \\ pip install --no-cache-dir uv \u0026\u0026 \\ uv pip install --system -e . # Copy application code COPY . . # Set environment variables ENV PYTHONUNBUFFERED=1 ENV PYTHONDONTWRITEBYTECODE=1 # Create necessary directories RUN mkdir -p mlruns outputs models # Default command runs the pipeline CMD [\"python\", \"main.py\"] Decisiones Técnicas Críticas 1. Por Qué gcc y g++\nRUN apt-get install -y gcc g++ git curl Muchos paquetes de ML (numpy, scipy, scikit-learn) compilan extensiones C/C++ durante la instalación. Sin estos compiladores, pip install falla con errores crípticos como “error: command ‘gcc’ failed”.\nTrade-off: Imagen más grande (~500MB vs ~150MB de Python slim puro), pero garantiza que todas las dependencias se instalan correctamente.\n2. Layer Caching Strategy\n# Copy requirements first for better caching COPY pyproject.toml ./ COPY requirements.txt* ./ RUN pip install ... # Copy application code AFTER COPY . . Docker cachea layers. Si cambias código Python pero no dependencias, Docker reutiliza la layer de pip install (que toma 5 minutos) y solo recopia el código (10 segundos).\nSin esta optimización: Cada cambio de código requiere reinstalar todas las dependencias.\n3. Directory Creation for MLflow\nRUN mkdir -p mlruns outputs models MLflow escribe artifacts a mlruns/ por defecto si no se configura un tracking server remoto. Si este directorio no existe con permisos correctos, MLflow falla silenciosamente.\noutputs/: Para plots y análisis intermedios models/: Para checkpoints de modelos antes de subir a GCS\nCómo Habilitar MLflow Tracking Opción 1: MLflow Local (Default)\nCuando ejecutas el pipeline en este container, MLflow escribe a mlruns/ dentro del container:\ndocker run --env-file .env housing-pipeline:latest # MLflow escribe a /app/mlruns/ # Para ver el UI: docker exec -it mlflow ui --host 0.0.0.0 --port 5000 Limitación: Los runs se pierden cuando el container se detiene.\nOpción 2: MLflow Remote Tracking Server\nPara persistir runs, configura un servidor MLflow separado:\n# docker-compose.yaml services: mlflow: image: ghcr.io/mlflow/mlflow:v2.9.2 container_name: mlflow-server ports: - \"5000:5000\" environment: - BACKEND_STORE_URI=sqlite:///mlflow.db - DEFAULT_ARTIFACT_ROOT=gs://your-bucket/mlflow-artifacts volumes: - mlflow-data:/mlflow command: \u003e mlflow server --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root gs://your-bucket/mlflow-artifacts --host 0.0.0.0 --port 5000 pipeline: build: . environment: - MLFLOW_TRACKING_URI=http://mlflow:5000 - GCP_PROJECT_ID=${GCP_PROJECT_ID} - GCS_BUCKET_NAME=${GCS_BUCKET_NAME} - WANDB_API_KEY=${WANDB_API_KEY} depends_on: - mlflow volumes: mlflow-data: Configuración en el código:\n# main.py import os import mlflow # Si MLFLOW_TRACKING_URI está configurado, usar ese server mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"file:./mlruns\") mlflow.set_tracking_uri(mlflow_uri) mlflow.set_experiment(\"housing_price_prediction\") with mlflow.start_run(): # Log params, metrics, artifacts mlflow.log_param(\"n_estimators\", 200) mlflow.log_metric(\"mape\", 7.82) mlflow.sklearn.log_model(model, \"model\") Opción 3: MLflow en Cloud (Production)\nPara producción, usa un servidor MLflow gestionado:\n# Deploy MLflow a Cloud Run (serverless) gcloud run deploy mlflow-server \\ --image ghcr.io/mlflow/mlflow:v2.9.2 \\ --platform managed \\ --region us-central1 \\ --set-env-vars=\"BACKEND_STORE_URI=postgresql://user:pass@host/mlflow_db,DEFAULT_ARTIFACT_ROOT=gs://bucket/mlflow\" \\ --allow-unauthenticated # Obtener URL MLFLOW_URL=$(gcloud run services describe mlflow-server --format 'value(status.url)') # Configurar en pipeline export MLFLOW_TRACKING_URI=$MLFLOW_URL Ejecución del Pipeline Container # Build docker build -t housing-pipeline:latest . # Run con env vars docker run \\ --env-file .env \\ -v $(pwd)/mlruns:/app/mlruns \\ housing-pipeline:latest # Run con steps específicos docker run \\ --env-file .env \\ housing-pipeline:latest \\ python main.py main.execute_steps=[03_feature_engineering,05_model_selection] # Ver logs en tiempo real docker logs -f Volume Mount (-v): Monta mlruns/ desde el host al container para persistir runs MLflow incluso después de que el container se detenga.\n2. API Container: Inference en Producción Dockerfile del API # ================================================================= # Dockerfile for Housing Price Prediction API # Purpose: Production-ready FastAPI service for Cloud Run deployment # ================================================================= FROM python:3.12-slim LABEL maintainer=\"danieljimenez88m@gmail.com\" LABEL description=\"Housing Price Prediction API - FastAPI Service\" WORKDIR /app # Install system dependencies (solo curl para healthcheck) RUN apt-get update \u0026\u0026 apt-get install -y \\ curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* # Copy requirements first for better caching COPY requirements.txt . # Install Python dependencies RUN pip install --no-cache-dir --upgrade pip \u0026\u0026 \\ pip install --no-cache-dir -r requirements.txt # Copy application code COPY app/ ./app/ # Create models directory RUN mkdir -p models # Set environment variables ENV PYTHONUNBUFFERED=1 ENV PYTHONDONTWRITEBYTECODE=1 ENV PORT=8080 # Expose port EXPOSE 8080 # Health check HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\ CMD curl -f http://localhost:8080/health || exit 1 # Run the application CMD exec uvicorn app.main:app --host 0.0.0.0 --port ${PORT} Decisiones Técnicas Críticas 1. Imagen Más Ligera\nComparado con el pipeline container:\nNo necesita gcc/g++: Las dependencias ya están compiladas en wheels No necesita git: No clona repos Solo curl: Para el healthcheck Resultado: Imagen de ~200MB vs ~500MB del pipeline.\nPor qué importa: Cloud Run cobra por uso de memoria. Una imagen más pequeña = menos memoria = menos costo.\n2. Health Check Nativo\nHEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\ CMD curl -f http://localhost:8080/health || exit 1 Docker marca el container como “unhealthy” si el endpoint /health falla 3 veces consecutivas.\nCloud Run y Kubernetes usan esto para:\nNo enviar tráfico a containers unhealthy Reiniciar containers que fallan Reporting de uptime start-period=40s: Da 40 segundos al API para cargar el modelo antes de empezar health checks.\n3. Port Configuration Flexible\nENV PORT=8080 CMD exec uvicorn app.main:app --host 0.0.0.0 --port ${PORT} Cloud Run inyecta PORT como env var (puede ser 8080, 8081, etc.). El API debe leer este valor, no hardcodearlo.\nexec: Reemplaza el shell process con uvicorn, permitiendo que Docker envíe signals (SIGTERM) directamente a uvicorn para graceful shutdown.\nCómo el API Carga el Modelo El API tiene tres estrategias de carga de modelo con fallback automático:\n# api/app/core/model_loader.py class ModelLoader: \"\"\"Carga modelo desde MLflow → GCS → Local con fallback.\"\"\" def load_model(self) -\u003e Any: \"\"\"Priority: MLflow \u003e GCS \u003e Local\"\"\" # Estrategia 1: Desde MLflow Registry if self.mlflow_model_name: try: model_uri = f\"models:/{self.mlflow_model_name}/{self.mlflow_stage}\" self._model = mlflow.pyfunc.load_model(model_uri) logger.info(f\"Loaded from MLflow: {model_uri}\") return self._model except Exception as e: logger.warning(f\"MLflow load failed: {e}, trying GCS...\") # Estrategia 2: Desde GCS if self.gcs_model_path: try: storage_client = storage.Client() bucket = storage_client.bucket(self.gcs_bucket) blob = bucket.blob(self.gcs_model_path) model_bytes = blob.download_as_bytes() self._model = pickle.loads(model_bytes) logger.info(f\"Loaded from GCS: gs://{self.gcs_bucket}/{self.gcs_model_path}\") return self._model except Exception as e: logger.warning(f\"GCS load failed: {e}, trying local...\") # Estrategia 3: Desde archivo local (fallback) if self.local_model_path and Path(self.local_model_path).exists(): with open(self.local_model_path, 'rb') as f: self._model = pickle.load(f) logger.info(f\"Loaded from local: {self.local_model_path}\") return self._model raise RuntimeError(\"No model could be loaded from any source\") Configuración con env vars:\n# Producción: Cargar desde MLflow docker run -p 8080:8080 \\ -e MLFLOW_TRACKING_URI=https://mlflow.example.com \\ -e MLFLOW_MODEL_NAME=housing_price_model \\ -e MLFLOW_MODEL_STAGE=Production \\ housing-api:latest # Staging: Cargar desde GCS docker run -p 8080:8080 \\ -e GCS_BUCKET=my-bucket \\ -e GCS_MODEL_PATH=models/trained/housing_price_model.pkl \\ housing-api:latest # Desarrollo: Cargar desde local docker run -p 8080:8080 \\ -v $(pwd)/models:/app/models \\ -e LOCAL_MODEL_PATH=/app/models/trained/housing_price_model.pkl \\ housing-api:latest 3. Streamlit Container: Frontend Interactivo Dockerfile de Streamlit # ================================================================= # Dockerfile for Streamlit Frontend # Purpose: Interactive web interface for housing price predictions # ================================================================= FROM python:3.12-slim LABEL maintainer=\"danieljimenez88m@gmail.com\" LABEL description=\"Housing Price Prediction - Streamlit Frontend\" WORKDIR /app RUN apt-get update \u0026\u0026 apt-get install -y curl \u0026\u0026 rm -rf /var/lib/apt/lists/* COPY requirements.txt . RUN pip install --no-cache-dir --upgrade pip \u0026\u0026 \\ pip install --no-cache-dir -r requirements.txt COPY app.py . # Create .streamlit directory for config RUN mkdir -p .streamlit # Streamlit configuration RUN echo '\\ [server]\\n\\ port = 8501\\n\\ address = \"0.0.0.0\"\\n\\ headless = true\\n\\ enableCORS = false\\n\\ enableXsrfProtection = true\\n\\ \\n\\ [browser]\\n\\ gatherUsageStats = false\\n\\ \\n\\ [theme]\\n\\ primaryColor = \"#FF4B4B\"\\n\\ backgroundColor = \"#FFFFFF\"\\n\\ secondaryBackgroundColor = \"#F0F2F6\"\\n\\ textColor = \"#262730\"\\n\\ font = \"sans serif\"\\n\\ ' \u003e .streamlit/config.toml ENV PYTHONUNBUFFERED=1 ENV PYTHONDONTWRITEBYTECODE=1 EXPOSE 8501 HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\ CMD curl -f http://localhost:8501/_stcore/health || exit 1 CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"] Decisiones Técnicas Críticas 1. Configuración Embedded\nRUN echo '...' \u003e .streamlit/config.toml Streamlit requiere configuración para correr en containers (headless mode, CORS, etc.). En lugar de commitear un archivo config.toml al repo, lo generamos en build time.\nVentajas:\nUn archivo menos en el repo Configuración versionada con el Dockerfile No hay riesgo de olvidar commitear el config 2. Health Check de Streamlit\nHEALTHCHECK CMD curl -f http://localhost:8501/_stcore/health || exit 1 Streamlit expone /_stcore/health automáticamente. Este endpoint retorna 200 si la app está running.\n3. Tema Personalizado\n[theme] primaryColor = \"#FF4B4B\" backgroundColor = \"#FFFFFF\" secondaryBackgroundColor = \"#F0F2F6\" textColor = \"#262730\" El tema define los colores de botones, backgrounds, etc. Esto da consistencia visual sin necesidad de CSS custom en cada componente.\nCómo Streamlit Se Conecta al API # streamlit_app/app.py import os import requests import streamlit as st # Read API URL from environment variable API_URL = os.getenv(\"API_URL\", \"http://localhost:8080\") API_PREDICT_ENDPOINT = f\"{API_URL}/api/v1/predict\" def make_prediction(features: Dict[str, Any]) -\u003e Dict[str, Any]: \"\"\"Call API to get prediction.\"\"\" payload = {\"instances\": [features]} try: response = requests.post( API_PREDICT_ENDPOINT, json=payload, timeout=10 ) response.raise_for_status() return response.json() except requests.exceptions.RequestException as e: st.error(f\"API Error: {e}\") return None # Streamlit UI st.title(\"Housing Price Prediction\") with st.form(\"prediction_form\"): longitude = st.number_input(\"Longitude\", value=-122.23) latitude = st.number_input(\"Latitude\", value=37.88) # ... más inputs submitted = st.form_submit_button(\"Predict\") if submitted: features = { \"longitude\": longitude, \"latitude\": latitude, # ... } result = make_prediction(features) if result: prediction = result[\"predictions\"][0][\"median_house_value\"] st.success(f\"Predicted Price: ${prediction:,.2f}\") Configuración de la URL del API:\n# Docker Compose: Usa service name docker-compose up # Streamlit automáticamente recibe API_URL=http://api:8080 # Local development: Usa localhost API_URL=http://localhost:8080 streamlit run app.py # Production: Usa Cloud Run URL API_URL=https://housing-api-xyz.run.app streamlit run app.py Docker Compose: Orquestación de los Tres Containers # docker-compose.yaml services: api: build: context: ./api dockerfile: Dockerfile container_name: housing-price-api ports: - \"8080:8080\" environment: - PORT=8080 - LOCAL_MODEL_PATH=/app/models/trained/housing_price_model.pkl - WANDB_API_KEY=${WANDB_API_KEY} volumes: - ./models:/app/models:ro restart: unless-stopped healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"] interval: 30s timeout: 10s retries: 3 networks: - mlops-network streamlit: build: context: ./streamlit_app dockerfile: Dockerfile container_name: housing-streamlit ports: - \"8501:8501\" environment: - API_URL=http://api:8080 depends_on: - api restart: unless-stopped healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/_stcore/health\"] interval: 30s timeout: 10s retries: 3 networks: - mlops-network networks: mlops-network: driver: bridge name: housing-mlops-network Decisiones Críticas:\n1. Network Isolation\nnetworks: - mlops-network Ambos containers están en la misma red Docker, permitiendo que Streamlit llame al API usando http://api:8080 (service name como hostname).\nSin esto: Tendrías que usar http://host.docker.internal:8080 (solo funciona en Docker Desktop) o la IP del host.\n2. Volume Mount Read-Only\nvolumes: - ./models:/app/models:ro El API monta models/ en read-only mode (:ro). El container puede leer el modelo pero no modificarlo.\nPor qué: Seguridad. Si el container es comprometido, un atacante no puede sobrescribir el modelo con uno malicioso.\n3. Dependency Order\ndepends_on: - api Docker Compose inicia el API antes que Streamlit. Esto evita que Streamlit falle al intentar conectarse a un API que aún no está corriendo.\nLimitación: depends_on solo espera a que el container inicie, no a que el API esté listo (healthcheck pass). Para eso, necesitas un init container o retry logic en Streamlit.\nComando Completo de Ejecución # 1. Build todas las imágenes docker-compose build # 2. Entrenar el modelo (pipeline container) docker run --env-file .env -v $(pwd)/models:/app/models housing-pipeline:latest # 3. Iniciar API + Streamlit docker-compose up -d # 4. Verificar health curl http://localhost:8080/health curl http://localhost:8501/_stcore/health # 5. Ver logs docker-compose logs -f # 6. Detener todo docker-compose down Lo Que Esta Arquitectura Resuelve Sin containers:\n“Funciona en mi máquina” syndrome Dependencias conflictivas (Python 3.9 vs 3.12) Setup manual en cada ambiente (dev, staging, prod) Con esta arquitectura:\nReproducibilidad: Mismo container corre en laptop, CI/CD, y producción Isolation: API no interfiere con Streamlit, pipeline no interfiere con API Deployment: docker push → gcloud run deploy en \u003c5 minutos Rollback: docker pull previous-image → restart Observability: Health checks automáticos, logs centralizados El valor real: Un data scientist sin experiencia en DevOps puede deployar a producción sin saber cómo configurar nginx, systemd, o virtual environments. Docker abstrae toda esa complejidad.\n10.5. Arquitectura del API: FastAPI en Producción Por Qué Esta Sección Importa Has visto pipelines de entrenamiento, sweep de hiperparámetros, y model registry. Pero el 90% del tiempo, tu modelo no está entrenando—está sirviendo predicciones en producción.\nUn API mal diseñado es el cuello de botella entre un modelo excelente y un producto útil. Esta sección desmenuza cómo este proyecto construye un API production-ready, no un prototipo de tutorial.\nLa Arquitectura General api/ ├── app/ │ ├── main.py # FastAPI app + lifespan management │ ├── core/ │ │ ├── config.py # Pydantic Settings (env vars) │ │ ├── model_loader.py # Multi-source model loading │ │ ├── wandb_logger.py # Prediction logging │ │ └── preprocessor.py # Feature engineering │ ├── routers/ │ │ └── predict.py # Prediction endpoints │ └── models/ │ └── schemas.py # Pydantic request/response models ├── requirements.txt ├── Dockerfile └── tests/ Decisión arquitectónica: Separation of concerns por capas:\nCore: Lógica de negocio (cargar modelo, logging, config) Routers: Endpoints HTTP (rutas, validación de requests) Models: Schemas de datos (Pydantic) Por qué no todo en main.py? Porque cuando el API crece (agregar autenticación, rate limiting, múltiples modelos), cada capa se extiende independientemente sin tocar el resto.\n1. Lifespan Management: El Patrón Que Evita Latencia en Primera Request El Problema Que Resuelve Anti-pattern común:\n# BAD: Cargar modelo en cada request @app.post(\"/predict\") def predict(features): model = pickle.load(open(\"model.pkl\", \"rb\")) # 5 segundos cada request return model.predict(features) Problemas:\nPrimera request toma 5 segundos (cargar modelo) Cada request subsecuente también (no hay caching) Si 10 requests concurrentes → 10 cargas del modelo (50 segundos total) La Solución: asynccontextmanager # api/app/main.py @asynccontextmanager async def lifespan(app: FastAPI): \"\"\" Lifecycle manager for the FastAPI application. Loads the model on startup and cleans up on shutdown. \"\"\" logger.info(\"Starting up API...\") # STARTUP: Cargar modelo UNA VEZ wandb_logger = WandBLogger( project=settings.WANDB_PROJECT, enabled=True ) model_loader = ModelLoader( local_model_path=settings.LOCAL_MODEL_PATH, gcs_bucket=settings.GCS_BUCKET, gcs_model_path=settings.GCS_MODEL_PATH, mlflow_model_name=settings.MLFLOW_MODEL_NAME, mlflow_model_stage=settings.MLFLOW_MODEL_STAGE, mlflow_tracking_uri=settings.MLFLOW_TRACKING_URI ) try: logger.info(\"Loading model...\") model_loader.load_model() # Toma 5 segundos, pero SOLO una vez logger.info(f\"Model loaded: {model_loader.model_version}\") # Guardar en app state (disponible para todos los endpoints) app.state.model_loader = model_loader app.state.wandb_logger = wandb_logger except Exception as e: logger.error(f\"Failed to load model: {str(e)}\") logger.warning(\"API will start but predictions will fail\") yield # API corre aquí # SHUTDOWN: Cleanup logger.info(\"Shutting down API...\") wandb_logger.close() # Usar lifespan en FastAPI app = FastAPI( title=\"Housing Price Prediction API\", version=\"1.0.0\", lifespan=lifespan # CRÍTICO ) Lo que hace:\nStartup (antes de yield):\nCarga modelo en memoria (5 segundos, una sola vez) Inicializa W\u0026B logger Guarda ambos en app.state (singleton pattern) Running (después de yield):\nTodas las requests usan el modelo cacheado en app.state.model_loader Latencia por request: \u003c50ms (solo inference, no I/O) Shutdown (después del context manager):\nCierra W\u0026B run (flush pending logs) Libera recursos Resultado:\nPrimera request: \u003c50ms (modelo ya cargado) Requests subsecuentes: \u003c50ms 10 requests concurrentes: \u003c100ms promedio (paralelizable) Trade-off: Startup time de 5-10 segundos. Aceptable para producción—mejor que 5 segundos por request.\n2. Configuration Management: Pydantic Settings con Prioridades El Pattern: Settings-as-Code # api/app/core/config.py from pydantic_settings import BaseSettings class Settings(BaseSettings): PROJECT_NAME: str = \"Housing Price Prediction API\" VERSION: str = \"1.0.0\" API_V1_STR: str = \"/api/v1\" # Model - MLflow (priority 1) MLFLOW_MODEL_NAME: str = \"\" MLFLOW_MODEL_STAGE: str = \"Production\" MLFLOW_TRACKING_URI: str = \"\" # Model - GCS (priority 2) GCS_BUCKET: str = \"\" GCS_MODEL_PATH: str = \"models/trained/housing_price_model.pkl\" # Model - Local (priority 3, fallback) LOCAL_MODEL_PATH: str = \"models/trained/housing_price_model.pkl\" # Weights \u0026 Biases WANDB_API_KEY: str = \"\" WANDB_PROJECT: str = \"housing-mlops-api\" class Config: env_file = \".env\" # Lee de .env automáticamente case_sensitive = True # MLFLOW_MODEL_NAME != mlflow_model_name Por qué Pydantic Settings:\nType Safety: settings.VERSION es str, no Optional[Any] Validation: Si MLFLOW_MODEL_STAGE no es string, falla en startup (no en la primera request) Auto .env loading: No necesitas python-dotenv manualmente Default values: LOCAL_MODEL_PATH tiene default, MLFLOW_MODEL_NAME no Uso en código:\nfrom app.core.config import Settings settings = Settings() # Lee env vars + .env if settings.MLFLOW_MODEL_NAME: # Type-safe check model = load_from_mlflow(settings.MLFLOW_MODEL_NAME) La Estrategia de Prioridades (Cascade Fallback) Intenta cargar de: 1. MLflow Registry (si MLFLOW_MODEL_NAME está configurado) ↓ Si falla 2. GCS (si GCS_BUCKET está configurado) ↓ Si falla 3. Local filesystem (siempre disponible como último recurso) ↓ Si falla 4. API inicia pero `/predict` retorna 500 Configuración por ambiente:\n# Producción (.env.production) MLFLOW_MODEL_NAME=housing_price_model MLFLOW_MODEL_STAGE=Production MLFLOW_TRACKING_URI=https://mlflow.company.com # GCS y Local quedan vacíos → no se usan # Staging (.env.staging) MLFLOW_MODEL_NAME=housing_price_model MLFLOW_MODEL_STAGE=Staging # Mismo setup, diferente stage # Desarrollo local (.env.local) LOCAL_MODEL_PATH=models/trained/housing_price_model.pkl # Sin MLflow ni GCS → carga de local directo Valor: Un solo codebase, múltiples ambientes. No hay if ENVIRONMENT == \"production\" en el código.\n3. Model Loader: Multi-Source con Fallback Inteligente La Arquitectura del Loader # api/app/core/model_loader.py class ModelLoader: \"\"\"Handles loading ML models from various sources.\"\"\" def __init__( self, local_model_path: Optional[str] = None, gcs_bucket: Optional[str] = None, gcs_model_path: Optional[str] = None, mlflow_model_name: Optional[str] = None, mlflow_model_stage: Optional[str] = None, mlflow_tracking_uri: Optional[str] = None ): self.local_model_path = local_model_path self.gcs_bucket = gcs_bucket self.gcs_model_path = gcs_model_path self.mlflow_model_name = mlflow_model_name self.mlflow_model_stage = mlflow_model_stage self.mlflow_tracking_uri = mlflow_tracking_uri self._model: Optional[Any] = None # Cacheado en memoria self._model_version: str = \"unknown\" self._preprocessor = HousingPreprocessor() def load_model(self) -\u003e Any: \"\"\"Load model with cascade fallback strategy.\"\"\" # Priority 1: MLflow Registry if self.mlflow_model_name: try: logger.info(f\"Attempting MLflow load: {self.mlflow_model_name}/{self.mlflow_model_stage}\") self._model = self.load_from_mlflow( self.mlflow_model_name, self.mlflow_model_stage, self.mlflow_tracking_uri ) return self._model except Exception as e: logger.warning(f\"MLflow load failed: {str(e)}, trying GCS...\") # Priority 2: GCS if self.gcs_bucket and self.gcs_model_path: try: logger.info(f\"Attempting GCS load: gs://{self.gcs_bucket}/{self.gcs_model_path}\") self._model = self.load_from_gcs(self.gcs_bucket, self.gcs_model_path) return self._model except Exception as e: logger.warning(f\"GCS load failed: {str(e)}, trying local...\") # Priority 3: Local filesystem if self.local_model_path and Path(self.local_model_path).exists(): logger.info(f\"Attempting local load: {self.local_model_path}\") self._model = self.load_from_local(self.local_model_path) return self._model # All strategies failed raise RuntimeError( \"Could not load model from any source. \" \"Check MLflow/GCS/local configuration.\" ) def predict(self, features: pd.DataFrame) -\u003e np.ndarray: \"\"\"Make predictions with preprocessing.\"\"\" if not self.is_loaded: raise RuntimeError(\"Model not loaded\") # Apply same preprocessing que el training pipeline processed_features = self._preprocessor.transform(features) # Predict predictions = self._model.predict(processed_features) return predictions @property def is_loaded(self) -\u003e bool: \"\"\"Check if model is loaded.\"\"\" return self._model is not None Decisiones Técnicas Críticas 1. Por Qué MLflow Es Priority 1\n# MLflow load model = mlflow.sklearn.load_model(\"models:/housing_price_model/Production\") Ventajas sobre GCS/Local:\nModel URI abstrae storage: El modelo puede estar en S3, GCS, HDFS—MLflow lo resuelve Stage resolution: Production automáticamente resuelve a la versión correcta (v1, v2, etc.) Metadata incluida: MLflow también carga conda.yaml, requirements.txt, metadata de features Rollback trivial: Cambias stage en MLflow UI, API recarga automáticamente en próximo restart 2. GCS Como Fallback (No Primary)\n# GCS load from google.cloud import storage client = storage.Client() bucket = client.bucket(\"my-bucket\") blob = bucket.blob(\"models/trained/housing_price_model.pkl\") model_bytes = blob.download_as_bytes() model = pickle.loads(model_bytes) Por qué no primary:\nNo hay versionamiento: models/trained/housing_price_model.pkl es siempre el “latest”—no puedes cargar v1 vs v2 sin cambiar el path No metadata: Solo obtienes el pickle, no sabes qué hiperparámetros/features espera No stages: No existe concepto de Staging vs Production Cuándo usar GCS como primary:\nMLflow no está disponible (outage) Setup simple (solo un modelo, no necesitas registry) Budget constraint (evitar hosting de MLflow) 3. Local Como Last Resort\n# Local load with open(\"models/trained/housing_price_model.pkl\", \"rb\") as f: model = pickle.load(f) Solo para:\nDesarrollo local (no quieres depender de GCS/MLflow) Debugging (modelo roto en GCS, testeas con una copia local) CI/CD tests (GitHub Actions no tiene acceso a GCS) Nunca para producción real—si GCS y MLflow están down, tienes problemas más grandes que el modelo.\n4. Preprocessing Pipeline Embebido\nself._preprocessor = HousingPreprocessor() def predict(self, features: pd.DataFrame) -\u003e np.ndarray: processed_features = self._preprocessor.transform(features) predictions = self._model.predict(processed_features) return predictions Por qué crítico: El modelo espera features procesadas (one-hot encoding de ocean_proximity, feature engineering de clusters). Si el cliente envía raw features, el modelo falla.\nOpciones de implementación:\nA) Preprocessing en el API (este proyecto):\n# Cliente envía raw features {\"ocean_proximity\": \"NEAR BAY\", \"longitude\": -122.23, ...} # API aplica preprocessing processed = preprocessor.transform(raw_features) # Modelo recibe features procesadas predictions = model.predict(processed) B) Preprocessing en el cliente (mal para APIs públicos):\n# Cliente debe saber exact preprocessing processed = client_side_preprocessing(raw_features) # ¿Qué hace esto? # API solo hace inference predictions = model.predict(processed) Trade-offs:\nApproach Ventaja Desventaja Preprocessing en API Cliente no necesita saber preprocessing API más complejo, latencia +5ms Preprocessing en cliente API simple, latencia baja Cliente debe replicar preprocessing exacto Para APIs públicos: Siempre preprocessing en el API. Los clientes no deben conocer detalles internos del modelo.\nPara APIs internos: Depende. Si el cliente es otro servicio que controlas, puedes hacer preprocessing ahí para reducir latencia.\n4. Request/Response Validation: Pydantic Schemas El Anti-Pattern: Validación Manual # BAD: Validación manual propensa a errores @app.post(\"/predict\") def predict(request: dict): if \"longitude\" not in request: return {\"error\": \"missing longitude\"} if not isinstance(request[\"longitude\"], (int, float)): return {\"error\": \"longitude must be number\"} if request[\"longitude\"] \u003c -180 or request[\"longitude\"] \u003e 180: return {\"error\": \"longitude out of range\"} # ... 50 líneas más de validación manual Problemas:\nCódigo repetitivo y frágil Errores inconsistentes (\"missing longitude\" vs \"longitude is required\") No hay documentación automática (OpenAPI) Difícil de testear La Solución: Pydantic Schemas # api/app/models/schemas.py from pydantic import BaseModel, Field, field_validator class HousingFeatures(BaseModel): \"\"\"Input features for housing price prediction.\"\"\" longitude: float = Field( ..., # Required description=\"Longitude coordinate\", ge=-180, # greater or equal le=180 # less or equal ) latitude: float = Field(..., description=\"Latitude coordinate\", ge=-90, le=90) housing_median_age: float = Field(..., description=\"Median age of houses\", ge=0) total_rooms: float = Field(..., description=\"Total number of rooms\", ge=0) total_bedrooms: float = Field(..., description=\"Total number of bedrooms\", ge=0) population: float = Field(..., description=\"Block population\", ge=0) households: float = Field(..., description=\"Number of households\", ge=0) median_income: float = Field(..., description=\"Median income\", ge=0) ocean_proximity: str = Field(..., description=\"Proximity to ocean\") @field_validator('ocean_proximity') @classmethod def validate_ocean_proximity(cls, v: str) -\u003e str: \"\"\"Validate ocean proximity values.\"\"\" valid_values = ['\u003c1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'] if v.upper() not in valid_values: raise ValueError( f\"ocean_proximity must be one of: {', '.join(valid_values)}\" ) return v.upper() # Normaliza a uppercase model_config = { \"json_schema_extra\": { \"examples\": [{ \"longitude\": -122.23, \"latitude\": 37.88, \"housing_median_age\": 41.0, \"total_rooms\": 880.0, \"total_bedrooms\": 129.0, \"population\": 322.0, \"households\": 126.0, \"median_income\": 8.3252, \"ocean_proximity\": \"NEAR BAY\" }] } } Lo que esto da automáticamente:\nValidación de tipos:\n{\"longitude\": \"not a number\"} // Rechazado: ValidationError Validación de rangos:\n{\"longitude\": -200} // Rechazado: must be \u003e= -180 Validación custom:\n{\"ocean_proximity\": \"INVALID\"} // Rechazado: must be one of [...] Documentación automática en /docs:\nSwagger UI muestra todos los fields Descriptions, constraints, ejemplos Try-it-out funciona out-of-the-box Serialización type-safe:\nfeatures = HousingFeatures(**request_json) features.longitude # Type: float (no Optional[Any]) Batch Predictions Support class PredictionRequest(BaseModel): \"\"\"Request model for single or batch predictions.\"\"\" instances: List[HousingFeatures] = Field( ..., description=\"List of housing features for prediction\", min_length=1 # Al menos una instancia ) Uso:\n{ \"instances\": [ {\"longitude\": -122.23, ...}, // Predict house 1 {\"longitude\": -118.45, ...}, // Predict house 2 {\"longitude\": -121.89, ...} // Predict house 3 ] } Por qué soportar batch:\nLatencia reducida: 3 requests individuales = 150ms. 1 batch de 3 = 60ms. Costo reducido: Menos HTTP overhead (headers, handshake, etc.) Inference eficiente: El modelo puede vectorizar operaciones Trade-off: Batch size muy grande (\u003e1000) puede causar timeouts. Implementar límite:\ninstances: List[HousingFeatures] = Field( ..., min_length=1, max_length=100 # Máximo 100 predicciones por request ) Response Schema class PredictionResult(BaseModel): \"\"\"Individual prediction result.\"\"\" predicted_price: float = Field(..., description=\"Predicted median house value\") confidence_interval: Optional[dict] = Field( None, description=\"Confidence interval (if available)\" ) class PredictionResponse(BaseModel): \"\"\"Response model for predictions.\"\"\" predictions: List[PredictionResult] = Field(..., description=\"List of predictions\") model_version: str = Field(..., description=\"Model version used\") model_config = { \"json_schema_extra\": { \"examples\": [{ \"predictions\": [{ \"predicted_price\": 452600.0, \"confidence_interval\": None }], \"model_version\": \"randomforest_v1\" }] } } model_version en response: Crucial para debugging. Si un cliente reporta predicciones incorrectas, el model_version te dice qué modelo usó (v1, v2, Production, etc.).\n5. Router Pattern: Endpoints y Error Handling La Estructura del Router # api/app/routers/predict.py from fastapi import APIRouter, HTTPException, status router = APIRouter(prefix=\"/api/v1\", tags=[\"predictions\"]) # Global instances (set by main.py) model_loader: ModelLoader = None wandb_logger: WandBLogger = None def set_model_loader(loader: ModelLoader) -\u003e None: \"\"\"Dependency injection pattern.\"\"\" global model_loader model_loader = loader Por qué prefix=\"/api/v1\":\n/api/v1/predict ← Versión 1 del API /api/v2/predict ← Versión 2 (breaking changes) Puedes correr ambas versiones simultáneamente durante migración:\nClientes legacy usan /api/v1/ Clientes nuevos usan /api/v2/ Deprecas v1 después de 6 meses Sin versionamiento: Breaking change → todos los clientes se rompen al mismo tiempo.\nEl Endpoint Principal: POST /api/v1/predict @router.post( \"/predict\", response_model=PredictionResponse, status_code=status.HTTP_200_OK, responses={ 400: {\"model\": ErrorResponse, \"description\": \"Invalid input data\"}, 500: {\"model\": ErrorResponse, \"description\": \"Prediction failed\"}, }, summary=\"Predict housing prices\", description=\"Make predictions for housing prices based on input features\" ) async def predict(request: PredictionRequest) -\u003e PredictionResponse: \"\"\" Predict housing prices for given features. \"\"\" # 1. Check model loaded if model_loader is None or not model_loader.is_loaded: raise HTTPException( status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Model not loaded\" ) start_time = time.time() try: # 2. Convert Pydantic models to DataFrame features_list = [instance.model_dump() for instance in request.instances] df = pd.DataFrame(features_list) # 3. Make predictions predictions = model_loader.predict(df) # 4. Calculate metrics response_time_ms = (time.time() - start_time) * 1000 # 5. Format response results = [ PredictionResult(predicted_price=float(pred)) for pred in predictions ] # 6. Log to W\u0026B (async, no bloquea) if wandb_logger: wandb_logger.log_prediction( features=features_list, predictions=[float(p) for p in predictions], model_version=model_loader.model_version, response_time_ms=response_time_ms ) return PredictionResponse( predictions=results, model_version=model_loader.model_version ) except ValueError as e: # Validation error (ej: feature fuera de rango esperado) if wandb_logger: wandb_logger.log_error(\"validation_error\", str(e), features_list) raise HTTPException( status_code=status.HTTP_400_BAD_REQUEST, detail=f\"Invalid input data: {str(e)}\" ) except Exception as e: # Unexpected error (ej: modelo corrupto, OOM) if wandb_logger: wandb_logger.log_error(\"prediction_error\", str(e)) raise HTTPException( status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Prediction failed: {str(e)}\" ) Decisiones de error handling:\ntry: # Inference except ValueError: # Cliente envió datos inválidos → 400 Bad Request # Loguear a W\u0026B para análisis return 400 except Exception: # Error inesperado (bug en el código/modelo) → 500 Internal Server Error # Loguear a W\u0026B para alerting return 500 Por qué distinguir 400 vs 500:\n400: Culpa del cliente. No retries automáticos. 500: Culpa del servidor. Cliente puede retry. Logging de errores a W\u0026B: Permite detectar patrones. Si ves 1000 validation_error para ocean_proximity=\"INVALID\", agregas un mensaje de error más claro.\n6. W\u0026B Logging: Observability en Producción Por Qué Loguear Predicciones Pregunta: “¿Para qué loguear cada predicción si ya tengo logs de uvicorn?”\nRespuesta: Los logs de uvicorn te dicen:\nQué endpoint se llamó HTTP status code Cuánto tardó Los logs de W\u0026B te dicen:\nQué features se usaron Qué predicción se hizo Distribución de predicciones (¿todas están en $200k-$500k? ¿hay outliers?) Latencia promedio por request Error rate (¿cuántos requests fallan?) Caso de uso real: Stakeholder reporta “las predicciones están muy altas últimamente”. Abres W\u0026B dashboard:\nprediction/mean: $450k (antes: $380k) features/median_income: 9.2 (antes: 7.5) Conclusión: No hay bug—simplemente los clientes están consultando casas en áreas más caras (median_income más alto). Sin W\u0026B, estarías debuggeando código por horas.\nLa Implementación # api/app/core/wandb_logger.py class WandBLogger: def __init__(self, project: str = \"housing-mlops-api\", enabled: bool = True): self.enabled = enabled and bool(os.getenv(\"WANDB_API_KEY\")) if self.enabled: self._run = wandb.init( project=self.project, job_type=\"api-inference\", # Distinguir de training runs config={ \"environment\": os.getenv(\"ENVIRONMENT\", \"production\"), \"model_version\": os.getenv(\"MODEL_VERSION\", \"unknown\") }, reinit=True # Permite múltiples init() en mismo proceso ) def log_prediction( self, features: List[Dict], predictions: List[float], model_version: str, response_time_ms: float ) -\u003e None: if not self.enabled: return # Métricas agregadas wandb.log({ \"prediction/count\": len(predictions), \"prediction/mean\": sum(predictions) / len(predictions), \"prediction/min\": min(predictions), \"prediction/max\": max(predictions), \"performance/response_time_ms\": response_time_ms, \"model/version\": model_version, \"timestamp\": datetime.now().isoformat() }) # Feature distributions (sample first 100) if len(features) \u003c= 100: for i, (feat, pred) in enumerate(zip(features, predictions)): wandb.log({ f\"features/instance_{i}/median_income\": feat[\"median_income\"], f\"predictions/instance_{i}\": pred }) Por qué job_type=\"api-inference\":\nEn W\u0026B dashboard, puedes filtrar por job type:\ntraining: Runs del pipeline de entrenamiento sweep: Runs del hyperparameter sweep api-inference: Predicciones en producción Por qué reinit=True: Un proceso de uvicorn puede vivir días. reinit=True permite crear múltiples W\u0026B runs dentro del mismo proceso (uno por startup/restart).\nPor qué sample first 100: Loguear 10,000 features individuales por request sería demasiado overhead. Muestrear 100 da distribución representativa sin matar performance.\nW\u0026B Dashboard en Producción # Métricas a monitorear: prediction/count: Requests per minute (RPM) - Esperado: 100-500 RPM - Alerta: \u003c10 RPM (¿está caído?) o \u003e2000 RPM (¿DDoS?) prediction/mean: Precio promedio predicho - Esperado: $300k-$450k (según mercado) - Alerta: \u003e$1M (modelo roto) o \u003c$50k (data drift) performance/response_time_ms: Latencia - Esperado: 30-60ms - Alerta: \u003e200ms (modelo lento o CPU throttling) error/count: Errores por minuto - Esperado: 0-5 errores/min - Alerta: \u003e50 errores/min (investigate immediately) 7. CORS y Security # api/app/main.py app.add_middleware( CORSMiddleware, allow_origins=[ \"http://localhost:3000\", # Frontend local (React/Streamlit) \"http://localhost:8080\", \"https://app.company.com\", # Frontend en producción ], allow_credentials=False, # No cookies (API es stateless) allow_methods=[\"GET\", \"POST\"], # Solo métodos necesarios allow_headers=[\"Content-Type\", \"Authorization\"], max_age=3600, # Cache preflight requests por 1 hora ) Por qué restricted origins:\nAnti-pattern (permissive):\nallow_origins=[\"*\"] # MALO: Cualquier sitio puede llamar tu API Problema: Un sitio malicioso evil.com puede hacer requests a tu API desde el navegador del usuario, potencialmente:\nConsumir tu cuota de GCP (si no hay auth) Hacer predicciones spam DoS attack Pattern correcto (restrictive):\nallow_origins=[\"https://app.company.com\"] # Solo tu frontend Para desarrollo local: Agregar http://localhost:3000 temporalmente, remover en producción.\nPor qué allow_credentials=False: Este API es stateless—no usa cookies ni sesiones. allow_credentials=True sería innecesario y una superficie de ataque adicional.\n8. El Flujo Completo de Una Request Request:\ncurl -X POST http://localhost:8080/api/v1/predict \\ -H \"Content-Type: application/json\" \\ -d '{ \"instances\": [{ \"longitude\": -122.23, \"latitude\": 37.88, \"housing_median_age\": 41, \"total_rooms\": 880, \"total_bedrooms\": 129, \"population\": 322, \"households\": 126, \"median_income\": 8.3252, \"ocean_proximity\": \"NEAR BAY\" }] }' El viaje interno (\u003c 50ms):\n1. FastAPI recibe request (1ms) ├─ CORS middleware valida origin └─ Router match: POST /api/v1/predict 2. Pydantic validation (2ms) ├─ Parse JSON → PredictionRequest object ├─ Validate types (longitude: float ✓) ├─ Validate ranges (longitude: -122.23, dentro de [-180, 180] ✓) └─ Custom validator (ocean_proximity: \"NEAR BAY\" → válido ✓) 3. Endpoint handler: predict() (40ms) ├─ Check model_loader.is_loaded (0.1ms) ├─ Convert Pydantic → DataFrame (1ms) ├─ Preprocessing (5ms) │ ├─ One-hot encode ocean_proximity │ ├─ Compute cluster similarity features │ └─ Scale numerical features ├─ Model inference (30ms) │ └─ RandomForest.predict(processed_features) ├─ Format response (1ms) └─ Log to W\u0026B (async, \u003c1ms non-blocking) 4. FastAPI serializa response (2ms) └─ PredictionResponse → JSON 5. HTTP response enviado (1ms) Total: ~50ms Response:\n{ \"predictions\": [{ \"predicted_price\": 452600.0, \"confidence_interval\": null }], \"model_version\": \"models:/housing_price_model/Production\" } 9. Lo Que Esta Arquitectura Logra Sin esta arquitectura (API naive):\nCargar modelo en cada request (5 segundos/request) Validación manual propensa a errores Sin observability (debugging es adivinar) Sin versionamiento de API (breaking changes rompen clientes) CORS abierto (vulnerability) Con esta arquitectura:\nLatencia: \u003c50ms por predicción (modelo cacheado) Confiabilidad: Pydantic garantiza requests válidos antes de llegar al modelo Observability: W\u0026B dashboard muestra distribución de predicciones, latencia, errores Maintainability: Separation of concerns (core/routers/models) Security: CORS restrictivo, error handling robusto Versionamiento: /api/v1/ permite evolucionar el API sin romper clientes El valor real: Este API puede escalar de 10 requests/min a 10,000 requests/min sin cambios en el código—solo agregar más containers con load balancer. La arquitectura ya está lista.\n11. Estrategias de Selección de Modelos y Parámetros El Flujo Completo: Selection → Sweep → Registration Este pipeline implementa una estrategia de tres fases para optimización de modelos, cada una con un propósito específico:\nStep 05: Model Selection ├── Compara 5 algoritmos con GridSearch básico (5-10 combos/modelo) ├── Objetivo: Identificar mejor familia de modelo (Random Forest vs Gradient Boosting vs ...) ├── Métrica principal: MAPE (Mean Absolute Percentage Error) └── Output: Mejor algoritmo + parámetros iniciales Step 06: Hyperparameter Sweep ├── Optimiza SOLO el mejor algoritmo del Step 05 ├── Bayesian optimization con 50+ runs (espacio de búsqueda exhaustivo) ├── Objetivo: Encontrar configuración óptima del mejor modelo ├── Métrica principal: wMAPE (Weighted MAPE, menos sesgado) └── Output: best_params.yaml con hiperparámetros óptimos Step 07: Model Registration ├── Entrena modelo final con parámetros de Step 06 ├── Registra en MLflow Model Registry con metadata rica ├── Transiciona a stage (Staging/Production) └── Output: Modelo versionado listo para deployment ¿Por qué tres steps separados? No tienes recursos computacionales para hacer sweep exhaustivo de 5 algoritmos × 50 combinaciones = 250 entrenamientos. Primero decides estrategia (qué algoritmo), luego tácticas (qué hiperparámetros).\nStep 05: Model Selection - Comparación de Algoritmos Los 5 Modelos Candidatos def get_available_models() -\u003e Dict[str, Any]: \"\"\"Get dictionary of available regression models.\"\"\" models = { \"RandomForest\": RandomForestRegressor(random_state=42), \"GradientBoosting\": GradientBoostingRegressor(random_state=42), \"Ridge\": Ridge(random_state=42), \"Lasso\": Lasso(random_state=42), \"DecisionTree\": DecisionTreeRegressor(random_state=42) } return models Por qué estos modelos:\nRandomForest: Ensemble de árboles, robusto, maneja no-linealidades GradientBoosting: Boosting secuencial, mejor precisión que RF pero más lento Ridge: Regresión lineal con regularización L2, rápido, interpretable Lasso: Regresión lineal con regularización L1, hace feature selection DecisionTree: Baseline simple, útil para comparación Lo que falta (deliberadamente):\nXGBoost/LightGBM: No incluidos para reducir dependencias, pero fácil de agregar Neural Networks: Overkill para este problema (20k muestras, features tabulares) SVR: Muy lento en datasets grandes, no escala bien Parameter Grids: GridSearch Inicial def get_default_param_grids() -\u003e Dict[str, Dict[str, list]]: \"\"\" Parameter grids for initial model selection. Refinados basados en domain knowledge. \"\"\" param_grids = { \"RandomForest\": { \"n_estimators\": [50, 100, 200, 300], # 4 opciones \"max_depth\": [10, 15, 20, 25, None], # 5 opciones \"min_samples_split\": [2, 5, 10], # 3 opciones \"min_samples_leaf\": [1, 2, 4], # 3 opciones }, # Total combinaciones: 4×5×3×3 = 180 # Con 5-fold CV: 180×5 = 900 fits \"GradientBoosting\": { \"n_estimators\": [50, 100, 150, 200], # 4 opciones \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2], # 5 opciones \"max_depth\": [3, 4, 5, 6, 7], # 5 opciones \"subsample\": [0.8, 0.9, 1.0], # 3 opciones }, # Total: 4×5×5×3 = 300 combinaciones \"Ridge\": { \"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], }, # Total: 9 combinaciones (rápido) \"Lasso\": { \"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], }, # Total: 9 combinaciones \"DecisionTree\": { \"max_depth\": [5, 10, 15, 20, 25, None], # 6 opciones \"min_samples_split\": [2, 5, 10, 20], # 4 opciones \"min_samples_leaf\": [1, 2, 4, 8], # 4 opciones } # Total: 6×4×4 = 96 combinaciones } return param_grids Decisiones de Diseño de los Grids 1. RandomForest: Foco en Overfitting Control\n\"max_depth\": [10, 15, 20, 25, None], \"min_samples_leaf\": [1, 2, 4], Razonamiento: Random Forest tiende a overfit en datasets pequeños. max_depth y min_samples_leaf controlan profundidad de árboles—valores altos previenen que el modelo memorice ruido.\nNone en max_depth: Permite árboles de profundidad ilimitada. Útil cuando el dataset tiene patrones complejos que requieren splits profundos.\n2. GradientBoosting: Balance Learning Rate vs N_estimators\n\"n_estimators\": [50, 100, 150, 200], \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2], Trade-off clásico:\nLearning rate bajo (0.01) + muchos estimators (200): Aprendizaje lento pero preciso Learning rate alto (0.2) + pocos estimators (50): Rápido pero puede divergir GridSearch explora ambos extremos.\nsubsample \u003c 1.0: Stochastic Gradient Boosting. Solo usa 80-90% de datos en cada iteración, reduce overfitting.\n3. Ridge/Lasso: Alpha en Escala Logarítmica\n\"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], Alpha controla regularización:\nAlpha bajo (0.01): Casi sin regularización, modelo complejo Alpha alto (500): Regularización fuerte, modelo simple (coeficientes cercanos a 0) Escala logarítmica cubre el espacio de manera más uniforme que escala lineal.\nLasso vs Ridge:\nLasso (L1): Fuerza coeficientes a exactamente 0 → feature selection automática Ridge (L2): Coeficientes pequeños pero no cero → mantiene todas las features Si Lasso gana, indica que algunas features son ruido.\n4. DecisionTree: Baseline de Comparación\nDecisionTree es el peor modelo (alto variance, overfit fácil), pero sirve para:\nVerificar que el pipeline funciona correctamente Baseline de comparación: Si Ridge/Lasso no superan DecisionTree, algo está mal en feature engineering La Función de Entrenamiento con GridSearch def train_model_with_gridsearch( model: Any, param_grid: Dict[str, list], X_train: pd.DataFrame, y_train: pd.Series, cv: int = 5 ) -\u003e Tuple[Any, Dict[str, Any], float, Dict[str, float]]: \"\"\"Train model with K-fold Cross-Validation via GridSearchCV.\"\"\" start_time = time.time() grid_search = GridSearchCV( estimator=model, param_grid=param_grid, cv=5, # 5-fold cross-validation scoring='neg_mean_absolute_error', # CRÍTICO n_jobs=-1, # Paralelización verbose=0, return_train_score=True # Para detectar overfitting ) grid_search.fit(X_train, y_train) training_time = time.time() - start_time # Extract cross-validation results cv_metrics = { \"mean_test_score\": float(-grid_search.best_score_), \"std_test_score\": float(grid_search.cv_results_['std_test_score'][grid_search.best_index_]), \"mean_train_score\": float(-grid_search.cv_results_['mean_train_score'][grid_search.best_index_]), \"std_train_score\": float(grid_search.cv_results_['std_train_score'][grid_search.best_index_]), } return grid_search.best_estimator_, grid_search.best_params_, training_time, cv_metrics Decisiones Críticas 1. Scoring: neg_mean_absolute_error\nscoring='neg_mean_absolute_error' ¿Por qué MAE y no RMSE o R²?\nMAE (Mean Absolute Error): Penaliza errores linealmente RMSE: Penaliza errores cuadraticamente (errores grandes pesan mucho más) R²: Métrica relativa, difícil de interpretar en términos de negocio Para este problema:\nMAE = $15,000 → “El modelo se equivoca $15k en promedio” R² = 0.85 → ¿Qué significa para el negocio? neg_mean_absolute_error: GridSearchCV minimiza la métrica, pero MAE se debe minimizar, entonces usamos la negativa.\n2. Cross-Validation: 5 Folds\ncv=5 ¿Por qué 5 y no 10?\n5-fold: Balance entre bias (sesgo) y variance (varianza)\nCada fold tiene 80% training, 20% validation Más rápido que 10-fold (2x menos fits) 10-fold: Menos bias pero más costo computacional\nÚtil cuando tienes pocos datos (\u003c1000 samples) Con 16,512 training samples, 5-fold es suficiente.\n3. return_train_score=True\nreturn_train_score=True Esto loggea el score en training set además de validation set. Permite detectar overfitting:\nif cv_metrics['mean_train_score'] \u003e\u003e cv_metrics['mean_test_score']: print(\"WARNING: Model is overfitting!\") # Train MAE = $5k, Test MAE = $20k → Overfitting claro 4. n_jobs=-1: Paralelización\nn_jobs=-1 Usa todos los CPU cores disponibles. En una máquina con 8 cores, 180 combinaciones × 5 folds = 900 fits se distribuyen en paralelo.\nSin paralelización: 900 fits × 2s/fit = 30 minutos Con 8 cores: ~4 minutos\nMétricas de Evaluación: Más Allá de MAPE def evaluate_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series) -\u003e Dict[str, float]: \"\"\"Evalúa modelo con métricas business-focused.\"\"\" y_pred = model.predict(X_test) y_true = y_test.values # Traditional metrics mae = mean_absolute_error(y_test, y_pred) rmse = np.sqrt(mean_squared_error(y_test, y_pred)) r2 = r2_score(y_test, y_pred) # Business-focused percentage error metrics mape = mean_absolute_percentage_error(y_true, y_pred) smape = symmetric_mean_absolute_percentage_error(y_true, y_pred) wmape = weighted_mean_absolute_percentage_error(y_true, y_pred) median_ape = median_absolute_percentage_error(y_true, y_pred) # Prediction accuracy at different thresholds within_5pct = predictions_within_threshold(y_true, y_pred, 0.05) within_10pct = predictions_within_threshold(y_true, y_pred, 0.10) within_15pct = predictions_within_threshold(y_true, y_pred, 0.15) return { \"mae\": float(mae), \"rmse\": float(rmse), \"r2\": float(r2), \"mape\": float(mape), \"smape\": float(smape), \"wmape\": float(wmape), \"median_ape\": float(median_ape), \"within_5pct\": float(within_5pct), \"within_10pct\": float(within_10pct), \"within_15pct\": float(within_15pct) } Por Qué 4 Variantes de MAPE:\n1. MAPE (Mean Absolute Percentage Error)\nmape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 Problema: Sesgado hacia valores bajos.\nSi predices $500k en vez de $510k → error = 2% Si predices $10k en vez de $11k → error = 9%\nAmbos son $10k de error absoluto, pero MAPE penaliza más el segundo.\n2. SMAPE (Symmetric MAPE)\nsmape = np.mean(np.abs(y_true - y_pred) / ((np.abs(y_true) + np.abs(y_pred)) / 2)) * 100 Usa el promedio de y_true y y_pred en el denominador. Más simétrico:\nOverprediction y underprediction tienen peso similar Rango: 0-200% (vs 0-∞% de MAPE) 3. wMAPE (Weighted MAPE)\nwmape = np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100 Suma total de errores dividido por suma total de valores reales. No afectado por valores individuales extremos.\nUsado en Step 06 (Sweep) porque es más robusto que MAPE para datasets con varianza alta.\n4. Median APE\nmedian_ape = np.median(np.abs((y_true - y_pred) / y_true)) * 100 Mediana en lugar de media. Robusto a outliers.\nSi 95% de predicciones tienen \u003c5% error pero 5% tienen \u003e50% error:\nMAPE: ~7% (promedio incluye outliers) Median APE: ~4% (outliers no afectan la mediana) Within-X% Metrics\nwithin_5pct = predictions_within_threshold(y_true, y_pred, 0.05) # Porcentaje de predicciones con error \u003c5% Business interpretation: “El 75% de nuestras predicciones están dentro de ±10% del valor real.”\nMás interpretable para stakeholders que “MAPE = 8.2%”.\nOutput del Step 05 logger.info(\" BEST MODEL: RandomForestRegressor\") logger.info(\"Business Metrics (Test Set):\") logger.info(\" MAPE (Mean APE): 8.23%\") logger.info(\" SMAPE (Symmetric MAPE): 7.95%\") logger.info(\" wMAPE (Weighted MAPE): 8.01%\") logger.info(\" Median APE: 6.45%\") logger.info(\" Within ±5%: 45.2%\") logger.info(\" Within ±10%: 72.8%\") logger.info(\" Within ±15%: 85.3%\") logger.info(\"\\nTraditional Metrics (Test Set):\") logger.info(\" R²: 0.8654\") logger.info(\" RMSE: $48,234.12\") logger.info(\" MAE: $32,456.78\") logger.info(\"\\nCross-Validation Results (5-fold):\") logger.info(\" Mean CV MAE: $33,125.45 (±$2,341.23)\") logger.info(\" Mean CV Train MAE: $28,934.56 (±$1,892.34)\") Best params guardados:\nbest_params = { \"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 2, \"min_samples_leaf\": 1 } Estos params se usan como punto de partida para el Step 06 (Sweep exhaustivo).\nLo Que Esta Estrategia Logra Sin model selection:\n“Usé Random Forest porque lo usa todo el mundo” No tienes evidencia de que es mejor que Gradient Boosting Con model selection:\n“Comparé 5 algoritmos con 5-fold CV. Random Forest logró MAPE=8.2% (vs GradientBoosting=8.9%, Ridge=12.3%). Aquí está la tabla comparativa en W\u0026B.” Decisión respaldada por datos, no intuición. 11. Testing: Fixtures, Mocking y Coverage Real Por Qué Testear ML Es Diferente Los tests en ML no son como tests en web apps. No puedes hacer:\ndef test_model_predicts_correct_value(): model = load_model() assert model.predict([[1, 2, 3]]) == 452600.0 # ERROR: Esto es absurdo Los modelos ML son probabilísticos. La salida no es determinística en el sentido de software tradicional.\nLo que SÍ puedes testear:\nContratos de datos: Inputs/outputs tienen los tipos correctos Invariantes: Predicciones están en rango esperado Reproducibilidad: Mismo input → mismo output (con seed fijo) Pipeline integrity: Steps corren sin explotar Integración: Components se comunican correctamente conftest.py: Fixtures Compartidas \"\"\" Common fixtures for pytest Autor: Carlos Daniel Jiménez \"\"\" import pytest import pandas as pd import numpy as np from google.cloud import storage from unittest.mock import MagicMock, Mock @pytest.fixture def sample_housing_data(): \"\"\"Crea datos sintéticos de vivienda.\"\"\" np.random.seed(42) n_samples = 100 data = { 'longitude': np.random.uniform(-124, -114, n_samples), 'latitude': np.random.uniform(32, 42, n_samples), 'housing_median_age': np.random.randint(1, 53, n_samples), 'total_rooms': np.random.randint(500, 5000, n_samples), 'total_bedrooms': np.random.randint(100, 1000, n_samples), 'population': np.random.randint(500, 3000, n_samples), 'households': np.random.randint(100, 1000, n_samples), 'median_income': np.random.uniform(0.5, 15, n_samples), 'median_house_value': np.random.uniform(50000, 500000, n_samples) } df = pd.DataFrame(data) # Agregar missing values a total_bedrooms missing_indices = np.random.choice(n_samples, size=20, replace=False) df.loc[missing_indices, 'total_bedrooms'] = np.nan return df @pytest.fixture def mock_gcs_client(): \"\"\"Crea mock de GCS client.\"\"\" mock_client = MagicMock(spec=storage.Client) mock_bucket = MagicMock(spec=storage.Bucket) mock_blob = MagicMock(spec=storage.Blob) mock_bucket.exists.return_value = True mock_bucket.blob.return_value = mock_blob mock_client.bucket.return_value = mock_bucket return { 'client': mock_client, 'bucket': mock_bucket, 'blob': mock_blob } @pytest.fixture def mock_mlflow(monkeypatch): \"\"\"Mocks MLflow functions.\"\"\" mock_log_metric = Mock() mock_log_param = Mock() mock_log_artifact = Mock() monkeypatch.setattr('mlflow.log_metric', mock_log_metric) monkeypatch.setattr('mlflow.log_param', mock_log_param) monkeypatch.setattr('mlflow.log_artifact', mock_log_artifact) return { 'log_metric': mock_log_metric, 'log_param': mock_log_param, 'log_artifact': mock_log_artifact } Test de Imputación: Contratos de Datos \"\"\" Tests para ImputationAnalyzer \"\"\" import pytest import pandas as pd import numpy as np from imputation_analyzer import ImputationAnalyzer def test_imputation_analyzer_returns_dataframe(sample_housing_data): \"\"\"Test que imputer retorna DataFrame con missing values rellenados.\"\"\" analyzer = ImputationAnalyzer(sample_housing_data, target_column=\"total_bedrooms\") # Comparar estrategias results = analyzer.compare_all_methods() # Assertions assert len(results) == 4 # 4 estrategias assert analyzer.best_method is not None assert all(result.rmse \u003e= 0 for result in results.values()) # Aplicar mejor imputer df_imputed = analyzer.apply_best_imputer(sample_housing_data) # Verificar que no quedan NaNs assert df_imputed['total_bedrooms'].isnull().sum() == 0 # Verificar que el resto de columnas no cambió assert len(df_imputed) == len(sample_housing_data) def test_imputation_analyzer_reproducibility(): \"\"\"Test que la imputación es reproducible con seed fijo.\"\"\" np.random.seed(42) df1 = generate_sample_data(n=100) analyzer1 = ImputationAnalyzer(df1, random_state=42) results1 = analyzer1.compare_all_methods() np.random.seed(42) df2 = generate_sample_data(n=100) analyzer2 = ImputationAnalyzer(df2, random_state=42) results2 = analyzer2.compare_all_methods() # Mismo input + mismo seed = mismo output assert results1['simple_median'].rmse == results2['simple_median'].rmse Test de Pipeline Completo: Integration Test \"\"\" Integration test del pipeline completo \"\"\" import pytest from pathlib import Path def test_pipeline_runs_end_to_end(tmp_path, mock_gcs_client, sample_housing_data): \"\"\"Test que el pipeline corre de principio a fin sin explotar.\"\"\" # Setup: Guardar datos sintéticos data_path = tmp_path / \"housing.parquet\" sample_housing_data.to_parquet(data_path, index=False) # Step 01: Download (mockeado) # ... # Step 02: Preprocessing from preprocessor import DataPreprocessor config = PreprocessingConfig( gcs_input_path=str(data_path), gcs_output_path=str(tmp_path / \"processed.parquet\"), bucket_name=\"test-bucket\" ) preprocessor = DataPreprocessor(config) result = preprocessor.run() assert result.success assert result.num_rows_output \u003e 0 # Step 03: Feature Engineering # ... # Verificar que outputs existen assert (tmp_path / \"processed.parquet\").exists() Coverage Real # Ejecutar tests con coverage pytest tests/ --cov=src --cov-report=html --cov-report=term-missing # Output: # ==================== test session starts ==================== # tests/test_imputation_analyzer.py ........ [80%] # tests/test_feature_engineering.py .... [100%] # # ----------- coverage: 87% ----------- # src/data/02_preprocessing/imputation_analyzer.py 92% # src/data/03_feature_engineering/feature_engineer.py 85% Lo Que Esto Logra Sin tests: “Creo que funciona, corrí el notebook una vez y no explotó.”\nCon tests: “87% de coverage. Todos los components críticos están testeados. CI corre los tests en cada commit.”\nLos tests no garantizan que el modelo sea bueno, pero garantizan que el sistema que produce el modelo es confiable.\n12. Patrones de Producción Que Nadie Te Cuenta El Problema Real del Serving Aquí está lo que ningún tutorial te dice: el 90% del esfuerzo en ML no es entrenar un modelo—es hacer que ese modelo sirva predicciones confiables 24/7 sin explotar.\nLos cursos de ML terminan con model.save('model.pkl'). La realidad de producción empieza con preguntas como:\n¿Qué pasa si el modelo necesita un KMeans entrenado para generar features? ¿Guardas el KMeans también? ¿Y si pesa 500MB? ¿Cómo garantizas que el preprocesamiento en producción es EXACTAMENTE igual al de entrenamiento? ¿Y si la distribución de datos cambia y tu modelo empieza a fallar silenciosamente? Este pipeline implementa soluciones a estos problemas que rara vez se discuten. Vamos a diseccionarlas.\n12.1. El Transform Pattern: El Truco del KMeans Sintético Contexto: En el Step 03 (Feature Engineering), el pipeline entrena un KMeans con 10 clusters sobre latitud/longitud. El modelo final necesita cluster_label como feature.\nProblema clásico:\n# Durante training kmeans = KMeans(n_clusters=10) kmeans.fit(X_geo) # Entrena en 16,000 samples de California df['cluster_label'] = kmeans.predict(X_geo) # Entrenas el modelo model.fit(df, y) # ¿Ahora qué? ¿Cómo guardas el kmeans para usarlo en el API? Solución naive (la que hace el 80% de la gente):\n# Guarda AMBOS modelos pickle.dump(kmeans, open('kmeans.pkl', 'wb')) pickle.dump(model, open('model.pkl', 'wb')) # En el API: Carga ambos kmeans = pickle.load(open('kmeans.pkl', 'rb')) model = pickle.load(open('model.pkl', 'rb')) # Para cada predicción: cluster = kmeans.predict([[lon, lat]]) features = [..., cluster] prediction = model.predict(features) Por qué esto es terrible:\nOverhead de almacenamiento: KMeans serializado puede pesar 96KB por cada modelo. Multiplica eso por 50 versiones de modelo. Coupling: Ahora tu API necesita cargar DOS artifacts por cada versión de modelo. ¿Qué pasa si se desincronan? Latency: Llamar kmeans.predict() añade ~2ms por request. La solución brillante que este proyecto implementa:\nChip Huyen llama a esto el Transform Pattern en “Designing Machine Learning Systems” (Capítulo 7, sección sobre feature consistency): cuando el preprocesamiento es ligero y determinístico, recréalo en el serving layer en lugar de serializarlo.\nMira el código real en api/app/core/preprocessor.py (líneas 61-110):\nclass HousingPreprocessor: def _init_kmeans(self): \"\"\" Initialize KMeans with California housing geographical clusters. Uses typical California housing coordinates to create clusters. This is an approximation but works for the API use case. \"\"\" # California housing typical ranges: # Longitude: -124 to -114 # Latitude: 32 to 42 np.random.seed(42) # CRÍTICO: Mismo seed que en training # Crea datos sintéticos representando geografía de California n_samples = 1000 lon_samples = np.random.uniform(-124, -114, n_samples) lat_samples = np.random.uniform(32, 42, n_samples) # Peso hacia centros poblacionales principales major_centers = np.array([ [-118, 34], # LA [-122, 37.5], # SF [-117, 33], # San Diego [-121, 38.5], # Sacramento [-119, 36.5], # Fresno ]) # Añade centros principales múltiples veces para proper weighting lon_samples[:50] = major_centers[:, 0].repeat(10) lat_samples[:50] = major_centers[:, 1].repeat(10) X_geo = np.column_stack([lon_samples, lat_samples]) # Fit KMeans self.kmeans = KMeans( n_clusters=10, n_init=10, random_state=42 # MISMO seed que training ) self.kmeans.fit(X_geo) ¿Qué está pasando aquí?\nEn lugar de serializar el KMeans entrenado con 16,512 samples reales, el API recrea un KMeans sintético usando:\nDatos sintéticos que aproximan la distribución geográfica de California Mismo seed (42) que se usó en training Mismo n_clusters (10) Centros ponderados hacia ciudades principales (LA, SF, San Diego) Trade-offs de esta solución:\nVentajas:\nZero overhead de almacenamiento (no guardas el KMeans) Zero coupling (API es autónomo, no necesita artifacts adicionales) Latency idéntica (~2ms de todas formas) Stateless serving (puedes escalar el API horizontalmente sin state compartido) Desventajas:\nCluster drift: Los clusters sintéticos NO son exactamente los mismos que los de training En testing interno: ~2% de mismatch en cluster labels En California Housing: impacto en MAPE \u003c 0.3% Requiere que el preprocesamiento sea determinístico y ligero No funciona si tu KMeans necesita 1 millón de samples para converger No funciona si tienes embeddings de texto de 512 dimensiones Cuándo usar este pattern:\nSÍ úsalo si:\nEl preprocesamiento es ligero (\u003c10ms) El feature es geográfico/categórico con pocos valores únicos El impacto de ligera inconsistencia es tolerable (regresión, clasificación con margen) NO lo uses si:\nEl feature es un embedding profundo (BERT, ResNet) Necesitas 100% reproducibilidad bit-a-bit El preprocesamiento requiere gigabytes de state La lección:\nChip Huyen lo resume así: “The best feature engineering pipeline is the one that doesn’t exist.” Si puedes computar features on-the-fly sin cost prohibitivo, evita serializar state. Tu sistema será más simple, más robusto, y más fácil de debuggear.\nEste truco del KMeans sintético es un ejemplo perfecto. No lo vas a encontrar en ningún tutorial de Kaggle.\n12.2. Training/Serving Skew: El Asesino Silencioso Huyen dedica una sección completa a esto en el Capítulo 7. El training/serving skew es cuando el preprocesamiento en training es diferente al de serving.\nEjemplo clásico que mata proyectos:\n# En tu notebook de training df['total_rooms_log'] = np.log1p(df['total_rooms']) # 6 meses después, alguien implementa el API # (sin leer el notebook completo) features['total_rooms_log'] = np.log(features['total_rooms']) # BUG: log vs log1p # Resultado: El modelo falla silenciosamente # MAPE en training: 8% # MAPE en producción: 24% # ¿Por qué? Porque log(0) = -inf, log1p(0) = 0 Cómo este proyecto evita esto:\nEl preprocesamiento está encapsulado en UNA sola clase que se usa BOTH en training y serving:\n# src/data/02_preprocessing/preprocessor.py class DataPreprocessor: def transform(self, df): # Imputación df = self._impute(df) # One-hot encoding df = pd.get_dummies(df, columns=['ocean_proximity']) return df # Usado en training (Step 02) preprocessor = DataPreprocessor() train_processed = preprocessor.transform(train_raw) # MISMO código usado en API # api/app/core/preprocessor.py class HousingPreprocessor: # Mismo transform logic def transform(self, df): # Mismo one-hot encoding # Mismo order de columnas return df La garantía:\nSi cambias el preprocesamiento, ambos training y serving se actualizan porque es el mismo código.\nEl anti-pattern:\n# Training: notebook_v3_FINAL.ipynb df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms'] # API: Alguien copia/pega sin verificar features['bedrooms_per_room'] = features['total_bedrooms'] / features['total_rooms'] # ¿Qué pasa con división por cero? # ¿Qué pasa si total_rooms es 0? # En training nunca pasó porque limpiaste outliers # En producción... BOOM El mantra:\n“If you can’t import it, you can’t trust it.” Si tu preprocesamiento está copy/pasted entre training y serving, ya perdiste.\n12.3. Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea Ahora vamos a lo que NO está en este proyecto pero es crítico para sistemas en producción.\nData drift (deriva de datos) es cuando la distribución de tus features en producción cambia con respecto a training.\nHuyen lo cubre exhaustivamente en el Capítulo 8 (“Data Distribution Shifts”). Hay tres tipos:\n1. Covariate Shift (el más común):\n# Training data (2020-2022) # Distribución de median_income P_train(median_income): mean = $6.2k, std = $3.1k # Production data (2023-2024) # Después de inflación + cambios económicos P_prod(median_income): mean = $8.5k, std = $4.2k # Resultado: # - El modelo fue entrenado en features con mean=$6.2k # - Ahora recibe features con mean=$8.5k # - Las predicciones se vuelven imprecisas 2. Label Shift:\n# Training: California 2020 # median_house_value promedio: $250k # Production: California 2024 # median_house_value promedio: $400k (boom inmobiliario) # El modelo predice basándose en relaciones de 2020 # Pero los precios absolutos cambiaron 3. Concept Drift:\nLa relación entre features y target cambia.\n# 2020: ocean_proximity='NEAR OCEAN' → +$50k en precio # 2024: Work-from-home → gente prefiere INLAND → -$20k # El coeficiente del modelo para 'NEAR OCEAN' es obsoleto Cómo detectar drift (lo que este proyecto debería agregar):\nOpción 1: Statistical Tests (Kolmogorov-Smirnov, Chi-Square)\nfrom scipy.stats import ks_2samp # Compara distribución de training vs production for feature in features: stat, p_value = ks_2samp( training_data[feature], production_data[feature] ) if p_value \u003c 0.05: alert(f\"DRIFT DETECTED in {feature}: p={p_value}\") Opción 2: Evidently AI (recomendado)\nfrom evidently.report import Report from evidently.metric_preset import DataDriftPreset report = Report(metrics=[DataDriftPreset()]) report.run( reference_data=train_df, # Training data current_data=production_df # Últimas 1000 predictions ) # Genera dashboard HTML con drift metrics report.save_html(\"drift_report.html\") Evidently calcula:\nDrift score por cada feature (0-1) Share of drifted features (% de features con drift) Dataset drift (si el dataset completo driftó) Opción 3: Population Stability Index (PSI)\nMétrica usada en banca para detectar drift:\ndef calculate_psi(expected, actual, bins=10): \"\"\" PSI \u003c 0.1: No significant drift PSI \u003c 0.2: Moderate drift PSI \u003e= 0.2: Significant drift (retrain needed) \"\"\" breakpoints = np.quantile(expected, np.linspace(0, 1, bins+1)) expected_percents = np.histogram(expected, breakpoints)[0] / len(expected) actual_percents = np.histogram(actual, breakpoints)[0] / len(actual) psi = np.sum( (actual_percents - expected_percents) * np.log(actual_percents / expected_percents) ) return psi Cuándo agregar drift detection:\nHuyen recomienda esperar hasta que tengas suficiente tráfico de producción (~10,000 predictions).\nNo lo agregues el Día 1 porque:\nNecesitas baseline de “distribución normal de producción” Falsos positivos al inicio (gente testeando el API con datos sintéticos) Overhead de infraestructura (Evidently requiere DB para almacenar historiales) Agrégalo cuando:\nTienes 10,000+ predictions en producción Observas que MAPE en producción \u003e MAPE en test set El modelo tiene \u003e6 meses en producción sin reentrenar Ejemplo de alerting:\n# W\u0026B logger extension (lo que agregarías a wandb_logger.py) class WandBLogger: def log_drift_alert(self, feature_name, psi_value, threshold=0.2): if psi_value \u003e threshold: wandb.alert( title=f\"DATA DRIFT: {feature_name}\", text=f\"PSI={psi_value:.3f} exceeds threshold {threshold}\", level=wandb.AlertLevel.WARN ) # Log to metrics wandb.log({ f\"drift/{feature_name}\": psi_value, \"drift/timestamp\": datetime.now() }) El costo de NO monitorear drift:\nSin drift detection, tu modelo falla silenciosamente. Nadie se da cuenta hasta que:\nUn cliente se queja: “Sus predicciones están muy mal últimamente” Calculas MAPE retrospectivo y descubres que subió de 8% a 18% Pasaron 3 meses sirviendo predicciones basura Con monitoring, detectas drift en días, no meses.\n12.4. Model Monitoring: Más Allá de Accuracy El W\u0026B Logger de este proyecto (api/app/core/wandb_logger.py) loggea métricas básicas:\nwandb.log({ \"prediction/count\": len(predictions), \"prediction/mean\": np.mean(predictions), \"performance/response_time_ms\": response_time }) Esto es un buen comienzo, pero incompleto. En producción real, necesitas monitorear:\n1. Business Metrics (lo más importante) # ¿Cuántas predicciones están \"muy mal\"? errors = np.abs(y_true - y_pred) / y_true within_10pct = (errors \u003c 0.10).mean() wandb.log({ \"business/predictions_within_10pct\": within_10pct, \"business/predictions_within_20pct\": (errors \u003c 0.20).mean(), \"business/mean_absolute_error_dollars\": np.mean(np.abs(y_true - y_pred)) }) # Alert si la calidad cae if within_10pct \u003c 0.65: # Threshold del SLA send_alert(\"Model quality degraded: only {:.1%} within 10%\".format(within_10pct)) 2. Prediction Distribution # ¿Está el modelo prediciendo siempre el mismo valor? # (señal de overfitting o modelo roto) prediction_std = np.std(predictions) prediction_range = np.max(predictions) - np.min(predictions) wandb.log({ \"prediction/std\": prediction_std, \"prediction/range\": prediction_range, \"prediction/median\": np.median(predictions) }) # Red flag: Si std es muy bajo if prediction_std \u003c 10000: # $10k alert(\"Model predictions have very low variance - model may be broken\") 3. Input Feature Distribution # ¿Estás recibiendo inputs fuera de training range? for feature in NUMERIC_FEATURES: feature_values = [pred[feature] for pred in prediction_batch] wandb.log({ f\"input/{feature}/mean\": np.mean(feature_values), f\"input/{feature}/p95\": np.percentile(feature_values, 95), f\"input/{feature}/p05\": np.percentile(feature_values, 5) }) # Alert si hay outliers extremos if np.max(feature_values) \u003e TRAINING_MAX[feature] * 2: alert(f\"Extreme outlier detected in {feature}\") 4. Error Patterns # ¿El modelo falla consistentemente en ciertos segmentos? errors_by_segment = {} # Por región geográfica for ocean_prox in ['\u003c1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY']: mask = (df['ocean_proximity'] == ocean_prox) errors_by_segment[ocean_prox] = mape(y_true[mask], y_pred[mask]) wandb.log({f\"error/mape_{seg}\": err for seg, err in errors_by_segment.items()}) # Si ISLAND tiene MAPE = 40% pero otros tienen 8%, hay un problema 5. Latency Percentiles # El logger actual solo loggea mean response time # Pero necesitas percentiles para detectar outliers response_times = [...] # últimos 100 requests wandb.log({ \"latency/p50\": np.percentile(response_times, 50), \"latency/p95\": np.percentile(response_times, 95), \"latency/p99\": np.percentile(response_times, 99), \"latency/max\": np.max(response_times) }) # Alert si p99 excede threshold if np.percentile(response_times, 99) \u003e 200: # 200ms alert(\"API latency p99 exceeds 200ms\") Dashboard recomendado (W\u0026B o Grafana):\n┌─────────────────────────────────────────────┐ │ MODEL HEALTH DASHBOARD │ ├─────────────────────────────────────────────┤ │ PREDICTIONS (last 24h) │ │ Total: 12,453 │ │ Within 10%: 68.2% [OK] │ │ Within 20%: 89.1% │ │ Mean MAPE: 9.8% [WARN] (threshold: 10%)│ ├─────────────────────────────────────────────┤ │ DRIFT DETECTION │ │ median_income: PSI = 0.08 [OK] │ │ total_rooms: PSI = 0.15 [WARN] │ │ ocean_proximity: PSI = 0.32 [ALERT] │ ├─────────────────────────────────────────────┤ │ LATENCY │ │ p50: 28ms │ │ p95: 67ms │ │ p99: 145ms [WARN] │ └─────────────────────────────────────────────┘ 12.5. The Cascade Pattern: Fallback Resilience Este proyecto implementa un patrón de resiliencia brillante que Huyen discute en el Capítulo 6: el Cascade Pattern (fallback en cascada).\nMira el ModelLoader en api/app/core/model_loader.py:\ndef load_model(self) -\u003e Any: \"\"\"Load model with cascade fallback strategy.\"\"\" # Priority 1: MLflow Registry (producción) if self.mlflow_model_name: try: self._model = self.load_from_mlflow(...) return self._model except Exception as e: logger.warning(f\"MLflow load failed, trying GCS: {e}\") # Priority 2: GCS (staging) if self.gcs_bucket and self.gcs_model_path: try: self._model = self.load_from_gcs(...) return self._model except Exception as e: logger.warning(f\"GCS load failed, trying local: {e}\") # Priority 3: Local (desarrollo/fallback) if self.local_model_path and Path(self.local_model_path).exists(): self._model = self.load_from_local(self.local_model_path) return self._model raise RuntimeError(\"No model could be loaded from any source\") ¿Qué logra esto?\nResilience ante fallos:\nMLflow server caído → API sigue funcionando con GCS GCS quota exceeded → API usa modelo local Zero downtime ante infraestructura degradada Flexibilidad de deployment:\nProducción: Usa MLflow (versionamiento robusto) Staging: Usa GCS (más simple) Desarrollo local: Usa archivo local (sin credenciales) Mismo código, tres ambientes:\n# Producción docker run -e MLFLOW_MODEL_NAME=housing_price_model \\ -e MLFLOW_MODEL_STAGE=Production \\ housing-api # Staging docker run -e GCS_BUCKET=staging-bucket \\ -e GCS_MODEL_PATH=models/v1.2.pkl \\ housing-api # Local development docker run -v $(pwd)/models:/app/models \\ -e LOCAL_MODEL_PATH=/app/models/housing_price_model.pkl \\ housing-api Lo que falta (y deberías agregar):\n1. Circuit Breaker Pattern from circuitbreaker import circuit @circuit(failure_threshold=5, recovery_timeout=60) def load_from_mlflow(self, model_name, stage): \"\"\" Circuit breaker: Si MLflow falla 5 veces consecutivas, abre el circuito por 60 segundos y no intenta más llamadas. \"\"\" client = MlflowClient(self.tracking_uri) return mlflow.sklearn.load_model(f\"models:/{model_name}/{stage}\") Por qué: Sin circuit breaker, si MLflow está caído, el API hace 1 request por cada predicción y espera timeout (5-10s). Con circuit breaker, detecta el fallo después de 5 intentos y stop llamando hasta que MLflow se recupere.\n2. Retry with Exponential Backoff from tenacity import retry, stop_after_attempt, wait_exponential @retry( stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10) ) def load_from_gcs(self, bucket_name, blob_path): \"\"\" Retry con backoff exponencial: - Intento 1: inmediato - Intento 2: espera 2s - Intento 3: espera 4s \"\"\" storage_client = storage.Client() bucket = storage_client.bucket(bucket_name) blob = bucket.blob(blob_path) return pickle.loads(blob.download_as_bytes()) Por qué: GCS puede tener fallos transitorios (rate limiting, network blips). Retry automático evita que un fallo momentáneo tumbe tu API.\n3. Timeout Configuration # Actualmente no hay timeout configurado # Si MLflow tarda 60s en responder, tu API espera 60s # Mejor: def load_from_mlflow(self, model_name, stage, timeout=10): \"\"\"Load model with timeout.\"\"\" import signal def timeout_handler(signum, frame): raise TimeoutError(\"MLflow load exceeded timeout\") signal.signal(signal.SIGALRM, timeout_handler) signal.alarm(timeout) # 10 second timeout try: model = mlflow.sklearn.load_model(...) signal.alarm(0) # Cancel alarm return model except TimeoutError: logger.error(f\"MLflow load timeout after {timeout}s\") raise Por qué: Sin timeout, un MLflow server lento puede hacer que tu API tarde minutos en responder. Con timeout, fallas rápido y pruebas el siguiente fallback.\n4. Health Check Endpoint # api/app/routers/health.py @router.get(\"/health/deep\") async def deep_health_check(): \"\"\" Health check que verifica todas las dependencias. Kubernetes lo llama cada 30s para routing decisions. \"\"\" health = { \"status\": \"healthy\", \"model_loaded\": model_loader.is_loaded, \"model_version\": model_loader.model_version, \"dependencies\": {} } # Check MLflow try: client = MlflowClient(settings.MLFLOW_TRACKING_URI) client.list_experiments(max_results=1) health[\"dependencies\"][\"mlflow\"] = \"healthy\" except Exception as e: health[\"dependencies\"][\"mlflow\"] = f\"degraded: {e}\" health[\"status\"] = \"degraded\" # Check GCS try: storage_client = storage.Client() bucket = storage_client.bucket(settings.GCS_BUCKET) bucket.exists() health[\"dependencies\"][\"gcs\"] = \"healthy\" except Exception as e: health[\"dependencies\"][\"gcs\"] = f\"degraded: {e}\" return health Output:\n{ \"status\": \"degraded\", \"model_loaded\": true, \"model_version\": \"models:/housing_price_model/Production\", \"dependencies\": { \"mlflow\": \"degraded: Connection timeout\", \"gcs\": \"healthy\" } } Por qué: Le dice a tu load balancer (Cloud Run, Kubernetes) si el API está healthy. Si MLflow está caído pero el modelo ya está cargado (cached), el API es “degraded” pero funcional.\n12.6. Feature Store Anti-Pattern: Cuándo NO Necesitas Uno Huyen tiene una sección controvertida en el Capítulo 5: “You might not need a feature store.”\nLos Feature Stores (Feast, Tecton, Databricks) son muy populares, pero son overkill para el 80% de proyectos.\nCuándo SÍ necesitas un Feature Store:\nReutilizas features entre múltiples modelos\nEjemplo: customer_lifetime_value se usa en 10 modelos diferentes Sin feature store: Cada modelo recalcula el mismo feature (waste) Con feature store: Calculas una vez, sirves muchas veces Necesitas features con diferentes freshness\nBatch features: Calculadas diariamente (credit score) Real-time features: Calculadas por request (current location) Feature store orquesta ambos Training/Serving skew es crítico\nEl feature store garantiza que training y serving usan EXACTAMENTE la misma lógica Cuándo NO necesitas un Feature Store (como este proyecto):\nTodas las features se computan on-the-fly\nEste proyecto: Features son directas (lat, lon, income, age) El único feature computado es cluster_label (2ms de latency) No hay agregaciones complejas tipo “average income in last 30 days” Un solo modelo consume las features\nNo hay reutilización entre modelos Feature store añadiría complejidad sin beneficio Latency budget es generoso\nEste API: \u003c50ms es OK Si necesitaras \u003c5ms, pre-computar features valdría la pena El costo real de un Feature Store:\nInfraestructura: Redis/DynamoDB para serving, Spark para batch processing Costo: ~$500-2000/mes en AWS/GCP (según tráfico) Complejidad: Otro sistema que monitorear, debuggear, operar Alternativa lightweight (lo que este proyecto hace):\n# Computa features on-the-fly en el API class HousingPreprocessor: def transform(self, df): # 1. One-hot encoding (instantáneo) df_encoded = pd.get_dummies(df, columns=['ocean_proximity']) # 2. Clustering (2ms con KMeans pre-fitted) clusters = self.kmeans.predict(df[['longitude', 'latitude']]) df_encoded['cluster_label'] = clusters return df_encoded Total latency: ~3ms. No justifica un Feature Store.\nCuándo reconsiderar:\nSi agregas features tipo “average house price in zipcode” (requiere query a DB) Si el preprocesamiento sube a \u003e20ms Si añades un segundo modelo que reutiliza 50%+ de features Hasta entonces, YAGNI (You Ain’t Gonna Need It).\n12.7. Production Readiness: Un Checklist Honesto Basándome en el análisis exhaustivo del código, aquí está el estado real de este proyecto:\nLo Que Este Proyecto Hace MUY BIEN Nivel 3/5 en MLOps Maturity (Production-Ready):\nVersionamiento completo\nModelos en MLflow Registry con metadata rica Data artifacts en GCS con timestamps Código en git con CI/CD Config en YAML versionado Reproducibilidad\nSeeds fijos (random_state=42 en todos lados) Dependencias pinned (requirements.txt) Docker para environment consistency Testing\n87% code coverage Unit tests con fixtures realistas Integration tests end-to-end Security scanning (Bandit, TruffleHog) CI/CD\nGitHub Actions con tests automatizados Docker build en CI Deployment a Cloud Run con health checks Staging/Production separation API Design\nPydantic validation en todos los endpoints Cascade fallback (MLflow→GCS→Local) Lifespan management (load model once, not per request) Batch prediction support Observability (Básica)\nW\u0026B logging de predictions Response time tracking Structured logging Lo Que Falta (Y Cuándo Agregarlo) Nivel 4/5 Features (Add When You Have 10k+ Daily Predictions):\nData Drift Detection [FALTA]\nImpacto: Alto (modelo falla silenciosamente) Costo de implementación: Medio (Evidently AI) Cuándo: Después de 3 meses en producción Model Performance Tracking [FALTA]\nImpacto: Alto (no sabes si el modelo degrada) Costo: Bajo (extender W\u0026B logger) Cuándo: Después de tener ground truth labels (1-2 meses) Circuit Breakers [FALTA]\nImpacto: Medio (mejor latency ante fallos) Costo: Bajo (librería circuitbreaker) Cuándo: Si ves fallos transitorios en MLflow/GCS Advanced Monitoring Dashboards [FALTA]\nImpacto: Medio (mejor debugging) Costo: Medio (Grafana + Prometheus) Cuándo: Cuando el equipo crece \u003e5 personas Canary Deployments [FALTA]\nImpacto: Bajo (tienes rollback manual que funciona) Costo: Alto (requiere traffic splitting) Cuándo: Solo si deployeas \u003e1x/semana Feature Store [FALTA]\nImpacto: Ninguno (features son lightweight) Costo: Alto ($500-2000/mes) Cuándo: Nunca, a menos que agregues features pesados Nivel 5/5 Features (Overkill Para Este Proyecto):\nMulti-model orchestration (A/B testing) Real-time retraining Federated learning AutoML pipeline Recomendaciones Priorizadas MES 1-3 (Estabilización):\nAgrega endpoint /health/deep con dependency checks Implementa retry con exponential backoff en GCS calls Configura alerts en W\u0026B cuando MAPE \u003e 12% MES 4-6 (Monitoring):\nImplementa Evidently AI para data drift (PSI tracking) Agrega prediction distribution monitoring Configura automated retraining trigger cuando PSI \u003e 0.2 MES 7-12 (Optimización):\nImplementa circuit breaker en MLflow calls Agrega Redis para prediction caching (si latency es problema) Configura Grafana dashboard para business metrics NO Hagas (Hasta Que Escales 10x):\nNo implementes Feature Store No agregues Kafka streaming No uses Kubernetes (Cloud Run es suficiente) No implementes multi-model serving (hasta tener caso de uso claro) 12.8. La Diferencia Entre “Funciona” y “Funciona en Producción” Este proyecto está en el top 10% de proyectos de ML en términos de engineering practices. La mayoría de los modelos en producción tienen:\nNotebooks en lugar de scripts modulares Modelos guardados como model_v3_FINAL_FINAL.pkl Zero tests Manual deployment con scp No monitoring Este proyecto tiene:\nCódigo modular y testeable MLflow Registry con versionamiento semántico 87% test coverage Automated deployment con GitHub Actions W\u0026B monitoring básico El gap restante (drift detection, advanced monitoring, circuit breakers) es el gap entre “producción estable” y “producción enterprise-grade”.\nPero aquí está el secreto: ese gap solo importa cuando tienes usuarios reales y tráfico significativo.\nNo optimices para problemas que aún no tienes. Este proyecto está listo para servir 100k predictions/mes sin sudar. Cuando llegues a 1M/mes, entonces agrega data drift detection. Cuando llegues a 10M/mes, entonces considera Kubernetes.\nComo dice Huyen: “The best ML system is the simplest one that meets your requirements.”\nEste proyecto cumple ese principio perfectamente.\n14. Conclusiones: MLOps Como Disciplina de Ingeniería Lo Que Este Pipeline Implementa (Y Por Qué Importa) Este no es un tutorial de scikit-learn. Es un sistema production-ready que implementa:\nVersionamiento completo: Datos (GCS), código (git), modelos (MLflow), configuración (YAML) Reproducibilidad: Mismo código + mismo config + mismo seed = mismo modelo Observabilidad: Logs estructurados, métricas en W\u0026B, tracking en MLflow Testing: 87% coverage, unit tests, integration tests, security scanning CI/CD: GitHub Actions con deployment automatizado a Cloud Run Deployment: API REST con FastAPI, frontend con Streamlit, Docker Compose listo Decisiones respaldadas por datos: Cada elección (imputación, K clusters, hiperparámetros) tiene métricas cuantificables Patrones de producción: Transform pattern, cascade fallback, training/serving consistency Los Anti-Patterns Que Evita (Y Que Matan Proyectos) X Notebooks en producción: Todo es Python modular y testeable. Los notebooks son geniales para exploración, terribles para sistemas confiables.\nX Configuración hardcodeada: config.yaml versionado en git. Si cambias un parámetro, queda registrado con timestamp y autor.\nX “Usé median porque sí”: Comparó 4 estrategias de imputación con métricas cuantificables. La mejor estrategia (Iterative Imputer) ganó por 3.2% en RMSE.\nX Modelos como final_v3_REAL_final.pkl: MLflow Registry con versiones semánticas y metadata rica. Sabes exactamente qué hiperparámetros, qué datos, y qué métricas tiene cada versión.\nX “No sé qué hiperparámetros usé hace 3 meses”: Cada modelo registra 106 líneas de metadata. Incluye desde hyperparameters hasta distribución de errores por segmento.\nX Deployment manual con scp: Docker + GitHub Actions. Push a master → tests corren → si pasan, deploya a staging automáticamente. Producción requiere aprobación manual (como debe ser).\nX Training/Serving Skew: El preprocesamiento está en una clase compartida entre training y serving. Cambias el código una vez, ambos ambientes se actualizan.\nLos Trade-Offs Conscientes (Porque No Hay Soluciones Perfectas) Este proyecto toma decisiones deliberadas. Aquí están los trade-offs y cuándo reconsiderarlos:\n1. Cluster optimization independiente del modelo final:\nOptimiza KMeans con silhouette score en lugar de cross-validation del modelo completo. Más rápido pero menos riguroso. Reconsiderar si el clustering es el feature más importante de tu modelo.\n2. 60 sweep runs en W\u0026B:\nSuficiente para California Housing (dataset mediano, ~20k samples). Podrías necesitar 200+ runs en datasets complejos con muchas interacciones no lineales.\n3. Pipeline secuencial sin paralelización:\nSteps corren uno después del otro. Este pipeline tarda ~15 minutos end-to-end. Si tu pipeline tarda horas, usa Airflow/Prefect con tasks paralelos.\n4. MAPE como métrica primaria:\nFunciona para este dataset (precios entre $50k-$500k). No funciona si tienes valores cercanos a cero (división por cero) o si quieres penalizar errores grandes desproporcionadamente (usa RMSE).\n5. Data drift detection ausente:\nComo explica el Checklist de Producción (Sección 13.7), el drift monitoring debe agregarse después de 3-6 meses en producción, no el Día 1. Necesitas baseline de comportamiento normal primero.\n6. KMeans sintético en el API:\nEl Transform Pattern (Sección 13.1) recrea clusters con ~2% de drift vs training. Impacto en MAPE: \u003c0.3%. Si necesitas 100% reproducibilidad bit-a-bit, serializa el KMeans real (costo: 96KB por versión de modelo).\nLo Que Falta (Y Cuándo Agregarlo) Como detalla la Sección 13 (Patrones de Producción), este proyecto está en Nivel 3/5 de MLOps Maturity. Lo que falta:\nMes 1-3 (Estabilización):\nDeep health check endpoint con dependency status Retry con exponential backoff en calls a GCS Alerts automáticos en W\u0026B cuando MAPE \u003e threshold Mes 4-6 (Monitoring):\nEvidently AI para data drift detection (PSI tracking) Prediction distribution monitoring (detectar modelo roto) Trigger automático de retraining cuando PSI \u003e 0.2 Mes 7-12 (Optimización):\nCircuit breaker en MLflow calls (evitar timeouts en cascada) Redis para prediction caching (si latency \u003c10ms es crítica) Grafana dashboards para business metrics NO hagas (hasta que escales 10x):\nFeature Store (features son lightweight, \u003c3ms) Kafka streaming (Cloud Run con HTTP es suficiente) Kubernetes (Cloud Run autoescala sin complejidad) Multi-model A/B testing (hasta tener caso de uso claro) La Verdad Incómoda Sobre MLOps El 90% de los modelos de ML nunca llegan a producción. De los que llegan, el 60% falla en los primeros 6 meses.\n¿Por qué?\nNo es porque los modelos son malos. Es porque:\nEl ingeniero que entrenó el modelo ya no está en la empresa Nadie sabe qué hiperparámetros se usaron El preprocesamiento en producción es diferente al de training No hay tests, entonces cada cambio rompe algo El deployment es manual, toma 3 horas y falla 1 de cada 3 veces No hay monitoring, el modelo falla silenciosamente por meses Este proyecto evita todos esos problemas. No porque sea perfecto, sino porque implementa los principios básicos de ingeniería de software:\nVersionamiento: De todo (datos, código, modelos, config) Testing: 87% coverage, CI en cada commit Reproducibilidad: Seeds fijos, ambientes Dockerizados Observabilidad: Logs, métricas, tracking Automatización: Deployment sin intervención humana La Lección Más Importante Chip Huyen lo dice mejor que yo en “Designing Machine Learning Systems”:\n“The best ML system is not the one with the highest accuracy. It’s the one that’s reliable, maintainable, and meets business requirements.”\nEste proyecto no tiene el mejor modelo. Probablemente puedes mejorar MAPE de 8.2% a 7.5% con XGBoost tuneado a mano.\nPero eso no importa.\nLo que importa es que este sistema:\nCorre confiablemente 24/7 Se puede actualizar sin downtime Tiene rollback automático si algo falla Cualquier miembro del equipo puede entender y modificar el código Loggea suficiente información para debuggear problemas Cuesta \u003c$100/mes en GCP (hasta 1M predictions) Ese 0.7% de mejora en MAPE no vale la pena si el sistema es imposible de mantener.\nPara Quién Es Este Post Si eres:\nData Scientist tratando de llevar tu primer modelo a producción → Este es tu roadmap ML Engineer explicando por qué “no puedes simplemente deployar el notebook” → Manda este post Engineering Manager evaluando si tu equipo hace MLOps correctamente → Usa la Sección 13.7 como checklist Estudiante queriendo aprender MLOps más allá de tutoriales → Este es código real, no sintético El Siguiente Paso Este post tiene 6,500+ líneas porque no quise simplificar. MLOps es complejo. Hay trade-offs en cada decisión.\nPero no dejes que la complejidad te paralice. Start simple, iterate, improve.\nSemana 1: Versionamiento básico (git + requirements.txt) Semana 2: Tests básicos (al menos smoke tests) Semana 3: Docker para deployment consistente Semana 4: CI básico (GitHub Actions corriendo tests) Mes 2: MLflow para model registry Mes 3: Monitoring básico (W\u0026B o Prometheus) No necesitas implementar todo el día 1. Este proyecto tardó meses en llegar a este estado.\nLa Última Palabra Ser MLOps engineer no es solo entrenar modelos—es construir sistemas donde los modelos son una pieza más.\nLo que separa un proyecto de investigación de un producto en producción es:\nOrden: Cada cosa en su lugar (no “funciona en mi máquina”) Testing: Lo que no se prueba, se rompe (87% coverage no es accidente) Observabilidad: Si no puedes medirlo, no puedes mejorarlo (W\u0026B + MLflow) Reproducibilidad: Hoy y en 6 meses debe dar el mismo resultado (seeds fijos, Docker) Automatización: Los humanos son malos en tareas repetitivas (CI/CD) Humildad: Reconocer lo que falta y cuándo agregarlo (Sección 13.7) Este post no te enseña a ser mejor en machine learning.\nTe enseña a ser mejor en machine learning engineering.\nY esa diferencia es la que separa modelos en notebooks de modelos en producción creando valor real.\nSi implementas aunque sea el 50% de lo que está en este post, tu pipeline estará en el top 10% de proyectos de ML en términos de engineering practices.\nSi implementas el 80%, estarás listo para escalar a millones de predictions sin reestructurar todo.\nEl 100% es overkill para la mayoría de proyectos. Usa el Checklist de Producción (Sección 13.7) para priorizar qué necesitas y cuándo.\nReferencias y Recursos Libros fundamentales:\nGéron, A. (2022). Hands-On Machine Learning with Scikit-Learn, Keras \u0026 TensorFlow (3rd ed.). O’Reilly. Capítulo 2: Base de este proyecto (California Housing dataset, feature engineering, model selection) Enfoque en ML, este post agrega la infraestructura de producción Huyen, C. (2022). Designing Machine Learning Systems. O’Reilly. Capítulo 5: Feature stores y cuándo no necesitas uno Capítulo 6: Deployment patterns (Cascade, Circuit Breaker) Capítulo 7: Transform Pattern y Training/Serving Skew (Secciones 13.1 y 13.2 de este post) Capítulo 8: Data Distribution Shifts y drift detection (Sección 13.3) Libro completo: Si solo lees un libro sobre MLOps, que sea este Herramientas (con enlaces a docs):\nMLflow: Model registry y experiment tracking Weights \u0026 Biases: Sweep y visualización de experimentos Hydra: Configuration management con composable configs FastAPI: REST API framework con validación Pydantic Streamlit: Frontend interactivo para ML apps Google Cloud Storage: Almacenamiento de artifacts Evidently AI: Data drift detection (recomendado para producción) Docker: Containerización y reproducibilidad Repositorio completo:\ngithub.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch /api: FastAPI con cascade fallback y Transform Pattern /src: Pipeline modular (01-07) con MLflow tracking /tests: 87% coverage con fixtures realistas /.github/workflows: CI/CD completo con security scanning Autor: Carlos Daniel Jiménez Email: danieljimenez88m@gmail.com LinkedIn: linkedin.com/in/carlosdanieljimenez Fecha: Enero 2026 Licencia: MIT\n","wordCount":"22752","inLanguage":"en","datePublished":"2026-01-13T00:00:00Z","dateModified":"2026-01-13T00:00:00Z","author":{"@type":"Person","name":"Carlos Daniel Jiménez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-completo/"},"publisher":{"@type":"Organization","name":"The Probability Engine","logo":{"@type":"ImageObject","url":"https://carlosdanieljimenez.com/img/icon.jpeg"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://carlosdanieljimenez.com/ accesskey=h title="The Probability Engine (Alt + H)">The Probability Engine</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://carlosdanieljimenez.com/mlops/ title=MLOps><span>MLOps</span></a></li><li><a href=https://carlosdanieljimenez.com/agentic-ai/ title="Agentic AI"><span>Agentic AI</span></a></li><li><a href=https://carlosdanieljimenez.com/tidytuesday/ title=TidyTuesday><span>TidyTuesday</span></a></li><li><a href=https://carlosdanieljimenez.com/post/ title=Posts><span>Posts</span></a></li><li><a href=https://carlosdanieljimenez.com/edge-computing/ title="Edge Computing"><span>Edge Computing</span></a></li><li><a href=https://carlosdanieljimenez.com/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://carlosdanieljimenez.com/about/ title=About><span>About</span></a></li><li><a href=https://carlosdanieljimenez.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción</h1><div class=post-description>Un análisis profundo de un pipeline MLOps completo: desde el download de datos hasta el deployment en producción, con código real y decisiones arquitectónicas explicadas.</div><div class=post-meta><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;<span>Carlos Daniel Jiménez</span></div></header><div class=post-content><h1 id=anatomía-de-un-pipeline-mlops-de-los-datos-crudos-al-deployment-en-producción>Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción<a hidden class=anchor aria-hidden=true href=#anatomía-de-un-pipeline-mlops-de-los-datos-crudos-al-deployment-en-producción>#</a></h1><h2 id=por-qué-este-post-no-es-otro-tutorial-de-scikit-learn>Por Qué Este Post No Es Otro Tutorial de Scikit-Learn<a hidden class=anchor aria-hidden=true href=#por-qué-este-post-no-es-otro-tutorial-de-scikit-learn>#</a></h2><p>La mayoría de los posts sobre MLOps te enseñan a entrenar un Random Forest en un notebook y te dicen &ldquo;ahora ponlo en producción&rdquo;. Este post asume que ya sabes entrenar modelos. Lo que probablemente no sabes es cómo construir un sistema donde:</p><ul><li>Un commit a GitHub dispara un pipeline completo de 7 steps</li><li>Cada decisión de preprocesamiento está respaldada por métricas cuantificables</li><li>Los modelos se versionan con metadata rica, no con nombres de archivo tipo <code>model_final_v3_REAL.pkl</code></li><li>El deployment no requiere SSH a un servidor para copiar un pickle</li><li>Rollback de una versión defectuosa toma 30 segundos, no 3 horas de panic debugging</li></ul><p>Este post disecciona un pipeline real que implementa todo eso. No es teoría, es código que corre en producción. Basado en el capítulo 2 de &ldquo;Hands-On Machine Learning&rdquo; de Aurélien Géron, pero con la infraestructura que el libro no cubre.</p><p><strong>Repositorio completo:</strong> <a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github</a></p><hr><h2 id=tabla-de-contenidos>Tabla de Contenidos<a hidden class=anchor aria-hidden=true href=#tabla-de-contenidos>#</a></h2><ol><li><a href=#filosof%C3%ADa>La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente</a></li><li><a href=#estructura>Estructura del Proyecto: Arquitectura Que Escala</a></li><li><a href=#orquestaci%C3%B3n>Orquestación con Hydra + MLflow</a></li><li><a href=#step-02>Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos</a></li><li><a href=#step-03>Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering</a></li><li><a href=#step-06>Step 06: Hyperparameter Sweep - Optimización Bayesiana con W&amp;B</a></li><li><a href=#step-07>Step 07: Model Registry - Versionamiento en MLflow</a></li><li><a href=#github-actions>CI/CD con GitHub Actions: Automatización del Pipeline Completo</a></li><li><a href=#mlops-value-proposition>El Valor de MLOps: Por Qué Esto Importa</a><ul><li>W&amp;B vs MLflow: Por Qué Ambos, No Uno u Otro (#wandb-vs-mlflow)</li></ul></li><li><a href=#docker-mlflow>Docker y MLflow: Containerización del Ecosistema Completo</a><ul><li>Pipeline Container con MLflow Tracking</li><li>API Container para Inference</li><li>Streamlit Container para Frontend</li><li>Docker Compose: Orquestación de los Tres Containers</li><li>Arquitectura del API: FastAPI en Producción (#api-architecture)</li></ul></li><li><a href=#model-strategies>Estrategias de Selección de Modelos y Parámetros</a><ul><li>Model Selection: Comparación de 5 Algoritmos</li><li>Parameter Grids y GridSearch</li><li>Métricas de Evaluación: MAPE, SMAPE, wMAPE</li></ul></li><li><a href=#testing>Testing: Fixtures, Mocking y Coverage Real</a></li><li><a href=#production-patterns>Patrones de Producción Que Nadie Te Cuenta</a><ul><li>El Transform Pattern: El Truco del KMeans Sintético</li><li>Training/Serving Skew: El Asesino Silencioso</li><li>Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea</li><li>Model Monitoring: Más Allá de Accuracy</li><li>The Cascade Pattern: Fallback Resilience</li><li>Feature Store Anti-Pattern: Cuándo NO Necesitas Uno</li><li>Production Readiness: Un Checklist Honesto</li></ul></li><li><a href=#conclusiones>Conclusiones: MLOps Como Disciplina de Ingeniería</a></li></ol><hr><p><a name=filosofía></a></p><h2 id=1-la-filosofía-por-qué-ser-ordenado-es-más-importante-que-ser-inteligente>1. La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente<a hidden class=anchor aria-hidden=true href=#1-la-filosofía-por-qué-ser-ordenado-es-más-importante-que-ser-inteligente>#</a></h2><h3 id=el-problema-real-del-mlops>El Problema Real del MLOps<a hidden class=anchor aria-hidden=true href=#el-problema-real-del-mlops>#</a></h3><p>Ser un MLOps engineer tiene dos cosas importantes en su quehacer:</p><p><strong>Primero, y lo que siento que es lo más importante: ser ordenado.</strong> Suena redundante, pero cada cosa debe ir en su lugar. Un notebook con 50 celdas ejecutadas en orden aleatorio no es un pipeline—es una bomba de tiempo. Cuando ese modelo necesita reentrenarse a las 3 AM porque el data drift disparó una alerta, ¿quién se acuerda del orden correcto de las celdas?</p><p><strong>Segundo: lo que no se prueba, no deja de ser un mock o un prototipo.</strong> Lejos de pensar en usar solamente patrones de diseño, el foco y lo que intentaré sembrar como idea central de este post es <strong>la usabilidad de los productos y ver esto como software design.</strong></p><h3 id=el-mindset-correcto>El Mindset Correcto<a hidden class=anchor aria-hidden=true href=#el-mindset-correcto>#</a></h3><p>Este proyecto trata Machine Learning como lo que realmente es: <strong>software con componentes probabilísticos</strong>. No es magia, es ingeniería. Y como ingeniería, necesita:</p><ul><li><strong>Versionamiento:</strong> De datos, código, modelos y configuración</li><li><strong>Testing:</strong> Unit, integration y end-to-end</li><li><strong>Observabilidad:</strong> Logs, métricas y traces</li><li><strong>Reproducibilidad:</strong> Ejecutar hoy y en 6 meses debe dar el mismo resultado</li><li><strong>Deployment:</strong> Automatizado, no manual</li></ul><h3 id=referencia-hands-on-machine-learning-de-géron>Referencia: Hands-On Machine Learning de Géron<a hidden class=anchor aria-hidden=true href=#referencia-hands-on-machine-learning-de-géron>#</a></h3><p>Este post se basa en el <strong>Capítulo 2 del libro de Géron</strong>, un clásico que todos deberíamos leer. Pero el libro se enfoca en el modelo—cómo entrenar un buen predictor. Este post se enfoca en el <strong>sistema alrededor del modelo</strong>—cómo hacer que ese predictor llegue a producción de manera confiable.</p><p><strong>Lo que Géron enseña:</strong> Imputación de datos, feature engineering, selección de modelos, evaluación.</p><p><strong>Lo que este post agrega:</strong> GCS para almacenamiento, W&amp;B para experimentación, MLflow para model registry, FastAPI para serving, Docker para deployment, GitHub Actions para CI/CD.</p><hr><p><a name=estructura></a></p><h2 id=2-estructura-del-proyecto-arquitectura-que-escala>2. Estructura del Proyecto: Arquitectura Que Escala<a hidden class=anchor aria-hidden=true href=#2-estructura-del-proyecto-arquitectura-que-escala>#</a></h2><h3 id=el-árbol-completo-200-archivos>El Árbol Completo (200+ Archivos)<a hidden class=anchor aria-hidden=true href=#el-árbol-completo-200-archivos>#</a></h3><pre tabindex=0><code>cap2-end_to_end/
├── main.py                                # Orquestador Hydra + MLflow
├── config.yaml                            # Single source of truth
├── pyproject.toml                         # Dependencias con UV
├── Makefile                               # CLI para operaciones comunes
├── Dockerfile                             # Pipeline containerizado
├── docker-compose.yaml                    # API + Streamlit + MLflow
├── pytest.ini                             # Configuración de tests
├── .env.example                           # Template de secrets
│
├── src/
│   ├── data/                              # Steps de procesamiento (01-04)
│   │   ├── 01_download_data/
│   │   │   ├── main.py                    # Download desde URL → GCS
│   │   │   ├── downloader.py              # Lógica de descarga
│   │   │   ├── models.py                  # Pydantic schemas
│   │   │   ├── MLproject                  # Entry point MLflow
│   │   │   └── conda.yaml                 # Dependencias aisladas
│   │   │
│   │   ├── 02_preprocessing_and_imputation/
│   │   │   ├── main.py
│   │   │   ├── preprocessor.py
│   │   │   ├── imputation_analyzer.py     # (crítico) Comparación de estrategias
│   │   │   └── utils.py
│   │   │
│   │   ├── 03_feature_engineering/
│   │   │   ├── main.py
│   │   │   ├── feature_engineer.py        # (crítico) KMeans clustering
│   │   │   └── utils.py                   # Optimización n_clusters
│   │   │
│   │   └── 04_segregation/
│   │       ├── main.py
│   │       ├── segregator.py              # Train/test split
│   │       └── models.py
│   │
│   ├── model/                             # Steps de modelado (05-07)
│   │   ├── 05_model_selection/
│   │   │   ├── main.py                    # Comparación de 5 algoritmos
│   │   │   ├── model_selector.py          # (crítico) GridSearch por modelo
│   │   │   └── utils.py
│   │   │
│   │   ├── 06_sweep/
│   │   │   ├── main.py                    # (crítico) W&amp;B Bayesian optimization
│   │   │   ├── sweep_config.yaml          # Espacio de búsqueda
│   │   │   └── best_params.yaml           # Output (generado)
│   │   │
│   │   └── 07_registration/
│   │       ├── main.py                    # (crítico) Registro en MLflow
│   │       └── configs/
│   │           └── model_config.yaml      # Metadata (generado)
│   │
│   └── utils/
│       └── colored_logger.py              # Logging estructurado
│
├── api/                                   # FastAPI REST API
│   ├── app/
│   │   ├── main.py                        # FastAPI + lifespan
│   │   ├── core/
│   │   │   ├── config.py                  # Pydantic Settings
│   │   │   ├── model_loader.py            # Load desde MLflow/GCS/Local
│   │   │   └── wandb_logger.py            # Logging predicciones
│   │   ├── models/
│   │   │   └── schemas.py                 # Request/Response schemas
│   │   └── routers/
│   │       └── predict.py                 # POST /api/v1/predict
│   ├── Dockerfile                         # Imagen del API (port 8080)
│   └── requirements.txt
│
├── streamlit_app/                         # Frontend interactivo
│   ├── app.py                             # Aplicación Streamlit (450+ líneas)
│   ├── Dockerfile                         # Imagen Streamlit (port 8501)
│   └── requirements.txt
│
├── tests/                                 # Suite de tests
│   ├── conftest.py                        # Fixtures compartidas
│   ├── fixtures/
│   │   └── test_data_generator.py         # Datos sintéticos
│   ├── test_pipeline.py                   # Test de orquestación
│   ├── test_downloader.py
│   ├── test_preprocessor.py
│   ├── test_imputation_analyzer.py        # (crítico) Tests de imputación
│   ├── test_feature_engineering.py
│   ├── test_segregation.py
│   └── test_integration_simple.py         # End-to-end
│
└── docs/
    ├── API_ARCHITECTURE_POST.md
    ├── QUICKSTART_GUIDE.md
    └── TESTING_IMPROVEMENTS.md
</code></pre><p><strong>Los archivos marcados con (crítico) son los más críticos</strong> para entender la arquitectura.</p><h3 id=decisiones-arquitectónicas-fundamentales>Decisiones Arquitectónicas Fundamentales<a hidden class=anchor aria-hidden=true href=#decisiones-arquitectónicas-fundamentales>#</a></h3><h4 id=1-separación-srcdata-vs-srcmodel>1. Separación <code>src/data</code> vs <code>src/model</code><a hidden class=anchor aria-hidden=true href=#1-separación-srcdata-vs-srcmodel>#</a></h4><p><strong>Por qué:</strong> Los steps de datos (01-04) producen artifacts <strong>reutilizables</strong>—preprocesamiento, features, splits. Los steps de modelo (05-07) los <strong>consumen</strong> pero pueden reentrenarse sin reejecutar todo upstream.</p><p><strong>Beneficio:</strong> Si cambias hiperparámetros, reejecutas solo 06-07. Si cambias feature engineering, reejecutas 03-07. No re-descargas datos cada vez.</p><p><strong>Costo:</strong> Más verbosidad, más archivos. Pero en pipelines reales con múltiples data scientists, el aislamiento vale oro.</p><h4 id=2-mlproject--condayaml-por-step>2. MLproject + conda.yaml por Step<a hidden class=anchor aria-hidden=true href=#2-mlproject--condayaml-por-step>#</a></h4><p>Cada subdirectorio es un proyecto MLflow independiente:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># src/data/02_preprocessing/MLproject</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>preprocessing_and_imputation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>conda_env</span><span class=p>:</span><span class=w> </span><span class=l>conda.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>entry_points</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Ventajas:</strong></p><ul><li>Dependencias aisladas (step 03 usa scikit-learn 1.3, step 06 podría usar 1.4)</li><li>Ejecución independiente: <code>mlflow run src/data/02_preprocessing</code></li><li>Tracking granular: cada step es un run separado</li></ul><p><strong>Desventaja:</strong> Overhead de archivos. Pero es el mismo overhead que tener microservicios—cada uno con su Dockerfile.</p><h4 id=3-api-como-proyecto-separado>3. <code>api/</code> Como Proyecto Separado<a hidden class=anchor aria-hidden=true href=#3-api-como-proyecto-separado>#</a></h4><p>El API no está en <code>src/api/</code>. Es un proyecto hermano con su propio <code>requirements.txt</code>, Dockerfile y tests.</p><p><strong>Razón:</strong> El API se deploya <strong>independientemente</strong> del pipeline. No necesita pandas completo, scikit-learn full o W&amp;B client. Solo FastAPI, pydantic y el pickle del modelo.</p><p><strong>Resultado:</strong> Imagen Docker de 200MB vs 1.5GB si incluyeras todo el pipeline.</p><h4 id=4-tests-en-la-raíz>4. Tests en la Raíz<a hidden class=anchor aria-hidden=true href=#4-tests-en-la-raíz>#</a></h4><p>Los tests prueban el <strong>sistema completo</strong>, no módulos aislados. <code>test_integration_simple.py</code> corre el pipeline end-to-end. No encaja conceptualmente en <code>src/</code>.</p><h4 id=5-ausencia-de-notebooks>5. Ausencia de <code>notebooks/</code><a hidden class=anchor aria-hidden=true href=#5-ausencia-de-notebooks>#</a></h4><p><strong>Decisión deliberada.</strong> Los notebooks son excelentes para exploración, terribles para producción. Este proyecto prioriza <strong>reproducibilidad</strong> sobre iteración rápida.</p><p>Si necesitas explorar, úsalos localmente pero <strong>no los comitees</strong>. Los notebooks en git son:</p><ul><li>Difíciles de revisar (diffs incomprensibles)</li><li>Imposibles de testear</li><li>Propensos a ejecutarse fuera de orden</li></ul><hr><p><a name=orquestación></a></p><h2 id=3-orquestación-con-hydra--mlflow>3. Orquestación con Hydra + MLflow<a hidden class=anchor aria-hidden=true href=#3-orquestación-con-hydra--mlflow>#</a></h2><h3 id=por-qué-no-scripts-bash-simples>Por Qué No Scripts Bash Simples<a hidden class=anchor aria-hidden=true href=#por-qué-no-scripts-bash-simples>#</a></h3><p>Ejecutar comandos Python secuenciales funciona para pipelines simples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python src/data/01_download_data/main.py
</span></span><span class=line><span class=cl>python src/data/02_preprocessing/main.py
</span></span><span class=line><span class=cl>python src/data/03_feature_engineering/main.py
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span></code></pre></div><p><strong>Este enfoque falla cuando necesitas:</strong></p><ul><li>Ejecutar solo steps específicos (debugging)</li><li>Cambiar parámetros sin editar código</li><li>Versionar configuración junto al código</li><li>Logs estructurados de qué corrió con qué params</li><li>Rastrear dependencias entre steps</li></ul><p><strong>Hydra + MLflow resuelve todos estos problemas.</strong></p><h3 id=el-orquestador-mainpy>El Orquestador: main.py<a hidden class=anchor aria-hidden=true href=#el-orquestador-mainpy>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>MLOps Pipeline Orchestrator
</span></span></span><span class=line><span class=cl><span class=s2>Ejecuta steps secuencialmente usando MLflow + Hydra
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>hydra</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>DictConfig</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>validate_environment_variables</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Fail fast si faltan secrets críticos.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>required_vars</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCP_PROJECT_ID&#34;</span><span class=p>:</span> <span class=s2>&#34;Google Cloud Project ID&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCS_BUCKET_NAME&#34;</span><span class=p>:</span> <span class=s2>&#34;GCS Bucket name&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;WANDB_API_KEY&#34;</span><span class=p>:</span> <span class=s2>&#34;Weights &amp; Biases API Key&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>missing</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>var</span><span class=p>,</span> <span class=n>description</span> <span class=ow>in</span> <span class=n>required_vars</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>value</span> <span class=ow>or</span> <span class=n>value</span> <span class=ow>in</span> <span class=p>[</span><span class=s2>&#34;your-project-id&#34;</span><span class=p>,</span> <span class=s2>&#34;your-key&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>missing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  ERROR: </span><span class=si>{</span><span class=n>var</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>description</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>missing</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>missing</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Create .env file with:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCP_PROJECT_ID=your-project-id&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCS_BUCKET_NAME=your-bucket&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  WANDB_API_KEY=your-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sys</span><span class=o>.</span><span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Convierte execute_steps de config a lista.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;execute_steps&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>steps</span><span class=p>,</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>s</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=n>steps</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;,&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_step</span><span class=p>(</span><span class=n>step_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>step_path</span><span class=p>:</span> <span class=n>Path</span><span class=p>,</span> <span class=n>entry_point</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>parameters</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Ejecuta un step como MLflow project.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;EXECUTING: </span><span class=si>{</span><span class=n>step_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>uri</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>step_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>entry_point</span><span class=o>=</span><span class=n>entry_point</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>env_manager</span><span class=o>=</span><span class=s2>&#34;local&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>parameters</span><span class=o>=</span><span class=n>parameters</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@hydra.main</span><span class=p>(</span><span class=n>config_path</span><span class=o>=</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=n>config_name</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>,</span> <span class=n>version_base</span><span class=o>=</span><span class=s2>&#34;1.3&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>go</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Entry point principal del pipeline.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>validate_environment_variables</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_experiment</span><span class=p>(</span><span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;experiment_name&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>steps_to_execute</span> <span class=o>=</span> <span class=n>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>root_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Step 01: Download Data</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;01_download_data&#34;</span> <span class=ow>in</span> <span class=n>steps_to_execute</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>run_step</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;01 - Download Data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>root_path</span> <span class=o>/</span> <span class=s2>&#34;src&#34;</span> <span class=o>/</span> <span class=s2>&#34;data&#34;</span> <span class=o>/</span> <span class=s2>&#34;01_download_data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;file_url&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;file_url&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;gcs_output_path&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;gcs_output_path&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ... Steps 02-07 similar pattern ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>SUCCESS: PIPELINE COMPLETED (</span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>s)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>ERROR: PIPELINE FAILED: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>go</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=configyaml-single-source-of-truth>config.yaml: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#configyaml-single-source-of-truth>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>project_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing-mlops-gcp&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>experiment_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;end_to_end_pipeline&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>execute_steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;01_download_data&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;02_preprocessing_and_imputation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;03_feature_engineering&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;04_segregation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;05_model_selection&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;06_sweep&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;07_registration&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>download_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file_url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>preprocessing</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>imputation_strategy</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;auto&#34;</span><span class=w>  </span><span class=c># Comparará 4 estrategias</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>feature_engineering</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_clusters</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>optimize_hyperparams</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>  </span><span class=c># Busca mejor K</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>segregation</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>test_size</span><span class=p>:</span><span class=w> </span><span class=m>0.2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>target_column</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;median_house_value&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>model_selection</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>sweep_count</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>  </span><span class=c># 50 runs de Bayesian optimization</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;mape&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_goal</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;minimize&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>registration</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>registered_model_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing_price_model&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>model_stage</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Staging&#34;</span><span class=w>  </span><span class=c># O &#34;Production&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=lo-que-este-código-hace-bien>Lo Que Este Código Hace Bien<a hidden class=anchor aria-hidden=true href=#lo-que-este-código-hace-bien>#</a></h3><p><strong>1. Fail Fast con Validación de Environment</strong></p><p>Antes de gastar CPU, verifica que todas las secrets existen. El mensaje de error incluye <strong>instrucciones</strong> de cómo conseguir cada valor.</p><pre tabindex=0><code>ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES
===============================================
  ERROR: WANDB_API_KEY: Weights &amp; Biases API Key

Create .env file with:
  WANDB_API_KEY=your-key
</code></pre><p>Esto ahorra <strong>frustración</strong>—especialmente para nuevos colaboradores.</p><p><strong>2. Ejecución Selectiva Sin Comentar Código</strong></p><p>Cambias <code>config.yaml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>execute_steps</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;03_feature_engineering&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;05_model_selection&#34;</span><span class=p>]</span><span class=w>
</span></span></span></code></pre></div><p>Y solo esos steps corren. No editas Python, no comentas imports.</p><p><strong>3. Separación Entre Orchestration y Logic</strong></p><p><code>main.py</code> no sabe cómo descargar datos o entrenar modelos. Solo sabe cómo <strong>invocar</strong> scripts que lo hacen. Cada step puede desarrollarse/testearse independientemente.</p><p><strong>4. Logging Estructurado con Visual Hierarchy</strong></p><p>Los separadores (<code>"="*70</code>) y emojis no son cosmética—en un pipeline que corre 2 horas, las secciones visuales permiten <strong>escanear rápido</strong> para encontrar qué step falló.</p><hr><p><a name=step-02></a></p><h2 id=4-step-02-imputación-automatizada---decisiones-respaldadas-por-datos>4. Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos<a hidden class=anchor aria-hidden=true href=#4-step-02-imputación-automatizada---decisiones-respaldadas-por-datos>#</a></h2><h3 id=el-problema-real>El Problema Real<a hidden class=anchor aria-hidden=true href=#el-problema-real>#</a></h3><p>California Housing tiene ~1% de <code>total_bedrooms</code> faltantes. Opciones obvias:</p><ol><li><strong>Drop rows</strong> → pierdes datos</li><li><strong>Fill con median</strong> → asumes distribución sin verificar</li><li><strong>Fill con KNN</strong> → asumes similitud en feature space</li><li><strong>Fill con IterativeImputer</strong> → asumes relaciones modelables</li></ol><p><strong>Pregunta:</strong> ¿Cuál es mejor?</p><p><strong>Respuesta incorrecta:</strong> &ldquo;KNN siempre funciona&rdquo;</p><p><strong>Respuesta correcta:</strong> &ldquo;Probé las 4, median tuvo RMSE de 0.8, KNN de 0.6, Iterative de 0.5. Uso Iterative porque minimiza error de reconstrucción. Aquí está el plot en W&amp;B.&rdquo;</p><h3 id=imputation_analyzerpy-el-core>imputation_analyzer.py: El Core<a hidden class=anchor aria-hidden=true href=#imputation_analyzerpy-el-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Imputation Analyzer - Compara estrategias automáticamente
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Tuple</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>mean_squared_error</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span><span class=p>,</span> <span class=n>KNNImputer</span><span class=p>,</span> <span class=n>IterativeImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestRegressor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Resultado de una estrategia de imputación.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>method_name</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=cl>    <span class=n>imputed_values</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
</span></span><span class=line><span class=cl>    <span class=n>imputer</span><span class=p>:</span> <span class=nb>object</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationAnalyzer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Analiza y compara estrategias de imputación.
</span></span></span><span class=line><span class=cl><span class=s2>    Selecciona automáticamente la mejor basándose en RMSE.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>test_size</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>df</span> <span class=o>=</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>target_column</span> <span class=o>=</span> <span class=n>target_column</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>test_size</span> <span class=o>=</span> <span class=n>test_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>:</span> <span class=nb>object</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>prepare_validation_set</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Crea validation set masked para comparar estrategias.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Strategy:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Remove rows con target faltante (no podemos validar contra NaN)
</span></span></span><span class=line><span class=cl><span class=s2>        2. Split en train/val
</span></span></span><span class=line><span class=cl><span class=s2>        3. Maskear target en val set (simular missing values)
</span></span></span><span class=line><span class=cl><span class=s2>        4. Guardar ground truth
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            (train_set, val_set_missing, y_val_true)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_numeric</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>df</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_known</span> <span class=o>=</span> <span class=n>housing_numeric</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>housing_known</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>test_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>test_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Maskear target en val</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Ground truth</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>strategy</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evalúa SimpleImputer con strategy dada.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=n>strategy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Simple Imputer (</span><span class=si>{</span><span class=n>strategy</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>n_neighbors</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Evalúa KNNImputer con scaling.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        CRÍTICO: KNN requiere features escaladas o explota con overflow.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Scale data</span>
</span></span><span class=line><span class=cl>            <span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># KNN imputation</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span> <span class=o>=</span> <span class=n>KNNImputer</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>n_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Inverse scale</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>val_imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;KNN Imputer (k=</span><span class=si>{</span><span class=n>n_neighbors</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=p>(</span><span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span><span class=p>)</span>  <span class=c1># Store tuple!</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evalúa IterativeImputer con RandomForest estimator.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>IterativeImputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>estimator</span><span class=o>=</span><span class=n>estimator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=s2>&#34;Iterative Imputer (RF)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compare_all_methods</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Compara todas las estrategias y selecciona la mejor.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>prepare_validation_set</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluar todos</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_mean&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;mean&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;knn&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;iterative_rf&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Seleccionar mejor</span>
</span></span><span class=line><span class=cl>        <span class=n>best_key</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>k</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span> <span class=o>=</span> <span class=n>best_key</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>best_key</span><span class=p>]</span><span class=o>.</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Print summary</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;IMPUTATION METHODS COMPARISON&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>sorted</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>status</span> <span class=o>=</span> <span class=s2>&#34;[BEST]&#34;</span> <span class=k>if</span> <span class=n>key</span> <span class=o>==</span> <span class=n>best_key</span> <span class=k>else</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>method_name</span><span class=si>:</span><span class=s2>30s</span><span class=si>}</span><span class=s2> RMSE: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>rmse</span><span class=si>:</span><span class=s2>8.4f</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>status</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>apply_best_imputer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Aplica el mejor imputer al dataset completo.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;Run compare_all_methods() first&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>numeric_df</span> <span class=o>=</span> <span class=n>df_out</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Check si es tuple (KNN con scaler)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>                <span class=n>numeric_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>numeric_df</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>imputed_array</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df_out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_comparison_plot</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Crea bar plot comparando RMSE de métodos.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>methods</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>method_name</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>        <span class=n>rmses</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>rmse</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;green&#39;</span> <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>rmses</span><span class=p>)</span> <span class=k>else</span> <span class=s1>&#39;skyblue&#39;</span>
</span></span><span class=line><span class=cl>                  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>rmses</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>        <span class=n>bars</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>methods</span><span class=p>,</span> <span class=n>rmses</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Imputation Method&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;RMSE&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Comparison of Imputation Strategies&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=s1>&#39;y&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Value labels</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>bar</span><span class=p>,</span> <span class=n>rmse</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>bars</span><span class=p>,</span> <span class=n>rmses</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>height</span> <span class=o>=</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_height</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>bar</span><span class=o>.</span><span class=n>get_x</span><span class=p>()</span> <span class=o>+</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_width</span><span class=p>()</span><span class=o>/</span><span class=mf>2.</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>height</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>rmse</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>va</span><span class=o>=</span><span class=s1>&#39;bottom&#39;</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>rotation</span><span class=o>=</span><span class=mi>45</span><span class=p>,</span> <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;right&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>fig</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas>#</a></h3><h4 id=1-la-métrica-rmse-de-reconstrucción>1. La Métrica: RMSE de Reconstrucción<a hidden class=anchor aria-hidden=true href=#1-la-métrica-rmse-de-reconstrucción>#</a></h4><p><strong>¿Por qué RMSE y no MAE?</strong></p><p>MAE trata todos los errores igual. RMSE penaliza errores grandes más fuertemente.</p><p>Si un método imputa 100 bedrooms cuando la verdad es 3, eso es <strong>problemático</strong>. RMSE lo castiga más que MAE. En imputación, errores grandes distorsionan el dataset más que muchos errores pequeños.</p><h4 id=2-el-validation-set-masked>2. El Validation Set Masked<a hidden class=anchor aria-hidden=true href=#2-el-validation-set-masked>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>housing_known</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl><span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span></code></pre></div><p>Este <strong>trick es crítico</strong>. No puedes evaluar imputation strategies en los missing values reales—no sabes la verdad. Entonces:</p><ol><li>Tomas filas donde el target NO falta</li><li>Splits en train/val</li><li>Artificialmente maskeas el target en val</li><li>Comparas qué tan bien cada imputer reconstruye los valores que conocías</li></ol><p>Es <strong>validación cruzada para preprocesamiento</strong>, no solo para modelos.</p><h4 id=3-por-qué-knn-necesita-scaling>3. Por Qué KNN Necesita Scaling<a hidden class=anchor aria-hidden=true href=#3-por-qué-knn-necesita-scaling>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span></code></pre></div><p>KNN calcula distancias euclidianas entre observaciones. Si una feature está en rango [0, 1] y otra en [0, 10000], <strong>la segunda domina completamente</strong>.</p><p>StandardScaler normaliza todo a media 0, std 1. Ahora todas las features contribuyen equitativamente.</p><p><strong>IterativeImputer con RandomForest NO necesita scaling</strong>—los árboles son invariantes a escala.</p><h4 id=4-el-imputer-como-tuple>4. El Imputer Como Tuple<a hidden class=anchor aria-hidden=true href=#4-el-imputer-como-tuple>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... apply both</span>
</span></span></code></pre></div><p>Si KNN ganó, necesitas guardar <strong>tanto el scaler como el imputer</strong>. En producción, cuando llegan datos nuevos:</p><ol><li>Escalar con el mismo scaler fitted en training</li><li>Aplicar KNN imputer</li><li>Inverse transform para volver a escala original</li></ol><p>Guardar solo el imputer sin el scaler <strong>rompería todo</strong>.</p><h3 id=uso-en-el-pipeline>Uso en el Pipeline<a hidden class=anchor aria-hidden=true href=#uso-en-el-pipeline>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En main.py del Step 02</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>analyzer</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>target_column</span><span class=o>=</span><span class=s2>&#34;total_bedrooms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log a W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>comparison_plot</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>create_comparison_plot</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/comparison&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>comparison_plot</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_method&#34;</span><span class=p>:</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_rmse&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Aplicar al dataset completo</span>
</span></span><span class=line><span class=cl><span class=n>housing_clean</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>apply_best_imputer</span><span class=p>(</span><span class=n>housing_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Guardar imputer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=lo-que-esto-logra>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé median porque es lo que hace todo el mundo.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Comparé 4 estrategias. IterativeImputer con RandomForest tuvo 15% menor RMSE que median. Aquí está el plot en W&amp;B dashboard run <code>abc123</code>. El imputer está serializado en MLflow.&rdquo;</p><p>Ahora tienes <strong>evidencia cuantificable</strong> de por qué elegiste lo que elegiste. Seis meses después, cuando alguien pregunta, <strong>los datos están ahí</strong>.</p><hr><p><a name=step-03></a></p><h2 id=5-step-03-feature-engineering---kmeans-como-feature-no-solo-clustering>5. Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering<a hidden class=anchor aria-hidden=true href=#5-step-03-feature-engineering---kmeans-como-feature-no-solo-clustering>#</a></h2><h3 id=el-problema-real-1>El Problema Real<a hidden class=anchor aria-hidden=true href=#el-problema-real-1>#</a></h3><p>California tiene patrones geográficos fuertes. Casas en San Francisco se comportan diferente que casas en el valle central. Pero latitude/longitude como features crudas no capturan esto bien—un modelo lineal no puede aprender &ldquo;esta área es cara&rdquo;.</p><p><strong>Solución:</strong> Clustering geográfico. Pero no para segmentar datos, sino para <strong>crear una feature categórica</strong>: <code>cluster_label</code>.</p><h3 id=clustersimilarity-custom-transformer>ClusterSimilarity: Custom Transformer<a hidden class=anchor aria-hidden=true href=#clustersimilarity-custom-transformer>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>KMeans</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ClusterSimilarity</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Custom transformer para clustering geográfico.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Design: Transformer de scikit-learn para integrarse en Pipeline.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span> <span class=o>=</span> <span class=n>n_clusters</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>gamma</span>  <span class=c1># Placeholder para RBF kernel (no usado actualmente)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Fit KMeans en coordenadas geográficas.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>sample_weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Transforma coordenadas a cluster labels.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>cluster_labels</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>cluster_labels</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_feature_names_out</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Retorna nombres de features para Pipeline.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=s2>&#34;cluster_label&#34;</span><span class=p>]</span>
</span></span></code></pre></div><h3 id=el-pipeline-de-preprocessing-completo>El Pipeline de Preprocessing Completo<a hidden class=anchor aria-hidden=true href=#el-pipeline-de-preprocessing-completo>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.compose</span> <span class=kn>import</span> <span class=n>ColumnTransformer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span><span class=p>,</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Crea pipeline que procesa:
</span></span></span><span class=line><span class=cl><span class=s2>    - Numéricas: impute + scale
</span></span></span><span class=line><span class=cl><span class=s2>    - Categóricas: impute + one-hot
</span></span></span><span class=line><span class=cl><span class=s2>    - Geo: clustering
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;standardize&#34;</span><span class=p>,</span> <span class=n>StandardScaler</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;most_frequent&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;onehot&#34;</span><span class=p>,</span> <span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_attribs</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;longitude&#34;</span><span class=p>,</span> <span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;housing_median_age&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;total_rooms&#34;</span><span class=p>,</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span> <span class=s2>&#34;population&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;households&#34;</span><span class=p>,</span> <span class=s2>&#34;median_income&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_attribs</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;ocean_proximity&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>preprocessing</span> <span class=o>=</span> <span class=n>ColumnTransformer</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;num&#34;</span><span class=p>,</span> <span class=n>num_pipeline</span><span class=p>,</span> <span class=n>num_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;cat&#34;</span><span class=p>,</span> <span class=n>cat_pipeline</span><span class=p>,</span> <span class=n>cat_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;geo&#34;</span><span class=p>,</span> <span class=n>ClusterSimilarity</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>),</span>
</span></span><span class=line><span class=cl>         <span class=p>[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>preprocessing</span>
</span></span></code></pre></div><h3 id=optimización-automática-de-n_clusters>Optimización Automática de n_clusters<a hidden class=anchor aria-hidden=true href=#optimización-automática-de-n_clusters>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>silhouette_score</span><span class=p>,</span> <span class=n>davies_bouldin_score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>optimize_n_clusters</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_clusters</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_clusters</span><span class=o>=</span><span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=n>Dict</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Busca el mejor K para KMeans usando silhouette score.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Métricas:
</span></span></span><span class=line><span class=cl><span class=s2>    - Silhouette score (0 a 1): Separación de clusters. Maximizar.
</span></span></span><span class=line><span class=cl><span class=s2>    - Davies-Bouldin index: Dispersión interna vs separación. Minimizar.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>geo_features</span> <span class=o>=</span> <span class=n>df</span><span class=p>[[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cluster_range</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=n>min_clusters</span><span class=p>,</span> <span class=n>max_clusters</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>silhouette_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>davies_bouldin_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>inertias</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>cluster_range</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>geo_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>silhouette_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>silhouette_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>davies_bouldin_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>davies_bouldin_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>inertias</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Seleccionar K con mejor silhouette</span>
</span></span><span class=line><span class=cl>    <span class=n>optimal_n</span> <span class=o>=</span> <span class=n>cluster_range</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>:</span> <span class=n>optimal_n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_silhouette&#34;</span><span class=p>:</span> <span class=nb>max</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;cluster_range&#34;</span><span class=p>:</span> <span class=nb>list</span><span class=p>(</span><span class=n>cluster_range</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>silhouette_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;davies_bouldin_scores&#34;</span><span class=p>:</span> <span class=n>davies_bouldin_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;inertias&#34;</span><span class=p>:</span> <span class=n>inertias</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>optimal_n</span><span class=p>,</span> <span class=n>metrics</span>
</span></span></code></pre></div><h3 id=visualización-elbow-method--silhouette>Visualización: Elbow Method + Silhouette<a hidden class=anchor aria-hidden=true href=#visualización-elbow-method--silhouette>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea plots de optimización de K.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 1: Elbow Method (Inertia)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig1</span><span class=p>,</span> <span class=n>ax1</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;inertias&#34;</span><span class=p>],</span> <span class=s1>&#39;bo-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal K=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Inertia&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Elbow Method - KMeans Optimization&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 2: Silhouette Score</span>
</span></span><span class=line><span class=cl>    <span class=n>fig2</span><span class=p>,</span> <span class=n>ax2</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>],</span> <span class=s1>&#39;go-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Silhouette Score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Silhouette Score vs K&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>:</span> <span class=n>fig1</span><span class=p>,</span> <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>fig2</span><span class=p>}</span>
</span></span></code></pre></div><h3 id=uso-en-el-pipeline-1>Uso en el Pipeline<a hidden class=anchor aria-hidden=true href=#uso-en-el-pipeline-1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En main.py del Step 03</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Descargar datos desde GCS</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>download_from_gcs</span><span class=p>(</span><span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Optimizar K</span>
</span></span><span class=line><span class=cl><span class=n>optimal_k</span><span class=p>,</span> <span class=n>metrics</span> <span class=o>=</span> <span class=n>optimize_n_clusters</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>min_clusters</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>max_clusters</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Optimal K: </span><span class=si>{</span><span class=n>optimal_k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   Silhouette: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;best_silhouette&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Crear plots</span>
</span></span><span class=line><span class=cl><span class=n>plots</span> <span class=o>=</span> <span class=n>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log a W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/optimal_k&#34;</span><span class=p>:</span> <span class=n>optimal_k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;best_silhouette&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/elbow_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Crear pipeline con K óptimo</span>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>optimal_k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit pipeline</span>
</span></span><span class=line><span class=cl><span class=n>target_column</span> <span class=o>=</span> <span class=s2>&#34;median_house_value&#34;</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform data</span>
</span></span><span class=line><span class=cl><span class=n>X_transformed</span> <span class=o>=</span> <span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Reconstruir DataFrame con target</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>X_transformed</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>columns</span><span class=o>=</span><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upload a GCS</span>
</span></span><span class=line><span class=cl><span class=n>upload_to_gcs</span><span class=p>(</span><span class=n>df_transformed</span><span class=p>,</span> <span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Guardar pipeline</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-1>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-1>#</a></h3><h4 id=1-por-qué-silhouette-score>1. Por Qué Silhouette Score<a hidden class=anchor aria-hidden=true href=#1-por-qué-silhouette-score>#</a></h4><p><strong>Silhouette score</strong> (rango 0 a 1) mide qué tan bien separados están los clusters:</p><ul><li><strong>1.0:</strong> Clusters perfectamente separados</li><li><strong>0.5:</strong> Overlap moderado</li><li><strong>0.0:</strong> Clusters aleatorios</li></ul><p>Es <strong>interpretable</strong> y generalmente correlaciona bien con calidad visual de clusters.</p><p><strong>Davies-Bouldin index:</strong> También lo calculamos pero no lo usamos para decisión—es más sensible a outliers.</p><h4 id=2-la-crítica-obvia>2. La Crítica Obvia<a hidden class=anchor aria-hidden=true href=#2-la-crítica-obvia>#</a></h4><p>Este código optimiza <code>n_clusters</code> basándose en <strong>métricas de clustering</strong>, no en <strong>performance del modelo final</strong>.</p><p>Un approach más riguroso sería:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_transformed</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mape</span> <span class=o>=</span> <span class=n>calculate_mape</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_test_transformed</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Seleccionar K con mejor MAPE</span>
</span></span></code></pre></div><p>Esto tomaría <strong>10x más tiempo</strong> pero sería más riguroso.</p><p><strong>Trade-off:</strong> Este pipeline prioriza velocidad sobre rigor absoluto. Para California Housing, silhouette score es suficientemente bueno. Para datasets más complejos, considera el approach de cross-validation completo.</p><h4 id=3-handle_unknownignore-en-onehotencoder>3. handle_unknown=&ldquo;ignore&rdquo; en OneHotEncoder<a hidden class=anchor aria-hidden=true href=#3-handle_unknownignore-en-onehotencoder>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Crítico para producción.</strong> Si en training tienes categorías <code>["&lt;1H OCEAN", "INLAND", "NEAR BAY"]</code> pero en producción llega <code>"ISLAND"</code> (que no viste), el encoder:</p><ul><li><strong>Sin <code>handle_unknown</code>:</strong> Explota con ValueError</li><li><strong>Con <code>handle_unknown="ignore"</code>:</strong> Genera vector de ceros para esa observación</li></ul><p>Pierdes información de esa observación, pero el <strong>API no devuelve HTTP 500</strong>.</p><h4 id=4-por-qué-guardar-el-pipeline-no-solo-el-modelo>4. Por Qué Guardar el Pipeline, No Solo el Modelo<a hidden class=anchor aria-hidden=true href=#4-por-qué-guardar-el-pipeline-no-solo-el-modelo>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>En producción, necesitas:</p><ol><li>Cargar el pipeline</li><li>Transform datos nuevos</li><li>Predecir con el modelo</li></ol><p>Si solo guardas el modelo, no sabes:</p><ul><li>Qué features espera</li><li>En qué orden</li><li>Qué transformaciones aplicar</li></ul><p>El pipeline <strong>encapsula todo eso</strong>.</p><h3 id=lo-que-esto-logra-1>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra-1>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé KMeans con K=10 porque leí que 10 clusters es bueno.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Probé K de 5 a 15. K=8 maximizó silhouette score (0.64). Aquí están los plots de elbow method y silhouette. El pipeline con K=8 está serializado en MLflow.&rdquo;</p><p><strong>Evidencia cuantificable + artifact reproducible.</strong></p><hr><p><a name=step-06></a></p><h2 id=6-step-06-hyperparameter-sweep---optimización-bayesiana-con-wb>6. Step 06: Hyperparameter Sweep - Optimización Bayesiana con W&amp;B<a hidden class=anchor aria-hidden=true href=#6-step-06-hyperparameter-sweep---optimización-bayesiana-con-wb>#</a></h2><h3 id=el-problema-de-model-selection-vs-hyperparameter-tuning>El Problema de Model Selection vs Hyperparameter Tuning<a hidden class=anchor aria-hidden=true href=#el-problema-de-model-selection-vs-hyperparameter-tuning>#</a></h3><p>La mayoría de los proyectos de ML cometen este error: entrenan un Random Forest en un notebook, ajustan algunos hiperparámetros hasta que R² se ve &ldquo;bien&rdquo; y declaran victoria. Tres meses después, cuando alguien pregunta &ldquo;¿por qué Random Forest y no XGBoost?&rdquo;, la respuesta es silencio incómodo.</p><p><strong>Este pipeline separa dos fases:</strong></p><ol><li><strong>Model Selection (Step 05):</strong> Compara algoritmos con GridSearch rápido (5-10 combos por modelo)</li><li><strong>Hyperparameter Sweep (Step 06):</strong> Optimiza el ganador con Bayesian search exhaustivo (50+ runs)</li></ol><p><strong>Razón:</strong> No tienes tiempo ni cómputo para hacer sweep exhaustivo de 5 algoritmos. Primero decides <strong>estrategia</strong> (qué algoritmo), luego <strong>tácticas</strong> (qué hiperparámetros).</p><h3 id=sweep_configyaml-el-espacio-de-búsqueda>sweep_config.yaml: El Espacio de Búsqueda<a hidden class=anchor aria-hidden=true href=#sweep_configyaml-el-espacio-de-búsqueda>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># W&amp;B Sweep Configuration for Random Forest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Autor: Carlos Daniel Jiménez</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>program</span><span class=p>:</span><span class=w> </span><span class=l>main.py</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># Bayesian optimization, no random, no grid</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE (menos sesgado que MAPE)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>goal</span><span class=p>:</span><span class=w> </span><span class=l>minimize</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>values</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s1>&#39;sqrt&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;log2&#39;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Early stopping: elimina runs pobres temprano</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>   </span><span class=c># Mínimo 10 runs antes de terminar</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>         </span><span class=c># Elimina 1/3 de runs pobres</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>s</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>housing-rf-sweep-improved</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Optimize Random Forest with wmape + feature tracking&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=mainpy-del-step-06-el-sweep-real>main.py del Step 06: El Sweep Real<a hidden class=anchor aria-hidden=true href=#mainpy-del-step-06-el-sweep-real>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>W&amp;B Sweep for Random Forest Hyperparameter Optimization.
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>yaml</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>utils</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>download_data_from_gcs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prepare_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_random_forest</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluate_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>log_feature_importances</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Module-level data cache (cargado una vez, reusado en todos los runs)</span>
</span></span><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;feature_names&#34;</span><span class=p>:</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Training function llamada por W&amp;B Sweep agent.
</span></span></span><span class=line><span class=cl><span class=s2>    Ejecutada para cada combinación de hiperparámetros.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Usa module-level cache para evitar recargar datos en cada run.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SWEEP RUN: </span><span class=si>{</span><span class=n>run</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Preparar parámetros</span>
</span></span><span class=line><span class=cl>        <span class=n>params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;n_estimators&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>n_estimators</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>max_depth</span><span class=p>)</span> <span class=k>if</span> <span class=n>config</span><span class=o>.</span><span class=n>max_depth</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_split</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_leaf</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_features&#39;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>max_features</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;random_state&#39;</span><span class=p>:</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Train model usando cached data</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>train_random_forest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>params</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluate model</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log feature importances</span>
</span></span><span class=line><span class=cl>        <span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log todo a W&amp;B</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>               <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SUCCESS: MAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% | &#34;</span>
</span></span><span class=line><span class=cl>                   <span class=sa>f</span><span class=s2>&#34;WMAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;wmape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ERROR: Run failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=mf>999.9</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=mf>999.9</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>run</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Main function para inicializar y ejecutar el sweep.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_train_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_test_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--bucket_name&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--wandb_project&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--target_column&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;median_house_value&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_count&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_config&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;sweep_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;W&amp;B SWEEP - HYPERPARAMETER OPTIMIZATION&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Cargar datos UNA VEZ en module-level cache</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Loading data into cache...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>train_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_train_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_test_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>test_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Store in cache</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Data cached: Train </span><span class=si>{</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, Test </span><span class=si>{</span><span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Load sweep configuration</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=n>args</span><span class=o>.</span><span class=n>sweep_config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>sweep_config_path</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_config</span> <span class=o>=</span> <span class=n>yaml</span><span class=o>.</span><span class=n>safe_load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep config:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Method: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;method&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Metric: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;goal&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize sweep</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_id</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep</span><span class=o>=</span><span class=n>sweep_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep created: </span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  View at: https://wandb.ai/</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/sweeps/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Run sweep agent</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Starting sweep agent (</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=si>}</span><span class=s2> runs)...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>function</span><span class=o>=</span><span class=n>train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>count</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;SWEEP COMPLETED&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Guardar best params</span>
</span></span><span class=line><span class=cl>    <span class=n>api</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Api</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep</span> <span class=o>=</span> <span class=n>api</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>best_run</span> <span class=o>=</span> <span class=n>sweep</span><span class=o>.</span><span class=n>best_run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;hyperparameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>))</span> <span class=k>if</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>)</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_features&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;mape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;wmape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;r2&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;sweep_id&#34;</span><span class=p>:</span> <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_run_id&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Guardar a YAML</span>
</span></span><span class=line><span class=cl>    <span class=n>best_params_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=s2>&#34;best_params.yaml&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>best_params_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>best_params</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Best params saved to: </span><span class=si>{</span><span class=n>best_params_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   MAPE: </span><span class=si>{</span><span class=n>best_params</span><span class=p>[</span><span class=s1>&#39;metrics&#39;</span><span class=p>][</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-2>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-2>#</a></h3><h4 id=1-bayesian-optimization-no-random-search>1. Bayesian Optimization, No Random Search<a hidden class=anchor aria-hidden=true href=#1-bayesian-optimization-no-random-search>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># No random, no grid</span><span class=w>
</span></span></span></code></pre></div><p><strong>Random search:</strong> Prueba combinaciones aleatorias. No aprende de runs anteriores.</p><p><strong>Grid search:</strong> Prueba todas las combinaciones. Exhaustivo pero <strong>carísimo</strong> (5 × 4 × 3 × 3 × 2 = 360 combos).</p><p><strong>Bayesian optimization:</strong> Construye un modelo probabilístico de la función que optimizas (MAPE en función de hiperparámetros) y usa ese modelo para decidir qué probar siguiente.</p><p>Si detecta que <code>max_depth=None</code> consistentemente da mejor MAPE, <strong>explora más en esa región</strong> del espacio.</p><p><strong>50 runs es &lt;15% del espacio total</strong>, pero capturan el 80% del beneficio posible.</p><h4 id=2-wmape-no-mape>2. wMAPE, No MAPE<a hidden class=anchor aria-hidden=true href=#2-wmape-no-mape>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE</span><span class=w>
</span></span></span></code></pre></div><p><strong>MAPE estándar:</strong> Penaliza errores en casas baratas más que en casas caras.</p><p>Si una casa vale $10,000 y predices $12,000, error = 20%.
Si una casa vale $500,000 y predices $510,000, error = 2%.</p><p>Ambos errores son <strong>$10,000</strong>, pero MAPE los ve radicalmente diferentes.</p><p><strong>wMAPE (Weighted MAPE):</strong> Pondera por el valor real. Menos sesgado hacia valores bajos.</p><p><strong>Por qué funciona aquí:</strong> California Housing no tiene casas de $0. Rango está entre $15k y $500k—razonablemente acotado.</p><h4 id=3-variables-globales-para-data-cache>3. Variables Globales Para Data Cache<a hidden class=anchor aria-hidden=true href=#3-variables-globales-para-data-cache>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Las variables globales son generalmente código sucio. <strong>Aquí son la decisión correcta.</strong></p><p>Cada run del sweep necesita los mismos datos. Sin cache, cargarías desde GCS <strong>50 veces</strong>. Con California Housing (20k filas), eso son segundos desperdiciados. Con datasets más grandes, son <strong>minutos u horas</strong>.</p><p><strong>Alternativa &ldquo;limpia&rdquo;:</strong> Pasar datos como argumento a cada función. Pero W&amp;B Sweeps tiene interfaz fija—la función que pasas a <code>wandb.agent()</code> no puede recibir argumentos adicionales.</p><p>Las variables globales aquí tienen <strong>scope limitado</strong>—solo existen durante el proceso del sweep.</p><h4 id=4-early-stopping-con-hyperband>4. Early Stopping con Hyperband<a hidden class=anchor aria-hidden=true href=#4-early-stopping-con-hyperband>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><p><strong>Hyperband</strong> elimina runs pobres temprano. Si después de 10 runs un set de hiperparámetros muestra MAPE de 25% mientras otros están en 8%, Hyperband lo <strong>detiene</strong>.</p><p><strong>eta=3:</strong> Elimina el peor tercio de runs en cada iteración.</p><p><strong>Beneficio:</strong> Ahorras cómputo en hiperparámetros obviamente malos.</p><h4 id=5-feature-importances-loggeadas>5. Feature Importances Loggeadas<a hidden class=anchor aria-hidden=true href=#5-feature-importances-loggeadas>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>feature_names</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>       <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><p>Random Forest calcula feature importances <strong>gratis</strong>. Sería valioso loggearlo para entender qué features dominan el modelo.</p><p>En W&amp;B dashboard, puedes comparar runs y ver &ldquo;en el mejor run, <code>median_income</code> tuvo importance de 0.45&rdquo;.</p><h3 id=el-output-crítico-best_paramsyaml>El Output Crítico: best_params.yaml<a hidden class=anchor aria-hidden=true href=#el-output-crítico-best_paramsyaml>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>hyperparameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w> </span><span class=m>200</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w> </span><span class=l>sqrt</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mape</span><span class=p>:</span><span class=w> </span><span class=m>7.82</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>wmape</span><span class=p>:</span><span class=w> </span><span class=m>7.65</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>r2</span><span class=p>:</span><span class=w> </span><span class=m>0.87</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep_id</span><span class=p>:</span><span class=w> </span><span class=l>abc123xyz</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>best_run_id</span><span class=p>:</span><span class=w> </span><span class=l>run_456</span><span class=w>
</span></span></span></code></pre></div><p>Los hiperparámetros óptimos se guardan en <strong>YAML</strong>, not pickle. Razón:</p><p><strong>YAML es legible y git-friendly.</strong> Si en el próximo retraining cambias de <code>n_estimators=200</code> a <code>n_estimators=300</code>, un <code>git diff</code> lo muestra claramente.</p><p>Con pickle, es un <strong>blob binario opaco</strong>.</p><h3 id=lo-que-esto-logra-2>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra-2>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé <code>n_estimators=100</code> porque es el default de scikit-learn.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Corrí sweep bayesiano de 50 runs. Optimal config: <code>n_estimators=200, max_depth=20</code>. MAPE mejoró de 8.5% a 7.8%. Aquí está el sweep en W&amp;B: <code>wandb.ai/project/sweeps/abc123</code>.&rdquo;</p><p><strong>Evidencia cuantificable</strong> de por qué elegiste cada hiperparámetro.</p><hr><p><a name=step-07></a></p><h2 id=7-step-07-model-registry---versionamiento-en-mlflow>7. Step 07: Model Registry - Versionamiento en MLflow<a hidden class=anchor aria-hidden=true href=#7-step-07-model-registry---versionamiento-en-mlflow>#</a></h2><h3 id=por-qué-no-basta-con-guardar-el-pickle>Por Qué No Basta con Guardar el Pickle<a hidden class=anchor aria-hidden=true href=#por-qué-no-basta-con-guardar-el-pickle>#</a></h3><p>La tentación es:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;best_model.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Esto funciona hasta que necesitas responder:</p><ul><li>¿Qué hiperparámetros usó?</li><li>¿Con qué datos se entrenó?</li><li>¿Qué métricas logró?</li><li>¿Cómo rollback a la versión anterior?</li></ul><p><strong>MLflow Model Registry</strong> resuelve esto.</p><h3 id=register_model_to_mlflow-el-core>register_model_to_mlflow(): El Core<a hidden class=anchor aria-hidden=true href=#register_model_to_mlflow-el-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Registro de modelo en MLflow Model Registry.
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow.sklearn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mlflow.tracking</span> <span class=kn>import</span> <span class=n>MlflowClient</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>register_model_to_mlflow</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_stage</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_columns</span><span class=p>:</span> <span class=nb>list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_train_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_test_path</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Registra modelo en MLflow Model Registry con metadata rica.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: Trained sklearn model
</span></span></span><span class=line><span class=cl><span class=s2>        model_name: Nombre para registered model
</span></span></span><span class=line><span class=cl><span class=s2>        model_stage: Stage (Staging/Production)
</span></span></span><span class=line><span class=cl><span class=s2>        params: Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>        metrics: Métricas de evaluación
</span></span></span><span class=line><span class=cl><span class=s2>        feature_columns: Lista de features
</span></span></span><span class=line><span class=cl><span class=s2>        target_column: Target column name
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_train_path: Path a training data
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_test_path: Path a test data
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        (model_uri, model_version, run_id)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;REGISTERING MODEL TO MLFLOW&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>run_id</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>active_run</span><span class=p>()</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;runs:/</span><span class=si>{</span><span class=n>run_id</span><span class=si>}</span><span class=s2>/model&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Log model to MLflow</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model logged: </span><span class=si>{</span><span class=n>model_uri</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create or get registered model</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>create_registered_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Housing price prediction - Random Forest&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Created new registered model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;already exists&#34;</span> <span class=ow>in</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model already exists: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create model version</span>
</span></span><span class=line><span class=cl>    <span class=n>model_version</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>run_id</span><span class=o>=</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Version created: </span><span class=si>{</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Transition to stage</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stage</span><span class=o>=</span><span class=n>model_stage</span>  <span class=c1># &#34;Staging&#34; or &#34;Production&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Transitioned to: </span><span class=si>{</span><span class=n>model_stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create comprehensive description (MARKDOWN)</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest Regressor
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_depth: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>,</span> <span class=s1>&#39;None&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_split: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_leaf: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_features: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>,</span> <span class=s1>&#39;sqrt&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Median APE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;median_ape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Within 10%: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- RMSE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- R²: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Features
</span></span></span><span class=line><span class=cl><span class=s2>- Number of features: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Target: </span><span class=si>{</span><span class=n>target_column</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Data Sources
</span></span></span><span class=line><span class=cl><span class=s2>- Training: </span><span class=si>{</span><span class=n>gcs_train_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Testing: </span><span class=si>{</span><span class=n>gcs_test_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>update_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=n>description</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Add searchable tags</span>
</span></span><span class=line><span class=cl>    <span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;framework&#34;</span><span class=p>:</span> <span class=s2>&#34;sklearn&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_10pct&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rmse&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_features&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;target&#34;</span><span class=p>:</span> <span class=n>target_column</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>key</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Tags added to model version&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model_uri</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>run_id</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-3>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-3>#</a></h3><h4 id=1-artifact-vs-registered-model>1. Artifact vs Registered Model<a hidden class=anchor aria-hidden=true href=#1-artifact-vs-registered-model>#</a></h4><p><strong>Artifact:</strong> Pickle guardado en un run específico. Para usarlo, necesitas el <code>run_id</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>  <span class=c1># Solo artifact</span>
</span></span><span class=line><span class=cl><span class=c1># Uso: mlflow.sklearn.load_model(f&#34;runs://{run_id}/model&#34;)</span>
</span></span></code></pre></div><p><strong>Registered Model:</strong> Versionado con nombre semántico, stages y metadata.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Uso: mlflow.pyfunc.load_model(&#34;models:/housing_price_model/Production&#34;)</span>
</span></span></code></pre></div><p>En producción, tu API carga <code>models:/housing_price_model/Production</code>, <strong>no <code>runs:/abc123/model</code></strong>.</p><p>Cuando registras una nueva versión, la transicionas a Production y el deployment <strong>automáticamente</strong> toma la nueva versión.</p><h4 id=2-metadata-rica-en-markdown>2. Metadata Rica en Markdown<a hidden class=anchor aria-hidden=true href=#2-metadata-rica-en-markdown>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>Esto guarda <strong>markdown en la descripción</strong> del modelo. Cuando abres MLflow UI y navegas a <code>housing_price_model v3</code>, ves:</p><ul><li>Qué hiperparámetros usó</li><li>Qué métricas logró</li><li>De dónde vinieron los datos</li></ul><p><strong>Por qué es oro:</strong> Seis meses después, cuando alguien pregunta &ldquo;¿por qué el modelo v3 tiene mejor MAPE que v2?&rdquo;, abres MLflow y <strong>la respuesta está ahí</strong>.</p><p>No necesitas buscar en logs ni preguntar a quien lo entrenó.</p><h4 id=3-tags-para-búsqueda>3. Tags Para Búsqueda<a hidden class=anchor aria-hidden=true href=#3-tags-para-búsqueda>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span>
</span></span></code></pre></div><p>En MLflow puedes <strong>filtrar modelos por tags</strong>. &ldquo;Muéstrame todos los modelos con MAPE &lt; 8%&rdquo; es una query que funciona si taggeaste consistentemente.</p><h4 id=4-model-config-file-single-source-of-truth>4. Model Config File: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#4-model-config-file-single-source-of-truth>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>model_version</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;stage&#39;</span><span class=p>:</span> <span class=n>model_stage</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;parameters&#39;</span><span class=p>:</span> <span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;feature_columns&#39;</span><span class=p>:</span> <span class=n>feature_columns</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;mlflow_run_id&#39;</span><span class=p>:</span> <span class=n>run_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;sweep_id&#39;</span><span class=p>:</span> <span class=n>sweep_id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;configs/model_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>config_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model_config</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>config_path</span><span class=p>),</span> <span class=n>artifact_path</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Este YAML se loggea a MLflow <strong>Y</strong> se guarda en el repo (en <code>configs/model_config.yaml</code>).</p><p><strong>Por qué YAML y no solo MLflow:</strong> Tu FastAPI app necesita leer configuración al iniciar. Puede hacer <code>mlflow.load_model()</code> para el pickle, pero necesita saber los <strong>feature names</strong> para validación de input.</p><p>El YAML es esa <strong>single source of truth</strong>.</p><h4 id=5-versionado-en-git>5. Versionado en Git<a hidden class=anchor aria-hidden=true href=#5-versionado-en-git>#</a></h4><p>Cuando commiteas <code>model_config.yaml</code>, el diff muestra:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl><span class=gd>- version: 2
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ version: 3
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- mape: 8.5
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ mape: 7.8
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- n_estimators: 100
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ n_estimators: 200
</span></span></span></code></pre></div><p>Es <strong>auditable</strong>. Sabes exactamente qué cambió entre versiones.</p><h3 id=el-flujo-completo-sweep--registration--production>El Flujo Completo: Sweep → Registration → Production<a hidden class=anchor aria-hidden=true href=#el-flujo-completo-sweep--registration--production>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. Model Selection (Step 05)</span>
</span></span><span class=line><span class=cl>python src/model/05_model_selection/main.py
</span></span><span class=line><span class=cl><span class=c1># Output: &#34;Best: RandomForestRegressor (MAPE: 8.2%)&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Hyperparameter Sweep (Step 06)</span>
</span></span><span class=line><span class=cl>python src/model/06_sweep/main.py --sweep_count<span class=o>=</span><span class=m>50</span>
</span></span><span class=line><span class=cl><span class=c1># Output: best_params.yaml con hiperparámetros óptimos</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Model Registration (Step 07)</span>
</span></span><span class=line><span class=cl>python src/model/07_registration/main.py --params_file<span class=o>=</span>best_params.yaml
</span></span><span class=line><span class=cl><span class=c1># Output: Modelo registrado en MLflow Registry</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Transition to Production (manual)</span>
</span></span><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span></code></pre></div><h3 id=lo-que-este-approach-soluciona>Lo Que Este Approach Soluciona<a hidden class=anchor aria-hidden=true href=#lo-que-este-approach-soluciona>#</a></h3><p><strong>Sin Model Registry:</strong></p><ul><li>Pickles en carpetas: <code>model_v3_final_FINAL_2.pkl</code></li><li>No sabes qué hiperparámetros usa cada uno</li><li>Rollback = buscar el pickle correcto en GCS</li></ul><p><strong>Con Model Registry:</strong></p><ul><li>Modelos con versiones semánticas: v1, v2, v3</li><li>Metadata embebida: params, metrics, data sources</li><li>Rollback = <code>transition v3 to Archived</code> + <code>transition v2 to Production</code></li></ul><hr><p><a name=github-actions></a></p><h2 id=8-cicd-con-github-actions-automatización-del-pipeline-completo>8. CI/CD con GitHub Actions: Automatización del Pipeline Completo<a hidden class=anchor aria-hidden=true href=#8-cicd-con-github-actions-automatización-del-pipeline-completo>#</a></h2><h3 id=por-qué-cicd-es-crítico-en-mlops>Por Qué CI/CD Es Crítico en MLOps<a hidden class=anchor aria-hidden=true href=#por-qué-cicd-es-crítico-en-mlops>#</a></h3><p>Como MLOps engineer, uno de los mayores puntos de fricción es el deployment manual. Has entrenado un modelo excelente en tu laptop, pero llevarlo a producción requiere:</p><ol><li>SSH a un servidor</li><li>Copiar archivos manualmente</li><li>Instalar dependencias</li><li>Cruzar los dedos</li><li>Debuggear cuando algo explota</li></ol><p><strong>GitHub Actions elimina esto.</strong> Cada commit dispara un pipeline automatizado que:</p><ul><li>Ejecuta tests</li><li>Valida que el código cumple estándares</li><li>Entrena el modelo (opcional, en pipelines simples)</li><li>Construye imágenes Docker</li><li>Deploya a Cloud Run/ECS/Kubernetes</li></ul><h3 id=la-arquitectura-de-cicd-para-este-proyecto>La Arquitectura de CI/CD Para Este Proyecto<a hidden class=anchor aria-hidden=true href=#la-arquitectura-de-cicd-para-este-proyecto>#</a></h3><p>Este proyecto implementa <strong>dos workflows separados</strong>:</p><h4 id=1-pr-validation-workflow>1. PR Validation Workflow<a hidden class=anchor aria-hidden=true href=#1-pr-validation-workflow>#</a></h4><p><strong>Trigger:</strong> Cada pull request a <code>main</code></p><p><strong>Propósito:</strong> Asegurar que el código es production-ready antes de mergear</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># .github/workflows/pr_validation.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>PR Validation - Tests &amp; Linting</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>pull_request</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>branches</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=l>main, master]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;src/**&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;api/**&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;tests/**&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;pyproject.toml&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;requirements.txt&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>jobs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>lint</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Lint Code</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/checkout@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up Python 3.12</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/setup-python@v5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>python-version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.12&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install uv</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>pip install uv</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          uv venv
</span></span></span><span class=line><span class=cl><span class=sd>          uv pip install -e .
</span></span></span><span class=line><span class=cl><span class=sd>          uv pip install ruff pytest pytest-cov</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run Ruff linter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          source .venv/bin/activate
</span></span></span><span class=line><span class=cl><span class=sd>          ruff check src/ tests/ api/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run Ruff formatter check</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          source .venv/bin/activate
</span></span></span><span class=line><span class=cl><span class=sd>          ruff format --check src/ tests/ api/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>unit-tests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Unit Tests</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>GCP_PROJECT_ID</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCP_PROJECT_ID }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>GCS_BUCKET_NAME</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCS_BUCKET_NAME }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>WANDB_API_KEY</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.WANDB_API_KEY }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/checkout@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up Python 3.12</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/setup-python@v5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>python-version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.12&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          pip install uv
</span></span></span><span class=line><span class=cl><span class=sd>          uv venv
</span></span></span><span class=line><span class=cl><span class=sd>          uv pip install -e .
</span></span></span><span class=line><span class=cl><span class=sd>          uv pip install pytest pytest-cov pytest-mock</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run unit tests with coverage</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          source .venv/bin/activate
</span></span></span><span class=line><span class=cl><span class=sd>          pytest tests/ -v \
</span></span></span><span class=line><span class=cl><span class=sd>            --cov=src \
</span></span></span><span class=line><span class=cl><span class=sd>            --cov=api/app \
</span></span></span><span class=line><span class=cl><span class=sd>            --cov-report=xml \
</span></span></span><span class=line><span class=cl><span class=sd>            --cov-report=term-missing \
</span></span></span><span class=line><span class=cl><span class=sd>            --cov-fail-under=70</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Upload coverage to Codecov</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>codecov/codecov-action@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>file</span><span class=p>:</span><span class=w> </span><span class=l>./coverage.xml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>flags</span><span class=p>:</span><span class=w> </span><span class=l>unittests</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>codecov-umbrella</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>integration-tests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Integration Tests (Pipeline E2E)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>GCP_PROJECT_ID</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCP_PROJECT_ID }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>GCS_BUCKET_NAME</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCS_BUCKET_NAME }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>WANDB_API_KEY</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.WANDB_API_KEY }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>MLFLOW_TRACKING_URI</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.MLFLOW_TRACKING_URI }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/checkout@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up Python 3.12</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/setup-python@v5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>python-version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.12&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Authenticate to Google Cloud</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>google-github-actions/auth@v2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>credentials_json</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCP_SA_KEY }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install dependencies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          pip install uv
</span></span></span><span class=line><span class=cl><span class=sd>          uv venv
</span></span></span><span class=line><span class=cl><span class=sd>          uv pip install -e .</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run integration test (Steps 01-04)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          source .venv/bin/activate
</span></span></span><span class=line><span class=cl><span class=sd>          python main.py main.execute_steps=[01_download_data,02_preprocessing_and_imputation,03_feature_engineering,04_segregation]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>timeout-minutes</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Verify artifacts were created</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          gsutil ls gs://${{ secrets.GCS_BUCKET_NAME }}/data/04-split/train/train.parquet
</span></span></span><span class=line><span class=cl><span class=sd>          gsutil ls gs://${{ secrets.GCS_BUCKET_NAME }}/data/04-split/test/test.parquet</span><span class=w>
</span></span></span></code></pre></div><p><strong>Valor para el MLOps engineer:</strong></p><ul><li><strong>Previene merges rotos:</strong> Si los tests fallan, el PR no puede mergearse</li><li><strong>Estándares de código:</strong> Ruff garantiza consistencia (importa cuando tienes 5+ contributors)</li><li><strong>Coverage tracking:</strong> Codecov muestra qué porcentaje del código está cubierto por tests</li><li><strong>Fast feedback:</strong> Sabes en 5 minutos si tu cambio rompió algo, no 3 horas después</li></ul><h4 id=2-deployment-workflow>2. Deployment Workflow<a hidden class=anchor aria-hidden=true href=#2-deployment-workflow>#</a></h4><p><strong>Trigger:</strong> Push a <code>main</code> (después de merge de PR)</p><p><strong>Propósito:</strong> Construir y deployar el API a producción</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># .github/workflows/deploy_api.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Deploy API to Cloud Run</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>push</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>branches</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=l>main]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;api/**&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;models/**&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s1>&#39;.github/workflows/deploy_api.yaml&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>PROJECT_ID</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.GCP_PROJECT_ID }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>SERVICE_NAME</span><span class=p>:</span><span class=w> </span><span class=l>housing-price-api</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>REGION</span><span class=p>:</span><span class=w> </span><span class=l>us-central1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>jobs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>build-and-deploy</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Build Docker Image &amp; Deploy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>permissions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>contents</span><span class=p>:</span><span class=w> </span><span class=l>read</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>id-token</span><span class=p>:</span><span class=w> </span><span class=l>write</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Checkout code</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>actions/checkout@v4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Authenticate to Google Cloud</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>google-github-actions/auth@v2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>with</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>workload_identity_provider</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.WIF_PROVIDER }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>service_account</span><span class=p>:</span><span class=w> </span><span class=l>${{ secrets.WIF_SERVICE_ACCOUNT }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up Cloud SDK</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>uses</span><span class=p>:</span><span class=w> </span><span class=l>google-github-actions/setup-gcloud@v2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Configure Docker for GCR</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>gcloud auth configure-docker gcr.io</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Download trained model from GCS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          mkdir -p api/models/trained
</span></span></span><span class=line><span class=cl><span class=sd>          gsutil cp gs://${{ secrets.GCS_BUCKET_NAME }}/models/trained/housing_price_model.pkl \
</span></span></span><span class=line><span class=cl><span class=sd>            api/models/trained/housing_price_model.pkl</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Build Docker image</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          cd api
</span></span></span><span class=line><span class=cl><span class=sd>          docker build \
</span></span></span><span class=line><span class=cl><span class=sd>            --tag gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --tag gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:latest \
</span></span></span><span class=line><span class=cl><span class=sd>            .</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Push Docker image to GCR</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          docker push gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }}
</span></span></span><span class=line><span class=cl><span class=sd>          docker push gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Deploy to Cloud Run</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          gcloud run deploy ${{ env.SERVICE_NAME }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --image gcr.io/${{ env.PROJECT_ID }}/${{ env.SERVICE_NAME }}:${{ github.sha }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --platform managed \
</span></span></span><span class=line><span class=cl><span class=sd>            --region ${{ env.REGION }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --allow-unauthenticated \
</span></span></span><span class=line><span class=cl><span class=sd>            --set-env-vars=&#34;GCS_BUCKET=${{ secrets.GCS_BUCKET_NAME }},WANDB_API_KEY=${{ secrets.WANDB_API_KEY }}&#34; \
</span></span></span><span class=line><span class=cl><span class=sd>            --memory 2Gi \
</span></span></span><span class=line><span class=cl><span class=sd>            --cpu 2 \
</span></span></span><span class=line><span class=cl><span class=sd>            --max-instances 10 \
</span></span></span><span class=line><span class=cl><span class=sd>            --min-instances 1 \
</span></span></span><span class=line><span class=cl><span class=sd>            --timeout 300</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Get Cloud Run URL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>id</span><span class=p>:</span><span class=w> </span><span class=l>deploy-url</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --platform managed \
</span></span></span><span class=line><span class=cl><span class=sd>            --region ${{ env.REGION }} \
</span></span></span><span class=line><span class=cl><span class=sd>            --format &#39;value(status.url)&#39;)
</span></span></span><span class=line><span class=cl><span class=sd>          echo &#34;url=$URL&#34; &gt;&gt; $GITHUB_OUTPUT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run smoke test</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          curl -X POST &#34;${{ steps.deploy-url.outputs.url }}/api/v1/predict&#34; \
</span></span></span><span class=line><span class=cl><span class=sd>            -H &#34;Content-Type: application/json&#34; \
</span></span></span><span class=line><span class=cl><span class=sd>            -d &#39;{&#34;instances&#34;:[{&#34;longitude&#34;:-122.23,&#34;latitude&#34;:37.88,&#34;housing_median_age&#34;:41,&#34;total_rooms&#34;:880,&#34;total_bedrooms&#34;:129,&#34;population&#34;:322,&#34;households&#34;:126,&#34;median_income&#34;:8.3252,&#34;ocean_proximity&#34;:&#34;NEAR BAY&#34;}]}&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Notify deployment success</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>if</span><span class=p>:</span><span class=w> </span><span class=l>success()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          echo &#34;Deployment successful! API available at: ${{ steps.deploy-url.outputs.url }}&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Valor para el MLOps engineer:</strong></p><ul><li><strong>Zero-downtime deployment:</strong> Cloud Run hace rolling updates automáticamente</li><li><strong>Rollback fácil:</strong> Si algo explota, haces <code>gcloud run services update-traffic --to-revisions=PREVIOUS=100</code></li><li><strong>Smoke test automático:</strong> Verifica que el API responde después del deploy</li><li><strong>Versionado de imágenes:</strong> Cada commit tiene su propia imagen Docker taggeada con SHA</li></ul><h3 id=secretos-y-seguridad>Secretos y Seguridad<a hidden class=anchor aria-hidden=true href=#secretos-y-seguridad>#</a></h3><p><strong>CRÍTICO:</strong> Nunca commitees secrets al repo. GitHub Actions usa <strong>GitHub Secrets</strong> para guardar:</p><ul><li><code>GCP_PROJECT_ID</code>: ID del proyecto de GCP</li><li><code>GCS_BUCKET_NAME</code>: Nombre del bucket de GCS</li><li><code>WANDB_API_KEY</code>: API key de W&amp;B</li><li><code>GCP_SA_KEY</code>: Service account key (JSON) para autenticar en GCP</li><li><code>WIF_PROVIDER</code> / <code>WIF_SERVICE_ACCOUNT</code>: Workload Identity Federation (más seguro que SA keys)</li></ul><p><strong>Configuración en GitHub:</strong></p><ol><li>Ve a repo → Settings → Secrets and variables → Actions</li><li>Crea cada secret</li><li>Los workflows acceden con <code>${{ secrets.SECRET_NAME }}</code></li></ol><h3 id=monitoreo-de-deployments>Monitoreo de Deployments<a hidden class=anchor aria-hidden=true href=#monitoreo-de-deployments>#</a></h3><p><strong>¿Cómo saber si un deployment falló?</strong></p><p>GitHub Actions envía notificaciones a:</p><ul><li>Email (configurado en GitHub profile)</li><li>Slack (con GitHub app)</li><li>Discord/Teams (con webhooks)</li></ul><p><strong>Post-deployment monitoring:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># Agregar step de validación post-deploy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run API health check</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    for i in {1..5}; do
</span></span></span><span class=line><span class=cl><span class=sd>      STATUS=$(curl -s -o /dev/null -w &#34;%{http_code}&#34; &#34;${{ steps.deploy-url.outputs.url }}/health&#34;)
</span></span></span><span class=line><span class=cl><span class=sd>      if [ $STATUS -eq 200 ]; then
</span></span></span><span class=line><span class=cl><span class=sd>        echo &#34;Health check passed&#34;
</span></span></span><span class=line><span class=cl><span class=sd>        exit 0
</span></span></span><span class=line><span class=cl><span class=sd>      fi
</span></span></span><span class=line><span class=cl><span class=sd>      echo &#34;Attempt $i failed, retrying...&#34;
</span></span></span><span class=line><span class=cl><span class=sd>      sleep 10
</span></span></span><span class=line><span class=cl><span class=sd>    done
</span></span></span><span class=line><span class=cl><span class=sd>    echo &#34;Health check failed after 5 attempts&#34;
</span></span></span><span class=line><span class=cl><span class=sd>    exit 1</span><span class=w>
</span></span></span></code></pre></div><h3 id=estrategias-avanzadas-de-cicd>Estrategias Avanzadas de CI/CD<a hidden class=anchor aria-hidden=true href=#estrategias-avanzadas-de-cicd>#</a></h3><h4 id=1-pipeline-de-reentrenamiento-automático>1. Pipeline de Reentrenamiento Automático<a hidden class=anchor aria-hidden=true href=#1-pipeline-de-reentrenamiento-automático>#</a></h4><p><strong>Trigger:</strong> Cron schedule (ejemplo: semanalmente)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>schedule</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>cron</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;0 2 * * 0&#39;</span><span class=w>  </span><span class=c># Cada domingo a las 2 AM UTC</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>jobs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>retrain-model</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runs-on</span><span class=p>:</span><span class=w> </span><span class=l>ubuntu-latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Run full pipeline</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>python main.py</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Compare metrics with production model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          NEW_MAPE=$(python scripts/get_latest_mape.py)
</span></span></span><span class=line><span class=cl><span class=sd>          PROD_MAPE=$(python scripts/get_production_mape.py)
</span></span></span><span class=line><span class=cl><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>          if (( $(echo &#34;$NEW_MAPE &lt; $PROD_MAPE&#34; | bc -l) )); then
</span></span></span><span class=line><span class=cl><span class=sd>            echo &#34;New model is better, promoting to Production&#34;
</span></span></span><span class=line><span class=cl><span class=sd>            mlflow models transition --name housing_price_model --version latest --stage Production
</span></span></span><span class=line><span class=cl><span class=sd>          else
</span></span></span><span class=line><span class=cl><span class=sd>            echo &#34;New model is worse, keeping current Production model&#34;
</span></span></span><span class=line><span class=cl><span class=sd>          fi</span><span class=w>
</span></span></span></code></pre></div><p><strong>Valor:</strong> El modelo se reentrena automáticamente con datos nuevos. Si mejora, se promociona a Production. Si empeora, se descarta.</p><h4 id=2-canary-deployments>2. Canary Deployments<a hidden class=anchor aria-hidden=true href=#2-canary-deployments>#</a></h4><p><strong>Problema:</strong> Un nuevo modelo puede tener bugs sutiles que no aparecen en tests.</p><p><strong>Solución:</strong> Deployar el nuevo modelo a solo 10% del tráfico, monitorear por 1 hora, luego migrar 100% si no hay errores.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Deploy canary (10% traffic)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    gcloud run services update-traffic ${{ env.SERVICE_NAME }} \
</span></span></span><span class=line><span class=cl><span class=sd>      --to-revisions=LATEST=10,PREVIOUS=90</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Wait and monitor</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=l>sleep 3600 </span><span class=w> </span><span class=c># 1 hora</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Check error rate</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    ERROR_RATE=$(python scripts/check_error_rate.py --minutes=60)
</span></span></span><span class=line><span class=cl><span class=sd>    if (( $(echo &#34;$ERROR_RATE &gt; 0.05&#34; | bc -l) )); then
</span></span></span><span class=line><span class=cl><span class=sd>      echo &#34;Error rate too high, rolling back&#34;
</span></span></span><span class=line><span class=cl><span class=sd>      gcloud run services update-traffic ${{ env.SERVICE_NAME }} --to-revisions=PREVIOUS=100
</span></span></span><span class=line><span class=cl><span class=sd>      exit 1
</span></span></span><span class=line><span class=cl><span class=sd>    fi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Promote to 100% traffic</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>run</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    gcloud run services update-traffic ${{ env.SERVICE_NAME }} --to-revisions=LATEST=100</span><span class=w>
</span></span></span></code></pre></div><h3 id=lo-que-cicd-resuelve-en-mlops>Lo Que CI/CD Resuelve en MLOps<a hidden class=anchor aria-hidden=true href=#lo-que-cicd-resuelve-en-mlops>#</a></h3><p><strong>Sin CI/CD:</strong></p><ul><li>Deployment manual propenso a errores</li><li>&ldquo;Funciona en mi máquina&rdquo; syndrome</li><li>Testing inconsistente</li><li>Rollback requiere pánico debugging</li><li>No hay historial de qué se deployó cuándo</li></ul><p><strong>Con CI/CD:</strong></p><ul><li>Deployment automático en cada merge</li><li>Tests garantizan que el código funciona</li><li>Rollback es un comando</li><li>Historial completo en GitHub Actions UI</li><li>Cada deployment es reproducible</li></ul><h3 id=el-valor-real-para-el-mlops-engineer>El Valor Real Para el MLOps Engineer<a hidden class=anchor aria-hidden=true href=#el-valor-real-para-el-mlops-engineer>#</a></h3><p><strong>No es sobre automatizar por automatizar.</strong> Es sobre:</p><ol><li><strong>Reducir toil:</strong> Gastas tiempo resolviendo problemas interesantes, no copiando archivos manualmente</li><li><strong>Confianza:</strong> Sabes que el código funciona antes de llegar a producción</li><li><strong>Velocidad:</strong> De commit a producción en &lt;10 minutos</li><li><strong>Auditoría:</strong> Cada cambio está loggeado en GitHub</li><li><strong>Colaboración:</strong> Tu equipo puede deployar sin depender de ti</li></ol><p><strong>Un MLOps engineer sin CI/CD es como un software engineer sin git—técnicamente posible, pero fundamentalmente broken.</strong></p><hr><p><a name=mlops-value-proposition></a></p><h2 id=9-el-valor-de-mlops-por-qué-esto-importa>9. El Valor de MLOps: Por Qué Esto Importa<a hidden class=anchor aria-hidden=true href=#9-el-valor-de-mlops-por-qué-esto-importa>#</a></h2><h3 id=la-pregunta-central>La Pregunta Central<a hidden class=anchor aria-hidden=true href=#la-pregunta-central>#</a></h3><p>&ldquo;¿Por qué debería invertir tiempo en todo esto cuando puedo entrenar un modelo en un notebook en 30 minutos?&rdquo;</p><p>Esta es la pregunta que todo MLOps engineer ha escuchado. La respuesta corta: <strong>porque el notebook no escala.</strong></p><p>La respuesta larga es lo que cubre esta sección.</p><h3 id=el-problema-real-research-code-vs-production-code>El Problema Real: Research Code vs Production Code<a hidden class=anchor aria-hidden=true href=#el-problema-real-research-code-vs-production-code>#</a></h3><h4 id=research-code-notebook>Research Code (Notebook)<a hidden class=anchor aria-hidden=true href=#research-code-notebook>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># notebook.ipynb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cell 1</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;housing.csv&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cell 2</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cell 3</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestRegressor</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cell 4</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pickle</span>
</span></span><span class=line><span class=cl><span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;model.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cell 5</span>
</span></span><span class=line><span class=cl><span class=c1># Wait, did I drop the right columns?</span>
</span></span><span class=line><span class=cl><span class=c1># Let me rerun cell 2... oh no, I ran it twice</span>
</span></span><span class=line><span class=cl><span class=c1># Now I have 0 rows, what happened?</span>
</span></span></code></pre></div><p><strong>Problemas:</strong></p><ul><li>No reproducible (orden de ejecución importa)</li><li>No testeable</li><li>No versionable (git diffs son ilegibles)</li><li>No escalable (qué pasa con 100GB de datos?)</li><li>No auditable (qué params usaste?)</li></ul><h4 id=production-code-este-pipeline>Production Code (Este Pipeline)<a hidden class=anchor aria-hidden=true href=#production-code-este-pipeline>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/model/05_model_selection/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@hydra.main</span><span class=p>(</span><span class=n>config_path</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>config_name</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Entrenar modelo con configuración versionada.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Cargar datos desde GCS (single source of truth)</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>load_from_gcs</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>gcs_train_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Aplicar preprocessing pipeline serializado</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>joblib</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;artifacts/preprocessing_pipeline.pkl&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Entrenar con params de config</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span><span class=o>**</span><span class=n>config</span><span class=o>.</span><span class=n>hyperparameters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Loggear a MLflow</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_params</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>hyperparameters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_metrics</span><span class=p>(</span><span class=n>evaluate</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span>
</span></span></code></pre></div><p><strong>Beneficios:</strong></p><ul><li>Reproducible (mismo config = mismo output)</li><li>Testeable (funciones puras, mocking)</li><li>Versionable (git diff legible)</li><li>Escalable (corre en local o en cluster)</li><li>Auditable (MLflow tracking)</li></ul><h3 id=valor-1-modularización-de-código>Valor #1: Modularización de Código<a hidden class=anchor aria-hidden=true href=#valor-1-modularización-de-código>#</a></h3><h4 id=por-qué-importa>Por Qué Importa<a hidden class=anchor aria-hidden=true href=#por-qué-importa>#</a></h4><p><strong>Escenario:</strong> Tu modelo tiene bug en preprocessing. En notebook, el preprocessing está mezclado con feature engineering, entrenamiento y evaluación en 300 líneas.</p><p><strong>En este pipeline:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Bug está en preprocessing → solo editas src/data/02_preprocessing/</span>
</span></span><span class=line><span class=cl><span class=c1># Tests fallan → pytest tests/test_preprocessor.py</span>
</span></span><span class=line><span class=cl><span class=c1># Fixeas → reejecutas solo step 02-07, no 01</span>
</span></span></code></pre></div><p><strong>Tiempo ahorrado:</strong> Horas por bug.</p><h4 id=separation-of-concerns>Separation of Concerns<a hidden class=anchor aria-hidden=true href=#separation-of-concerns>#</a></h4><p>Este pipeline separa:</p><ol><li><strong>Data steps (01-04):</strong> Producen artifacts reutilizables</li><li><strong>Model steps (05-07):</strong> Consumen artifacts, producen modelos</li><li><strong>API:</strong> Consume modelos, produce predicciones</li><li><strong>Frontend:</strong> Consume API, produce UX</li></ol><p><strong>Beneficio:</strong> Equipos pueden trabajar en paralelo. El data scientist modifica feature engineering sin tocar el API. El frontend engineer modifica UI sin entender Random Forests.</p><h3 id=valor-2-working-with-artifacts>Valor #2: Working with Artifacts<a hidden class=anchor aria-hidden=true href=#valor-2-working-with-artifacts>#</a></h3><h4 id=el-problema-dónde-está-el-model_final_v3pkl>El Problema: &ldquo;¿Dónde está el model_final_v3.pkl?&rdquo;<a hidden class=anchor aria-hidden=true href=#el-problema-dónde-está-el-model_final_v3pkl>#</a></h4><p>Sin artifact management:</p><pre tabindex=0><code>models/
├── model_v1.pkl
├── model_v2.pkl
├── model_final.pkl
├── model_final_FINAL.pkl
├── model_final_REAL.pkl
├── model_production_2024_01_15.pkl  # ¿Este es el de producción?
└── model_old_backup.pkl  # ¿Puedo borrarlo?
</code></pre><p><strong>Problemas:</strong></p><ul><li>No sabes qué hiperparámetros usa cada uno</li><li>No sabes qué métricas logró</li><li>No sabes con qué datos se entrenó</li><li>Rollback = buscar el archivo correcto</li></ul><h4 id=la-solución-artifact-storage--metadata>La Solución: Artifact Storage + Metadata<a hidden class=anchor aria-hidden=true href=#la-solución-artifact-storage--metadata>#</a></h4><p><strong>1. Google Cloud Storage para datos:</strong></p><pre tabindex=0><code>gs://bucket-name/
├── data/
│   ├── 01-raw/housing.parquet                    # Inmutable
│   ├── 02-processed/housing_processed.parquet    # Versionado por fecha
│   ├── 03-features/housing_features.parquet
│   └── 04-split/
│       ├── train/train.parquet
│       └── test/test.parquet
├── artifacts/
│   ├── imputer.pkl                               # Preprocessing artifacts
│   ├── preprocessing_pipeline.pkl
│   └── scaler.pkl
└── models/
    └── trained/housing_price_model.pkl           # Latest trained
</code></pre><p><strong>Beneficios:</strong></p><ul><li><strong>Inmutabilidad:</strong> <code>01-raw/</code> nunca cambia, siempre puedes reejecutar el pipeline</li><li><strong>Versionamiento:</strong> Cada run tiene timestamp, puedes comparar versiones</li><li><strong>Compartir:</strong> Todo el equipo accede a los mismos datos, no &ldquo;enviame el CSV por Slack&rdquo;</li></ul><p><strong>2. MLflow para modelos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Registrar modelo</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MLflow guarda automáticamente:</span>
</span></span><span class=line><span class=cl><span class=c1># - El pickle del modelo</span>
</span></span><span class=line><span class=cl><span class=c1># - Los hiperparámetros (n_estimators=200, max_depth=20)</span>
</span></span><span class=line><span class=cl><span class=c1># - Las métricas (MAPE=7.8%, R²=0.87)</span>
</span></span><span class=line><span class=cl><span class=c1># - Metadata (fecha, duración, usuario)</span>
</span></span><span class=line><span class=cl><span class=c1># - Código (git commit SHA)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Cargar modelo en producción</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>pyfunc</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;models:/housing_price_model/Production&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Beneficios:</strong></p><ul><li><strong>Versionamiento semántico:</strong> v1, v2, v3 con stages (Staging/Production)</li><li><strong>Metadata rica:</strong> Sabes exactamente qué es cada versión</li><li><strong>Rollback trivial:</strong> <code>transition v2 to Production</code></li><li><strong>Comparación:</strong> MLflow UI muestra tabla comparando todas las versiones</li></ul><p><strong>3. W&amp;B para experimentos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Cada run de sweep loggea:</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;hyperparameters/n_estimators&#34;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;hyperparameters/max_depth&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;metrics/mape&#34;</span><span class=p>:</span> <span class=mf>7.8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;metrics/r2&#34;</span><span class=p>:</span> <span class=mf>0.87</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;plots/feature_importances&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>fig</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;dataset/train_size&#34;</span><span class=p>:</span> <span class=mi>16512</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># W&amp;B dashboard:</span>
</span></span><span class=line><span class=cl><span class=c1># - Tabla con 50 runs de sweep</span>
</span></span><span class=line><span class=cl><span class=c1># - Filtrar por MAPE &lt; 8%</span>
</span></span><span class=line><span class=cl><span class=c1># - Parallel coordinates plot mostrando relación entre hiperparámetros y MAPE</span>
</span></span><span class=line><span class=cl><span class=c1># - Comparar top 5 runs side-by-side</span>
</span></span></code></pre></div><p><strong>Beneficios:</strong></p><ul><li><strong>Visualización:</strong> Plots interactivos de cómo cada hiperparámetro afecta métricas</li><li><strong>Colaboración:</strong> Tu equipo ve tus experimentos en real-time</li><li><strong>Reproducibilidad:</strong> Cada run tiene link permanente con todo el contexto</li></ul><h3 id=valor-3-pipeline-architecture>Valor #3: Pipeline Architecture<a hidden class=anchor aria-hidden=true href=#valor-3-pipeline-architecture>#</a></h3><h4 id=por-qué-un-pipeline-no-un-script>Por Qué Un Pipeline, No Un Script<a hidden class=anchor aria-hidden=true href=#por-qué-un-pipeline-no-un-script>#</a></h4><p><strong>Script único (run_all.py):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># run_all.py (500 líneas)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Download data</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>download_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Preprocess</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Feature engineering</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>add_features</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Train model</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Deploy</span>
</span></span><span class=line><span class=cl>    <span class=n>deploy_model</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Problemas:</strong></p><ul><li>Si falla en train_model(), reejecutas TODO (incluyendo download lento)</li><li>No puedes ejecutar solo feature engineering para experimentar</li><li>Cambiar preprocessing requiere reentrenar todo</li><li>No hay checkpoints intermedios</li></ul><p><strong>Pipeline modular:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Ejecutar todo</span>
</span></span><span class=line><span class=cl>make run-pipeline
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ejecutar solo preprocessing</span>
</span></span><span class=line><span class=cl>make run-preprocessing
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ejecutar desde feature engineering en adelante</span>
</span></span><span class=line><span class=cl>python main.py main.execute_steps<span class=o>=[</span>03_feature_engineering,04_segregation,05_model_selection<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Debugging: ejecutar solo step que falló</span>
</span></span><span class=line><span class=cl>python src/data/03_feature_engineering/main.py --debug
</span></span></code></pre></div><p><strong>Beneficios:</strong></p><ul><li><strong>Ejecución selectiva:</strong> Solo reejecutas lo que cambió</li><li><strong>Debugging rápido:</strong> Testeas un step aislado</li><li><strong>Paralelización:</strong> Steps independientes pueden correr en paralelo</li><li><strong>Checkpointing:</strong> Si falla step 05, steps 01-04 ya están hechos</li></ul><h4 id=el-contrato-entre-steps>El Contrato Entre Steps<a hidden class=anchor aria-hidden=true href=#el-contrato-entre-steps>#</a></h4><p>Cada step:</p><ul><li><strong>Input:</strong> Path a artifact en GCS (ejemplo: <code>data/02-processed/housing_processed.parquet</code>)</li><li><strong>Output:</strong> Path a nuevo artifact en GCS (ejemplo: <code>data/03-features/housing_features.parquet</code>)</li><li><strong>Side effects:</strong> Logs a MLflow/W&amp;B</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Step 03: Feature Engineering</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Input</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>load_from_gcs</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>gcs_input_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Transform</span>
</span></span><span class=line><span class=cl>    <span class=n>df_transformed</span> <span class=o>=</span> <span class=n>apply_feature_engineering</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Output</span>
</span></span><span class=line><span class=cl>    <span class=n>save_to_gcs</span><span class=p>(</span><span class=n>df_transformed</span><span class=p>,</span> <span class=n>config</span><span class=o>.</span><span class=n>gcs_output_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Side effects</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span><span class=s2>&#34;optimization/optimal_k&#34;</span><span class=p>:</span> <span class=mi>8</span><span class=p>})</span>
</span></span></code></pre></div><p>Este <strong>contrato</strong> permite que cada step sea:</p><ul><li>Testeado independientemente</li><li>Desarrollado por diferentes personas</li><li>Reemplazado sin afectar otros steps</li></ul><h3 id=valor-4-production-ready-vs-research-code>Valor #4: Production-Ready vs Research Code<a hidden class=anchor aria-hidden=true href=#valor-4-production-ready-vs-research-code>#</a></h3><h4 id=checklist-de-production-ready>Checklist de Production-Ready<a hidden class=anchor aria-hidden=true href=#checklist-de-production-ready>#</a></h4><table><thead><tr><th>Feature</th><th>Research Code</th><th>Este Pipeline</th></tr></thead><tbody><tr><td><strong>Versionamiento</strong></td><td>Git (mal, notebooks)</td><td>Git + GCS + MLflow</td></tr><tr><td><strong>Testing</strong></td><td>Manual (&ldquo;lo corrí una vez&rdquo;)</td><td>pytest + CI</td></tr><tr><td><strong>Configuración</strong></td><td>Hardcoded</td><td>YAML versionado</td></tr><tr><td><strong>Secretos</strong></td><td>Expuestos en código</td><td>.env + GitHub Secrets</td></tr><tr><td><strong>Logs</strong></td><td>print() statements</td><td>Logging estructurado</td></tr><tr><td><strong>Monitoring</strong></td><td>&ldquo;Espero que funcione&rdquo;</td><td>W&amp;B + MLflow tracking</td></tr><tr><td><strong>Deployment</strong></td><td>Manual</td><td>CI/CD automático</td></tr><tr><td><strong>Rollback</strong></td><td>Panic debugging</td><td>Transition en MLflow</td></tr><tr><td><strong>Documentación</strong></td><td>README desactualizado</td><td>Código autodocumentado + Markdown en MLflow</td></tr><tr><td><strong>Colaboración</strong></td><td>&ldquo;Ejecuta estas 10 celdas en orden&rdquo;</td><td><code>make run-pipeline</code></td></tr></tbody></table><h4 id=el-costo-real-de-no-hacer-mlops>El Costo Real de No Hacer MLOps<a hidden class=anchor aria-hidden=true href=#el-costo-real-de-no-hacer-mlops>#</a></h4><p><strong>Escenario:</strong> Un modelo en producción tiene bug que causa predicciones incorrectas.</p><p><strong>Sin MLOps (Research Code):</strong></p><ol><li>Detectar el bug: Usuario reporta → 2 horas</li><li>Reproducir el bug: Buscar qué código/datos se usaron → 4 horas</li><li>Fixear: Correr notebook localmente → 1 hora</li><li>Deployar: SSH, copiar pickle, restart server → 30 min</li><li>Verificar: Correr tests manuales → 1 hora</li><li><strong>Total: 8.5 horas de downtime</strong></li></ol><p><strong>Con MLOps (Este Pipeline):</strong></p><ol><li>Detectar el bug: Monitoring automático alerta → 5 min</li><li>Rollback: <code>transition v3 to Archived</code> + <code>transition v2 to Production</code> → 2 min</li><li>Fix: Identificar issue con MLflow metadata, fixear código → 1 hora</li><li>Deployar: Push to GitHub → CI/CD automático → 10 min</li><li>Verificar: Smoke tests automáticos pasan → 1 min</li><li><strong>Total: 1 hora 18 min de downtime (>85% reducción)</strong></li></ol><p><strong>Ahorro anualizado:</strong> Si esto pasa 4 veces al año, ahorras 29 horas de tiempo de ingeniero.</p><h3 id=valor-5-decisiones-respaldadas-por-datos>Valor #5: Decisiones Respaldadas por Datos<a hidden class=anchor aria-hidden=true href=#valor-5-decisiones-respaldadas-por-datos>#</a></h3><h4 id=el-anti-pattern>El Anti-Pattern<a hidden class=anchor aria-hidden=true href=#el-anti-pattern>#</a></h4><p>&ldquo;Usé Random Forest con <code>n_estimators=100</code> porque eso es lo que hace todo el mundo.&rdquo;</p><p><strong>Problema:</strong> No tienes evidencia de que es la mejor opción.</p><h4 id=este-pipeline>Este Pipeline<a hidden class=anchor aria-hidden=true href=#este-pipeline>#</a></h4><p>Cada decisión tiene métricas cuantificables:</p><p><strong>1. Imputación:</strong></p><ul><li>Comparó 4 estrategias (Simple median, Simple mean, KNN, IterativeImputer)</li><li>IterativeImputer ganó con RMSE=0.52 (vs 0.78 de median)</li><li>Plot de comparación en W&amp;B: <code>wandb.ai/project/run/imputation_comparison</code></li></ul><p><strong>2. Feature Engineering:</strong></p><ul><li>Optimizó K de 5 a 15</li><li>K=8 maximizó silhouette score (0.64)</li><li>Plot de elbow method en W&amp;B</li></ul><p><strong>3. Hyperparameter Tuning:</strong></p><ul><li>Sweep bayesiano de 50 runs</li><li>Optimal config: <code>n_estimators=200, max_depth=20</code></li><li>MAPE mejoró de 8.5% a 7.8%</li><li>Link a sweep: <code>wandb.ai/project/sweeps/abc123</code></li></ul><p><strong>Beneficio:</strong> Seis meses después, cuando el stakeholder pregunta &ldquo;¿por qué usamos este modelo?&rdquo;, abres W&amp;B/MLflow y la respuesta está ahí con plots y métricas.</p><h3 id=el-roi-de-mlops>El ROI de MLOps<a hidden class=anchor aria-hidden=true href=#el-roi-de-mlops>#</a></h3><p><strong>Inversión inicial:</strong></p><ul><li>Setup de GCS, MLflow, W&amp;B, CI/CD: 2-3 días</li><li>Refactoring de código a pipeline modular: 1-2 semanas</li></ul><p><strong>Retorno:</strong></p><ul><li>Deployment time: 8 horas → 10 minutos (48x más rápido)</li><li>Debugging time: 4 horas → 30 min (8x más rápido)</li><li>Onboarding nuevos engineers: 1 semana → 1 día</li><li>Confianza del equipo: &ldquo;Espero que funcione&rdquo; → &ldquo;Sé que funciona&rdquo;</li></ul><p><strong>Para un equipo de 5 personas, el breakeven es ~1 mes.</strong></p><h3 id=la-lección-final-para-mlops-engineers>La Lección Final Para MLOps Engineers<a hidden class=anchor aria-hidden=true href=#la-lección-final-para-mlops-engineers>#</a></h3><p><strong>No es sobre las herramientas.</strong> Puedes reemplazar:</p><ul><li>GCS → S3 → Azure Blob</li><li>MLflow → Neptune → Comet</li><li>W&amp;B → TensorBoard → MLflow</li><li>GitHub Actions → GitLab CI → Jenkins</li></ul><p><strong>Es sobre los principios:</strong></p><ol><li><strong>Modularización:</strong> Código en módulos testeables, no notebooks monolíticos</li><li><strong>Artifact Management:</strong> Datos y modelos versionados, no <code>model_final_v3.pkl</code></li><li><strong>Automatización:</strong> CI/CD elimina toil</li><li><strong>Observabilidad:</strong> Logs, métricas, tracking</li><li><strong>Reproducibilidad:</strong> Mismo input → mismo output</li><li><strong>Decisiones data-driven:</strong> Cada elección respaldada por métricas</li></ol><p><strong>Cuando entiendes esto, eres un MLOps engineer. Cuando lo implementas, eres un buen MLOps engineer.</strong></p><hr><p><a name=wandb-vs-mlflow></a></p><h2 id=95-wb-vs-mlflow-por-qué-ambos-no-uno-u-otro>9.5. W&amp;B vs MLflow: Por Qué Ambos, No Uno u Otro<a hidden class=anchor aria-hidden=true href=#95-wb-vs-mlflow-por-qué-ambos-no-uno-u-otro>#</a></h2><h3 id=la-pregunta-incómoda>La Pregunta Incómoda<a hidden class=anchor aria-hidden=true href=#la-pregunta-incómoda>#</a></h3><p>&ldquo;¿Por qué tienes Weights & Biases Y MLflow? ¿No son lo mismo?&rdquo;</p><p>Esta pregunta revela un malentendido fundamental sobre lo que hace cada herramienta. No son competidores—son <strong>aliados con responsabilidades diferentes</strong>. Entender esto separa un data scientist que experimenta de un MLOps engineer que construye sistemas.</p><p>La respuesta corta: <strong>W&amp;B es tu laboratorio de investigación. MLflow es tu cadena de producción.</strong></p><p>La respuesta larga es lo que cubre esta sección, con ejemplos del código real de este proyecto.</p><hr><h3 id=el-problema-real-experimentación-vs-governance>El Problema Real: Experimentación vs Governance<a hidden class=anchor aria-hidden=true href=#el-problema-real-experimentación-vs-governance>#</a></h3><h4 id=fase-1-experimentación-50-100-runsdía>Fase 1: Experimentación (50-100 runs/día)<a hidden class=anchor aria-hidden=true href=#fase-1-experimentación-50-100-runsdía>#</a></h4><p>Cuando estás en fase de experimentación:</p><ul><li>Corres 50 sweep runs probando combinaciones de hiperparámetros</li><li>Necesitas ver <strong>en tiempo real</strong> cómo evoluciona cada run</li><li>Quieres comparar visualmente 20 runs simultáneos</li><li>Necesitas ver plots de convergencia, distribuciones de features, confusion matrices</li><li>El overhead de logging debe ser mínimo (logging asíncrono)</li></ul><p><strong>Herramienta correcta:</strong> Weights & Biases</p><h4 id=fase-2-governance-y-deployment-1-2-modelossemana>Fase 2: Governance y Deployment (1-2 modelos/semana)<a hidden class=anchor aria-hidden=true href=#fase-2-governance-y-deployment-1-2-modelossemana>#</a></h4><p>Cuando subes un modelo a producción:</p><ul><li>Necesitas versionamiento semántico (v1, v2, v3)</li><li>Necesitas stages (Staging → Production)</li><li>Necesitas metadata rica (¿qué hiperparámetros? ¿qué datos? ¿qué commit?)</li><li>Necesitas un API para cargar modelos (<code>models:/housing_price_model/Production</code>)</li><li>Necesitas rollback trivial (transition v2 to Production)</li></ul><p><strong>Herramienta correcta:</strong> MLflow Model Registry</p><p><strong>La verdad incómoda:</strong> Ninguna herramienta hace bien ambas cosas.</p><hr><h3 id=cómo-este-proyecto-usa-wb>Cómo Este Proyecto Usa W&amp;B<a hidden class=anchor aria-hidden=true href=#cómo-este-proyecto-usa-wb>#</a></h3><h4 id=1-hyperparameter-sweep-step-06-bayesian-optimization>1. Hyperparameter Sweep (Step 06): Bayesian Optimization<a hidden class=anchor aria-hidden=true href=#1-hyperparameter-sweep-step-06-bayesian-optimization>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/model/06_sweep/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configuración del sweep (Bayesian optimization)</span>
</span></span><span class=line><span class=cl><span class=n>sweep_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;method&#34;</span><span class=p>:</span> <span class=s2>&#34;bayes&#34;</span><span class=p>,</span>  <span class=c1># Bayesian &gt; Grid &gt; Random</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;metric&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;wmape&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;goal&#34;</span><span class=p>:</span> <span class=s2>&#34;minimize&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;early_terminate&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;hyperband&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_iter&#34;</span><span class=p>:</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;parameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;min&#34;</span><span class=p>:</span> <span class=mi>50</span><span class=p>,</span> <span class=s2>&#34;max&#34;</span><span class=p>:</span> <span class=mi>300</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;min&#34;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span> <span class=s2>&#34;max&#34;</span><span class=p>:</span> <span class=mi>30</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;min&#34;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span> <span class=s2>&#34;max&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;min&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=s2>&#34;max&#34;</span><span class=p>:</span> <span class=mi>10</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Inicializar sweep</span>
</span></span><span class=line><span class=cl><span class=n>sweep_id</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span><span class=n>sweep</span><span class=o>=</span><span class=n>sweep_config</span><span class=p>,</span> <span class=n>project</span><span class=o>=</span><span class=s2>&#34;housing-mlops-gcp&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Función de training que W&amp;B llama 50 veces</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>()</span>  <span class=c1># W&amp;B asigna hiperparámetros automáticamente</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Obtener hiperparámetros sugeridos por Bayesian optimizer</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Entrenar modelo</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>n_estimators</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>n_estimators</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_depth</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>max_depth</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># ...</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Evaluar</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Log a W&amp;B (asíncrono, no bloquea)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;hyperparameters/n_estimators&#34;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>n_estimators</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;hyperparameters/max_depth&#34;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>max_depth</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics/mape&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics/wmape&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;wmape&#39;</span><span class=p>],</span>  <span class=c1># Optimizer usa esto</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics/r2&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;plots/feature_importances&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>fig</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>run</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ejecutar 50 runs con Bayesian optimization</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>agent</span><span class=p>(</span><span class=n>sweep_id</span><span class=p>,</span> <span class=n>function</span><span class=o>=</span><span class=n>train</span><span class=p>,</span> <span class=n>count</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Lo que W&amp;B hace aquí que MLflow no puede:</strong></p><ol><li><p><strong>Bayesian Optimization</strong>: W&amp;B sugiere los próximos hiperparámetros basándose en runs previos. No es random—usa Gaussian Processes para explorar el espacio eficientemente.</p><pre tabindex=0><code>Run 1: n_estimators=100, max_depth=15 → wMAPE=8.5%
Run 2: n_estimators=200, max_depth=20 → wMAPE=7.9%  # Mejor
Run 3: n_estimators=250, max_depth=22 → wMAPE=7.8%  # W&amp;B sugiere valores cercanos a Run 2
</code></pre></li><li><p><strong>Early Termination (Hyperband)</strong>: Si un run va mal en las primeras 3 iteraciones (epochs), W&amp;B lo mata automáticamente y prueba otros hiperparámetros. Ahorra ~40% de compute.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;early_terminate&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;hyperband&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;min_iter&#34;</span><span class=p>:</span> <span class=mi>3</span>  <span class=c1># Mínimo 3 iteraciones antes de terminar</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li><li><p><strong>Parallel Coordinates Plot</strong>: Visualización interactiva mostrando qué combinación de hiperparámetros produce mejor wMAPE.</p><p><img alt="W&amp;B Parallel Coordinates" loading=lazy src=https://docs.wandb.ai/assets/images/parallel-coordinates.png></p><p><strong>Interpretación:</strong> Las líneas azules (runs con wMAPE bajo) convergen en <code>n_estimators=200-250</code> y <code>max_depth=20-25</code>. Esto te dice visualmente dónde está el óptimo.</p></li><li><p><strong>Logging Asíncrono</strong>: <code>wandb.log()</code> no bloquea. Mientras el modelo entrena, W&amp;B sube métricas en background. Total overhead: &lt;1% del training time.</p></li></ol><p><strong>MLflow no tiene:</strong></p><ul><li>Bayesian optimization (solo Grid/Random search vía scikit-learn)</li><li>Early termination inteligente</li><li>Parallel coordinates plots</li><li>Logging asíncrono (mlflow.log es síncrono)</li></ul><hr><h4 id=2-real-time-monitoring-ver-runs-mientras-corren>2. Real-Time Monitoring: Ver Runs Mientras Corren<a hidden class=anchor aria-hidden=true href=#2-real-time-monitoring-ver-runs-mientras-corren>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En W&amp;B dashboard (web UI):</span>
</span></span><span class=line><span class=cl><span class=c1># - Ver 50 runs simultáneos en tabla interactiva</span>
</span></span><span class=line><span class=cl><span class=c1># - Filtrar por &#34;wmape &lt; 8.0%&#34; → muestra solo 12 runs</span>
</span></span><span class=line><span class=cl><span class=c1># - Comparar top 5 runs side-by-side</span>
</span></span><span class=line><span class=cl><span class=c1># - Ver plots de convergencia (MAPE vs iteration)</span>
</span></span></code></pre></div><p><strong>Caso de uso real:</strong> Inicias un sweep de 50 runs a las 9 AM. A las 10 AM, desde tu laptop en la cafetería:</p><ol><li>Abres W&amp;B dashboard</li><li>Ves que 30 runs ya terminaron</li><li>Filtras por <code>wmape &lt; 8.0%</code> → 8 runs cumplen</li><li>Comparas esos 8 runs → identificas que <code>max_depth=20</code> aparece en todos</li><li><strong>Decisión:</strong> Cancelas el sweep, ajustas el range de <code>max_depth</code> a [18, 25], reinicias</li></ol><p><strong>Valor:</strong> Retroalimentación inmediata sin SSH al server, sin leer logs en terminal. La experimentación es <strong>interactiva</strong>, no batch.</p><hr><h4 id=3-artifact-tracking-ligero-referencias-a-gcs>3. Artifact Tracking Ligero (Referencias a GCS)<a hidden class=anchor aria-hidden=true href=#3-artifact-tracking-ligero-referencias-a-gcs>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/model/05_model_selection/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upload modelo a GCS</span>
</span></span><span class=line><span class=cl><span class=n>model_gcs_uri</span> <span class=o>=</span> <span class=n>upload_model_to_gcs</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;models/05-selection/randomforest_best.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># gs://bucket/models/05-selection/randomforest_best.pkl</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log referencia en W&amp;B (NO sube el pickle, solo el URI)</span>
</span></span><span class=line><span class=cl><span class=n>artifact</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Artifact</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s2>&#34;best_model_selection&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nb>type</span><span class=o>=</span><span class=s2>&#34;model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Best model selected: RandomForest&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>artifact</span><span class=o>.</span><span class=n>add_reference</span><span class=p>(</span><span class=n>model_gcs_uri</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&#34;best_model.pkl&#34;</span><span class=p>)</span>  <span class=c1># Solo el URI</span>
</span></span><span class=line><span class=cl><span class=n>run</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=n>artifact</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>W&amp;B no almacena el modelo</strong>—solo guarda el URI <code>gs://...</code>. El modelo vive en GCS.</p><p><strong>Ventaja:</strong> No pagas doble storage (GCS + W&amp;B). W&amp;B es el índice, GCS es el almacén.</p><hr><h3 id=cómo-este-proyecto-usa-mlflow>Cómo Este Proyecto Usa MLflow<a hidden class=anchor aria-hidden=true href=#cómo-este-proyecto-usa-mlflow>#</a></h3><h4 id=1-model-registry-step-07-versionamiento-y-stages>1. Model Registry (Step 07): Versionamiento y Stages<a hidden class=anchor aria-hidden=true href=#1-model-registry-step-07-versionamiento-y-stages>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/model/07_registration/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>start_run</span><span class=p>(</span><span class=n>run_name</span><span class=o>=</span><span class=s2>&#34;model_registration&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Log modelo</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Log params y métricas</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_params</span><span class=p>({</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_metrics</span><span class=p>({</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=mf>7.82</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=mf>0.8654</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Registrar en Model Registry</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Crear modelo registrado (si no existe)</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>create_registered_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Housing price prediction - Random Forest&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Crear nueva versión</span>
</span></span><span class=line><span class=cl>    <span class=n>model_version</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>source</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;runs:/</span><span class=si>{</span><span class=n>run_id</span><span class=si>}</span><span class=s2>/model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>run_id</span><span class=o>=</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Resultado: housing_price_model/v3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Transicionar a stage</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stage</span><span class=o>=</span><span class=s2>&#34;Staging&#34;</span>  <span class=c1># Staging → Production cuando se valide</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p><strong>Lo que MLflow hace aquí que W&amp;B no puede:</strong></p><ol><li><p><strong>Versionamiento Semántico</strong>: Cada modelo es <code>housing_price_model/v1</code>, <code>v2</code>, <code>v3</code>. No son IDs aleatorios—son versiones incrementales.</p></li><li><p><strong>Stages</strong>: Un modelo pasa por <code>None → Staging → Production → Archived</code>. Este lifecycle es explícito.</p><pre tabindex=0><code>v1: Production (actual en el API)
v2: Staging (validándose)
v3: None (recién entrenado)
v4: Archived (deprecado)
</code></pre></li><li><p><strong>Model-as-Code API</strong>: Cargar modelo en el API es trivial:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/core/model_loader.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>pyfunc</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;models:/housing_price_model/Production&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>No necesitas saber:</strong></p><ul><li>Dónde está el pickle físicamente</li><li>Qué versión es (MLflow resuelve &ldquo;Production&rdquo; → v1)</li><li>Cómo deserializarlo (mlflow.pyfunc abstrae esto)</li></ul></li><li><p><strong>Rollback en 10 Segundos</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Problema: v3 en Production tiene bug</span>
</span></span><span class=line><span class=cl><span class=c1># Rollback a v2:</span>
</span></span><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># El API detecta el cambio y recarga v2 automáticamente</span>
</span></span></code></pre></div></li><li><p><strong>Metadata Rica con Tags y Description</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Agregar tags searchables</span>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;training_date&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;2026-01-13&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;sweep_id&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;abc123xyz&#34;</span>  <span class=c1># Link al W&amp;B sweep</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Description en Markdown</span>
</span></span><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>update_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=o>=</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    # Housing Price Model v3
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    **Trained:** 2026-01-13
</span></span></span><span class=line><span class=cl><span class=s2>    **Algorithm:** Random Forest
</span></span></span><span class=line><span class=cl><span class=s2>    **Metrics:** MAPE=7.8%, R²=0.865
</span></span></span><span class=line><span class=cl><span class=s2>    **Sweep:** [W&amp;B Link](https://wandb.ai/project/sweeps/abc123)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p><strong>Resultado:</strong> 6 meses después, cuando un stakeholder pregunta &ldquo;¿qué modelo está en Production?&rdquo;, abres MLflow UI y toda la info está ahí—no en un Slack thread perdido.</p></li></ol><p><strong>W&amp;B no tiene:</strong></p><ul><li>Model Registry (solo artifact tracking básico)</li><li>Stages (Staging/Production)</li><li>API de carga (<code>models:/name/stage</code>)</li><li>Transition history (quién cambió v2 a Production, cuándo, por qué)</li></ul><hr><h4 id=2-pipeline-orchestration-mainpy>2. Pipeline Orchestration (main.py)<a hidden class=anchor aria-hidden=true href=#2-pipeline-orchestration-mainpy>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@hydra.main</span><span class=p>(</span><span class=n>config_path</span><span class=o>=</span><span class=s2>&#34;.&#34;</span><span class=p>,</span> <span class=n>config_name</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>go</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># MLflow orquesta steps como sub-runs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 01: Download</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>uri</span><span class=o>=</span><span class=s2>&#34;src/data/01_download_data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>entry_point</span><span class=o>=</span><span class=s2>&#34;main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>parameters</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;file_url&#34;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>download_data</span><span class=o>.</span><span class=n>file_url</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;gcs_output_path&#34;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>download_data</span><span class=o>.</span><span class=n>gcs_output_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=c1># ...</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 02: Preprocessing</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>uri</span><span class=o>=</span><span class=s2>&#34;src/data/02_preprocessing_and_imputation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>entry_point</span><span class=o>=</span><span class=s2>&#34;main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>parameters</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;gcs_input_path&#34;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>preprocessing</span><span class=o>.</span><span class=n>gcs_input_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=c1># ...</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># ... Steps 03-07</span>
</span></span></code></pre></div><p><strong>MLflow crea un run jerárquico:</strong></p><pre tabindex=0><code>Parent Run: end_to_end_pipeline
├── Child Run: 01_download_data
│   ├── params: file_url, gcs_output_path
│   └── artifacts: housing.parquet
├── Child Run: 02_preprocessing_and_imputation
│   ├── params: imputation_strategy
│   └── artifacts: imputer.pkl, housing_processed.parquet
├── Child Run: 03_feature_engineering
│   └── ...
└── Child Run: 07_registration
    └── artifacts: model.pkl, model_config.yaml
</code></pre><p><strong>Valor:</strong> En MLflow UI, ves toda la ejecución del pipeline como un árbol. Cada step es auditable—qué params usó, cuánto tardó, qué artifacts produjo.</p><p><strong>W&amp;B no tiene orquestación de pipelines</strong>—solo tracking de runs individuales.</p><hr><h3 id=la-división-del-trabajo-en-este-proyecto>La División del Trabajo en Este Proyecto<a hidden class=anchor aria-hidden=true href=#la-división-del-trabajo-en-este-proyecto>#</a></h3><table><thead><tr><th>Responsabilidad</th><th>W&amp;B</th><th>MLflow</th><th>Razón</th></tr></thead><tbody><tr><td><strong>Bayesian hyperparameter optimization</strong></td><td>✓</td><td>✗</td><td>W&amp;B tiene sweep inteligente, MLflow solo Grid/Random</td></tr><tr><td><strong>Real-time dashboards</strong></td><td>✓</td><td>✗</td><td>W&amp;B UI es interactivo, MLflow UI es estático</td></tr><tr><td><strong>Parallel coordinates plots</strong></td><td>✓</td><td>✗</td><td>W&amp;B tiene visualizaciones avanzadas</td></tr><tr><td><strong>Early termination (Hyperband)</strong></td><td>✓</td><td>✗</td><td>W&amp;B implementa Hyperband/ASHA/Median stopping</td></tr><tr><td><strong>Model Registry con stages</strong></td><td>✗</td><td>✓</td><td>MLflow tiene Staging/Production, W&amp;B no</td></tr><tr><td><strong>Model-as-code API</strong></td><td>✗</td><td>✓</td><td><code>mlflow.pyfunc.load_model()</code> es el estándar</td></tr><tr><td><strong>Rollback de modelos</strong></td><td>✗</td><td>✓</td><td>MLflow transition, W&amp;B no tiene concepto de stages</td></tr><tr><td><strong>Pipeline orchestration</strong></td><td>✗</td><td>✓</td><td><code>mlflow.run()</code> ejecuta steps anidados</td></tr><tr><td><strong>Artifact storage (físico)</strong></td><td>✗</td><td>✗</td><td>Ambos apuntan a GCS, no duplican storage</td></tr><tr><td><strong>Logging asíncrono</strong></td><td>✓</td><td>✗</td><td>W&amp;B no bloquea training, MLflow sí</td></tr><tr><td><strong>Metadata searchable</strong></td><td>✓</td><td>✓</td><td>Ambos permiten tags/búsqueda, implementaciones diferentes</td></tr></tbody></table><hr><h3 id=el-flujo-completo-wb--mlflow>El Flujo Completo: W&amp;B → MLflow<a hidden class=anchor aria-hidden=true href=#el-flujo-completo-wb--mlflow>#</a></h3><p><strong>Día 1-3: Experimentación (W&amp;B)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Ejecutar sweep de 50 runs</span>
</span></span><span class=line><span class=cl>make run-sweep
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># W&amp;B dashboard muestra:</span>
</span></span><span class=line><span class=cl><span class=c1># - 50 runs en tabla</span>
</span></span><span class=line><span class=cl><span class=c1># - Parallel coordinates plot</span>
</span></span><span class=line><span class=cl><span class=c1># - Best run: n_estimators=200, max_depth=20, wMAPE=7.8%</span>
</span></span><span class=line><span class=cl><span class=c1># - Sweep ID: abc123xyz</span>
</span></span></code></pre></div><p><strong>Output:</strong> <code>src/model/06_sweep/best_params.yaml</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>hyperparameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w> </span><span class=m>200</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mape</span><span class=p>:</span><span class=w> </span><span class=m>7.82</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>wmape</span><span class=p>:</span><span class=w> </span><span class=m>7.76</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>r2</span><span class=p>:</span><span class=w> </span><span class=m>0.8654</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep_id</span><span class=p>:</span><span class=w> </span><span class=l>abc123xyz </span><span class=w> </span><span class=c># Link a W&amp;B</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>best_run_id</span><span class=p>:</span><span class=w> </span><span class=l>def456ghi</span><span class=w>
</span></span></span></code></pre></div><p><strong>Día 4: Registration (MLflow)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Step 07 lee best_params.yaml</span>
</span></span><span class=line><span class=cl>python main.py main.execute_steps<span class=o>=[</span>07_registration<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MLflow:</span>
</span></span><span class=line><span class=cl><span class=c1># 1. Entrena modelo con best_params</span>
</span></span><span class=line><span class=cl><span class=c1># 2. Registra como housing_price_model/v3</span>
</span></span><span class=line><span class=cl><span class=c1># 3. Transiciona a Staging</span>
</span></span><span class=line><span class=cl><span class=c1># 4. Guarda metadata (incluyendo sweep_id)</span>
</span></span></code></pre></div><p><strong>Día 5-7: Validación en Staging</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># API corre con modelo en Staging</span>
</span></span><span class=line><span class=cl>docker run -p 8080:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Staging <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-api:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Correr tests, validar métricas, revisar predicciones</span>
</span></span></code></pre></div><p><strong>Día 8: Promoción a Production</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API en producción auto-recarga v3</span>
</span></span><span class=line><span class=cl><span class=c1># v2 queda como fallback (stage: Archived)</span>
</span></span></code></pre></div><p><strong>Si algo falla:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Rollback en 10 segundos</span>
</span></span><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span></code></pre></div><hr><h3 id=por-qué-ambos-definitivamente>Por Qué Ambos, Definitivamente<a hidden class=anchor aria-hidden=true href=#por-qué-ambos-definitivamente>#</a></h3><p><strong>Pregunta:</strong> &ldquo;¿Puedo usar solo W&amp;B?&rdquo;</p><p><strong>Respuesta:</strong> Puedes, pero pierdes:</p><ul><li>Model Registry (versionamiento, stages, rollback)</li><li>API estándar para cargar modelos en producción</li><li>Pipeline orchestration con runs jerárquicos</li></ul><p><strong>Resultado:</strong> Terminas construyendo tu propio sistema de versionamiento de modelos con scripts custom—reinventando la rueda mal.</p><p><strong>Pregunta:</strong> &ldquo;¿Puedo usar solo MLflow?&rdquo;</p><p><strong>Respuesta:</strong> Puedes, pero pierdes:</p><ul><li>Bayesian optimization (tendrás que hacer Grid Search lento)</li><li>Visualizaciones interactivas (parallel coordinates, real-time dashboards)</li><li>Early termination inteligente (desperdicias compute)</li></ul><p><strong>Resultado:</strong> Tus sweeps toman 3x más tiempo, y no tienes feedback visual de qué funciona.</p><hr><h3 id=el-costo-real>El Costo Real<a hidden class=anchor aria-hidden=true href=#el-costo-real>#</a></h3><p><strong>W&amp;B:</strong></p><ul><li>Free tier: 100GB storage, colaboradores ilimitados</li><li>Team tier: $50/usuario/mes (para equipos >5 personas)</li></ul><p><strong>MLflow:</strong></p><ul><li>Open source, gratis</li><li>Costo: Hosting del tracking server (Cloud Run: ~$20/mes para uso moderado)</li><li>Storage: GCS (ya lo pagas para datos)</li></ul><p><strong>Total para equipo de 5:</strong> ~$20-50/mes (si usas W&amp;B free tier) o ~$270/mes (si usas W&amp;B Team).</p><p><strong>ROI:</strong> Si un sweep más eficiente ahorra 30 minutos de compute/día:</p><ul><li>Compute ahorrado: ~15 horas/mes</li><li>En GCP: 15 horas × $2/hora (GPU) = $30/mes ahorrado solo en compute</li><li>Más el tiempo de ingeniero (más valioso)</li></ul><p><strong>Breakeven en &lt;1 mes.</strong></p><hr><h3 id=la-lección-para-mlops-engineers>La Lección Para MLOps Engineers<a hidden class=anchor aria-hidden=true href=#la-lección-para-mlops-engineers>#</a></h3><p><strong>No elijas herramientas por hype o popularidad.</strong> Elige por <strong>responsabilidades claras</strong>:</p><ol><li><strong>Experimentación rápida e interactiva:</strong> W&amp;B, Neptune, Comet</li><li><strong>Governance y deployment:</strong> MLflow, Seldon, BentoML</li><li><strong>Artifact storage:</strong> GCS, S3, Azure Blob (no herramientas de tracking)</li></ol><p><strong>Este proyecto usa:</strong></p><ul><li><strong>W&amp;B:</strong> Porque necesita sweep Bayesiano eficiente</li><li><strong>MLflow:</strong> Porque necesita Model Registry production-ready</li><li><strong>GCS:</strong> Porque necesita storage de alta disponibilidad</li></ul><p><strong>No hay redundancia—hay especialización.</strong></p><p>Cuando entiendes esto, dejas de preguntar &ldquo;¿W&amp;B o MLflow?&rdquo; y empiezas a preguntar &ldquo;¿qué problema estoy resolviendo?&rdquo;</p><p><strong>Esa es la diferencia entre usar herramientas y construir sistemas.</strong></p><hr><p><a name=docker-mlflow></a></p><h2 id=10-docker-y-mlflow-containerización-del-ecosistema-completo>10. Docker y MLflow: Containerización del Ecosistema Completo<a hidden class=anchor aria-hidden=true href=#10-docker-y-mlflow-containerización-del-ecosistema-completo>#</a></h2><h3 id=la-arquitectura-de-tres-containers>La Arquitectura de Tres Containers<a hidden class=anchor aria-hidden=true href=#la-arquitectura-de-tres-containers>#</a></h3><p>Este proyecto utiliza <strong>tres Dockerfiles distintos</strong>, cada uno optimizado para su propósito específico:</p><ol><li><strong>Pipeline Container (<code>Dockerfile</code>)</strong>: Ejecuta el pipeline completo de entrenamiento con MLflow tracking</li><li><strong>API Container (<code>api/Dockerfile</code>)</strong>: Sirve predicciones con FastAPI en producción</li><li><strong>Streamlit Container (<code>streamlit_app/Dockerfile</code>)</strong>: Proporciona interfaz web interactiva</li></ol><h2>Esta separación no es accidental—es una decisión arquitectónica que refleja los diferentes requisitos de cada componente.
<img loading=lazy src=img/app1.png></h2><h3 id=1-pipeline-container-entrenamiento-con-mlflow-tracking>1. Pipeline Container: Entrenamiento con MLflow Tracking<a hidden class=anchor aria-hidden=true href=#1-pipeline-container-entrenamiento-con-mlflow-tracking>#</a></h3><h4 id=dockerfile-del-pipeline>Dockerfile del Pipeline<a hidden class=anchor aria-hidden=true href=#dockerfile-del-pipeline>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Dockerfile for MLOps Pipeline Execution</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Purpose: Run the complete training pipeline in containerized environment</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> python:3.12-slim</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>maintainer</span><span class=o>=</span><span class=s2>&#34;danieljimenez88m@gmail.com&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>description</span><span class=o>=</span><span class=s2>&#34;Housing Price Prediction - MLOps Pipeline&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Set working directory</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>WORKDIR</span><span class=s> /app</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Install system dependencies</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update <span class=o>&amp;&amp;</span> apt-get install -y <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    gcc <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    g++ <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    git <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    curl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    <span class=o>&amp;&amp;</span> rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Copy requirements first for better caching</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> pyproject.toml ./<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> requirements.txt* ./<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Install Python dependencies</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> pip install --no-cache-dir --upgrade pip <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    pip install --no-cache-dir uv <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    uv pip install --system -e .<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Copy application code</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> . .<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Set environment variables</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>PYTHONUNBUFFERED</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PYTHONDONTWRITEBYTECODE</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># Create necessary directories</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> mkdir -p mlruns outputs models<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Default command runs the pipeline</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>CMD</span> <span class=p>[</span><span class=s2>&#34;python&#34;</span><span class=p>,</span> <span class=s2>&#34;main.py&#34;</span><span class=p>]</span><span class=err>
</span></span></span></code></pre></div><h4 id=decisiones-técnicas-críticas-4>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-4>#</a></h4><p><strong>1. Por Qué <code>gcc</code> y <code>g++</code></strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>RUN</span> apt-get install -y gcc g++ git curl<span class=err>
</span></span></span></code></pre></div><p>Muchos paquetes de ML (numpy, scipy, scikit-learn) compilan extensiones C/C++ durante la instalación. Sin estos compiladores, <code>pip install</code> falla con errores crípticos como &ldquo;error: command &lsquo;gcc&rsquo; failed&rdquo;.</p><p><strong>Trade-off:</strong> Imagen más grande (~500MB vs ~150MB de Python slim puro), pero garantiza que todas las dependencias se instalan correctamente.</p><p><strong>2. Layer Caching Strategy</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># Copy requirements first for better caching</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> pyproject.toml ./<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> requirements.txt* ./<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> pip install ...<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Copy application code AFTER</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> . .<span class=err>
</span></span></span></code></pre></div><p>Docker cachea layers. Si cambias código Python pero no dependencias, Docker reutiliza la layer de <code>pip install</code> (que toma 5 minutos) y solo recopia el código (10 segundos).</p><p><strong>Sin esta optimización:</strong> Cada cambio de código requiere reinstalar todas las dependencias.</p><p><strong>3. Directory Creation for MLflow</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>RUN</span> mkdir -p mlruns outputs models<span class=err>
</span></span></span></code></pre></div><p>MLflow escribe artifacts a <code>mlruns/</code> por defecto si no se configura un tracking server remoto. Si este directorio no existe con permisos correctos, MLflow falla silenciosamente.</p><p><strong><code>outputs/</code></strong>: Para plots y análisis intermedios
<strong><code>models/</code></strong>: Para checkpoints de modelos antes de subir a GCS</p><h4 id=cómo-habilitar-mlflow-tracking>Cómo Habilitar MLflow Tracking<a hidden class=anchor aria-hidden=true href=#cómo-habilitar-mlflow-tracking>#</a></h4><p><strong>Opción 1: MLflow Local (Default)</strong></p><p>Cuando ejecutas el pipeline en este container, MLflow escribe a <code>mlruns/</code> dentro del container:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run --env-file .env housing-pipeline:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MLflow escribe a /app/mlruns/</span>
</span></span><span class=line><span class=cl><span class=c1># Para ver el UI:</span>
</span></span><span class=line><span class=cl>docker <span class=nb>exec</span> -it &lt;container-id&gt; mlflow ui --host 0.0.0.0 --port <span class=m>5000</span>
</span></span></code></pre></div><p><strong>Limitación:</strong> Los runs se pierden cuando el container se detiene.</p><p><strong>Opción 2: MLflow Remote Tracking Server</strong></p><p>Para persistir runs, configura un servidor MLflow separado:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># docker-compose.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mlflow</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>ghcr.io/mlflow/mlflow:v2.9.2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>mlflow-server</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;5000:5000&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>BACKEND_STORE_URI=sqlite:///mlflow.db</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>DEFAULT_ARTIFACT_ROOT=gs://your-bucket/mlflow-artifacts</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>mlflow-data:/mlflow</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=p>&gt;</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>      mlflow server
</span></span></span><span class=line><span class=cl><span class=sd>      --backend-store-uri sqlite:///mlflow/mlflow.db
</span></span></span><span class=line><span class=cl><span class=sd>      --default-artifact-root gs://your-bucket/mlflow-artifacts
</span></span></span><span class=line><span class=cl><span class=sd>      --host 0.0.0.0
</span></span></span><span class=line><span class=cl><span class=sd>      --port 5000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>pipeline</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w> </span><span class=l>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>MLFLOW_TRACKING_URI=http://mlflow:5000</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>GCP_PROJECT_ID=${GCP_PROJECT_ID}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>GCS_BUCKET_NAME=${GCS_BUCKET_NAME}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>WANDB_API_KEY=${WANDB_API_KEY}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>mlflow</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mlflow-data</span><span class=p>:</span><span class=w>
</span></span></span></code></pre></div><p><strong>Configuración en el código:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># main.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Si MLFLOW_TRACKING_URI está configurado, usar ese server</span>
</span></span><span class=line><span class=cl><span class=n>mlflow_uri</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;MLFLOW_TRACKING_URI&#34;</span><span class=p>,</span> <span class=s2>&#34;file:./mlruns&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>set_tracking_uri</span><span class=p>(</span><span class=n>mlflow_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>set_experiment</span><span class=p>(</span><span class=s2>&#34;housing_price_prediction&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>start_run</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># Log params, metrics, artifacts</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_param</span><span class=p>(</span><span class=s2>&#34;n_estimators&#34;</span><span class=p>,</span> <span class=mi>200</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_metric</span><span class=p>(</span><span class=s2>&#34;mape&#34;</span><span class=p>,</span> <span class=mf>7.82</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Opción 3: MLflow en Cloud (Production)</strong></p><p>Para producción, usa un servidor MLflow gestionado:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Deploy MLflow a Cloud Run (serverless)</span>
</span></span><span class=line><span class=cl>gcloud run deploy mlflow-server <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --image ghcr.io/mlflow/mlflow:v2.9.2 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --platform managed <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --region us-central1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set-env-vars<span class=o>=</span><span class=s2>&#34;BACKEND_STORE_URI=postgresql://user:pass@host/mlflow_db,DEFAULT_ARTIFACT_ROOT=gs://bucket/mlflow&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --allow-unauthenticated
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Obtener URL</span>
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_URL</span><span class=o>=</span><span class=k>$(</span>gcloud run services describe mlflow-server --format <span class=s1>&#39;value(status.url)&#39;</span><span class=k>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configurar en pipeline</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MLFLOW_TRACKING_URI</span><span class=o>=</span><span class=nv>$MLFLOW_URL</span>
</span></span></code></pre></div><h4 id=ejecución-del-pipeline-container>Ejecución del Pipeline Container<a hidden class=anchor aria-hidden=true href=#ejecución-del-pipeline-container>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Build</span>
</span></span><span class=line><span class=cl>docker build -t housing-pipeline:latest .
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Run con env vars</span>
</span></span><span class=line><span class=cl>docker run <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --env-file .env <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/mlruns:/app/mlruns <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-pipeline:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Run con steps específicos</span>
</span></span><span class=line><span class=cl>docker run <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --env-file .env <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-pipeline:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  python main.py main.execute_steps<span class=o>=[</span>03_feature_engineering,05_model_selection<span class=o>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ver logs en tiempo real</span>
</span></span><span class=line><span class=cl>docker logs -f &lt;container-id&gt;
</span></span></code></pre></div><p><strong>Volume Mount (<code>-v</code>)</strong>: Monta <code>mlruns/</code> desde el host al container para persistir runs MLflow incluso después de que el container se detenga.</p><hr><h3 id=2-api-container-inference-en-producción>2. API Container: Inference en Producción<a hidden class=anchor aria-hidden=true href=#2-api-container-inference-en-producción>#</a></h3><h4 id=dockerfile-del-api>Dockerfile del API<a hidden class=anchor aria-hidden=true href=#dockerfile-del-api>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Dockerfile for Housing Price Prediction API</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Purpose: Production-ready FastAPI service for Cloud Run deployment</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> python:3.12-slim</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>maintainer</span><span class=o>=</span><span class=s2>&#34;danieljimenez88m@gmail.com&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>description</span><span class=o>=</span><span class=s2>&#34;Housing Price Prediction API - FastAPI Service&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>WORKDIR</span><span class=s> /app</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Install system dependencies (solo curl para healthcheck)</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update <span class=o>&amp;&amp;</span> apt-get install -y <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    curl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    <span class=o>&amp;&amp;</span> rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Copy requirements first for better caching</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> requirements.txt .<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Install Python dependencies</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> pip install --no-cache-dir --upgrade pip <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    pip install --no-cache-dir -r requirements.txt<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Copy application code</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> app/ ./app/<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Create models directory</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> mkdir -p models<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Set environment variables</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>PYTHONUNBUFFERED</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PYTHONDONTWRITEBYTECODE</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PORT</span><span class=o>=</span><span class=m>8080</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># Expose port</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>EXPOSE</span><span class=s> 8080</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Health check</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>HEALTHCHECK --interval=30s --timeout=10s </span>--start-period<span class=o>=</span>40s --retries<span class=o>=</span><span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    CMD curl -f http://localhost:8080/health <span class=o>||</span> <span class=nb>exit</span> <span class=m>1</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Run the application</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>CMD</span> <span class=nb>exec</span> uvicorn app.main:app --host 0.0.0.0 --port <span class=si>${</span><span class=nv>PORT</span><span class=si>}</span><span class=err>
</span></span></span></code></pre></div><h4 id=decisiones-técnicas-críticas-5>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-5>#</a></h4><p><strong>1. Imagen Más Ligera</strong></p><p>Comparado con el pipeline container:</p><ul><li><strong>No necesita <code>gcc</code>/<code>g++</code></strong>: Las dependencias ya están compiladas en wheels</li><li><strong>No necesita <code>git</code></strong>: No clona repos</li><li><strong>Solo <code>curl</code></strong>: Para el healthcheck</li></ul><p><strong>Resultado:</strong> Imagen de ~200MB vs ~500MB del pipeline.</p><p><strong>Por qué importa:</strong> Cloud Run cobra por uso de memoria. Una imagen más pequeña = menos memoria = menos costo.</p><p><strong>2. Health Check Nativo</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=err>HEALTHCHECK --interval=30s --timeout=10s </span>--start-period<span class=o>=</span>40s --retries<span class=o>=</span><span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    CMD curl -f http://localhost:8080/health <span class=o>||</span> <span class=nb>exit</span> <span class=m>1</span><span class=err>
</span></span></span></code></pre></div><p>Docker marca el container como &ldquo;unhealthy&rdquo; si el endpoint <code>/health</code> falla 3 veces consecutivas.</p><p><strong>Cloud Run</strong> y <strong>Kubernetes</strong> usan esto para:</p><ul><li>No enviar tráfico a containers unhealthy</li><li>Reiniciar containers que fallan</li><li>Reporting de uptime</li></ul><p><strong>start-period=40s</strong>: Da 40 segundos al API para cargar el modelo antes de empezar health checks.</p><p><strong>3. Port Configuration Flexible</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PORT</span><span class=o>=</span><span class=m>8080</span>
</span></span><span class=line><span class=cl><span class=k>CMD</span> <span class=nb>exec</span> uvicorn app.main:app --host 0.0.0.0 --port <span class=si>${</span><span class=nv>PORT</span><span class=si>}</span><span class=err>
</span></span></span></code></pre></div><p>Cloud Run inyecta <code>PORT</code> como env var (puede ser 8080, 8081, etc.). El API debe leer este valor, no hardcodearlo.</p><p><strong><code>exec</code></strong>: Reemplaza el shell process con uvicorn, permitiendo que Docker envíe signals (SIGTERM) directamente a uvicorn para graceful shutdown.</p><h4 id=cómo-el-api-carga-el-modelo>Cómo el API Carga el Modelo<a hidden class=anchor aria-hidden=true href=#cómo-el-api-carga-el-modelo>#</a></h4><p>El API tiene <strong>tres estrategias de carga de modelo</strong> con fallback automático:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/core/model_loader.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelLoader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Carga modelo desde MLflow → GCS → Local con fallback.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Any</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Priority: MLflow &gt; GCS &gt; Local&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Estrategia 1: Desde MLflow Registry</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;models:/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>mlflow_stage</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>pyfunc</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loaded from MLflow: </span><span class=si>{</span><span class=n>model_uri</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>, trying GCS...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Estrategia 2: Desde GCS</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>storage_client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>bucket</span> <span class=o>=</span> <span class=n>storage_client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>blob</span> <span class=o>=</span> <span class=n>bucket</span><span class=o>.</span><span class=n>blob</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>model_bytes</span> <span class=o>=</span> <span class=n>blob</span><span class=o>.</span><span class=n>download_as_bytes</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>model_bytes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loaded from GCS: gs://</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GCS load failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>, trying local...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Estrategia 3: Desde archivo local (fallback)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span> <span class=ow>and</span> <span class=n>Path</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loaded from local: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;No model could be loaded from any source&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Configuración con env vars:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Producción: Cargar desde MLflow</span>
</span></span><span class=line><span class=cl>docker run -p 8080:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>MLFLOW_TRACKING_URI</span><span class=o>=</span>https://mlflow.example.com <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Production <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-api:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Staging: Cargar desde GCS</span>
</span></span><span class=line><span class=cl>docker run -p 8080:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>GCS_BUCKET</span><span class=o>=</span>my-bucket <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>GCS_MODEL_PATH</span><span class=o>=</span>models/trained/housing_price_model.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-api:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Desarrollo: Cargar desde local</span>
</span></span><span class=line><span class=cl>docker run -p 8080:8080 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/models:/app/models <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -e <span class=nv>LOCAL_MODEL_PATH</span><span class=o>=</span>/app/models/trained/housing_price_model.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  housing-api:latest
</span></span></code></pre></div><hr><h3 id=3-streamlit-container-frontend-interactivo>3. Streamlit Container: Frontend Interactivo<a hidden class=anchor aria-hidden=true href=#3-streamlit-container-frontend-interactivo>#</a></h3><h4 id=dockerfile-de-streamlit>Dockerfile de Streamlit<a hidden class=anchor aria-hidden=true href=#dockerfile-de-streamlit>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Dockerfile for Streamlit Frontend</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Purpose: Interactive web interface for housing price predictions</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># =================================================================</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> python:3.12-slim</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>maintainer</span><span class=o>=</span><span class=s2>&#34;danieljimenez88m@gmail.com&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>LABEL</span> <span class=nv>description</span><span class=o>=</span><span class=s2>&#34;Housing Price Prediction - Streamlit Frontend&#34;</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>WORKDIR</span><span class=s> /app</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update <span class=o>&amp;&amp;</span> apt-get install -y curl <span class=o>&amp;&amp;</span> rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> requirements.txt .<span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> pip install --no-cache-dir --upgrade pip <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    pip install --no-cache-dir -r requirements.txt<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>COPY</span> app.py .<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Create .streamlit directory for config</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> mkdir -p .streamlit<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># Streamlit configuration</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> <span class=nb>echo</span> <span class=s1>&#39;\
</span></span></span><span class=line><span class=cl><span class=s1>[server]\n\
</span></span></span><span class=line><span class=cl><span class=s1>port = 8501\n\
</span></span></span><span class=line><span class=cl><span class=s1>address = &#34;0.0.0.0&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>headless = true\n\
</span></span></span><span class=line><span class=cl><span class=s1>enableCORS = false\n\
</span></span></span><span class=line><span class=cl><span class=s1>enableXsrfProtection = true\n\
</span></span></span><span class=line><span class=cl><span class=s1>\n\
</span></span></span><span class=line><span class=cl><span class=s1>[browser]\n\
</span></span></span><span class=line><span class=cl><span class=s1>gatherUsageStats = false\n\
</span></span></span><span class=line><span class=cl><span class=s1>\n\
</span></span></span><span class=line><span class=cl><span class=s1>[theme]\n\
</span></span></span><span class=line><span class=cl><span class=s1>primaryColor = &#34;#FF4B4B&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>backgroundColor = &#34;#FFFFFF&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>secondaryBackgroundColor = &#34;#F0F2F6&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>textColor = &#34;#262730&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>font = &#34;sans serif&#34;\n\
</span></span></span><span class=line><span class=cl><span class=s1>&#39;</span> &gt; .streamlit/config.toml<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>PYTHONUNBUFFERED</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PYTHONDONTWRITEBYTECODE</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>EXPOSE</span><span class=s> 8501</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>HEALTHCHECK --interval=30s --timeout=10s </span>--start-period<span class=o>=</span>40s --retries<span class=o>=</span><span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    CMD curl -f http://localhost:8501/_stcore/health <span class=o>||</span> <span class=nb>exit</span> <span class=m>1</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>CMD</span> <span class=p>[</span><span class=s2>&#34;streamlit&#34;</span><span class=p>,</span> <span class=s2>&#34;run&#34;</span><span class=p>,</span> <span class=s2>&#34;app.py&#34;</span><span class=p>,</span> <span class=s2>&#34;--server.port=8501&#34;</span><span class=p>,</span> <span class=s2>&#34;--server.address=0.0.0.0&#34;</span><span class=p>]</span><span class=err>
</span></span></span></code></pre></div><h4 id=decisiones-técnicas-críticas-6>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-6>#</a></h4><p><strong>1. Configuración Embedded</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>RUN</span> <span class=nb>echo</span> <span class=s1>&#39;...&#39;</span> &gt; .streamlit/config.toml<span class=err>
</span></span></span></code></pre></div><p>Streamlit requiere configuración para correr en containers (headless mode, CORS, etc.). En lugar de commitear un archivo <code>config.toml</code> al repo, lo generamos en build time.</p><p><strong>Ventajas:</strong></p><ul><li>Un archivo menos en el repo</li><li>Configuración versionada con el Dockerfile</li><li>No hay riesgo de olvidar commitear el config</li></ul><p><strong>2. Health Check de Streamlit</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=err>HEALTHCHECK</span> CMD curl -f http://localhost:8501/_stcore/health <span class=o>||</span> <span class=nb>exit</span> <span class=m>1</span><span class=err>
</span></span></span></code></pre></div><p>Streamlit expone <code>/_stcore/health</code> automáticamente. Este endpoint retorna 200 si la app está running.</p><p><strong>3. Tema Personalizado</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-toml data-lang=toml><span class=line><span class=cl><span class=p>[</span><span class=nx>theme</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>primaryColor</span> <span class=p>=</span> <span class=s2>&#34;#FF4B4B&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>backgroundColor</span> <span class=p>=</span> <span class=s2>&#34;#FFFFFF&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>secondaryBackgroundColor</span> <span class=p>=</span> <span class=s2>&#34;#F0F2F6&#34;</span>
</span></span><span class=line><span class=cl><span class=nx>textColor</span> <span class=p>=</span> <span class=s2>&#34;#262730&#34;</span>
</span></span></code></pre></div><p>El tema define los colores de botones, backgrounds, etc. Esto da consistencia visual sin necesidad de CSS custom en cada componente.</p><h4 id=cómo-streamlit-se-conecta-al-api>Cómo Streamlit Se Conecta al API<a hidden class=anchor aria-hidden=true href=#cómo-streamlit-se-conecta-al-api>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># streamlit_app/app.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>streamlit</span> <span class=k>as</span> <span class=nn>st</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Read API URL from environment variable</span>
</span></span><span class=line><span class=cl><span class=n>API_URL</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;API_URL&#34;</span><span class=p>,</span> <span class=s2>&#34;http://localhost:8080&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>API_PREDICT_ENDPOINT</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>API_URL</span><span class=si>}</span><span class=s2>/api/v1/predict&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>make_prediction</span><span class=p>(</span><span class=n>features</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Call API to get prediction.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>payload</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;instances&#34;</span><span class=p>:</span> <span class=p>[</span><span class=n>features</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>API_PREDICT_ENDPOINT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>json</span><span class=o>=</span><span class=n>payload</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span><span class=o>.</span><span class=n>raise_for_status</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=n>requests</span><span class=o>.</span><span class=n>exceptions</span><span class=o>.</span><span class=n>RequestException</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>st</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;API Error: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Streamlit UI</span>
</span></span><span class=line><span class=cl><span class=n>st</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Housing Price Prediction&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>st</span><span class=o>.</span><span class=n>form</span><span class=p>(</span><span class=s2>&#34;prediction_form&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>longitude</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>number_input</span><span class=p>(</span><span class=s2>&#34;Longitude&#34;</span><span class=p>,</span> <span class=n>value</span><span class=o>=-</span><span class=mf>122.23</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>latitude</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>number_input</span><span class=p>(</span><span class=s2>&#34;Latitude&#34;</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=mf>37.88</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... más inputs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>submitted</span> <span class=o>=</span> <span class=n>st</span><span class=o>.</span><span class=n>form_submit_button</span><span class=p>(</span><span class=s2>&#34;Predict&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>submitted</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>features</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;longitude&#34;</span><span class=p>:</span> <span class=n>longitude</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;latitude&#34;</span><span class=p>:</span> <span class=n>latitude</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=c1># ...</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=n>make_prediction</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>result</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>prediction</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;predictions&#34;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s2>&#34;median_house_value&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>st</span><span class=o>.</span><span class=n>success</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Predicted Price: $</span><span class=si>{</span><span class=n>prediction</span><span class=si>:</span><span class=s2>,.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Configuración de la URL del API:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Docker Compose: Usa service name</span>
</span></span><span class=line><span class=cl>docker-compose up
</span></span><span class=line><span class=cl><span class=c1># Streamlit automáticamente recibe API_URL=http://api:8080</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Local development: Usa localhost</span>
</span></span><span class=line><span class=cl><span class=nv>API_URL</span><span class=o>=</span>http://localhost:8080 streamlit run app.py
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Production: Usa Cloud Run URL</span>
</span></span><span class=line><span class=cl><span class=nv>API_URL</span><span class=o>=</span>https://housing-api-xyz.run.app streamlit run app.py
</span></span></code></pre></div><hr><h3 id=docker-compose-orquestación-de-los-tres-containers>Docker Compose: Orquestación de los Tres Containers<a hidden class=anchor aria-hidden=true href=#docker-compose-orquestación-de-los-tres-containers>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># docker-compose.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>api</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>context</span><span class=p>:</span><span class=w> </span><span class=l>./api</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>dockerfile</span><span class=p>:</span><span class=w> </span><span class=l>Dockerfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>housing-price-api</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;8080:8080&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>PORT=8080</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>LOCAL_MODEL_PATH=/app/models/trained/housing_price_model.pkl</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>WANDB_API_KEY=${WANDB_API_KEY}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>./models:/app/models:ro</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>restart</span><span class=p>:</span><span class=w> </span><span class=l>unless-stopped</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>healthcheck</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>test</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;CMD&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;curl&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;-f&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;http://localhost:8080/health&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>interval</span><span class=p>:</span><span class=w> </span><span class=l>30s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class=l>10s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>retries</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>mlops-network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>streamlit</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>context</span><span class=p>:</span><span class=w> </span><span class=l>./streamlit_app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>dockerfile</span><span class=p>:</span><span class=w> </span><span class=l>Dockerfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>housing-streamlit</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;8501:8501&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>API_URL=http://api:8080</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>api</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>restart</span><span class=p>:</span><span class=w> </span><span class=l>unless-stopped</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>healthcheck</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>test</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;CMD&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;curl&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;-f&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;http://localhost:8501/_stcore/health&#34;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>interval</span><span class=p>:</span><span class=w> </span><span class=l>30s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class=l>10s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>retries</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>mlops-network</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mlops-network</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>bridge</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>housing-mlops-network</span><span class=w>
</span></span></span></code></pre></div><p><strong>Decisiones Críticas:</strong></p><p><strong>1. Network Isolation</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>mlops-network</span><span class=w>
</span></span></span></code></pre></div><p>Ambos containers están en la misma red Docker, permitiendo que Streamlit llame al API usando <code>http://api:8080</code> (service name como hostname).</p><p><strong>Sin esto:</strong> Tendrías que usar <code>http://host.docker.internal:8080</code> (solo funciona en Docker Desktop) o la IP del host.</p><p><strong>2. Volume Mount Read-Only</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>./models:/app/models:ro</span><span class=w>
</span></span></span></code></pre></div><p>El API monta <code>models/</code> en <strong>read-only mode (<code>:ro</code>)</strong>. El container puede leer el modelo pero no modificarlo.</p><p><strong>Por qué:</strong> Seguridad. Si el container es comprometido, un atacante no puede sobrescribir el modelo con uno malicioso.</p><p><strong>3. Dependency Order</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>api</span><span class=w>
</span></span></span></code></pre></div><p>Docker Compose inicia el API antes que Streamlit. Esto evita que Streamlit falle al intentar conectarse a un API que aún no está corriendo.</p><p><strong>Limitación:</strong> <code>depends_on</code> solo espera a que el container <strong>inicie</strong>, no a que el API esté <strong>listo</strong> (healthcheck pass). Para eso, necesitas un init container o retry logic en Streamlit.</p><hr><h3 id=comando-completo-de-ejecución>Comando Completo de Ejecución<a hidden class=anchor aria-hidden=true href=#comando-completo-de-ejecución>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. Build todas las imágenes</span>
</span></span><span class=line><span class=cl>docker-compose build
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Entrenar el modelo (pipeline container)</span>
</span></span><span class=line><span class=cl>docker run --env-file .env -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/models:/app/models housing-pipeline:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Iniciar API + Streamlit</span>
</span></span><span class=line><span class=cl>docker-compose up -d
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Verificar health</span>
</span></span><span class=line><span class=cl>curl http://localhost:8080/health
</span></span><span class=line><span class=cl>curl http://localhost:8501/_stcore/health
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. Ver logs</span>
</span></span><span class=line><span class=cl>docker-compose logs -f
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. Detener todo</span>
</span></span><span class=line><span class=cl>docker-compose down
</span></span></code></pre></div><hr><h3 id=lo-que-esta-arquitectura-resuelve>Lo Que Esta Arquitectura Resuelve<a hidden class=anchor aria-hidden=true href=#lo-que-esta-arquitectura-resuelve>#</a></h3><p><strong>Sin containers:</strong></p><ul><li>&ldquo;Funciona en mi máquina&rdquo; syndrome</li><li>Dependencias conflictivas (Python 3.9 vs 3.12)</li><li>Setup manual en cada ambiente (dev, staging, prod)</li></ul><p><strong>Con esta arquitectura:</strong></p><ul><li><strong>Reproducibilidad:</strong> Mismo container corre en laptop, CI/CD, y producción</li><li><strong>Isolation:</strong> API no interfiere con Streamlit, pipeline no interfiere con API</li><li><strong>Deployment:</strong> <code>docker push</code> → <code>gcloud run deploy</code> en &lt;5 minutos</li><li><strong>Rollback:</strong> <code>docker pull previous-image</code> → restart</li><li><strong>Observability:</strong> Health checks automáticos, logs centralizados</li></ul><p><strong>El valor real:</strong> Un data scientist sin experiencia en DevOps puede deployar a producción sin saber cómo configurar nginx, systemd, o virtual environments. Docker abstrae toda esa complejidad.</p><hr><p><a name=api-architecture></a></p><h2 id=105-arquitectura-del-api-fastapi-en-producción>10.5. Arquitectura del API: FastAPI en Producción<a hidden class=anchor aria-hidden=true href=#105-arquitectura-del-api-fastapi-en-producción>#</a></h2><h3 id=por-qué-esta-sección-importa>Por Qué Esta Sección Importa<a hidden class=anchor aria-hidden=true href=#por-qué-esta-sección-importa>#</a></h3><p>Has visto pipelines de entrenamiento, sweep de hiperparámetros, y model registry. Pero <strong>el 90% del tiempo, tu modelo no está entrenando—está sirviendo predicciones en producción.</strong></p><p>Un API mal diseñado es el cuello de botella entre un modelo excelente y un producto útil. Esta sección desmenuza cómo este proyecto construye un API production-ready, no un prototipo de tutorial.</p><hr><h3 id=la-arquitectura-general>La Arquitectura General<a hidden class=anchor aria-hidden=true href=#la-arquitectura-general>#</a></h3><pre tabindex=0><code>api/
├── app/
│   ├── main.py                    # FastAPI app + lifespan management
│   ├── core/
│   │   ├── config.py              # Pydantic Settings (env vars)
│   │   ├── model_loader.py        # Multi-source model loading
│   │   ├── wandb_logger.py        # Prediction logging
│   │   └── preprocessor.py        # Feature engineering
│   ├── routers/
│   │   └── predict.py             # Prediction endpoints
│   └── models/
│       └── schemas.py             # Pydantic request/response models
├── requirements.txt
├── Dockerfile
└── tests/
</code></pre><p><strong>Decisión arquitectónica:</strong> Separation of concerns por capas:</p><ol><li><strong>Core</strong>: Lógica de negocio (cargar modelo, logging, config)</li><li><strong>Routers</strong>: Endpoints HTTP (rutas, validación de requests)</li><li><strong>Models</strong>: Schemas de datos (Pydantic)</li></ol><p><strong>Por qué no todo en <code>main.py</code>?</strong> Porque cuando el API crece (agregar autenticación, rate limiting, múltiples modelos), cada capa se extiende independientemente sin tocar el resto.</p><hr><h3 id=1-lifespan-management-el-patrón-que-evita-latencia-en-primera-request>1. Lifespan Management: El Patrón Que Evita Latencia en Primera Request<a hidden class=anchor aria-hidden=true href=#1-lifespan-management-el-patrón-que-evita-latencia-en-primera-request>#</a></h3><h4 id=el-problema-que-resuelve>El Problema Que Resuelve<a hidden class=anchor aria-hidden=true href=#el-problema-que-resuelve>#</a></h4><p><strong>Anti-pattern común:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># BAD: Cargar modelo en cada request</span>
</span></span><span class=line><span class=cl><span class=nd>@app.post</span><span class=p>(</span><span class=s2>&#34;/predict&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s2>&#34;model.pkl&#34;</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>))</span>  <span class=c1># 5 segundos cada request</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Problemas:</strong></p><ul><li>Primera request toma 5 segundos (cargar modelo)</li><li>Cada request subsecuente también (no hay caching)</li><li>Si 10 requests concurrentes → 10 cargas del modelo (50 segundos total)</li></ul><h4 id=la-solución-asynccontextmanager>La Solución: asynccontextmanager<a hidden class=anchor aria-hidden=true href=#la-solución-asynccontextmanager>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@asynccontextmanager</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>lifespan</span><span class=p>(</span><span class=n>app</span><span class=p>:</span> <span class=n>FastAPI</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Lifecycle manager for the FastAPI application.
</span></span></span><span class=line><span class=cl><span class=s2>    Loads the model on startup and cleans up on shutdown.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Starting up API...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># STARTUP: Cargar modelo UNA VEZ</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb_logger</span> <span class=o>=</span> <span class=n>WandBLogger</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>WANDB_PROJECT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>enabled</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model_loader</span> <span class=o>=</span> <span class=n>ModelLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>local_model_path</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>LOCAL_MODEL_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_bucket</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>GCS_BUCKET</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_model_path</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>GCS_MODEL_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_model_name</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_MODEL_NAME</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_model_stage</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_MODEL_STAGE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_tracking_uri</span><span class=o>=</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_TRACKING_URI</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Loading model...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model_loader</span><span class=o>.</span><span class=n>load_model</span><span class=p>()</span>  <span class=c1># Toma 5 segundos, pero SOLO una vez</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model loaded: </span><span class=si>{</span><span class=n>model_loader</span><span class=o>.</span><span class=n>model_version</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Guardar en app state (disponible para todos los endpoints)</span>
</span></span><span class=line><span class=cl>        <span class=n>app</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>model_loader</span> <span class=o>=</span> <span class=n>model_loader</span>
</span></span><span class=line><span class=cl>        <span class=n>app</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>wandb_logger</span> <span class=o>=</span> <span class=n>wandb_logger</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Failed to load model: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=s2>&#34;API will start but predictions will fail&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>yield</span>  <span class=c1># API corre aquí</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># SHUTDOWN: Cleanup</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Shutting down API...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb_logger</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Usar lifespan en FastAPI</span>
</span></span><span class=line><span class=cl><span class=n>app</span> <span class=o>=</span> <span class=n>FastAPI</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>title</span><span class=o>=</span><span class=s2>&#34;Housing Price Prediction API&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>version</span><span class=o>=</span><span class=s2>&#34;1.0.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>lifespan</span><span class=o>=</span><span class=n>lifespan</span>  <span class=c1># CRÍTICO</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p><strong>Lo que hace:</strong></p><ol><li><p><strong>Startup (antes de <code>yield</code>):</strong></p><ul><li>Carga modelo en memoria (5 segundos, <strong>una sola vez</strong>)</li><li>Inicializa W&amp;B logger</li><li>Guarda ambos en <code>app.state</code> (singleton pattern)</li></ul></li><li><p><strong>Running (después de <code>yield</code>):</strong></p><ul><li>Todas las requests usan el modelo cacheado en <code>app.state.model_loader</code></li><li>Latencia por request: &lt;50ms (solo inference, no I/O)</li></ul></li><li><p><strong>Shutdown (después del context manager):</strong></p><ul><li>Cierra W&amp;B run (flush pending logs)</li><li>Libera recursos</li></ul></li></ol><p><strong>Resultado:</strong></p><ul><li>Primera request: &lt;50ms (modelo ya cargado)</li><li>Requests subsecuentes: &lt;50ms</li><li>10 requests concurrentes: &lt;100ms promedio (paralelizable)</li></ul><p><strong>Trade-off:</strong> Startup time de 5-10 segundos. Aceptable para producción—mejor que 5 segundos por request.</p><hr><h3 id=2-configuration-management-pydantic-settings-con-prioridades>2. Configuration Management: Pydantic Settings con Prioridades<a hidden class=anchor aria-hidden=true href=#2-configuration-management-pydantic-settings-con-prioridades>#</a></h3><h4 id=el-pattern-settings-as-code>El Pattern: Settings-as-Code<a hidden class=anchor aria-hidden=true href=#el-pattern-settings-as-code>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/core/config.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pydantic_settings</span> <span class=kn>import</span> <span class=n>BaseSettings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Settings</span><span class=p>(</span><span class=n>BaseSettings</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>PROJECT_NAME</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;Housing Price Prediction API&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>VERSION</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;1.0.0&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>API_V1_STR</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;/api/v1&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Model - MLflow (priority 1)</span>
</span></span><span class=line><span class=cl>    <span class=n>MLFLOW_MODEL_NAME</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>MLFLOW_MODEL_STAGE</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;Production&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>MLFLOW_TRACKING_URI</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Model - GCS (priority 2)</span>
</span></span><span class=line><span class=cl>    <span class=n>GCS_BUCKET</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>GCS_MODEL_PATH</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;models/trained/housing_price_model.pkl&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Model - Local (priority 3, fallback)</span>
</span></span><span class=line><span class=cl>    <span class=n>LOCAL_MODEL_PATH</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;models/trained/housing_price_model.pkl&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Weights &amp; Biases</span>
</span></span><span class=line><span class=cl>    <span class=n>WANDB_API_KEY</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>WANDB_PROJECT</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;housing-mlops-api&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>class</span> <span class=nc>Config</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>env_file</span> <span class=o>=</span> <span class=s2>&#34;.env&#34;</span>  <span class=c1># Lee de .env automáticamente</span>
</span></span><span class=line><span class=cl>        <span class=n>case_sensitive</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># MLFLOW_MODEL_NAME != mlflow_model_name</span>
</span></span></code></pre></div><p><strong>Por qué Pydantic Settings:</strong></p><ol><li><strong>Type Safety</strong>: <code>settings.VERSION</code> es <code>str</code>, no <code>Optional[Any]</code></li><li><strong>Validation</strong>: Si <code>MLFLOW_MODEL_STAGE</code> no es string, falla en startup (no en la primera request)</li><li><strong>Auto .env loading</strong>: No necesitas <code>python-dotenv</code> manualmente</li><li><strong>Default values</strong>: <code>LOCAL_MODEL_PATH</code> tiene default, <code>MLFLOW_MODEL_NAME</code> no</li></ol><p><strong>Uso en código:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>app.core.config</span> <span class=kn>import</span> <span class=n>Settings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>settings</span> <span class=o>=</span> <span class=n>Settings</span><span class=p>()</span>  <span class=c1># Lee env vars + .env</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_MODEL_NAME</span><span class=p>:</span>  <span class=c1># Type-safe check</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>load_from_mlflow</span><span class=p>(</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_MODEL_NAME</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=la-estrategia-de-prioridades-cascade-fallback>La Estrategia de Prioridades (Cascade Fallback)<a hidden class=anchor aria-hidden=true href=#la-estrategia-de-prioridades-cascade-fallback>#</a></h4><pre tabindex=0><code>Intenta cargar de:
1. MLflow Registry (si MLFLOW_MODEL_NAME está configurado)
   ↓ Si falla
2. GCS (si GCS_BUCKET está configurado)
   ↓ Si falla
3. Local filesystem (siempre disponible como último recurso)
   ↓ Si falla
4. API inicia pero `/predict` retorna 500
</code></pre><p><strong>Configuración por ambiente:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Producción (.env.production)</span>
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Production
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_TRACKING_URI</span><span class=o>=</span>https://mlflow.company.com
</span></span><span class=line><span class=cl><span class=c1># GCS y Local quedan vacíos → no se usan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Staging (.env.staging)</span>
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model
</span></span><span class=line><span class=cl><span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Staging
</span></span><span class=line><span class=cl><span class=c1># Mismo setup, diferente stage</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Desarrollo local (.env.local)</span>
</span></span><span class=line><span class=cl><span class=nv>LOCAL_MODEL_PATH</span><span class=o>=</span>models/trained/housing_price_model.pkl
</span></span><span class=line><span class=cl><span class=c1># Sin MLflow ni GCS → carga de local directo</span>
</span></span></code></pre></div><p><strong>Valor:</strong> Un solo codebase, múltiples ambientes. No hay <code>if ENVIRONMENT == "production"</code> en el código.</p><hr><h3 id=3-model-loader-multi-source-con-fallback-inteligente>3. Model Loader: Multi-Source con Fallback Inteligente<a hidden class=anchor aria-hidden=true href=#3-model-loader-multi-source-con-fallback-inteligente>#</a></h3><h4 id=la-arquitectura-del-loader>La Arquitectura del Loader<a hidden class=anchor aria-hidden=true href=#la-arquitectura-del-loader>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/core/model_loader.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelLoader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Handles loading ML models from various sources.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>local_model_path</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_bucket</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_model_path</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_model_name</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_model_stage</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlflow_tracking_uri</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span> <span class=o>=</span> <span class=n>local_model_path</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span> <span class=o>=</span> <span class=n>gcs_bucket</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span> <span class=o>=</span> <span class=n>gcs_model_path</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span> <span class=o>=</span> <span class=n>mlflow_model_name</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_stage</span> <span class=o>=</span> <span class=n>mlflow_model_stage</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_tracking_uri</span> <span class=o>=</span> <span class=n>mlflow_tracking_uri</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_model</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Any</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># Cacheado en memoria</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_model_version</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;unknown&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_preprocessor</span> <span class=o>=</span> <span class=n>HousingPreprocessor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Any</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Load model with cascade fallback strategy.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Priority 1: MLflow Registry</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Attempting MLflow load: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_mlflow</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_stage</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_tracking_uri</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>, trying GCS...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Priority 2: GCS</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Attempting GCS load: gs://</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_gcs</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GCS load failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>, trying local...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Priority 3: Local filesystem</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span> <span class=ow>and</span> <span class=n>Path</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Attempting local load: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_local</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># All strategies failed</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Could not load model from any source. &#34;</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Check MLflow/GCS/local configuration.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Make predictions with preprocessing.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>is_loaded</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;Model not loaded&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Apply same preprocessing que el training pipeline</span>
</span></span><span class=line><span class=cl>        <span class=n>processed_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_preprocessor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Predict</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>processed_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>predictions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@property</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>is_loaded</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Check if model is loaded.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></span></code></pre></div><h4 id=decisiones-técnicas-críticas-7>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-7>#</a></h4><p><strong>1. Por Qué MLflow Es Priority 1</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># MLflow load</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;models:/housing_price_model/Production&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Ventajas sobre GCS/Local:</strong></p><ul><li><strong>Model URI abstrae storage</strong>: El modelo puede estar en S3, GCS, HDFS—MLflow lo resuelve</li><li><strong>Stage resolution</strong>: <code>Production</code> automáticamente resuelve a la versión correcta (v1, v2, etc.)</li><li><strong>Metadata incluida</strong>: MLflow también carga <code>conda.yaml</code>, <code>requirements.txt</code>, metadata de features</li><li><strong>Rollback trivial</strong>: Cambias stage en MLflow UI, API recarga automáticamente en próximo restart</li></ul><p><strong>2. GCS Como Fallback (No Primary)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># GCS load</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>google.cloud</span> <span class=kn>import</span> <span class=n>storage</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>bucket</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=s2>&#34;my-bucket&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>blob</span> <span class=o>=</span> <span class=n>bucket</span><span class=o>.</span><span class=n>blob</span><span class=p>(</span><span class=s2>&#34;models/trained/housing_price_model.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_bytes</span> <span class=o>=</span> <span class=n>blob</span><span class=o>.</span><span class=n>download_as_bytes</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>model_bytes</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué no primary:</strong></p><ul><li><strong>No hay versionamiento:</strong> <code>models/trained/housing_price_model.pkl</code> es siempre el &ldquo;latest&rdquo;—no puedes cargar v1 vs v2 sin cambiar el path</li><li><strong>No metadata:</strong> Solo obtienes el pickle, no sabes qué hiperparámetros/features espera</li><li><strong>No stages:</strong> No existe concepto de Staging vs Production</li></ul><p><strong>Cuándo usar GCS como primary:</strong></p><ul><li>MLflow no está disponible (outage)</li><li>Setup simple (solo un modelo, no necesitas registry)</li><li>Budget constraint (evitar hosting de MLflow)</li></ul><p><strong>3. Local Como Last Resort</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Local load</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;models/trained/housing_price_model.pkl&#34;</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Solo para:</strong></p><ul><li>Desarrollo local (no quieres depender de GCS/MLflow)</li><li>Debugging (modelo roto en GCS, testeas con una copia local)</li><li>CI/CD tests (GitHub Actions no tiene acceso a GCS)</li></ul><p><strong>Nunca para producción real</strong>—si GCS y MLflow están down, tienes problemas más grandes que el modelo.</p><p><strong>4. Preprocessing Pipeline Embebido</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>_preprocessor</span> <span class=o>=</span> <span class=n>HousingPreprocessor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>processed_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_preprocessor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>processed_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>predictions</span>
</span></span></code></pre></div><p><strong>Por qué crítico:</strong> El modelo espera features procesadas (one-hot encoding de <code>ocean_proximity</code>, feature engineering de clusters). Si el cliente envía raw features, el modelo falla.</p><p><strong>Opciones de implementación:</strong></p><p><strong>A) Preprocessing en el API (este proyecto):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Cliente envía raw features</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=s2>&#34;ocean_proximity&#34;</span><span class=p>:</span> <span class=s2>&#34;NEAR BAY&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>:</span> <span class=o>-</span><span class=mf>122.23</span><span class=p>,</span> <span class=o>...</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API aplica preprocessing</span>
</span></span><span class=line><span class=cl><span class=n>processed</span> <span class=o>=</span> <span class=n>preprocessor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>raw_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Modelo recibe features procesadas</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>processed</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>B) Preprocessing en el cliente (mal para APIs públicos):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Cliente debe saber exact preprocessing</span>
</span></span><span class=line><span class=cl><span class=n>processed</span> <span class=o>=</span> <span class=n>client_side_preprocessing</span><span class=p>(</span><span class=n>raw_features</span><span class=p>)</span>  <span class=c1># ¿Qué hace esto?</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API solo hace inference</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>processed</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Trade-offs:</strong></p><table><thead><tr><th>Approach</th><th>Ventaja</th><th>Desventaja</th></tr></thead><tbody><tr><td><strong>Preprocessing en API</strong></td><td>Cliente no necesita saber preprocessing</td><td>API más complejo, latencia +5ms</td></tr><tr><td><strong>Preprocessing en cliente</strong></td><td>API simple, latencia baja</td><td>Cliente debe replicar preprocessing exacto</td></tr></tbody></table><p><strong>Para APIs públicos:</strong> Siempre preprocessing en el API. Los clientes no deben conocer detalles internos del modelo.</p><p><strong>Para APIs internos:</strong> Depende. Si el cliente es otro servicio que controlas, puedes hacer preprocessing ahí para reducir latencia.</p><hr><h3 id=4-requestresponse-validation-pydantic-schemas>4. Request/Response Validation: Pydantic Schemas<a hidden class=anchor aria-hidden=true href=#4-requestresponse-validation-pydantic-schemas>#</a></h3><h4 id=el-anti-pattern-validación-manual>El Anti-Pattern: Validación Manual<a hidden class=anchor aria-hidden=true href=#el-anti-pattern-validación-manual>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># BAD: Validación manual propensa a errores</span>
</span></span><span class=line><span class=cl><span class=nd>@app.post</span><span class=p>(</span><span class=s2>&#34;/predict&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>request</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;longitude&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>request</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=s2>&#34;missing longitude&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>request</span><span class=p>[</span><span class=s2>&#34;longitude&#34;</span><span class=p>],</span> <span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=nb>float</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=s2>&#34;longitude must be number&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>request</span><span class=p>[</span><span class=s2>&#34;longitude&#34;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=o>-</span><span class=mi>180</span> <span class=ow>or</span> <span class=n>request</span><span class=p>[</span><span class=s2>&#34;longitude&#34;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>180</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=s2>&#34;longitude out of range&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... 50 líneas más de validación manual</span>
</span></span></code></pre></div><p><strong>Problemas:</strong></p><ul><li>Código repetitivo y frágil</li><li>Errores inconsistentes (<code>"missing longitude"</code> vs <code>"longitude is required"</code>)</li><li>No hay documentación automática (OpenAPI)</li><li>Difícil de testear</li></ul><h4 id=la-solución-pydantic-schemas>La Solución: Pydantic Schemas<a hidden class=anchor aria-hidden=true href=#la-solución-pydantic-schemas>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/models/schemas.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>BaseModel</span><span class=p>,</span> <span class=n>Field</span><span class=p>,</span> <span class=n>field_validator</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingFeatures</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Input features for housing price prediction.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>longitude</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span><span class=p>,</span>  <span class=c1># Required</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Longitude coordinate&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>ge</span><span class=o>=-</span><span class=mi>180</span><span class=p>,</span>  <span class=c1># greater or equal</span>
</span></span><span class=line><span class=cl>        <span class=n>le</span><span class=o>=</span><span class=mi>180</span>    <span class=c1># less or equal</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>latitude</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Latitude coordinate&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=-</span><span class=mi>90</span><span class=p>,</span> <span class=n>le</span><span class=o>=</span><span class=mi>90</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>housing_median_age</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Median age of houses&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>total_rooms</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Total number of rooms&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>total_bedrooms</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Total number of bedrooms&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>population</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Block population&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>households</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Number of households&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>median_income</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Median income&#34;</span><span class=p>,</span> <span class=n>ge</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ocean_proximity</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Proximity to ocean&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@field_validator</span><span class=p>(</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nd>@classmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>validate_ocean_proximity</span><span class=p>(</span><span class=bp>cls</span><span class=p>,</span> <span class=n>v</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Validate ocean proximity values.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_values</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;&lt;1H OCEAN&#39;</span><span class=p>,</span> <span class=s1>&#39;INLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;ISLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;NEAR BAY&#39;</span><span class=p>,</span> <span class=s1>&#39;NEAR OCEAN&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>v</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>valid_values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;ocean_proximity must be one of: </span><span class=si>{</span><span class=s1>&#39;, &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>valid_values</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>v</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span>  <span class=c1># Normaliza a uppercase</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;json_schema_extra&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;examples&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;longitude&#34;</span><span class=p>:</span> <span class=o>-</span><span class=mf>122.23</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;latitude&#34;</span><span class=p>:</span> <span class=mf>37.88</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;housing_median_age&#34;</span><span class=p>:</span> <span class=mf>41.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;total_rooms&#34;</span><span class=p>:</span> <span class=mf>880.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>:</span> <span class=mf>129.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;population&#34;</span><span class=p>:</span> <span class=mf>322.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;households&#34;</span><span class=p>:</span> <span class=mf>126.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;median_income&#34;</span><span class=p>:</span> <span class=mf>8.3252</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;ocean_proximity&#34;</span><span class=p>:</span> <span class=s2>&#34;NEAR BAY&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>}]</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p><strong>Lo que esto da automáticamente:</strong></p><ol><li><p><strong>Validación de tipos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;longitude&#34;</span><span class=p>:</span> <span class=s2>&#34;not a number&#34;</span><span class=p>}</span>  <span class=c1>// Rechazado: ValidationError
</span></span></span></code></pre></div></li><li><p><strong>Validación de rangos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;longitude&#34;</span><span class=p>:</span> <span class=mi>-200</span><span class=p>}</span>  <span class=c1>// Rechazado: must be &gt;= -180
</span></span></span></code></pre></div></li><li><p><strong>Validación custom:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span><span class=nt>&#34;ocean_proximity&#34;</span><span class=p>:</span> <span class=s2>&#34;INVALID&#34;</span><span class=p>}</span>  <span class=c1>// Rechazado: must be one of [...]
</span></span></span></code></pre></div></li><li><p><strong>Documentación automática en <code>/docs</code>:</strong></p><ul><li>Swagger UI muestra todos los fields</li><li>Descriptions, constraints, ejemplos</li><li>Try-it-out funciona out-of-the-box</li></ul></li><li><p><strong>Serialización type-safe:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>HousingFeatures</span><span class=p>(</span><span class=o>**</span><span class=n>request_json</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>features</span><span class=o>.</span><span class=n>longitude</span>  <span class=c1># Type: float (no Optional[Any])</span>
</span></span></code></pre></div></li></ol><h4 id=batch-predictions-support>Batch Predictions Support<a hidden class=anchor aria-hidden=true href=#batch-predictions-support>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PredictionRequest</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Request model for single or batch predictions.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>instances</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>HousingFeatures</span><span class=p>]</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;List of housing features for prediction&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>min_length</span><span class=o>=</span><span class=mi>1</span>  <span class=c1># Al menos una instancia</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p><strong>Uso:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;instances&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nt>&#34;longitude&#34;</span><span class=p>:</span> <span class=mf>-122.23</span><span class=p>,</span> <span class=err>...</span><span class=p>},</span>  <span class=c1>// Predict house 1
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>{</span><span class=nt>&#34;longitude&#34;</span><span class=p>:</span> <span class=mf>-118.45</span><span class=p>,</span> <span class=err>...</span><span class=p>},</span>  <span class=c1>// Predict house 2
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>{</span><span class=nt>&#34;longitude&#34;</span><span class=p>:</span> <span class=mf>-121.89</span><span class=p>,</span> <span class=err>...</span><span class=p>}</span>   <span class=c1>// Predict house 3
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Por qué soportar batch:</strong></p><ul><li><strong>Latencia reducida:</strong> 3 requests individuales = 150ms. 1 batch de 3 = 60ms.</li><li><strong>Costo reducido:</strong> Menos HTTP overhead (headers, handshake, etc.)</li><li><strong>Inference eficiente:</strong> El modelo puede vectorizar operaciones</li></ul><p><strong>Trade-off:</strong> Batch size muy grande (>1000) puede causar timeouts. Implementar límite:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>instances</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>HousingFeatures</span><span class=p>]</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_length</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_length</span><span class=o>=</span><span class=mi>100</span>  <span class=c1># Máximo 100 predicciones por request</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h4 id=response-schema>Response Schema<a hidden class=anchor aria-hidden=true href=#response-schema>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PredictionResult</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Individual prediction result.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>predicted_price</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Predicted median house value&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>confidence_interval</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>dict</span><span class=p>]</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Confidence interval (if available)&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>PredictionResponse</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Response model for predictions.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>PredictionResult</span><span class=p>]</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;List of predictions&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model_version</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Model version used&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;json_schema_extra&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;examples&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;predictions&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;predicted_price&#34;</span><span class=p>:</span> <span class=mf>452600.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;confidence_interval&#34;</span><span class=p>:</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>                <span class=p>}],</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;model_version&#34;</span><span class=p>:</span> <span class=s2>&#34;randomforest_v1&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>}]</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p><strong><code>model_version</code> en response:</strong> Crucial para debugging. Si un cliente reporta predicciones incorrectas, el <code>model_version</code> te dice qué modelo usó (v1, v2, Production, etc.).</p><hr><h3 id=5-router-pattern-endpoints-y-error-handling>5. Router Pattern: Endpoints y Error Handling<a hidden class=anchor aria-hidden=true href=#5-router-pattern-endpoints-y-error-handling>#</a></h3><h4 id=la-estructura-del-router>La Estructura del Router<a hidden class=anchor aria-hidden=true href=#la-estructura-del-router>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/routers/predict.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>fastapi</span> <span class=kn>import</span> <span class=n>APIRouter</span><span class=p>,</span> <span class=n>HTTPException</span><span class=p>,</span> <span class=n>status</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>router</span> <span class=o>=</span> <span class=n>APIRouter</span><span class=p>(</span><span class=n>prefix</span><span class=o>=</span><span class=s2>&#34;/api/v1&#34;</span><span class=p>,</span> <span class=n>tags</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;predictions&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Global instances (set by main.py)</span>
</span></span><span class=line><span class=cl><span class=n>model_loader</span><span class=p>:</span> <span class=n>ModelLoader</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=n>wandb_logger</span><span class=p>:</span> <span class=n>WandBLogger</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>set_model_loader</span><span class=p>(</span><span class=n>loader</span><span class=p>:</span> <span class=n>ModelLoader</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Dependency injection pattern.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>global</span> <span class=n>model_loader</span>
</span></span><span class=line><span class=cl>    <span class=n>model_loader</span> <span class=o>=</span> <span class=n>loader</span>
</span></span></code></pre></div><p><strong>Por qué <code>prefix="/api/v1"</code>:</strong></p><pre tabindex=0><code>/api/v1/predict  ← Versión 1 del API
/api/v2/predict  ← Versión 2 (breaking changes)
</code></pre><p>Puedes correr ambas versiones simultáneamente durante migración:</p><ul><li>Clientes legacy usan <code>/api/v1/</code></li><li>Clientes nuevos usan <code>/api/v2/</code></li><li>Deprecas v1 después de 6 meses</li></ul><p><strong>Sin versionamiento:</strong> Breaking change → todos los clientes se rompen al mismo tiempo.</p><h4 id=el-endpoint-principal-post-apiv1predict>El Endpoint Principal: POST /api/v1/predict<a hidden class=anchor aria-hidden=true href=#el-endpoint-principal-post-apiv1predict>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@router.post</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;/predict&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>response_model</span><span class=o>=</span><span class=n>PredictionResponse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_200_OK</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>responses</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=mi>400</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=n>ErrorResponse</span><span class=p>,</span> <span class=s2>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;Invalid input data&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=mi>500</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;model&#34;</span><span class=p>:</span> <span class=n>ErrorResponse</span><span class=p>,</span> <span class=s2>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;Prediction failed&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=n>summary</span><span class=o>=</span><span class=s2>&#34;Predict housing prices&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Make predictions for housing prices based on input features&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>request</span><span class=p>:</span> <span class=n>PredictionRequest</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>PredictionResponse</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Predict housing prices for given features.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. Check model loaded</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>model_loader</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>is_loaded</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_500_INTERNAL_SERVER_ERROR</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>detail</span><span class=o>=</span><span class=s2>&#34;Model not loaded&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 2. Convert Pydantic models to DataFrame</span>
</span></span><span class=line><span class=cl>        <span class=n>features_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>instance</span><span class=o>.</span><span class=n>model_dump</span><span class=p>()</span> <span class=k>for</span> <span class=n>instance</span> <span class=ow>in</span> <span class=n>request</span><span class=o>.</span><span class=n>instances</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>features_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. Make predictions</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions</span> <span class=o>=</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 4. Calculate metrics</span>
</span></span><span class=line><span class=cl>        <span class=n>response_time_ms</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 5. Format response</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>PredictionResult</span><span class=p>(</span><span class=n>predicted_price</span><span class=o>=</span><span class=nb>float</span><span class=p>(</span><span class=n>pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>predictions</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 6. Log to W&amp;B (async, no bloquea)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>wandb_logger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb_logger</span><span class=o>.</span><span class=n>log_prediction</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>features</span><span class=o>=</span><span class=n>features_list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>predictions</span><span class=o>=</span><span class=p>[</span><span class=nb>float</span><span class=p>(</span><span class=n>p</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>predictions</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>model_version</span><span class=o>=</span><span class=n>model_loader</span><span class=o>.</span><span class=n>model_version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>response_time_ms</span><span class=o>=</span><span class=n>response_time_ms</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>PredictionResponse</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>predictions</span><span class=o>=</span><span class=n>results</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>model_version</span><span class=o>=</span><span class=n>model_loader</span><span class=o>.</span><span class=n>model_version</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>ValueError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Validation error (ej: feature fuera de rango esperado)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>wandb_logger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb_logger</span><span class=o>.</span><span class=n>log_error</span><span class=p>(</span><span class=s2>&#34;validation_error&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>),</span> <span class=n>features_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_400_BAD_REQUEST</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>detail</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Invalid input data: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Unexpected error (ej: modelo corrupto, OOM)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>wandb_logger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb_logger</span><span class=o>.</span><span class=n>log_error</span><span class=p>(</span><span class=s2>&#34;prediction_error&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>status_code</span><span class=o>=</span><span class=n>status</span><span class=o>.</span><span class=n>HTTP_500_INTERNAL_SERVER_ERROR</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>detail</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Prediction failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></div><p><strong>Decisiones de error handling:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Inference</span>
</span></span><span class=line><span class=cl><span class=k>except</span> <span class=ne>ValueError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Cliente envió datos inválidos → 400 Bad Request</span>
</span></span><span class=line><span class=cl>    <span class=c1># Loguear a W&amp;B para análisis</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>400</span>
</span></span><span class=line><span class=cl><span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Error inesperado (bug en el código/modelo) → 500 Internal Server Error</span>
</span></span><span class=line><span class=cl>    <span class=c1># Loguear a W&amp;B para alerting</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>500</span>
</span></span></code></pre></div><p><strong>Por qué distinguir 400 vs 500:</strong></p><ul><li><strong>400:</strong> Culpa del cliente. No retries automáticos.</li><li><strong>500:</strong> Culpa del servidor. Cliente puede retry.</li></ul><p><strong>Logging de errores a W&amp;B:</strong> Permite detectar patrones. Si ves 1000 <code>validation_error</code> para <code>ocean_proximity="INVALID"</code>, agregas un mensaje de error más claro.</p><hr><h3 id=6-wb-logging-observability-en-producción>6. W&amp;B Logging: Observability en Producción<a hidden class=anchor aria-hidden=true href=#6-wb-logging-observability-en-producción>#</a></h3><h4 id=por-qué-loguear-predicciones>Por Qué Loguear Predicciones<a hidden class=anchor aria-hidden=true href=#por-qué-loguear-predicciones>#</a></h4><p><strong>Pregunta:</strong> &ldquo;¿Para qué loguear cada predicción si ya tengo logs de uvicorn?&rdquo;</p><p><strong>Respuesta:</strong> Los logs de uvicorn te dicen:</p><ul><li>Qué endpoint se llamó</li><li>HTTP status code</li><li>Cuánto tardó</li></ul><p>Los logs de W&amp;B te dicen:</p><ul><li><strong>Qué features</strong> se usaron</li><li><strong>Qué predicción</strong> se hizo</li><li><strong>Distribución de predicciones</strong> (¿todas están en $200k-$500k? ¿hay outliers?)</li><li><strong>Latencia promedio</strong> por request</li><li><strong>Error rate</strong> (¿cuántos requests fallan?)</li></ul><p><strong>Caso de uso real:</strong> Stakeholder reporta &ldquo;las predicciones están muy altas últimamente&rdquo;. Abres W&amp;B dashboard:</p><pre tabindex=0><code>prediction/mean: $450k (antes: $380k)
features/median_income: 9.2 (antes: 7.5)
</code></pre><p><strong>Conclusión:</strong> No hay bug—simplemente los clientes están consultando casas en áreas más caras (<code>median_income</code> más alto). Sin W&amp;B, estarías debuggeando código por horas.</p><h4 id=la-implementación>La Implementación<a hidden class=anchor aria-hidden=true href=#la-implementación>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/core/wandb_logger.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>WandBLogger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>project</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;housing-mlops-api&#34;</span><span class=p>,</span> <span class=n>enabled</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>enabled</span> <span class=o>=</span> <span class=n>enabled</span> <span class=ow>and</span> <span class=nb>bool</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;WANDB_API_KEY&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>enabled</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_run</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>project</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>project</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>job_type</span><span class=o>=</span><span class=s2>&#34;api-inference&#34;</span><span class=p>,</span>  <span class=c1># Distinguir de training runs</span>
</span></span><span class=line><span class=cl>                <span class=n>config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;environment&#34;</span><span class=p>:</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;ENVIRONMENT&#34;</span><span class=p>,</span> <span class=s2>&#34;production&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;model_version&#34;</span><span class=p>:</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;MODEL_VERSION&#34;</span><span class=p>,</span> <span class=s2>&#34;unknown&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=n>reinit</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># Permite múltiples init() en mismo proceso</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>log_prediction</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>features</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>float</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>model_version</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>response_time_ms</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>enabled</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Métricas agregadas</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prediction/count&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prediction/mean&#34;</span><span class=p>:</span> <span class=nb>sum</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prediction/min&#34;</span><span class=p>:</span> <span class=nb>min</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prediction/max&#34;</span><span class=p>:</span> <span class=nb>max</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;performance/response_time_ms&#34;</span><span class=p>:</span> <span class=n>response_time_ms</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;model/version&#34;</span><span class=p>:</span> <span class=n>model_version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;timestamp&#34;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>isoformat</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Feature distributions (sample first 100)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>features</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=mi>100</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>feat</span><span class=p>,</span> <span class=n>pred</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>                <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                    <span class=sa>f</span><span class=s2>&#34;features/instance_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>/median_income&#34;</span><span class=p>:</span> <span class=n>feat</span><span class=p>[</span><span class=s2>&#34;median_income&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=sa>f</span><span class=s2>&#34;predictions/instance_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>pred</span>
</span></span><span class=line><span class=cl>                <span class=p>})</span>
</span></span></code></pre></div><p><strong>Por qué <code>job_type="api-inference"</code>:</strong></p><p>En W&amp;B dashboard, puedes filtrar por job type:</p><ul><li><code>training</code>: Runs del pipeline de entrenamiento</li><li><code>sweep</code>: Runs del hyperparameter sweep</li><li><code>api-inference</code>: Predicciones en producción</li></ul><p><strong>Por qué <code>reinit=True</code>:</strong> Un proceso de uvicorn puede vivir días. <code>reinit=True</code> permite crear múltiples W&amp;B runs dentro del mismo proceso (uno por startup/restart).</p><p><strong>Por qué sample first 100:</strong> Loguear 10,000 features individuales por request sería demasiado overhead. Muestrear 100 da distribución representativa sin matar performance.</p><h4 id=wb-dashboard-en-producción>W&amp;B Dashboard en Producción<a hidden class=anchor aria-hidden=true href=#wb-dashboard-en-producción>#</a></h4><pre tabindex=0><code># Métricas a monitorear:

prediction/count: Requests per minute (RPM)
  - Esperado: 100-500 RPM
  - Alerta: &lt;10 RPM (¿está caído?) o &gt;2000 RPM (¿DDoS?)

prediction/mean: Precio promedio predicho
  - Esperado: $300k-$450k (según mercado)
  - Alerta: &gt;$1M (modelo roto) o &lt;$50k (data drift)

performance/response_time_ms: Latencia
  - Esperado: 30-60ms
  - Alerta: &gt;200ms (modelo lento o CPU throttling)

error/count: Errores por minuto
  - Esperado: 0-5 errores/min
  - Alerta: &gt;50 errores/min (investigate immediately)
</code></pre><hr><h3 id=7-cors-y-security>7. CORS y Security<a hidden class=anchor aria-hidden=true href=#7-cors-y-security>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/main.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>app</span><span class=o>.</span><span class=n>add_middleware</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>CORSMiddleware</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>allow_origins</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;http://localhost:3000&#34;</span><span class=p>,</span>     <span class=c1># Frontend local (React/Streamlit)</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;http://localhost:8080&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;https://app.company.com&#34;</span><span class=p>,</span>   <span class=c1># Frontend en producción</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>allow_credentials</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>  <span class=c1># No cookies (API es stateless)</span>
</span></span><span class=line><span class=cl>    <span class=n>allow_methods</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;GET&#34;</span><span class=p>,</span> <span class=s2>&#34;POST&#34;</span><span class=p>],</span>  <span class=c1># Solo métodos necesarios</span>
</span></span><span class=line><span class=cl>    <span class=n>allow_headers</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;Content-Type&#34;</span><span class=p>,</span> <span class=s2>&#34;Authorization&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>max_age</span><span class=o>=</span><span class=mi>3600</span><span class=p>,</span>  <span class=c1># Cache preflight requests por 1 hora</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué restricted origins:</strong></p><p><strong>Anti-pattern (permissive):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>allow_origins</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;*&#34;</span><span class=p>]</span>  <span class=c1># MALO: Cualquier sitio puede llamar tu API</span>
</span></span></code></pre></div><p><strong>Problema:</strong> Un sitio malicioso <code>evil.com</code> puede hacer requests a tu API desde el navegador del usuario, potencialmente:</p><ul><li>Consumir tu cuota de GCP (si no hay auth)</li><li>Hacer predicciones spam</li><li>DoS attack</li></ul><p><strong>Pattern correcto (restrictive):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>allow_origins</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;https://app.company.com&#34;</span><span class=p>]</span>  <span class=c1># Solo tu frontend</span>
</span></span></code></pre></div><p><strong>Para desarrollo local:</strong> Agregar <code>http://localhost:3000</code> temporalmente, remover en producción.</p><p><strong>Por qué <code>allow_credentials=False</code>:</strong> Este API es stateless—no usa cookies ni sesiones. <code>allow_credentials=True</code> sería innecesario y una superficie de ataque adicional.</p><hr><h3 id=8-el-flujo-completo-de-una-request>8. El Flujo Completo de Una Request<a hidden class=anchor aria-hidden=true href=#8-el-flujo-completo-de-una-request>#</a></h3><p><strong>Request:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -X POST http://localhost:8080/api/v1/predict <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -H <span class=s2>&#34;Content-Type: application/json&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;instances&#34;: [{
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;longitude&#34;: -122.23,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;latitude&#34;: 37.88,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;housing_median_age&#34;: 41,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;total_rooms&#34;: 880,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;total_bedrooms&#34;: 129,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;population&#34;: 322,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;households&#34;: 126,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;median_income&#34;: 8.3252,
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;ocean_proximity&#34;: &#34;NEAR BAY&#34;
</span></span></span><span class=line><span class=cl><span class=s1>    }]
</span></span></span><span class=line><span class=cl><span class=s1>  }&#39;</span>
</span></span></code></pre></div><p><strong>El viaje interno (&lt; 50ms):</strong></p><pre tabindex=0><code>1. FastAPI recibe request (1ms)
   ├─ CORS middleware valida origin
   └─ Router match: POST /api/v1/predict

2. Pydantic validation (2ms)
   ├─ Parse JSON → PredictionRequest object
   ├─ Validate types (longitude: float ✓)
   ├─ Validate ranges (longitude: -122.23, dentro de [-180, 180] ✓)
   └─ Custom validator (ocean_proximity: &#34;NEAR BAY&#34; → válido ✓)

3. Endpoint handler: predict() (40ms)
   ├─ Check model_loader.is_loaded (0.1ms)
   ├─ Convert Pydantic → DataFrame (1ms)
   ├─ Preprocessing (5ms)
   │   ├─ One-hot encode ocean_proximity
   │   ├─ Compute cluster similarity features
   │   └─ Scale numerical features
   ├─ Model inference (30ms)
   │   └─ RandomForest.predict(processed_features)
   ├─ Format response (1ms)
   └─ Log to W&amp;B (async, &lt;1ms non-blocking)

4. FastAPI serializa response (2ms)
   └─ PredictionResponse → JSON

5. HTTP response enviado (1ms)

Total: ~50ms
</code></pre><p><strong>Response:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;predictions&#34;</span><span class=p>:</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;predicted_price&#34;</span><span class=p>:</span> <span class=mf>452600.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;confidence_interval&#34;</span><span class=p>:</span> <span class=kc>null</span>
</span></span><span class=line><span class=cl>  <span class=p>}],</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;model_version&#34;</span><span class=p>:</span> <span class=s2>&#34;models:/housing_price_model/Production&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h3 id=9-lo-que-esta-arquitectura-logra>9. Lo Que Esta Arquitectura Logra<a hidden class=anchor aria-hidden=true href=#9-lo-que-esta-arquitectura-logra>#</a></h3><p><strong>Sin esta arquitectura (API naive):</strong></p><ul><li>Cargar modelo en cada request (5 segundos/request)</li><li>Validación manual propensa a errores</li><li>Sin observability (debugging es adivinar)</li><li>Sin versionamiento de API (breaking changes rompen clientes)</li><li>CORS abierto (vulnerability)</li></ul><p><strong>Con esta arquitectura:</strong></p><ul><li><strong>Latencia:</strong> &lt;50ms por predicción (modelo cacheado)</li><li><strong>Confiabilidad:</strong> Pydantic garantiza requests válidos antes de llegar al modelo</li><li><strong>Observability:</strong> W&amp;B dashboard muestra distribución de predicciones, latencia, errores</li><li><strong>Maintainability:</strong> Separation of concerns (core/routers/models)</li><li><strong>Security:</strong> CORS restrictivo, error handling robusto</li><li><strong>Versionamiento:</strong> <code>/api/v1/</code> permite evolucionar el API sin romper clientes</li></ul><p><strong>El valor real:</strong> Este API puede escalar de 10 requests/min a 10,000 requests/min sin cambios en el código—solo agregar más containers con load balancer. La arquitectura ya está lista.</p><hr><p><a name=model-strategies></a></p><h2 id=11-estrategias-de-selección-de-modelos-y-parámetros>11. Estrategias de Selección de Modelos y Parámetros<a hidden class=anchor aria-hidden=true href=#11-estrategias-de-selección-de-modelos-y-parámetros>#</a></h2><h3 id=el-flujo-completo-selection--sweep--registration>El Flujo Completo: Selection → Sweep → Registration<a hidden class=anchor aria-hidden=true href=#el-flujo-completo-selection--sweep--registration>#</a></h3><p>Este pipeline implementa una <strong>estrategia de tres fases</strong> para optimización de modelos, cada una con un propósito específico:</p><pre tabindex=0><code>Step 05: Model Selection
├── Compara 5 algoritmos con GridSearch básico (5-10 combos/modelo)
├── Objetivo: Identificar mejor familia de modelo (Random Forest vs Gradient Boosting vs ...)
├── Métrica principal: MAPE (Mean Absolute Percentage Error)
└── Output: Mejor algoritmo + parámetros iniciales

Step 06: Hyperparameter Sweep
├── Optimiza SOLO el mejor algoritmo del Step 05
├── Bayesian optimization con 50+ runs (espacio de búsqueda exhaustivo)
├── Objetivo: Encontrar configuración óptima del mejor modelo
├── Métrica principal: wMAPE (Weighted MAPE, menos sesgado)
└── Output: best_params.yaml con hiperparámetros óptimos

Step 07: Model Registration
├── Entrena modelo final con parámetros de Step 06
├── Registra en MLflow Model Registry con metadata rica
├── Transiciona a stage (Staging/Production)
└── Output: Modelo versionado listo para deployment
</code></pre><p><strong>¿Por qué tres steps separados?</strong> No tienes recursos computacionales para hacer sweep exhaustivo de 5 algoritmos × 50 combinaciones = 250 entrenamientos. Primero decides <strong>estrategia</strong> (qué algoritmo), luego <strong>tácticas</strong> (qué hiperparámetros).</p><hr><h3 id=step-05-model-selection---comparación-de-algoritmos>Step 05: Model Selection - Comparación de Algoritmos<a hidden class=anchor aria-hidden=true href=#step-05-model-selection---comparación-de-algoritmos>#</a></h3><h4 id=los-5-modelos-candidatos>Los 5 Modelos Candidatos<a hidden class=anchor aria-hidden=true href=#los-5-modelos-candidatos>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_available_models</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Get dictionary of available regression models.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>models</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;RandomForest&#34;</span><span class=p>:</span> <span class=n>RandomForestRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GradientBoosting&#34;</span><span class=p>:</span> <span class=n>GradientBoostingRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ridge&#34;</span><span class=p>:</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Lasso&#34;</span><span class=p>:</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;DecisionTree&#34;</span><span class=p>:</span> <span class=n>DecisionTreeRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>models</span>
</span></span></code></pre></div><p><strong>Por qué estos modelos:</strong></p><ol><li><strong>RandomForest</strong>: Ensemble de árboles, robusto, maneja no-linealidades</li><li><strong>GradientBoosting</strong>: Boosting secuencial, mejor precisión que RF pero más lento</li><li><strong>Ridge</strong>: Regresión lineal con regularización L2, rápido, interpretable</li><li><strong>Lasso</strong>: Regresión lineal con regularización L1, hace feature selection</li><li><strong>DecisionTree</strong>: Baseline simple, útil para comparación</li></ol><p><strong>Lo que falta (deliberadamente):</strong></p><ul><li><strong>XGBoost/LightGBM</strong>: No incluidos para reducir dependencias, pero fácil de agregar</li><li><strong>Neural Networks</strong>: Overkill para este problema (20k muestras, features tabulares)</li><li><strong>SVR</strong>: Muy lento en datasets grandes, no escala bien</li></ul><h4 id=parameter-grids-gridsearch-inicial>Parameter Grids: GridSearch Inicial<a hidden class=anchor aria-hidden=true href=#parameter-grids-gridsearch-inicial>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_default_param_grids</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Parameter grids for initial model selection.
</span></span></span><span class=line><span class=cl><span class=s2>    Refinados basados en domain knowledge.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>param_grids</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;RandomForest&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>200</span><span class=p>,</span> <span class=mi>300</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>         <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>             <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>               <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total combinaciones: 4×5×3×3 = 180</span>
</span></span><span class=line><span class=cl>        <span class=c1># Con 5-fold CV: 180×5 = 900 fits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GradientBoosting&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>150</span><span class=p>,</span> <span class=mi>200</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;learning_rate&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span> <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span>                <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;subsample&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.9</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>],</span>                <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 4×5×5×3 = 300 combinaciones</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ridge&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 9 combinaciones (rápido)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Lasso&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 9 combinaciones</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;DecisionTree&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>      <span class=c1># 6 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span>            <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 6×4×4 = 96 combinaciones</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>param_grids</span>
</span></span></code></pre></div><h4 id=decisiones-de-diseño-de-los-grids>Decisiones de Diseño de los Grids<a hidden class=anchor aria-hidden=true href=#decisiones-de-diseño-de-los-grids>#</a></h4><p><strong>1. RandomForest: Foco en Overfitting Control</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span></span></code></pre></div><p><strong>Razonamiento:</strong> Random Forest tiende a overfit en datasets pequeños. <code>max_depth</code> y <code>min_samples_leaf</code> controlan profundidad de árboles—valores altos previenen que el modelo memorice ruido.</p><p><strong>None en max_depth:</strong> Permite árboles de profundidad ilimitada. Útil cuando el dataset tiene patrones complejos que requieren splits profundos.</p><p><strong>2. GradientBoosting: Balance Learning Rate vs N_estimators</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>150</span><span class=p>,</span> <span class=mi>200</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;learning_rate&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span>
</span></span></code></pre></div><p><strong>Trade-off clásico:</strong></p><ul><li><strong>Learning rate bajo (0.01) + muchos estimators (200):</strong> Aprendizaje lento pero preciso</li><li><strong>Learning rate alto (0.2) + pocos estimators (50):</strong> Rápido pero puede divergir</li></ul><p>GridSearch explora ambos extremos.</p><p><strong>subsample &lt; 1.0:</strong> Stochastic Gradient Boosting. Solo usa 80-90% de datos en cada iteración, reduce overfitting.</p><p><strong>3. Ridge/Lasso: Alpha en Escala Logarítmica</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span></code></pre></div><p>Alpha controla regularización:</p><ul><li><strong>Alpha bajo (0.01):</strong> Casi sin regularización, modelo complejo</li><li><strong>Alpha alto (500):</strong> Regularización fuerte, modelo simple (coeficientes cercanos a 0)</li></ul><p>Escala logarítmica cubre el espacio de manera más uniforme que escala lineal.</p><p><strong>Lasso vs Ridge:</strong></p><ul><li><strong>Lasso (L1):</strong> Fuerza coeficientes a <strong>exactamente 0</strong> → feature selection automática</li><li><strong>Ridge (L2):</strong> Coeficientes pequeños pero <strong>no cero</strong> → mantiene todas las features</li></ul><p>Si Lasso gana, indica que algunas features son ruido.</p><p><strong>4. DecisionTree: Baseline de Comparación</strong></p><p>DecisionTree es el peor modelo (alto variance, overfit fácil), pero sirve para:</p><ul><li>Verificar que el pipeline funciona correctamente</li><li>Baseline de comparación: Si Ridge/Lasso no superan DecisionTree, algo está mal en feature engineering</li></ul><h4 id=la-función-de-entrenamiento-con-gridsearch>La Función de Entrenamiento con GridSearch<a hidden class=anchor aria-hidden=true href=#la-función-de-entrenamiento-con-gridsearch>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model_with_gridsearch</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>param_grid</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>y_train</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>Any</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=nb>float</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Train model with K-fold Cross-Validation via GridSearchCV.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>  <span class=c1># 5-fold cross-validation</span>
</span></span><span class=line><span class=cl>        <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;neg_mean_absolute_error&#39;</span><span class=p>,</span>  <span class=c1># CRÍTICO</span>
</span></span><span class=line><span class=cl>        <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># Paralelización</span>
</span></span><span class=line><span class=cl>        <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># Para detectar overfitting</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>training_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Extract cross-validation results</span>
</span></span><span class=line><span class=cl>    <span class=n>cv_metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mean_test_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=o>-</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;std_test_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;std_test_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mean_train_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=o>-</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_train_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;std_train_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;std_train_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>,</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=p>,</span> <span class=n>training_time</span><span class=p>,</span> <span class=n>cv_metrics</span>
</span></span></code></pre></div><h4 id=decisiones-críticas>Decisiones Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-críticas>#</a></h4><p><strong>1. Scoring: neg_mean_absolute_error</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;neg_mean_absolute_error&#39;</span>
</span></span></code></pre></div><p><strong>¿Por qué MAE y no RMSE o R²?</strong></p><ul><li><strong>MAE (Mean Absolute Error)</strong>: Penaliza errores linealmente</li><li><strong>RMSE</strong>: Penaliza errores cuadraticamente (errores grandes pesan mucho más)</li><li><strong>R²</strong>: Métrica relativa, difícil de interpretar en términos de negocio</li></ul><p>Para este problema:</p><ul><li>MAE = $15,000 → &ldquo;El modelo se equivoca $15k en promedio&rdquo;</li><li>R² = 0.85 → ¿Qué significa para el negocio?</li></ul><p><strong>neg_mean_absolute_error:</strong> GridSearchCV minimiza la métrica, pero MAE se debe minimizar, entonces usamos la negativa.</p><p><strong>2. Cross-Validation: 5 Folds</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>cv</span><span class=o>=</span><span class=mi>5</span>
</span></span></code></pre></div><p><strong>¿Por qué 5 y no 10?</strong></p><ul><li><p><strong>5-fold:</strong> Balance entre bias (sesgo) y variance (varianza)</p><ul><li>Cada fold tiene 80% training, 20% validation</li><li>Más rápido que 10-fold (2x menos fits)</li></ul></li><li><p><strong>10-fold:</strong> Menos bias pero más costo computacional</p><ul><li>Útil cuando tienes pocos datos (&lt;1000 samples)</li></ul></li></ul><p>Con 16,512 training samples, 5-fold es suficiente.</p><p><strong>3. return_train_score=True</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span>
</span></span></code></pre></div><p>Esto loggea el score en <strong>training set</strong> además de validation set. Permite detectar overfitting:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=n>cv_metrics</span><span class=p>[</span><span class=s1>&#39;mean_train_score&#39;</span><span class=p>]</span> <span class=o>&gt;&gt;</span> <span class=n>cv_metrics</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;WARNING: Model is overfitting!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Train MAE = $5k, Test MAE = $20k → Overfitting claro</span>
</span></span></code></pre></div><p><strong>4. n_jobs=-1: Paralelización</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span>
</span></span></code></pre></div><p>Usa todos los CPU cores disponibles. En una máquina con 8 cores, 180 combinaciones × 5 folds = 900 fits se distribuyen en paralelo.</p><p><strong>Sin paralelización:</strong> 900 fits × 2s/fit = 30 minutos
<strong>Con 8 cores:</strong> ~4 minutos</p><h4 id=métricas-de-evaluación-más-allá-de-mape>Métricas de Evaluación: Más Allá de MAPE<a hidden class=anchor aria-hidden=true href=#métricas-de-evaluación-más-allá-de-mape>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span> <span class=n>X_test</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>y_test</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Evalúa modelo con métricas business-focused.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y_true</span> <span class=o>=</span> <span class=n>y_test</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Traditional metrics</span>
</span></span><span class=line><span class=cl>    <span class=n>mae</span> <span class=o>=</span> <span class=n>mean_absolute_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Business-focused percentage error metrics</span>
</span></span><span class=line><span class=cl>    <span class=n>mape</span> <span class=o>=</span> <span class=n>mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>smape</span> <span class=o>=</span> <span class=n>symmetric_mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wmape</span> <span class=o>=</span> <span class=n>weighted_mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>median_ape</span> <span class=o>=</span> <span class=n>median_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Prediction accuracy at different thresholds</span>
</span></span><span class=line><span class=cl>    <span class=n>within_5pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>within_10pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>within_15pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mae&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>mae</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rmse&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>rmse</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>r2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>mape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;smape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>smape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>wmape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;median_ape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>median_ape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_5pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_5pct</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_10pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_10pct</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_15pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_15pct</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p><strong>Por Qué 4 Variantes de MAPE:</strong></p><p><strong>1. MAPE (Mean Absolute Percentage Error)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>((</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p><strong>Problema:</strong> Sesgado hacia valores bajos.</p><p>Si predices $500k en vez de $510k → error = 2%
Si predices $10k en vez de $11k → error = 9%</p><p>Ambos son $10k de error absoluto, pero MAPE penaliza más el segundo.</p><p><strong>2. SMAPE (Symmetric MAPE)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>smape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=p>((</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span><span class=p>)</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_pred</span><span class=p>))</span> <span class=o>/</span> <span class=mi>2</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Usa el promedio de <code>y_true</code> y <code>y_pred</code> en el denominador. Más simétrico:</p><ul><li>Overprediction y underprediction tienen peso similar</li><li>Rango: 0-200% (vs 0-∞% de MAPE)</li></ul><p><strong>3. wMAPE (Weighted MAPE)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wmape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>))</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Suma total de errores dividido por suma total de valores reales. No afectado por valores individuales extremos.</p><p><strong>Usado en Step 06 (Sweep)</strong> porque es más robusto que MAPE para datasets con varianza alta.</p><p><strong>4. Median APE</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>median_ape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>((</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Mediana en lugar de media. Robusto a outliers.</p><p>Si 95% de predicciones tienen &lt;5% error pero 5% tienen >50% error:</p><ul><li><strong>MAPE:</strong> ~7% (promedio incluye outliers)</li><li><strong>Median APE:</strong> ~4% (outliers no afectan la mediana)</li></ul><p><strong>Within-X% Metrics</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>within_5pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Porcentaje de predicciones con error &lt;5%</span>
</span></span></code></pre></div><p><strong>Business interpretation:</strong> &ldquo;El 75% de nuestras predicciones están dentro de ±10% del valor real.&rdquo;</p><p>Más interpretable para stakeholders que &ldquo;MAPE = 8.2%&rdquo;.</p><h4 id=output-del-step-05>Output del Step 05<a hidden class=anchor aria-hidden=true href=#output-del-step-05>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34; BEST MODEL: RandomForestRegressor&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Business Metrics (Test Set):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  MAPE (Mean APE): 8.23%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  SMAPE (Symmetric MAPE): 7.95%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  wMAPE (Weighted MAPE): 8.01%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Median APE: 6.45%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±5%: 45.2%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±10%: 72.8%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±15%: 85.3%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Traditional Metrics (Test Set):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  R²: 0.8654&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  RMSE: $48,234.12&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  MAE: $32,456.78&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Cross-Validation Results (5-fold):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Mean CV MAE: $33,125.45 (±$2,341.23)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Mean CV Train MAE: $28,934.56 (±$1,892.34)&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Best params guardados:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Estos params se usan como <strong>punto de partida</strong> para el Step 06 (Sweep exhaustivo).</p><hr><h3 id=lo-que-esta-estrategia-logra>Lo Que Esta Estrategia Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esta-estrategia-logra>#</a></h3><p><strong>Sin model selection:</strong></p><ul><li>&ldquo;Usé Random Forest porque lo usa todo el mundo&rdquo;</li><li>No tienes evidencia de que es mejor que Gradient Boosting</li></ul><p><strong>Con model selection:</strong></p><ul><li>&ldquo;Comparé 5 algoritmos con 5-fold CV. Random Forest logró MAPE=8.2% (vs GradientBoosting=8.9%, Ridge=12.3%). Aquí está la tabla comparativa en W&amp;B.&rdquo;</li><li><strong>Decisión respaldada por datos, no intuición.</strong></li></ul><hr><p><a name=testing></a></p><h2 id=11-testing-fixtures-mocking-y-coverage-real>11. Testing: Fixtures, Mocking y Coverage Real<a hidden class=anchor aria-hidden=true href=#11-testing-fixtures-mocking-y-coverage-real>#</a></h2><h3 id=por-qué-testear-ml-es-diferente>Por Qué Testear ML Es Diferente<a hidden class=anchor aria-hidden=true href=#por-qué-testear-ml-es-diferente>#</a></h3><p>Los tests en ML no son como tests en web apps. No puedes hacer:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_model_predicts_correct_value</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>load_model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>]])</span> <span class=o>==</span> <span class=mf>452600.0</span>  <span class=c1># ERROR: Esto es absurdo</span>
</span></span></code></pre></div><p>Los modelos ML son <strong>probabilísticos</strong>. La salida no es determinística en el sentido de software tradicional.</p><p><strong>Lo que SÍ puedes testear:</strong></p><ol><li><strong>Contratos de datos:</strong> Inputs/outputs tienen los tipos correctos</li><li><strong>Invariantes:</strong> Predicciones están en rango esperado</li><li><strong>Reproducibilidad:</strong> Mismo input → mismo output (con seed fijo)</li><li><strong>Pipeline integrity:</strong> Steps corren sin explotar</li><li><strong>Integración:</strong> Components se comunican correctamente</li></ol><h3 id=conftestpy-fixtures-compartidas>conftest.py: Fixtures Compartidas<a hidden class=anchor aria-hidden=true href=#conftestpy-fixtures-compartidas>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Common fixtures for pytest
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>google.cloud</span> <span class=kn>import</span> <span class=n>storage</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>unittest.mock</span> <span class=kn>import</span> <span class=n>MagicMock</span><span class=p>,</span> <span class=n>Mock</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sample_housing_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea datos sintéticos de vivienda.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;longitude&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>124</span><span class=p>,</span> <span class=o>-</span><span class=mi>114</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;latitude&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;housing_median_age&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>53</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;total_rooms&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>500</span><span class=p>,</span> <span class=mi>5000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;total_bedrooms&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;population&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>500</span><span class=p>,</span> <span class=mi>3000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;households&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;median_income&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;median_house_value&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>50000</span><span class=p>,</span> <span class=mi>500000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Agregar missing values a total_bedrooms</span>
</span></span><span class=line><span class=cl>    <span class=n>missing_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>n_samples</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>missing_indices</span><span class=p>,</span> <span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mock_gcs_client</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea mock de GCS client.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_client</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Bucket</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_blob</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Blob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span><span class=o>.</span><span class=n>exists</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span><span class=o>.</span><span class=n>blob</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=n>mock_blob</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_client</span><span class=o>.</span><span class=n>bucket</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=n>mock_bucket</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;client&#39;</span><span class=p>:</span> <span class=n>mock_client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;bucket&#39;</span><span class=p>:</span> <span class=n>mock_bucket</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;blob&#39;</span><span class=p>:</span> <span class=n>mock_blob</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mock_mlflow</span><span class=p>(</span><span class=n>monkeypatch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Mocks MLflow functions.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_metric</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_param</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_artifact</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_metric&#39;</span><span class=p>,</span> <span class=n>mock_log_metric</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_param&#39;</span><span class=p>,</span> <span class=n>mock_log_param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_artifact&#39;</span><span class=p>,</span> <span class=n>mock_log_artifact</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_metric&#39;</span><span class=p>:</span> <span class=n>mock_log_metric</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_param&#39;</span><span class=p>:</span> <span class=n>mock_log_param</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_artifact&#39;</span><span class=p>:</span> <span class=n>mock_log_artifact</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><h3 id=test-de-imputación-contratos-de-datos>Test de Imputación: Contratos de Datos<a hidden class=anchor aria-hidden=true href=#test-de-imputación-contratos-de-datos>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Tests para ImputationAnalyzer
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>imputation_analyzer</span> <span class=kn>import</span> <span class=n>ImputationAnalyzer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_imputation_analyzer_returns_dataframe</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que imputer retorna DataFrame con missing values rellenados.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>analyzer</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>,</span> <span class=n>target_column</span><span class=o>=</span><span class=s2>&#34;total_bedrooms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Comparar estrategias</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Assertions</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span>  <span class=c1># 4 estrategias</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>all</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>rmse</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=k>for</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Aplicar mejor imputer</span>
</span></span><span class=line><span class=cl>    <span class=n>df_imputed</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>apply_best_imputer</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que no quedan NaNs</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>df_imputed</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que el resto de columnas no cambió</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>df_imputed</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_imputation_analyzer_reproducibility</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que la imputación es reproducible con seed fijo.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df1</span> <span class=o>=</span> <span class=n>generate_sample_data</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>analyzer1</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results1</span> <span class=o>=</span> <span class=n>analyzer1</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df2</span> <span class=o>=</span> <span class=n>generate_sample_data</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>analyzer2</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results2</span> <span class=o>=</span> <span class=n>analyzer2</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Mismo input + mismo seed = mismo output</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>results1</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span> <span class=o>==</span> <span class=n>results2</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span>
</span></span></code></pre></div><h3 id=test-de-pipeline-completo-integration-test>Test de Pipeline Completo: Integration Test<a hidden class=anchor aria-hidden=true href=#test-de-pipeline-completo-integration-test>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Integration test del pipeline completo
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_pipeline_runs_end_to_end</span><span class=p>(</span><span class=n>tmp_path</span><span class=p>,</span> <span class=n>mock_gcs_client</span><span class=p>,</span> <span class=n>sample_housing_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que el pipeline corre de principio a fin sin explotar.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Setup: Guardar datos sintéticos</span>
</span></span><span class=line><span class=cl>    <span class=n>data_path</span> <span class=o>=</span> <span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;housing.parquet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>sample_housing_data</span><span class=o>.</span><span class=n>to_parquet</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 01: Download (mockeado)</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 02: Preprocessing</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>preprocessor</span> <span class=kn>import</span> <span class=n>DataPreprocessor</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>PreprocessingConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_input_path</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>data_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_output_path</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;processed.parquet&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket_name</span><span class=o>=</span><span class=s2>&#34;test-bucket&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>preprocessor</span> <span class=o>=</span> <span class=n>DataPreprocessor</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>preprocessor</span><span class=o>.</span><span class=n>run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>result</span><span class=o>.</span><span class=n>success</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>result</span><span class=o>.</span><span class=n>num_rows_output</span> <span class=o>&gt;</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 03: Feature Engineering</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que outputs existen</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=p>(</span><span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;processed.parquet&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=coverage-real>Coverage Real<a hidden class=anchor aria-hidden=true href=#coverage-real>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Ejecutar tests con coverage</span>
</span></span><span class=line><span class=cl>pytest tests/ --cov<span class=o>=</span>src --cov-report<span class=o>=</span>html --cov-report<span class=o>=</span>term-missing
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Output:</span>
</span></span><span class=line><span class=cl><span class=c1># ==================== test session starts ====================</span>
</span></span><span class=line><span class=cl><span class=c1># tests/test_imputation_analyzer.py ........    [80%]</span>
</span></span><span class=line><span class=cl><span class=c1># tests/test_feature_engineering.py ....       [100%]</span>
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl><span class=c1># ----------- coverage: 87% -----------</span>
</span></span><span class=line><span class=cl><span class=c1># src/data/02_preprocessing/imputation_analyzer.py   92%</span>
</span></span><span class=line><span class=cl><span class=c1># src/data/03_feature_engineering/feature_engineer.py   85%</span>
</span></span></code></pre></div><h3 id=lo-que-esto-logra-3>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra-3>#</a></h3><p><strong>Sin tests:</strong> &ldquo;Creo que funciona, corrí el notebook una vez y no explotó.&rdquo;</p><p><strong>Con tests:</strong> &ldquo;87% de coverage. Todos los components críticos están testeados. CI corre los tests en cada commit.&rdquo;</p><p>Los tests <strong>no garantizan que el modelo sea bueno</strong>, pero garantizan que el <strong>sistema que produce el modelo es confiable</strong>.</p><hr><p><a name=production-patterns></a></p><h2 id=12-patrones-de-producción-que-nadie-te-cuenta>12. Patrones de Producción Que Nadie Te Cuenta<a hidden class=anchor aria-hidden=true href=#12-patrones-de-producción-que-nadie-te-cuenta>#</a></h2><h3 id=el-problema-real-del-serving>El Problema Real del Serving<a hidden class=anchor aria-hidden=true href=#el-problema-real-del-serving>#</a></h3><p>Aquí está lo que ningún tutorial te dice: el 90% del esfuerzo en ML no es entrenar un modelo—es hacer que ese modelo sirva predicciones confiables 24/7 sin explotar.</p><p>Los cursos de ML terminan con <code>model.save('model.pkl')</code>. La realidad de producción empieza con preguntas como:</p><ul><li>¿Qué pasa si el modelo necesita un KMeans entrenado para generar features?</li><li>¿Guardas el KMeans también? ¿Y si pesa 500MB?</li><li>¿Cómo garantizas que el preprocesamiento en producción es EXACTAMENTE igual al de entrenamiento?</li><li>¿Y si la distribución de datos cambia y tu modelo empieza a fallar silenciosamente?</li></ul><p>Este pipeline implementa soluciones a estos problemas que rara vez se discuten. Vamos a diseccionarlas.</p><hr><h3 id=121-el-transform-pattern-el-truco-del-kmeans-sintético>12.1. El Transform Pattern: El Truco del KMeans Sintético<a hidden class=anchor aria-hidden=true href=#121-el-transform-pattern-el-truco-del-kmeans-sintético>#</a></h3><p><strong>Contexto:</strong> En el Step 03 (Feature Engineering), el pipeline entrena un KMeans con 10 clusters sobre latitud/longitud. El modelo final necesita <code>cluster_label</code> como feature.</p><p><strong>Problema clásico:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Durante training</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>  <span class=c1># Entrena en 16,000 samples de California</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cluster_label&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Entrenas el modelo</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ¿Ahora qué? ¿Cómo guardas el kmeans para usarlo en el API?</span>
</span></span></code></pre></div><p><strong>Solución naive (la que hace el 80% de la gente):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Guarda AMBOS modelos</span>
</span></span><span class=line><span class=cl><span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>kmeans</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;kmeans.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;model.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># En el API: Carga ambos</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s1>&#39;kmeans.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s1>&#39;model.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Para cada predicción:</span>
</span></span><span class=line><span class=cl><span class=n>cluster</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>([[</span><span class=n>lon</span><span class=p>,</span> <span class=n>lat</span><span class=p>]])</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=n>cluster</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>prediction</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué esto es terrible:</strong></p><ol><li><strong>Overhead de almacenamiento:</strong> KMeans serializado puede pesar 96KB por cada modelo. Multiplica eso por 50 versiones de modelo.</li><li><strong>Coupling:</strong> Ahora tu API necesita cargar DOS artifacts por cada versión de modelo. ¿Qué pasa si se desincronan?</li><li><strong>Latency:</strong> Llamar <code>kmeans.predict()</code> añade ~2ms por request.</li></ol><p><strong>La solución brillante que este proyecto implementa:</strong></p><p>Chip Huyen llama a esto el <strong>Transform Pattern</strong> en &ldquo;Designing Machine Learning Systems&rdquo; (Capítulo 7, sección sobre feature consistency): cuando el preprocesamiento es ligero y determinístico, <strong>recréalo en el serving layer en lugar de serializarlo</strong>.</p><p>Mira el código real en <code>api/app/core/preprocessor.py</code> (líneas 61-110):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_init_kmeans</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Initialize KMeans with California housing geographical clusters.
</span></span></span><span class=line><span class=cl><span class=s2>        Uses typical California housing coordinates to create clusters.
</span></span></span><span class=line><span class=cl><span class=s2>        This is an approximation but works for the API use case.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># California housing typical ranges:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Longitude: -124 to -114</span>
</span></span><span class=line><span class=cl>        <span class=c1># Latitude: 32 to 42</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>  <span class=c1># CRÍTICO: Mismo seed que en training</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Crea datos sintéticos representando geografía de California</span>
</span></span><span class=line><span class=cl>        <span class=n>n_samples</span> <span class=o>=</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl>        <span class=n>lon_samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>124</span><span class=p>,</span> <span class=o>-</span><span class=mi>114</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lat_samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Peso hacia centros poblacionales principales</span>
</span></span><span class=line><span class=cl>        <span class=n>major_centers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>118</span><span class=p>,</span> <span class=mi>34</span><span class=p>],</span>   <span class=c1># LA</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>122</span><span class=p>,</span> <span class=mf>37.5</span><span class=p>],</span> <span class=c1># SF</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>117</span><span class=p>,</span> <span class=mi>33</span><span class=p>],</span>   <span class=c1># San Diego</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>121</span><span class=p>,</span> <span class=mf>38.5</span><span class=p>],</span> <span class=c1># Sacramento</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>119</span><span class=p>,</span> <span class=mf>36.5</span><span class=p>],</span> <span class=c1># Fresno</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Añade centros principales múltiples veces para proper weighting</span>
</span></span><span class=line><span class=cl>        <span class=n>lon_samples</span><span class=p>[:</span><span class=mi>50</span><span class=p>]</span> <span class=o>=</span> <span class=n>major_centers</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lat_samples</span><span class=p>[:</span><span class=mi>50</span><span class=p>]</span> <span class=o>=</span> <span class=n>major_centers</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>X_geo</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>column_stack</span><span class=p>([</span><span class=n>lon_samples</span><span class=p>,</span> <span class=n>lat_samples</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Fit KMeans</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>  <span class=c1># MISMO seed que training</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>¿Qué está pasando aquí?</strong></p><p>En lugar de serializar el KMeans entrenado con 16,512 samples reales, el API <strong>recrea un KMeans sintético</strong> usando:</p><ol><li><strong>Datos sintéticos</strong> que aproximan la distribución geográfica de California</li><li><strong>Mismo seed (42)</strong> que se usó en training</li><li><strong>Mismo n_clusters (10)</strong></li><li><strong>Centros ponderados</strong> hacia ciudades principales (LA, SF, San Diego)</li></ol><p><strong>Trade-offs de esta solución:</strong></p><p><strong>Ventajas:</strong></p><ul><li>Zero overhead de almacenamiento (no guardas el KMeans)</li><li>Zero coupling (API es autónomo, no necesita artifacts adicionales)</li><li>Latency idéntica (~2ms de todas formas)</li><li>Stateless serving (puedes escalar el API horizontalmente sin state compartido)</li></ul><p><strong>Desventajas:</strong></p><ul><li><strong>Cluster drift:</strong> Los clusters sintéticos NO son exactamente los mismos que los de training<ul><li>En testing interno: ~2% de mismatch en cluster labels</li><li>En California Housing: impacto en MAPE &lt; 0.3%</li></ul></li><li>Requiere que el preprocesamiento sea <strong>determinístico y ligero</strong><ul><li>No funciona si tu KMeans necesita 1 millón de samples para converger</li><li>No funciona si tienes embeddings de texto de 512 dimensiones</li></ul></li></ul><p><strong>Cuándo usar este pattern:</strong></p><p><strong>SÍ úsalo si:</strong></p><ul><li>El preprocesamiento es ligero (&lt;10ms)</li><li>El feature es geográfico/categórico con pocos valores únicos</li><li>El impacto de ligera inconsistencia es tolerable (regresión, clasificación con margen)</li></ul><p><strong>NO lo uses si:</strong></p><ul><li>El feature es un embedding profundo (BERT, ResNet)</li><li>Necesitas 100% reproducibilidad bit-a-bit</li><li>El preprocesamiento requiere gigabytes de state</li></ul><p><strong>La lección:</strong></p><p>Chip Huyen lo resume así: &ldquo;The best feature engineering pipeline is the one that doesn&rsquo;t exist.&rdquo; Si puedes computar features on-the-fly sin cost prohibitivo, evita serializar state. Tu sistema será más simple, más robusto, y más fácil de debuggear.</p><p>Este truco del KMeans sintético es un ejemplo perfecto. <strong>No lo vas a encontrar en ningún tutorial de Kaggle.</strong></p><hr><h3 id=122-trainingserving-skew-el-asesino-silencioso>12.2. Training/Serving Skew: El Asesino Silencioso<a hidden class=anchor aria-hidden=true href=#122-trainingserving-skew-el-asesino-silencioso>#</a></h3><p>Huyen dedica una sección completa a esto en el Capítulo 7. El <strong>training/serving skew</strong> es cuando el preprocesamiento en training es diferente al de serving.</p><p><strong>Ejemplo clásico que mata proyectos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En tu notebook de training</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms_log&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log1p</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6 meses después, alguien implementa el API</span>
</span></span><span class=line><span class=cl><span class=c1># (sin leer el notebook completo)</span>
</span></span><span class=line><span class=cl><span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms_log&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>])</span>  <span class=c1># BUG: log vs log1p</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Resultado: El modelo falla silenciosamente</span>
</span></span><span class=line><span class=cl><span class=c1># MAPE en training: 8%</span>
</span></span><span class=line><span class=cl><span class=c1># MAPE en producción: 24%</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Por qué? Porque log(0) = -inf, log1p(0) = 0</span>
</span></span></code></pre></div><p><strong>Cómo este proyecto evita esto:</strong></p><p>El preprocesamiento está encapsulado en <strong>UNA sola clase</strong> que se usa BOTH en training y serving:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/data/02_preprocessing/preprocessor.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Imputación</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_impute</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># One-hot encoding</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Usado en training (Step 02)</span>
</span></span><span class=line><span class=cl><span class=n>preprocessor</span> <span class=o>=</span> <span class=n>DataPreprocessor</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_processed</span> <span class=o>=</span> <span class=n>preprocessor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>train_raw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MISMO código usado en API</span>
</span></span><span class=line><span class=cl><span class=c1># api/app/core/preprocessor.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>  <span class=c1># Mismo transform logic</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Mismo one-hot encoding</span>
</span></span><span class=line><span class=cl>        <span class=c1># Mismo order de columnas</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df</span>
</span></span></code></pre></div><p><strong>La garantía:</strong></p><p>Si cambias el preprocesamiento, <strong>ambos</strong> training y serving se actualizan porque es <strong>el mismo código</strong>.</p><p><strong>El anti-pattern:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training: notebook_v3_FINAL.ipynb</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;bedrooms_per_room&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API: Alguien copia/pega sin verificar</span>
</span></span><span class=line><span class=cl><span class=n>features</span><span class=p>[</span><span class=s1>&#39;bedrooms_per_room&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Qué pasa con división por cero?</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Qué pasa si total_rooms es 0?</span>
</span></span><span class=line><span class=cl><span class=c1># En training nunca pasó porque limpiaste outliers</span>
</span></span><span class=line><span class=cl><span class=c1># En producción... BOOM</span>
</span></span></code></pre></div><p><strong>El mantra:</strong></p><p>&ldquo;If you can&rsquo;t import it, you can&rsquo;t trust it.&rdquo; Si tu preprocesamiento está copy/pasted entre training y serving, <strong>ya perdiste</strong>.</p><hr><h3 id=123-data-drift-el-enemigo-que-este-proyecto-aún-no-monitorea>12.3. Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea<a hidden class=anchor aria-hidden=true href=#123-data-drift-el-enemigo-que-este-proyecto-aún-no-monitorea>#</a></h3><p>Ahora vamos a lo que <strong>NO</strong> está en este proyecto pero es crítico para sistemas en producción.</p><p><strong>Data drift</strong> (deriva de datos) es cuando la distribución de tus features en producción cambia con respecto a training.</p><p>Huyen lo cubre exhaustivamente en el Capítulo 8 (&ldquo;Data Distribution Shifts&rdquo;). Hay tres tipos:</p><p><strong>1. Covariate Shift (el más común):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training data (2020-2022)</span>
</span></span><span class=line><span class=cl><span class=c1># Distribución de median_income</span>
</span></span><span class=line><span class=cl><span class=n>P_train</span><span class=p>(</span><span class=n>median_income</span><span class=p>):</span> <span class=n>mean</span> <span class=o>=</span> <span class=err>$</span><span class=mf>6.2</span><span class=n>k</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=err>$</span><span class=mf>3.1</span><span class=n>k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Production data (2023-2024)</span>
</span></span><span class=line><span class=cl><span class=c1># Después de inflación + cambios económicos</span>
</span></span><span class=line><span class=cl><span class=n>P_prod</span><span class=p>(</span><span class=n>median_income</span><span class=p>):</span> <span class=n>mean</span> <span class=o>=</span> <span class=err>$</span><span class=mf>8.5</span><span class=n>k</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=err>$</span><span class=mf>4.2</span><span class=n>k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Resultado:</span>
</span></span><span class=line><span class=cl><span class=c1># - El modelo fue entrenado en features con mean=$6.2k</span>
</span></span><span class=line><span class=cl><span class=c1># - Ahora recibe features con mean=$8.5k</span>
</span></span><span class=line><span class=cl><span class=c1># - Las predicciones se vuelven imprecisas</span>
</span></span></code></pre></div><p><strong>2. Label Shift:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training: California 2020</span>
</span></span><span class=line><span class=cl><span class=c1># median_house_value promedio: $250k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Production: California 2024</span>
</span></span><span class=line><span class=cl><span class=c1># median_house_value promedio: $400k (boom inmobiliario)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># El modelo predice basándose en relaciones de 2020</span>
</span></span><span class=line><span class=cl><span class=c1># Pero los precios absolutos cambiaron</span>
</span></span></code></pre></div><p><strong>3. Concept Drift:</strong></p><p>La relación entre features y target cambia.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 2020: ocean_proximity=&#39;NEAR OCEAN&#39; → +$50k en precio</span>
</span></span><span class=line><span class=cl><span class=c1># 2024: Work-from-home → gente prefiere INLAND → -$20k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># El coeficiente del modelo para &#39;NEAR OCEAN&#39; es obsoleto</span>
</span></span></code></pre></div><p><strong>Cómo detectar drift (lo que este proyecto debería agregar):</strong></p><p><strong>Opción 1: Statistical Tests (Kolmogorov-Smirnov, Chi-Square)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>ks_2samp</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Compara distribución de training vs production</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>features</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ks_2samp</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>training_data</span><span class=p>[</span><span class=n>feature</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>production_data</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>alert</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;DRIFT DETECTED in </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>: p=</span><span class=si>{</span><span class=n>p_value</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Opción 2: Evidently AI (recomendado)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>evidently.report</span> <span class=kn>import</span> <span class=n>Report</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>evidently.metric_preset</span> <span class=kn>import</span> <span class=n>DataDriftPreset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>report</span> <span class=o>=</span> <span class=n>Report</span><span class=p>(</span><span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=n>DataDriftPreset</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>report</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>reference_data</span><span class=o>=</span><span class=n>train_df</span><span class=p>,</span>  <span class=c1># Training data</span>
</span></span><span class=line><span class=cl>    <span class=n>current_data</span><span class=o>=</span><span class=n>production_df</span>  <span class=c1># Últimas 1000 predictions</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Genera dashboard HTML con drift metrics</span>
</span></span><span class=line><span class=cl><span class=n>report</span><span class=o>.</span><span class=n>save_html</span><span class=p>(</span><span class=s2>&#34;drift_report.html&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Evidently calcula:</strong></p><ul><li><strong>Drift score</strong> por cada feature (0-1)</li><li><strong>Share of drifted features</strong> (% de features con drift)</li><li><strong>Dataset drift</strong> (si el dataset completo driftó)</li></ul><p><strong>Opción 3: Population Stability Index (PSI)</strong></p><p>Métrica usada en banca para detectar drift:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calculate_psi</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>actual</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &lt; 0.1: No significant drift
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &lt; 0.2: Moderate drift
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &gt;= 0.2: Significant drift (retrain needed)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>breakpoints</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>quantile</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>bins</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>expected_percents</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>expected</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>actual_percents</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>psi</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>actual_percents</span> <span class=o>-</span> <span class=n>expected_percents</span><span class=p>)</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>actual_percents</span> <span class=o>/</span> <span class=n>expected_percents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>psi</span>
</span></span></code></pre></div><p><strong>Cuándo agregar drift detection:</strong></p><p>Huyen recomienda esperar hasta que tengas <strong>suficiente tráfico de producción</strong> (~10,000 predictions).</p><p><strong>No lo agregues el Día 1</strong> porque:</p><ul><li>Necesitas baseline de &ldquo;distribución normal de producción&rdquo;</li><li>Falsos positivos al inicio (gente testeando el API con datos sintéticos)</li><li>Overhead de infraestructura (Evidently requiere DB para almacenar historiales)</li></ul><p><strong>Agrégalo cuando:</strong></p><ul><li>Tienes 10,000+ predictions en producción</li><li>Observas que MAPE en producción > MAPE en test set</li><li>El modelo tiene >6 meses en producción sin reentrenar</li></ul><p><strong>Ejemplo de alerting:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># W&amp;B logger extension (lo que agregarías a wandb_logger.py)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>WandBLogger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>log_drift_alert</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>feature_name</span><span class=p>,</span> <span class=n>psi_value</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>psi_value</span> <span class=o>&gt;</span> <span class=n>threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb</span><span class=o>.</span><span class=n>alert</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>title</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;DATA DRIFT: </span><span class=si>{</span><span class=n>feature_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>text</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;PSI=</span><span class=si>{</span><span class=n>psi_value</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> exceeds threshold </span><span class=si>{</span><span class=n>threshold</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>level</span><span class=o>=</span><span class=n>wandb</span><span class=o>.</span><span class=n>AlertLevel</span><span class=o>.</span><span class=n>WARN</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Log to metrics</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;drift/</span><span class=si>{</span><span class=n>feature_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>psi_value</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;drift/timestamp&#34;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span></code></pre></div><p><strong>El costo de NO monitorear drift:</strong></p><p>Sin drift detection, tu modelo <strong>falla silenciosamente</strong>. Nadie se da cuenta hasta que:</p><ul><li>Un cliente se queja: &ldquo;Sus predicciones están muy mal últimamente&rdquo;</li><li>Calculas MAPE retrospectivo y descubres que subió de 8% a 18%</li><li>Pasaron 3 meses sirviendo predicciones basura</li></ul><p>Con monitoring, detectas drift <strong>en días</strong>, no meses.</p><hr><h3 id=124-model-monitoring-más-allá-de-accuracy>12.4. Model Monitoring: Más Allá de Accuracy<a hidden class=anchor aria-hidden=true href=#124-model-monitoring-más-allá-de-accuracy>#</a></h3><p>El W&amp;B Logger de este proyecto (<code>api/app/core/wandb_logger.py</code>) loggea métricas básicas:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/count&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/mean&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;performance/response_time_ms&#34;</span><span class=p>:</span> <span class=n>response_time</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><p><strong>Esto es un buen comienzo, pero incompleto.</strong> En producción real, necesitas monitorear:</p><h4 id=1-business-metrics-lo-más-importante>1. Business Metrics (lo más importante)<a hidden class=anchor aria-hidden=true href=#1-business-metrics-lo-más-importante>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Cuántas predicciones están &#34;muy mal&#34;?</span>
</span></span><span class=line><span class=cl><span class=n>errors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span>
</span></span><span class=line><span class=cl><span class=n>within_10pct</span> <span class=o>=</span> <span class=p>(</span><span class=n>errors</span> <span class=o>&lt;</span> <span class=mf>0.10</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/predictions_within_10pct&#34;</span><span class=p>:</span> <span class=n>within_10pct</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/predictions_within_20pct&#34;</span><span class=p>:</span> <span class=p>(</span><span class=n>errors</span> <span class=o>&lt;</span> <span class=mf>0.20</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/mean_absolute_error_dollars&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Alert si la calidad cae</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>within_10pct</span> <span class=o>&lt;</span> <span class=mf>0.65</span><span class=p>:</span>  <span class=c1># Threshold del SLA</span>
</span></span><span class=line><span class=cl>    <span class=n>send_alert</span><span class=p>(</span><span class=s2>&#34;Model quality degraded: only </span><span class=si>{:.1%}</span><span class=s2> within 10%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>within_10pct</span><span class=p>))</span>
</span></span></code></pre></div><h4 id=2-prediction-distribution>2. Prediction Distribution<a hidden class=anchor aria-hidden=true href=#2-prediction-distribution>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Está el modelo prediciendo siempre el mismo valor?</span>
</span></span><span class=line><span class=cl><span class=c1># (señal de overfitting o modelo roto)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prediction_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>prediction_range</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/std&#34;</span><span class=p>:</span> <span class=n>prediction_std</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/range&#34;</span><span class=p>:</span> <span class=n>prediction_range</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/median&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Red flag: Si std es muy bajo</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>prediction_std</span> <span class=o>&lt;</span> <span class=mi>10000</span><span class=p>:</span>  <span class=c1># $10k</span>
</span></span><span class=line><span class=cl>    <span class=n>alert</span><span class=p>(</span><span class=s2>&#34;Model predictions have very low variance - model may be broken&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=3-input-feature-distribution>3. Input Feature Distribution<a hidden class=anchor aria-hidden=true href=#3-input-feature-distribution>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Estás recibiendo inputs fuera de training range?</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>NUMERIC_FEATURES</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>pred</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>prediction_batch</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/mean&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>feature_values</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/p95&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>feature_values</span><span class=p>,</span> <span class=mi>95</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/p05&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>feature_values</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Alert si hay outliers extremos</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>feature_values</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>TRAINING_MAX</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=o>*</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>alert</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Extreme outlier detected in </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=4-error-patterns>4. Error Patterns<a hidden class=anchor aria-hidden=true href=#4-error-patterns>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿El modelo falla consistentemente en ciertos segmentos?</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>errors_by_segment</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Por región geográfica</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ocean_prox</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;&lt;1H OCEAN&#39;</span><span class=p>,</span> <span class=s1>&#39;INLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;ISLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;NEAR BAY&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=n>mask</span> <span class=o>=</span> <span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=n>ocean_prox</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>errors_by_segment</span><span class=p>[</span><span class=n>ocean_prox</span><span class=p>]</span> <span class=o>=</span> <span class=n>mape</span><span class=p>(</span><span class=n>y_true</span><span class=p>[</span><span class=n>mask</span><span class=p>],</span> <span class=n>y_pred</span><span class=p>[</span><span class=n>mask</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span><span class=sa>f</span><span class=s2>&#34;error/mape_</span><span class=si>{</span><span class=n>seg</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>err</span> <span class=k>for</span> <span class=n>seg</span><span class=p>,</span> <span class=n>err</span> <span class=ow>in</span> <span class=n>errors_by_segment</span><span class=o>.</span><span class=n>items</span><span class=p>()})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Si ISLAND tiene MAPE = 40% pero otros tienen 8%, hay un problema</span>
</span></span></code></pre></div><h4 id=5-latency-percentiles>5. Latency Percentiles<a hidden class=anchor aria-hidden=true href=#5-latency-percentiles>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># El logger actual solo loggea mean response time</span>
</span></span><span class=line><span class=cl><span class=c1># Pero necesitas percentiles para detectar outliers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response_times</span> <span class=o>=</span> <span class=p>[</span><span class=o>...</span><span class=p>]</span>  <span class=c1># últimos 100 requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p50&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>50</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p95&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>95</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p99&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>99</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/max&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>response_times</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Alert si p99 excede threshold</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>99</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>200</span><span class=p>:</span>  <span class=c1># 200ms</span>
</span></span><span class=line><span class=cl>    <span class=n>alert</span><span class=p>(</span><span class=s2>&#34;API latency p99 exceeds 200ms&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Dashboard recomendado (W&amp;B o Grafana):</strong></p><pre tabindex=0><code>┌─────────────────────────────────────────────┐
│ MODEL HEALTH DASHBOARD                       │
├─────────────────────────────────────────────┤
│ PREDICTIONS (last 24h)                       │
│   Total:        12,453                       │
│   Within 10%:   68.2% [OK]                   │
│   Within 20%:   89.1%                        │
│   Mean MAPE:    9.8%  [WARN] (threshold: 10%)│
├─────────────────────────────────────────────┤
│ DRIFT DETECTION                              │
│   median_income:     PSI = 0.08 [OK]        │
│   total_rooms:       PSI = 0.15 [WARN]      │
│   ocean_proximity:   PSI = 0.32 [ALERT]     │
├─────────────────────────────────────────────┤
│ LATENCY                                      │
│   p50:   28ms                                │
│   p95:   67ms                                │
│   p99:   145ms [WARN]                        │
└─────────────────────────────────────────────┘
</code></pre><hr><h3 id=125-the-cascade-pattern-fallback-resilience>12.5. The Cascade Pattern: Fallback Resilience<a hidden class=anchor aria-hidden=true href=#125-the-cascade-pattern-fallback-resilience>#</a></h3><p>Este proyecto implementa un patrón de resiliencia brillante que Huyen discute en el Capítulo 6: el <strong>Cascade Pattern</strong> (fallback en cascada).</p><p>Mira el <code>ModelLoader</code> en <code>api/app/core/model_loader.py</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Any</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Load model with cascade fallback strategy.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 1: MLflow Registry (producción)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_mlflow</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load failed, trying GCS: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 2: GCS (staging)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_gcs</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GCS load failed, trying local: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 3: Local (desarrollo/fallback)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span> <span class=ow>and</span> <span class=n>Path</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_local</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;No model could be loaded from any source&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>¿Qué logra esto?</strong></p><p><strong>Resilience ante fallos:</strong></p><ul><li>MLflow server caído → API sigue funcionando con GCS</li><li>GCS quota exceeded → API usa modelo local</li><li>Zero downtime ante infraestructura degradada</li></ul><p><strong>Flexibilidad de deployment:</strong></p><ul><li><strong>Producción:</strong> Usa MLflow (versionamiento robusto)</li><li><strong>Staging:</strong> Usa GCS (más simple)</li><li><strong>Desarrollo local:</strong> Usa archivo local (sin credenciales)</li></ul><p><strong>Mismo código, tres ambientes:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Producción</span>
</span></span><span class=line><span class=cl>docker run -e <span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Production <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Staging</span>
</span></span><span class=line><span class=cl>docker run -e <span class=nv>GCS_BUCKET</span><span class=o>=</span>staging-bucket <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>GCS_MODEL_PATH</span><span class=o>=</span>models/v1.2.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Local development</span>
</span></span><span class=line><span class=cl>docker run -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/models:/app/models <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>LOCAL_MODEL_PATH</span><span class=o>=</span>/app/models/housing_price_model.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span></code></pre></div><p><strong>Lo que falta (y deberías agregar):</strong></p><h4 id=1-circuit-breaker-pattern>1. Circuit Breaker Pattern<a hidden class=anchor aria-hidden=true href=#1-circuit-breaker-pattern>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>circuitbreaker</span> <span class=kn>import</span> <span class=n>circuit</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@circuit</span><span class=p>(</span><span class=n>failure_threshold</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>recovery_timeout</span><span class=o>=</span><span class=mi>60</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_mlflow</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>,</span> <span class=n>stage</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Circuit breaker: Si MLflow falla 5 veces consecutivas,
</span></span></span><span class=line><span class=cl><span class=s2>    abre el circuito por 60 segundos y no intenta más llamadas.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tracking_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;models:/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Sin circuit breaker, si MLflow está caído, el API hace 1 request por cada predicción y espera timeout (5-10s). Con circuit breaker, detecta el fallo después de 5 intentos y stop llamando hasta que MLflow se recupere.</p><h4 id=2-retry-with-exponential-backoff>2. Retry with Exponential Backoff<a hidden class=anchor aria-hidden=true href=#2-retry-with-exponential-backoff>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tenacity</span> <span class=kn>import</span> <span class=n>retry</span><span class=p>,</span> <span class=n>stop_after_attempt</span><span class=p>,</span> <span class=n>wait_exponential</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@retry</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>stop</span><span class=o>=</span><span class=n>stop_after_attempt</span><span class=p>(</span><span class=mi>3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>wait</span><span class=o>=</span><span class=n>wait_exponential</span><span class=p>(</span><span class=n>multiplier</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=nb>min</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=nb>max</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_gcs</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bucket_name</span><span class=p>,</span> <span class=n>blob_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Retry con backoff exponencial:
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 1: inmediato
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 2: espera 2s
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 3: espera 4s
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>storage_client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>bucket</span> <span class=o>=</span> <span class=n>storage_client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=n>bucket_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>blob</span> <span class=o>=</span> <span class=n>bucket</span><span class=o>.</span><span class=n>blob</span><span class=p>(</span><span class=n>blob_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pickle</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>blob</span><span class=o>.</span><span class=n>download_as_bytes</span><span class=p>())</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> GCS puede tener fallos transitorios (rate limiting, network blips). Retry automático evita que un fallo momentáneo tumbe tu API.</p><h4 id=3-timeout-configuration>3. Timeout Configuration<a hidden class=anchor aria-hidden=true href=#3-timeout-configuration>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Actualmente no hay timeout configurado</span>
</span></span><span class=line><span class=cl><span class=c1># Si MLflow tarda 60s en responder, tu API espera 60s</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Mejor:</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_mlflow</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>,</span> <span class=n>stage</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Load model with timeout.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>signal</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>timeout_handler</span><span class=p>(</span><span class=n>signum</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>TimeoutError</span><span class=p>(</span><span class=s2>&#34;MLflow load exceeded timeout&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>signal</span><span class=o>.</span><span class=n>signal</span><span class=p>(</span><span class=n>signal</span><span class=o>.</span><span class=n>SIGALRM</span><span class=p>,</span> <span class=n>timeout_handler</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>signal</span><span class=o>.</span><span class=n>alarm</span><span class=p>(</span><span class=n>timeout</span><span class=p>)</span>  <span class=c1># 10 second timeout</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>signal</span><span class=o>.</span><span class=n>alarm</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Cancel alarm</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>TimeoutError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load timeout after </span><span class=si>{</span><span class=n>timeout</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Sin timeout, un MLflow server lento puede hacer que tu API tarde minutos en responder. Con timeout, fallas rápido y pruebas el siguiente fallback.</p><h4 id=4-health-check-endpoint>4. Health Check Endpoint<a hidden class=anchor aria-hidden=true href=#4-health-check-endpoint>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/routers/health.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@router.get</span><span class=p>(</span><span class=s2>&#34;/health/deep&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>deep_health_check</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Health check que verifica todas las dependencias.
</span></span></span><span class=line><span class=cl><span class=s2>    Kubernetes lo llama cada 30s para routing decisions.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>health</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;healthy&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_loaded&#34;</span><span class=p>:</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>is_loaded</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_version&#34;</span><span class=p>:</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>model_version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dependencies&#34;</span><span class=p>:</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check MLflow</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>(</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_TRACKING_URI</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>list_experiments</span><span class=p>(</span><span class=n>max_results</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;mlflow&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;mlflow&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;degraded: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;status&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;degraded&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check GCS</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>storage_client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket</span> <span class=o>=</span> <span class=n>storage_client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=n>settings</span><span class=o>.</span><span class=n>GCS_BUCKET</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket</span><span class=o>.</span><span class=n>exists</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;gcs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;gcs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;degraded: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>health</span>
</span></span></code></pre></div><p><strong>Output:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;degraded&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;model_loaded&#34;</span><span class=p>:</span> <span class=kc>true</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;model_version&#34;</span><span class=p>:</span> <span class=s2>&#34;models:/housing_price_model/Production&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;dependencies&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;mlflow&#34;</span><span class=p>:</span> <span class=s2>&#34;degraded: Connection timeout&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;gcs&#34;</span><span class=p>:</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Le dice a tu load balancer (Cloud Run, Kubernetes) si el API está healthy. Si MLflow está caído pero el modelo ya está cargado (cached), el API es &ldquo;degraded&rdquo; pero funcional.</p><hr><h3 id=126-feature-store-anti-pattern-cuándo-no-necesitas-uno>12.6. Feature Store Anti-Pattern: Cuándo NO Necesitas Uno<a hidden class=anchor aria-hidden=true href=#126-feature-store-anti-pattern-cuándo-no-necesitas-uno>#</a></h3><p>Huyen tiene una sección controvertida en el Capítulo 5: &ldquo;You might not need a feature store.&rdquo;</p><p>Los Feature Stores (Feast, Tecton, Databricks) son muy populares, pero son <strong>overkill</strong> para el 80% de proyectos.</p><p><strong>Cuándo SÍ necesitas un Feature Store:</strong></p><ol><li><p><strong>Reutilizas features entre múltiples modelos</strong></p><ul><li>Ejemplo: <code>customer_lifetime_value</code> se usa en 10 modelos diferentes</li><li>Sin feature store: Cada modelo recalcula el mismo feature (waste)</li><li>Con feature store: Calculas una vez, sirves muchas veces</li></ul></li><li><p><strong>Necesitas features con diferentes freshness</strong></p><ul><li>Batch features: Calculadas diariamente (credit score)</li><li>Real-time features: Calculadas por request (current location)</li><li>Feature store orquesta ambos</li></ul></li><li><p><strong>Training/Serving skew es crítico</strong></p><ul><li>El feature store garantiza que training y serving usan EXACTAMENTE la misma lógica</li></ul></li></ol><p><strong>Cuándo NO necesitas un Feature Store (como este proyecto):</strong></p><ol><li><p><strong>Todas las features se computan on-the-fly</strong></p><ul><li>Este proyecto: Features son directas (lat, lon, income, age)</li><li>El único feature computado es <code>cluster_label</code> (2ms de latency)</li><li>No hay agregaciones complejas tipo &ldquo;average income in last 30 days&rdquo;</li></ul></li><li><p><strong>Un solo modelo consume las features</strong></p><ul><li>No hay reutilización entre modelos</li><li>Feature store añadiría complejidad sin beneficio</li></ul></li><li><p><strong>Latency budget es generoso</strong></p><ul><li>Este API: &lt;50ms es OK</li><li>Si necesitaras &lt;5ms, pre-computar features valdría la pena</li></ul></li></ol><p><strong>El costo real de un Feature Store:</strong></p><ul><li><strong>Infraestructura:</strong> Redis/DynamoDB para serving, Spark para batch processing</li><li><strong>Costo:</strong> ~$500-2000/mes en AWS/GCP (según tráfico)</li><li><strong>Complejidad:</strong> Otro sistema que monitorear, debuggear, operar</li></ul><p><strong>Alternativa lightweight (lo que este proyecto hace):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Computa features on-the-fly en el API</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. One-hot encoding (instantáneo)</span>
</span></span><span class=line><span class=cl>        <span class=n>df_encoded</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. Clustering (2ms con KMeans pre-fitted)</span>
</span></span><span class=line><span class=cl>        <span class=n>clusters</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>df</span><span class=p>[[</span><span class=s1>&#39;longitude&#39;</span><span class=p>,</span> <span class=s1>&#39;latitude&#39;</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>df_encoded</span><span class=p>[</span><span class=s1>&#39;cluster_label&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>clusters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df_encoded</span>
</span></span></code></pre></div><p><strong>Total latency:</strong> ~3ms. No justifica un Feature Store.</p><p><strong>Cuándo reconsiderar:</strong></p><ul><li>Si agregas features tipo &ldquo;average house price in zipcode&rdquo; (requiere query a DB)</li><li>Si el preprocesamiento sube a >20ms</li><li>Si añades un segundo modelo que reutiliza 50%+ de features</li></ul><p>Hasta entonces, YAGNI (You Ain&rsquo;t Gonna Need It).</p><hr><h3 id=127-production-readiness-un-checklist-honesto>12.7. Production Readiness: Un Checklist Honesto<a hidden class=anchor aria-hidden=true href=#127-production-readiness-un-checklist-honesto>#</a></h3><p>Basándome en el análisis exhaustivo del código, aquí está el estado <strong>real</strong> de este proyecto:</p><h4 id=lo-que-este-proyecto-hace-muy-bien>Lo Que Este Proyecto Hace MUY BIEN<a hidden class=anchor aria-hidden=true href=#lo-que-este-proyecto-hace-muy-bien>#</a></h4><p><strong>Nivel 3/5 en MLOps Maturity (Production-Ready):</strong></p><ol><li><p><strong>Versionamiento completo</strong></p><ul><li>Modelos en MLflow Registry con metadata rica</li><li>Data artifacts en GCS con timestamps</li><li>Código en git con CI/CD</li><li>Config en YAML versionado</li></ul></li><li><p><strong>Reproducibilidad</strong></p><ul><li>Seeds fijos (random_state=42 en todos lados)</li><li>Dependencias pinned (requirements.txt)</li><li>Docker para environment consistency</li></ul></li><li><p><strong>Testing</strong></p><ul><li>87% code coverage</li><li>Unit tests con fixtures realistas</li><li>Integration tests end-to-end</li><li>Security scanning (Bandit, TruffleHog)</li></ul></li><li><p><strong>CI/CD</strong></p><ul><li>GitHub Actions con tests automatizados</li><li>Docker build en CI</li><li>Deployment a Cloud Run con health checks</li><li>Staging/Production separation</li></ul></li><li><p><strong>API Design</strong></p><ul><li>Pydantic validation en todos los endpoints</li><li>Cascade fallback (MLflow→GCS→Local)</li><li>Lifespan management (load model once, not per request)</li><li>Batch prediction support</li></ul></li><li><p><strong>Observability (Básica)</strong></p><ul><li>W&amp;B logging de predictions</li><li>Response time tracking</li><li>Structured logging</li></ul></li></ol><h4 id=lo-que-falta-y-cuándo-agregarlo>Lo Que Falta (Y Cuándo Agregarlo)<a hidden class=anchor aria-hidden=true href=#lo-que-falta-y-cuándo-agregarlo>#</a></h4><p><strong>Nivel 4/5 Features (Add When You Have 10k+ Daily Predictions):</strong></p><ol><li><p><strong>Data Drift Detection</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Alto (modelo falla silenciosamente)</li><li><strong>Costo de implementación:</strong> Medio (Evidently AI)</li><li><strong>Cuándo:</strong> Después de 3 meses en producción</li></ul></li><li><p><strong>Model Performance Tracking</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Alto (no sabes si el modelo degrada)</li><li><strong>Costo:</strong> Bajo (extender W&amp;B logger)</li><li><strong>Cuándo:</strong> Después de tener ground truth labels (1-2 meses)</li></ul></li><li><p><strong>Circuit Breakers</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Medio (mejor latency ante fallos)</li><li><strong>Costo:</strong> Bajo (librería <code>circuitbreaker</code>)</li><li><strong>Cuándo:</strong> Si ves fallos transitorios en MLflow/GCS</li></ul></li><li><p><strong>Advanced Monitoring Dashboards</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Medio (mejor debugging)</li><li><strong>Costo:</strong> Medio (Grafana + Prometheus)</li><li><strong>Cuándo:</strong> Cuando el equipo crece >5 personas</li></ul></li><li><p><strong>Canary Deployments</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Bajo (tienes rollback manual que funciona)</li><li><strong>Costo:</strong> Alto (requiere traffic splitting)</li><li><strong>Cuándo:</strong> Solo si deployeas >1x/semana</li></ul></li><li><p><strong>Feature Store</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Ninguno (features son lightweight)</li><li><strong>Costo:</strong> Alto ($500-2000/mes)</li><li><strong>Cuándo:</strong> Nunca, a menos que agregues features pesados</li></ul></li></ol><p><strong>Nivel 5/5 Features (Overkill Para Este Proyecto):</strong></p><ul><li>Multi-model orchestration (A/B testing)</li><li>Real-time retraining</li><li>Federated learning</li><li>AutoML pipeline</li></ul><h4 id=recomendaciones-priorizadas>Recomendaciones Priorizadas<a hidden class=anchor aria-hidden=true href=#recomendaciones-priorizadas>#</a></h4><p><strong>MES 1-3 (Estabilización):</strong></p><ol><li>Agrega endpoint <code>/health/deep</code> con dependency checks</li><li>Implementa retry con exponential backoff en GCS calls</li><li>Configura alerts en W&amp;B cuando MAPE > 12%</li></ol><p><strong>MES 4-6 (Monitoring):</strong></p><ol start=4><li>Implementa Evidently AI para data drift (PSI tracking)</li><li>Agrega prediction distribution monitoring</li><li>Configura automated retraining trigger cuando PSI > 0.2</li></ol><p><strong>MES 7-12 (Optimización):</strong></p><ol start=7><li>Implementa circuit breaker en MLflow calls</li><li>Agrega Redis para prediction caching (si latency es problema)</li><li>Configura Grafana dashboard para business metrics</li></ol><p><strong>NO Hagas (Hasta Que Escales 10x):</strong></p><ul><li>No implementes Feature Store</li><li>No agregues Kafka streaming</li><li>No uses Kubernetes (Cloud Run es suficiente)</li><li>No implementes multi-model serving (hasta tener caso de uso claro)</li></ul><hr><h3 id=128-la-diferencia-entre-funciona-y-funciona-en-producción>12.8. La Diferencia Entre &ldquo;Funciona&rdquo; y &ldquo;Funciona en Producción&rdquo;<a hidden class=anchor aria-hidden=true href=#128-la-diferencia-entre-funciona-y-funciona-en-producción>#</a></h3><p>Este proyecto está en el top 10% de proyectos de ML en términos de engineering practices. La mayoría de los modelos en producción tienen:</p><ul><li>Notebooks en lugar de scripts modulares</li><li>Modelos guardados como <code>model_v3_FINAL_FINAL.pkl</code></li><li>Zero tests</li><li>Manual deployment con <code>scp</code></li><li>No monitoring</li></ul><p>Este proyecto tiene:</p><ul><li>Código modular y testeable</li><li>MLflow Registry con versionamiento semántico</li><li>87% test coverage</li><li>Automated deployment con GitHub Actions</li><li>W&amp;B monitoring básico</li></ul><p><strong>El gap restante</strong> (drift detection, advanced monitoring, circuit breakers) es el gap entre &ldquo;producción estable&rdquo; y &ldquo;producción enterprise-grade&rdquo;.</p><p>Pero aquí está el secreto: <strong>ese gap solo importa cuando tienes usuarios reales y tráfico significativo.</strong></p><p>No optimices para problemas que aún no tienes. Este proyecto está listo para servir 100k predictions/mes sin sudar. Cuando llegues a 1M/mes, entonces agrega data drift detection. Cuando llegues a 10M/mes, entonces considera Kubernetes.</p><p>Como dice Huyen: <strong>&ldquo;The best ML system is the simplest one that meets your requirements.&rdquo;</strong></p><p>Este proyecto cumple ese principio perfectamente.</p><hr><p><a name=conclusiones></a></p><h2 id=14-conclusiones-mlops-como-disciplina-de-ingeniería>14. Conclusiones: MLOps Como Disciplina de Ingeniería<a hidden class=anchor aria-hidden=true href=#14-conclusiones-mlops-como-disciplina-de-ingeniería>#</a></h2><h3 id=lo-que-este-pipeline-implementa-y-por-qué-importa>Lo Que Este Pipeline Implementa (Y Por Qué Importa)<a hidden class=anchor aria-hidden=true href=#lo-que-este-pipeline-implementa-y-por-qué-importa>#</a></h3><p>Este no es un tutorial de scikit-learn. Es un <strong>sistema production-ready</strong> que implementa:</p><ol><li><strong>Versionamiento completo:</strong> Datos (GCS), código (git), modelos (MLflow), configuración (YAML)</li><li><strong>Reproducibilidad:</strong> Mismo código + mismo config + mismo seed = mismo modelo</li><li><strong>Observabilidad:</strong> Logs estructurados, métricas en W&amp;B, tracking en MLflow</li><li><strong>Testing:</strong> 87% coverage, unit tests, integration tests, security scanning</li><li><strong>CI/CD:</strong> GitHub Actions con deployment automatizado a Cloud Run</li><li><strong>Deployment:</strong> API REST con FastAPI, frontend con Streamlit, Docker Compose listo</li><li><strong>Decisiones respaldadas por datos:</strong> Cada elección (imputación, K clusters, hiperparámetros) tiene métricas cuantificables</li><li><strong>Patrones de producción:</strong> Transform pattern, cascade fallback, training/serving consistency</li></ol><h3 id=los-anti-patterns-que-evita-y-que-matan-proyectos>Los Anti-Patterns Que Evita (Y Que Matan Proyectos)<a hidden class=anchor aria-hidden=true href=#los-anti-patterns-que-evita-y-que-matan-proyectos>#</a></h3><p><strong>X Notebooks en producción:</strong> Todo es Python modular y testeable. Los notebooks son geniales para exploración, terribles para sistemas confiables.</p><p><strong>X Configuración hardcodeada:</strong> config.yaml versionado en git. Si cambias un parámetro, queda registrado con timestamp y autor.</p><p><strong>X &ldquo;Usé median porque sí&rdquo;:</strong> Comparó 4 estrategias de imputación con métricas cuantificables. La mejor estrategia (Iterative Imputer) ganó por 3.2% en RMSE.</p><p><strong>X Modelos como <code>final_v3_REAL_final.pkl</code>:</strong> MLflow Registry con versiones semánticas y metadata rica. Sabes exactamente qué hiperparámetros, qué datos, y qué métricas tiene cada versión.</p><p><strong>X &ldquo;No sé qué hiperparámetros usé hace 3 meses&rdquo;:</strong> Cada modelo registra 106 líneas de metadata. Incluye desde hyperparameters hasta distribución de errores por segmento.</p><p><strong>X Deployment manual con scp:</strong> Docker + GitHub Actions. Push a master → tests corren → si pasan, deploya a staging automáticamente. Producción requiere aprobación manual (como debe ser).</p><p><strong>X Training/Serving Skew:</strong> El preprocesamiento está en una clase compartida entre training y serving. Cambias el código una vez, ambos ambientes se actualizan.</p><h3 id=los-trade-offs-conscientes-porque-no-hay-soluciones-perfectas>Los Trade-Offs Conscientes (Porque No Hay Soluciones Perfectas)<a hidden class=anchor aria-hidden=true href=#los-trade-offs-conscientes-porque-no-hay-soluciones-perfectas>#</a></h3><p>Este proyecto toma decisiones deliberadas. Aquí están los trade-offs y cuándo reconsiderarlos:</p><p><strong>1. Cluster optimization independiente del modelo final:</strong></p><p>Optimiza KMeans con silhouette score en lugar de cross-validation del modelo completo. <strong>Más rápido pero menos riguroso.</strong> Reconsiderar si el clustering es el feature más importante de tu modelo.</p><p><strong>2. 60 sweep runs en W&amp;B:</strong></p><p>Suficiente para California Housing (dataset mediano, ~20k samples). <strong>Podrías necesitar 200+ runs</strong> en datasets complejos con muchas interacciones no lineales.</p><p><strong>3. Pipeline secuencial sin paralelización:</strong></p><p>Steps corren uno después del otro. Este pipeline tarda ~15 minutos end-to-end. Si tu pipeline tarda horas, usa Airflow/Prefect con tasks paralelos.</p><p><strong>4. MAPE como métrica primaria:</strong></p><p>Funciona para este dataset (precios entre $50k-$500k). <strong>No funciona</strong> si tienes valores cercanos a cero (división por cero) o si quieres penalizar errores grandes desproporcionadamente (usa RMSE).</p><p><strong>5. Data drift detection ausente:</strong></p><p>Como explica el Checklist de Producción (Sección 13.7), el drift monitoring debe agregarse <strong>después de 3-6 meses en producción</strong>, no el Día 1. Necesitas baseline de comportamiento normal primero.</p><p><strong>6. KMeans sintético en el API:</strong></p><p>El Transform Pattern (Sección 13.1) recrea clusters con ~2% de drift vs training. <strong>Impacto en MAPE: &lt;0.3%.</strong> Si necesitas 100% reproducibilidad bit-a-bit, serializa el KMeans real (costo: 96KB por versión de modelo).</p><h3 id=lo-que-falta-y-cuándo-agregarlo-1>Lo Que Falta (Y Cuándo Agregarlo)<a hidden class=anchor aria-hidden=true href=#lo-que-falta-y-cuándo-agregarlo-1>#</a></h3><p>Como detalla la Sección 13 (Patrones de Producción), este proyecto está en <strong>Nivel 3/5 de MLOps Maturity</strong>. Lo que falta:</p><p><strong>Mes 1-3 (Estabilización):</strong></p><ul><li>Deep health check endpoint con dependency status</li><li>Retry con exponential backoff en calls a GCS</li><li>Alerts automáticos en W&amp;B cuando MAPE > threshold</li></ul><p><strong>Mes 4-6 (Monitoring):</strong></p><ul><li>Evidently AI para data drift detection (PSI tracking)</li><li>Prediction distribution monitoring (detectar modelo roto)</li><li>Trigger automático de retraining cuando PSI > 0.2</li></ul><p><strong>Mes 7-12 (Optimización):</strong></p><ul><li>Circuit breaker en MLflow calls (evitar timeouts en cascada)</li><li>Redis para prediction caching (si latency &lt;10ms es crítica)</li><li>Grafana dashboards para business metrics</li></ul><p><strong>NO hagas (hasta que escales 10x):</strong></p><ul><li>Feature Store (features son lightweight, &lt;3ms)</li><li>Kafka streaming (Cloud Run con HTTP es suficiente)</li><li>Kubernetes (Cloud Run autoescala sin complejidad)</li><li>Multi-model A/B testing (hasta tener caso de uso claro)</li></ul><h3 id=la-verdad-incómoda-sobre-mlops>La Verdad Incómoda Sobre MLOps<a hidden class=anchor aria-hidden=true href=#la-verdad-incómoda-sobre-mlops>#</a></h3><p>El 90% de los modelos de ML nunca llegan a producción. De los que llegan, el 60% falla en los primeros 6 meses.</p><p><strong>¿Por qué?</strong></p><p>No es porque los modelos son malos. Es porque:</p><ul><li>El ingeniero que entrenó el modelo ya no está en la empresa</li><li>Nadie sabe qué hiperparámetros se usaron</li><li>El preprocesamiento en producción es diferente al de training</li><li>No hay tests, entonces cada cambio rompe algo</li><li>El deployment es manual, toma 3 horas y falla 1 de cada 3 veces</li><li>No hay monitoring, el modelo falla silenciosamente por meses</li></ul><p>Este proyecto evita todos esos problemas. <strong>No porque sea perfecto</strong>, sino porque implementa los principios básicos de ingeniería de software:</p><ul><li><strong>Versionamiento:</strong> De todo (datos, código, modelos, config)</li><li><strong>Testing:</strong> 87% coverage, CI en cada commit</li><li><strong>Reproducibilidad:</strong> Seeds fijos, ambientes Dockerizados</li><li><strong>Observabilidad:</strong> Logs, métricas, tracking</li><li><strong>Automatización:</strong> Deployment sin intervención humana</li></ul><h3 id=la-lección-más-importante>La Lección Más Importante<a hidden class=anchor aria-hidden=true href=#la-lección-más-importante>#</a></h3><p>Chip Huyen lo dice mejor que yo en &ldquo;Designing Machine Learning Systems&rdquo;:</p><blockquote><p>&ldquo;The best ML system is not the one with the highest accuracy. It&rsquo;s the one that&rsquo;s reliable, maintainable, and meets business requirements.&rdquo;</p></blockquote><p>Este proyecto no tiene el mejor modelo. Probablemente puedes mejorar MAPE de 8.2% a 7.5% con XGBoost tuneado a mano.</p><p><strong>Pero eso no importa.</strong></p><p>Lo que importa es que este sistema:</p><ul><li>Corre confiablemente 24/7</li><li>Se puede actualizar sin downtime</li><li>Tiene rollback automático si algo falla</li><li>Cualquier miembro del equipo puede entender y modificar el código</li><li>Loggea suficiente información para debuggear problemas</li><li>Cuesta &lt;$100/mes en GCP (hasta 1M predictions)</li></ul><p><strong>Ese 0.7% de mejora en MAPE no vale la pena si el sistema es imposible de mantener.</strong></p><h3 id=para-quién-es-este-post>Para Quién Es Este Post<a hidden class=anchor aria-hidden=true href=#para-quién-es-este-post>#</a></h3><p>Si eres:</p><ul><li><strong>Data Scientist</strong> tratando de llevar tu primer modelo a producción → Este es tu roadmap</li><li><strong>ML Engineer</strong> explicando por qué &ldquo;no puedes simplemente deployar el notebook&rdquo; → Manda este post</li><li><strong>Engineering Manager</strong> evaluando si tu equipo hace MLOps correctamente → Usa la Sección 13.7 como checklist</li><li><strong>Estudiante</strong> queriendo aprender MLOps más allá de tutoriales → Este es código real, no sintético</li></ul><h3 id=el-siguiente-paso>El Siguiente Paso<a hidden class=anchor aria-hidden=true href=#el-siguiente-paso>#</a></h3><p>Este post tiene 6,500+ líneas porque no quise simplificar. MLOps es complejo. Hay trade-offs en cada decisión.</p><p>Pero no dejes que la complejidad te paralice. <strong>Start simple, iterate, improve.</strong></p><ol><li><strong>Semana 1:</strong> Versionamiento básico (git + requirements.txt)</li><li><strong>Semana 2:</strong> Tests básicos (al menos smoke tests)</li><li><strong>Semana 3:</strong> Docker para deployment consistente</li><li><strong>Semana 4:</strong> CI básico (GitHub Actions corriendo tests)</li><li><strong>Mes 2:</strong> MLflow para model registry</li><li><strong>Mes 3:</strong> Monitoring básico (W&amp;B o Prometheus)</li></ol><p><strong>No necesitas implementar todo el día 1.</strong> Este proyecto tardó meses en llegar a este estado.</p><h3 id=la-última-palabra>La Última Palabra<a hidden class=anchor aria-hidden=true href=#la-última-palabra>#</a></h3><p><strong>Ser MLOps engineer no es solo entrenar modelos—es construir sistemas donde los modelos son una pieza más.</strong></p><p>Lo que separa un proyecto de investigación de un producto en producción es:</p><ul><li><strong>Orden:</strong> Cada cosa en su lugar (no &ldquo;funciona en mi máquina&rdquo;)</li><li><strong>Testing:</strong> Lo que no se prueba, se rompe (87% coverage no es accidente)</li><li><strong>Observabilidad:</strong> Si no puedes medirlo, no puedes mejorarlo (W&amp;B + MLflow)</li><li><strong>Reproducibilidad:</strong> Hoy y en 6 meses debe dar el mismo resultado (seeds fijos, Docker)</li><li><strong>Automatización:</strong> Los humanos son malos en tareas repetitivas (CI/CD)</li><li><strong>Humildad:</strong> Reconocer lo que falta y cuándo agregarlo (Sección 13.7)</li></ul><p>Este post no te enseña a ser mejor en machine learning.</p><p><strong>Te enseña a ser mejor en machine learning engineering.</strong></p><p>Y esa diferencia es la que separa modelos en notebooks de modelos en producción creando valor real.</p><hr><p>Si implementas aunque sea el 50% de lo que está en este post, tu pipeline estará en el top 10% de proyectos de ML en términos de engineering practices.</p><p>Si implementas el 80%, estarás listo para escalar a millones de predictions sin reestructurar todo.</p><p>El 100% es overkill para la mayoría de proyectos. Usa el Checklist de Producción (Sección 13.7) para priorizar qué necesitas y cuándo.</p><hr><h2 id=referencias-y-recursos>Referencias y Recursos<a hidden class=anchor aria-hidden=true href=#referencias-y-recursos>#</a></h2><p><strong>Libros fundamentales:</strong></p><ul><li>Géron, A. (2022). <em>Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow</em> (3rd ed.). O&rsquo;Reilly.<ul><li><strong>Capítulo 2:</strong> Base de este proyecto (California Housing dataset, feature engineering, model selection)</li><li>Enfoque en ML, este post agrega la infraestructura de producción</li></ul></li><li>Huyen, C. (2022). <em>Designing Machine Learning Systems</em>. O&rsquo;Reilly.<ul><li><strong>Capítulo 5:</strong> Feature stores y cuándo no necesitas uno</li><li><strong>Capítulo 6:</strong> Deployment patterns (Cascade, Circuit Breaker)</li><li><strong>Capítulo 7:</strong> Transform Pattern y Training/Serving Skew (Secciones 13.1 y 13.2 de este post)</li><li><strong>Capítulo 8:</strong> Data Distribution Shifts y drift detection (Sección 13.3)</li><li><strong>Libro completo:</strong> Si solo lees un libro sobre MLOps, que sea este</li></ul></li></ul><p><strong>Herramientas (con enlaces a docs):</strong></p><ul><li><a href=https://mlflow.org/>MLflow</a>: Model registry y experiment tracking</li><li><a href=https://wandb.ai/>Weights & Biases</a>: Sweep y visualización de experimentos</li><li><a href=https://hydra.cc/>Hydra</a>: Configuration management con composable configs</li><li><a href=https://fastapi.tiangolo.com/>FastAPI</a>: REST API framework con validación Pydantic</li><li><a href=https://streamlit.io/>Streamlit</a>: Frontend interactivo para ML apps</li><li><a href=https://cloud.google.com/storage>Google Cloud Storage</a>: Almacenamiento de artifacts</li><li><a href=https://evidentlyai.com/>Evidently AI</a>: Data drift detection (recomendado para producción)</li><li><a href=https://www.docker.com/>Docker</a>: Containerización y reproducibilidad</li></ul><p><strong>Repositorio completo:</strong></p><ul><li><a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch</a><ul><li><code>/api</code>: FastAPI con cascade fallback y Transform Pattern</li><li><code>/src</code>: Pipeline modular (01-07) con MLflow tracking</li><li><code>/tests</code>: 87% coverage con fixtures realistas</li><li><code>/.github/workflows</code>: CI/CD completo con security scanning</li></ul></li></ul><hr><p><strong>Autor:</strong> Carlos Daniel Jiménez
<strong>Email:</strong> <a href=mailto:danieljimenez88m@gmail.com>danieljimenez88m@gmail.com</a>
<strong>LinkedIn:</strong> <a href=https://linkedin.com/in/carlosdanieljimenez>linkedin.com/in/carlosdanieljimenez</a>
<strong>Fecha:</strong> Enero 2026
<strong>Licencia:</strong> MIT</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://carlosdanieljimenez.com/tags/mlops/>Mlops</a></li><li><a href=https://carlosdanieljimenez.com/tags/machine-learning/>Machine-Learning</a></li><li><a href=https://carlosdanieljimenez.com/tags/python/>Python</a></li><li><a href=https://carlosdanieljimenez.com/tags/gcp/>Gcp</a></li><li><a href=https://carlosdanieljimenez.com/tags/mlflow/>Mlflow</a></li><li><a href=https://carlosdanieljimenez.com/tags/wandb/>Wandb</a></li><li><a href=https://carlosdanieljimenez.com/tags/fastapi/>Fastapi</a></li><li><a href=https://carlosdanieljimenez.com/tags/docker/>Docker</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://carlosdanieljimenez.com/>The Probability Engine</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><div class=newsletter-cta><div class=newsletter-content><h3>📬 Did this help?</h3><p>I write about MLOps, Edge AI, and making models work outside the lab.
One email per month, max. No spam, no course pitches, just technical content.</p><form action=https://buttondown.com/api/emails/embed-subscribe/carlosjimenez88m method=post class=newsletter-form target=popupwindow onsubmit='window.open("https://buttondown.com/carlosjimenez88m","popupwindow")'><div class=form-group><input type=email name=email id=bd-email placeholder=your@email.com required aria-label="Email address">
<input type=submit value=Subscribe></div></form><p class=newsletter-stats>Join engineers building ML systems and Edge Computing infrastructure.</p></div></div><style>.newsletter-cta{margin:3rem auto 2rem;padding:2rem;max-width:650px;background:var(--entry);border:1px solid var(--border);border-radius:8px;text-align:center}.newsletter-content h3{margin:0 0 1rem;font-size:1.5rem;color:var(--primary)}.newsletter-content p{margin:0 0 1.5rem;color:var(--secondary);line-height:1.6}.newsletter-form{margin:1.5rem 0}.form-group{display:flex;gap:.5rem;max-width:500px;margin:0 auto;flex-wrap:wrap;justify-content:center}.newsletter-form input[type=email]{flex:1;min-width:250px;padding:.75rem 1rem;font-size:1rem;border:1px solid var(--border);border-radius:6px;background:var(--theme);color:var(--content);transition:border-color .2s ease}.newsletter-form input[type=email]:focus{outline:none;border-color:var(--primary);box-shadow:0 0 0 3px rgba(var(--primary-rgb),.1)}.newsletter-form input[type=submit]{padding:.75rem 2rem;font-size:1rem;font-weight:600;color:#fff;background:var(--primary);border:none;border-radius:6px;cursor:pointer;transition:opacity .2s ease}.newsletter-form input[type=submit]:hover{opacity:.9}.newsletter-stats{font-size:.875rem;color:var(--secondary);margin-top:1rem;font-style:italic}@media screen and (max-width:600px){.newsletter-cta{padding:1.5rem 1rem;margin:2rem .5rem 1rem}.newsletter-content h3{font-size:1.25rem}.form-group{flex-direction:column;width:100%}.newsletter-form input[type=email],.newsletter-form input[type=submit]{width:100%;min-width:100%}}</style><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>