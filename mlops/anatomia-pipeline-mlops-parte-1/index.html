<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación | The Probability Engine</title>
<meta name=keywords content="mlops,machine-learning,python,gcp,mlflow,wandb"><meta name=description content="Parte 1: Filosofía, arquitectura del proyecto y orquestación con Hydra + MLflow. Steps de preprocessing, feature engineering, hyperparameter tuning y model registry."><meta name=author content="Carlos Daniel Jiménez"><link rel=canonical href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-1/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=16x16 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=32x32 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=apple-touch-icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=mask-icon href=https://carlosdanieljimenez.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=icon type=image/png href=/img/icon.jpeg><link rel=apple-touch-icon href=/img/icon.jpeg><link rel="shortcut icon" href=/img/icon.jpeg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-1/"><meta property="og:site_name" content="The Probability Engine"><meta property="og:title" content="Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación"><meta property="og:description" content="Parte 1: Filosofía, arquitectura del proyecto y orquestación con Hydra + MLflow. Steps de preprocessing, feature engineering, hyperparameter tuning y model registry."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="mlops"><meta property="article:published_time" content="2026-01-13T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-13T00:00:00+00:00"><meta property="article:tag" content="Mlops"><meta property="article:tag" content="Machine-Learning"><meta property="article:tag" content="Python"><meta property="article:tag" content="Gcp"><meta property="article:tag" content="Mlflow"><meta property="article:tag" content="Wandb"><meta name=twitter:card content="summary"><meta name=twitter:title content="Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación"><meta name=twitter:description content="Parte 1: Filosofía, arquitectura del proyecto y orquestación con Hydra + MLflow. Steps de preprocessing, feature engineering, hyperparameter tuning y model registry."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"MLOps Guides","item":"https://carlosdanieljimenez.com/mlops/"},{"@type":"ListItem","position":2,"name":"Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación","item":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación","name":"Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación","description":"Parte 1: Filosofía, arquitectura del proyecto y orquestación con Hydra + MLflow. Steps de preprocessing, feature engineering, hyperparameter tuning y model registry.","keywords":["mlops","machine-learning","python","gcp","mlflow","wandb"],"articleBody":" Serie MLOps Completo: Parte 1 (actual) | Parte 2: Deployment → | Parte 3: Producción →\nAnatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción Por Qué Este Post No Es Otro Tutorial de Scikit-Learn La mayoría de los posts sobre MLOps te enseñan a entrenar un Random Forest en un notebook y te dicen “ahora ponlo en producción”. Este post asume que ya sabes entrenar modelos. Lo que probablemente no sabes es cómo construir un sistema donde:\nUn commit a GitHub dispara un pipeline completo de 7 steps Cada decisión de preprocesamiento está respaldada por métricas cuantificables Los modelos se versionan con metadata rica, no con nombres de archivo tipo model_final_v3_REAL.pkl El deployment no requiere SSH a un servidor para copiar un pickle Rollback de una versión defectuosa toma 30 segundos, no 3 horas de panic debugging Este post disecciona un pipeline real que implementa todo eso. No es teoría, es código que corre en producción. Basado en el capítulo 2 de “Hands-On Machine Learning” de Aurélien Géron, pero con la infraestructura que el libro no cubre.\nRepositorio completo: github\nTabla de Contenidos La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente Estructura del Proyecto: Arquitectura Que Escala Orquestación con Hydra + MLflow Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering Step 06: Hyperparameter Sweep - Optimización Bayesiana con W\u0026B Step 07: Model Registry - Versionamiento en MLflow CI/CD con GitHub Actions: Automatización del Pipeline Completo El Valor de MLOps: Por Qué Esto Importa W\u0026B vs MLflow: Por Qué Ambos, No Uno u Otro (#wandb-vs-mlflow) Docker y MLflow: Containerización del Ecosistema Completo Pipeline Container con MLflow Tracking API Container para Inference Streamlit Container para Frontend Docker Compose: Orquestación de los Tres Containers Arquitectura del API: FastAPI en Producción (#api-architecture) Estrategias de Selección de Modelos y Parámetros Model Selection: Comparación de 5 Algoritmos Parameter Grids y GridSearch Métricas de Evaluación: MAPE, SMAPE, wMAPE Testing: Fixtures, Mocking y Coverage Real Patrones de Producción Que Nadie Te Cuenta El Transform Pattern: El Truco del KMeans Sintético Training/Serving Skew: El Asesino Silencioso Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea Model Monitoring: Más Allá de Accuracy The Cascade Pattern: Fallback Resilience Feature Store Anti-Pattern: Cuándo NO Necesitas Uno Production Readiness: Un Checklist Honesto Conclusiones: MLOps Como Disciplina de Ingeniería 1. La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente El Problema Real del MLOps Ser un MLOps engineer tiene dos cosas importantes en su quehacer:\nPrimero, y lo que siento que es lo más importante: ser ordenado. Suena redundante, pero cada cosa debe ir en su lugar. Un notebook con 50 celdas ejecutadas en orden aleatorio no es un pipeline—es una bomba de tiempo. Cuando ese modelo necesita reentrenarse a las 3 AM porque el data drift disparó una alerta, ¿quién se acuerda del orden correcto de las celdas?\nSegundo: lo que no se prueba, no deja de ser un mock o un prototipo. Lejos de pensar en usar solamente patrones de diseño, el foco y lo que intentaré sembrar como idea central de este post es la usabilidad de los productos y ver esto como software design.\nEl Mindset Correcto Este proyecto trata Machine Learning como lo que realmente es: software con componentes probabilísticos. No es magia, es ingeniería. Y como ingeniería, necesita:\nVersionamiento: De datos, código, modelos y configuración Testing: Unit, integration y end-to-end Observabilidad: Logs, métricas y traces Reproducibilidad: Ejecutar hoy y en 6 meses debe dar el mismo resultado Deployment: Automatizado, no manual Referencia: Hands-On Machine Learning de Géron Este post se basa en el Capítulo 2 del libro de Géron, un clásico que todos deberíamos leer. Pero el libro se enfoca en el modelo—cómo entrenar un buen predictor. Este post se enfoca en el sistema alrededor del modelo—cómo hacer que ese predictor llegue a producción de manera confiable.\nLo que Géron enseña: Imputación de datos, feature engineering, selección de modelos, evaluación.\nLo que este post agrega: GCS para almacenamiento, W\u0026B para experimentación, MLflow para model registry, FastAPI para serving, Docker para deployment, GitHub Actions para CI/CD.\n2. Estructura del Proyecto: Arquitectura Que Escala El Árbol Completo (200+ Archivos) cap2-end_to_end/ ├── main.py # Orquestador Hydra + MLflow ├── config.yaml # Single source of truth ├── pyproject.toml # Dependencias con UV ├── Makefile # CLI para operaciones comunes ├── Dockerfile # Pipeline containerizado ├── docker-compose.yaml # API + Streamlit + MLflow ├── pytest.ini # Configuración de tests ├── .env.example # Template de secrets │ ├── src/ │ ├── data/ # Steps de procesamiento (01-04) │ │ ├── 01_download_data/ │ │ │ ├── main.py # Download desde URL → GCS │ │ │ ├── downloader.py # Lógica de descarga │ │ │ ├── models.py # Pydantic schemas │ │ │ ├── MLproject # Entry point MLflow │ │ │ └── conda.yaml # Dependencias aisladas │ │ │ │ │ ├── 02_preprocessing_and_imputation/ │ │ │ ├── main.py │ │ │ ├── preprocessor.py │ │ │ ├── imputation_analyzer.py # (crítico) Comparación de estrategias │ │ │ └── utils.py │ │ │ │ │ ├── 03_feature_engineering/ │ │ │ ├── main.py │ │ │ ├── feature_engineer.py # (crítico) KMeans clustering │ │ │ └── utils.py # Optimización n_clusters │ │ │ │ │ └── 04_segregation/ │ │ ├── main.py │ │ ├── segregator.py # Train/test split │ │ └── models.py │ │ │ ├── model/ # Steps de modelado (05-07) │ │ ├── 05_model_selection/ │ │ │ ├── main.py # Comparación de 5 algoritmos │ │ │ ├── model_selector.py # (crítico) GridSearch por modelo │ │ │ └── utils.py │ │ │ │ │ ├── 06_sweep/ │ │ │ ├── main.py # (crítico) W\u0026B Bayesian optimization │ │ │ ├── sweep_config.yaml # Espacio de búsqueda │ │ │ └── best_params.yaml # Output (generado) │ │ │ │ │ └── 07_registration/ │ │ ├── main.py # (crítico) Registro en MLflow │ │ └── configs/ │ │ └── model_config.yaml # Metadata (generado) │ │ │ └── utils/ │ └── colored_logger.py # Logging estructurado │ ├── api/ # FastAPI REST API │ ├── app/ │ │ ├── main.py # FastAPI + lifespan │ │ ├── core/ │ │ │ ├── config.py # Pydantic Settings │ │ │ ├── model_loader.py # Load desde MLflow/GCS/Local │ │ │ └── wandb_logger.py # Logging predicciones │ │ ├── models/ │ │ │ └── schemas.py # Request/Response schemas │ │ └── routers/ │ │ └── predict.py # POST /api/v1/predict │ ├── Dockerfile # Imagen del API (port 8080) │ └── requirements.txt │ ├── streamlit_app/ # Frontend interactivo │ ├── app.py # Aplicación Streamlit (450+ líneas) │ ├── Dockerfile # Imagen Streamlit (port 8501) │ └── requirements.txt │ ├── tests/ # Suite de tests │ ├── conftest.py # Fixtures compartidas │ ├── fixtures/ │ │ └── test_data_generator.py # Datos sintéticos │ ├── test_pipeline.py # Test de orquestación │ ├── test_downloader.py │ ├── test_preprocessor.py │ ├── test_imputation_analyzer.py # (crítico) Tests de imputación │ ├── test_feature_engineering.py │ ├── test_segregation.py │ └── test_integration_simple.py # End-to-end │ └── docs/ ├── API_ARCHITECTURE_POST.md ├── QUICKSTART_GUIDE.md └── TESTING_IMPROVEMENTS.md Los archivos marcados con (crítico) son los más críticos para entender la arquitectura.\nDecisiones Arquitectónicas Fundamentales 1. Separación src/data vs src/model Por qué: Los steps de datos (01-04) producen artifacts reutilizables—preprocesamiento, features, splits. Los steps de modelo (05-07) los consumen pero pueden reentrenarse sin reejecutar todo upstream.\nBeneficio: Si cambias hiperparámetros, reejecutas solo 06-07. Si cambias feature engineering, reejecutas 03-07. No re-descargas datos cada vez.\nCosto: Más verbosidad, más archivos. Pero en pipelines reales con múltiples data scientists, el aislamiento vale oro.\n2. MLproject + conda.yaml por Step Cada subdirectorio es un proyecto MLflow independiente:\n# src/data/02_preprocessing/MLproject name: preprocessing_and_imputation conda_env: conda.yaml entry_points: main: parameters: gcs_input_path: {type: string} gcs_output_path: {type: string} command: \"python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}\" Ventajas:\nDependencias aisladas (step 03 usa scikit-learn 1.3, step 06 podría usar 1.4) Ejecución independiente: mlflow run src/data/02_preprocessing Tracking granular: cada step es un run separado Desventaja: Overhead de archivos. Pero es el mismo overhead que tener microservicios—cada uno con su Dockerfile.\n3. api/ Como Proyecto Separado El API no está en src/api/. Es un proyecto hermano con su propio requirements.txt, Dockerfile y tests.\nRazón: El API se deploya independientemente del pipeline. No necesita pandas completo, scikit-learn full o W\u0026B client. Solo FastAPI, pydantic y el pickle del modelo.\nResultado: Imagen Docker de 200MB vs 1.5GB si incluyeras todo el pipeline.\n4. Tests en la Raíz Los tests prueban el sistema completo, no módulos aislados. test_integration_simple.py corre el pipeline end-to-end. No encaja conceptualmente en src/.\n5. Ausencia de notebooks/ Decisión deliberada. Los notebooks son excelentes para exploración, terribles para producción. Este proyecto prioriza reproducibilidad sobre iteración rápida.\nSi necesitas explorar, úsalos localmente pero no los comitees. Los notebooks en git son:\nDifíciles de revisar (diffs incomprensibles) Imposibles de testear Propensos a ejecutarse fuera de orden 3. Orquestación con Hydra + MLflow Por Qué No Scripts Bash Simples Ejecutar comandos Python secuenciales funciona para pipelines simples:\npython src/data/01_download_data/main.py python src/data/02_preprocessing/main.py python src/data/03_feature_engineering/main.py # ... Este enfoque falla cuando necesitas:\nEjecutar solo steps específicos (debugging) Cambiar parámetros sin editar código Versionar configuración junto al código Logs estructurados de qué corrió con qué params Rastrear dependencias entre steps Hydra + MLflow resuelve todos estos problemas.\nEl Orquestador: main.py \"\"\" MLOps Pipeline Orchestrator Ejecuta steps secuencialmente usando MLflow + Hydra \"\"\" import os import sys import mlflow import hydra from omegaconf import DictConfig from pathlib import Path import time def validate_environment_variables() -\u003e None: \"\"\"Fail fast si faltan secrets críticos.\"\"\" required_vars = { \"GCP_PROJECT_ID\": \"Google Cloud Project ID\", \"GCS_BUCKET_NAME\": \"GCS Bucket name\", \"WANDB_API_KEY\": \"Weights \u0026 Biases API Key\", } missing = [] for var, description in required_vars.items(): value = os.getenv(var) if not value or value in [\"your-project-id\", \"your-key\"]: missing.append(f\" ERROR: {var}: {description}\") if missing: print(\"\\n\" + \"=\"*70) print(\"ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES\") print(\"=\"*70) print(\"\\n\".join(missing)) print(\"\\nCreate .env file with:\") print(\" GCP_PROJECT_ID=your-project-id\") print(\" GCS_BUCKET_NAME=your-bucket\") print(\" WANDB_API_KEY=your-key\") sys.exit(1) def get_steps_to_execute(config: DictConfig) -\u003e list[str]: \"\"\"Convierte execute_steps de config a lista.\"\"\" steps = config['main']['execute_steps'] if isinstance(steps, str): return [s.strip() for s in steps.split(',')] return list(steps) def run_step(step_name: str, step_path: Path, entry_point: str, parameters: dict): \"\"\"Ejecuta un step como MLflow project.\"\"\" print(f\"\\n{'='*70}\") print(f\"EXECUTING: {step_name}\") print(f\"{'='*70}\") mlflow.run( uri=str(step_path), entry_point=entry_point, env_manager=\"local\", parameters=parameters ) @hydra.main(config_path='.', config_name=\"config\", version_base=\"1.3\") def go(config: DictConfig) -\u003e None: \"\"\"Entry point principal del pipeline.\"\"\" validate_environment_variables() mlflow.set_experiment(config['main']['experiment_name']) steps_to_execute = get_steps_to_execute(config) root_path = Path(__file__).parent start_time = time.time() try: # Step 01: Download Data if \"01_download_data\" in steps_to_execute: run_step( \"01 - Download Data\", root_path / \"src\" / \"data\" / \"01_download_data\", \"main\", { \"file_url\": config[\"download_data\"][\"file_url\"], \"gcs_output_path\": config[\"download_data\"][\"gcs_output_path\"], } ) # ... Steps 02-07 similar pattern ... elapsed = time.time() - start_time print(f\"\\nSUCCESS: PIPELINE COMPLETED ({elapsed:.1f}s)\") except Exception as e: print(f\"\\nERROR: PIPELINE FAILED: {e}\") raise if __name__ == \"__main__\": go() config.yaml: Single Source of Truth main: project_name: \"housing-mlops-gcp\" experiment_name: \"end_to_end_pipeline\" execute_steps: - \"01_download_data\" - \"02_preprocessing_and_imputation\" - \"03_feature_engineering\" - \"04_segregation\" - \"05_model_selection\" - \"06_sweep\" - \"07_registration\" download_data: file_url: \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\" gcs_output_path: \"data/01-raw/housing.parquet\" preprocessing: gcs_input_path: \"data/01-raw/housing.parquet\" gcs_output_path: \"data/02-processed/housing_processed.parquet\" imputation_strategy: \"auto\" # Comparará 4 estrategias feature_engineering: gcs_input_path: \"data/02-processed/housing_processed.parquet\" gcs_output_path: \"data/03-features/housing_features.parquet\" n_clusters: 10 optimize_hyperparams: true # Busca mejor K segregation: gcs_input_path: \"data/03-features/housing_features.parquet\" gcs_train_output_path: \"data/04-split/train/train.parquet\" gcs_test_output_path: \"data/04-split/test/test.parquet\" test_size: 0.2 target_column: \"median_house_value\" model_selection: gcs_train_path: \"data/04-split/train/train.parquet\" gcs_test_path: \"data/04-split/test/test.parquet\" sweep: sweep_count: 50 # 50 runs de Bayesian optimization metric_name: \"mape\" metric_goal: \"minimize\" registration: registered_model_name: \"housing_price_model\" model_stage: \"Staging\" # O \"Production\" Lo Que Este Código Hace Bien 1. Fail Fast con Validación de Environment\nAntes de gastar CPU, verifica que todas las secrets existen. El mensaje de error incluye instrucciones de cómo conseguir cada valor.\nERROR: MISSING REQUIRED ENVIRONMENT VARIABLES =============================================== ERROR: WANDB_API_KEY: Weights \u0026 Biases API Key Create .env file with: WANDB_API_KEY=your-key Esto ahorra frustración—especialmente para nuevos colaboradores.\n2. Ejecución Selectiva Sin Comentar Código\nCambias config.yaml:\nexecute_steps: [\"03_feature_engineering\", \"05_model_selection\"] Y solo esos steps corren. No editas Python, no comentas imports.\n3. Separación Entre Orchestration y Logic\nmain.py no sabe cómo descargar datos o entrenar modelos. Solo sabe cómo invocar scripts que lo hacen. Cada step puede desarrollarse/testearse independientemente.\n4. Logging Estructurado con Visual Hierarchy\nLos separadores (\"=\"*70) y emojis no son cosmética—en un pipeline que corre 2 horas, las secciones visuales permiten escanear rápido para encontrar qué step falló.\n4. Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos El Problema Real California Housing tiene ~1% de total_bedrooms faltantes. Opciones obvias:\nDrop rows → pierdes datos Fill con median → asumes distribución sin verificar Fill con KNN → asumes similitud en feature space Fill con IterativeImputer → asumes relaciones modelables Pregunta: ¿Cuál es mejor?\nRespuesta incorrecta: “KNN siempre funciona”\nRespuesta correcta: “Probé las 4, median tuvo RMSE de 0.8, KNN de 0.6, Iterative de 0.5. Uso Iterative porque minimiza error de reconstrucción. Aquí está el plot en W\u0026B.”\nimputation_analyzer.py: El Core \"\"\" Imputation Analyzer - Compara estrategias automáticamente Autor: Carlos Daniel Jiménez \"\"\" from dataclasses import dataclass from typing import Dict, Tuple import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer from sklearn.ensemble import RandomForestRegressor from sklearn.preprocessing import StandardScaler import matplotlib.pyplot as plt @dataclass class ImputationResult: \"\"\"Resultado de una estrategia de imputación.\"\"\" method_name: str rmse: float imputed_values: np.ndarray imputer: object class ImputationAnalyzer: \"\"\" Analiza y compara estrategias de imputación. Selecciona automáticamente la mejor basándose en RMSE. \"\"\" def __init__( self, df: pd.DataFrame, target_column: str = \"total_bedrooms\", test_size: float = 0.2, random_state: int = 42 ): self.df = df self.target_column = target_column self.test_size = test_size self.random_state = random_state self.results: Dict[str, ImputationResult] = {} self.best_method: str = None self.best_imputer: object = None def prepare_validation_set(self) -\u003e Tuple[pd.DataFrame, pd.DataFrame, pd.Series]: \"\"\" Crea validation set masked para comparar estrategias. Strategy: 1. Remove rows con target faltante (no podemos validar contra NaN) 2. Split en train/val 3. Maskear target en val set (simular missing values) 4. Guardar ground truth Returns: (train_set, val_set_missing, y_val_true) \"\"\" housing_numeric = self.df.select_dtypes(include=[np.number]) housing_known = housing_numeric.dropna(subset=[self.target_column]) train_set, val_set = train_test_split( housing_known, test_size=self.test_size, random_state=self.random_state ) # Maskear target en val val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan # Ground truth y_val_true = val_set[self.target_column].copy() return train_set, val_set_missing, y_val_true def evaluate_simple_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, strategy: str = \"median\" ) -\u003e ImputationResult: \"\"\"Evalúa SimpleImputer con strategy dada.\"\"\" imputer = SimpleImputer(strategy=strategy) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"Simple Imputer ({strategy})\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def evaluate_knn_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, n_neighbors: int = 5 ) -\u003e ImputationResult: \"\"\" Evalúa KNNImputer con scaling. CRÍTICO: KNN requiere features escaladas o explota con overflow. \"\"\" import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Scale data scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) val_scaled = scaler.transform(val_set_missing) # KNN imputation imputer = KNNImputer(n_neighbors=n_neighbors) imputer.fit(train_scaled) val_imputed_scaled = imputer.transform(val_scaled) # Inverse scale val_imputed = scaler.inverse_transform(val_imputed_scaled) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"KNN Imputer (k={n_neighbors})\", rmse=rmse, imputed_values=y_val_pred, imputer=(scaler, imputer) # Store tuple! ) def evaluate_iterative_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series ) -\u003e ImputationResult: \"\"\"Evalúa IterativeImputer con RandomForest estimator.\"\"\" estimator = RandomForestRegressor( n_jobs=-1, random_state=self.random_state ) imputer = IterativeImputer( estimator=estimator, random_state=self.random_state ) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=\"Iterative Imputer (RF)\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def compare_all_methods(self) -\u003e Dict[str, ImputationResult]: \"\"\"Compara todas las estrategias y selecciona la mejor.\"\"\" train_set, val_set_missing, y_val_true = self.prepare_validation_set() # Evaluar todos self.results['simple_median'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"median\" ) self.results['simple_mean'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"mean\" ) self.results['knn'] = self.evaluate_knn_imputer( train_set, val_set_missing, y_val_true, n_neighbors=5 ) self.results['iterative_rf'] = self.evaluate_iterative_imputer( train_set, val_set_missing, y_val_true ) # Seleccionar mejor best_key = min(self.results, key=lambda k: self.results[k].rmse) self.best_method = best_key self.best_imputer = self.results[best_key].imputer # Print summary print(\"\\n\" + \"=\"*70) print(\"IMPUTATION METHODS COMPARISON\") print(\"=\"*70) for key, result in sorted(self.results.items(), key=lambda x: x[1].rmse): status = \"[BEST]\" if key == best_key else \"\" print(f\" {result.method_name:30s} RMSE: {result.rmse:8.4f} {status}\") print(\"=\"*70) return self.results def apply_best_imputer(self, df: pd.DataFrame) -\u003e pd.DataFrame: \"\"\"Aplica el mejor imputer al dataset completo.\"\"\" if self.best_imputer is None: raise ValueError(\"Run compare_all_methods() first\") df_out = df.copy() numeric_df = df_out.select_dtypes(include=[np.number]) import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Check si es tuple (KNN con scaler) if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer numeric_scaled = scaler.transform(numeric_df) imputed_scaled = imputer.transform(numeric_scaled) imputed_array = scaler.inverse_transform(imputed_scaled) else: imputed_array = self.best_imputer.transform(numeric_df) target_col_idx = numeric_df.columns.get_loc(self.target_column) df_out[self.target_column] = imputed_array[:, target_col_idx] return df_out def create_comparison_plot(self) -\u003e plt.Figure: \"\"\"Crea bar plot comparando RMSE de métodos.\"\"\" methods = [r.method_name for r in self.results.values()] rmses = [r.rmse for r in self.results.values()] fig, ax = plt.subplots(figsize=(10, 6)) colors = ['green' if i == np.argmin(rmses) else 'skyblue' for i in range(len(rmses))] bars = ax.bar(methods, rmses, color=colors) ax.set_xlabel('Imputation Method', fontweight='bold') ax.set_ylabel('RMSE', fontweight='bold') ax.set_title('Comparison of Imputation Strategies', fontsize=14) ax.grid(axis='y', alpha=0.3) # Value labels for bar, rmse in zip(bars, rmses): height = bar.get_height() ax.text( bar.get_x() + bar.get_width()/2., height, f'{rmse:.4f}', ha='center', va='bottom' ) plt.xticks(rotation=45, ha='right') plt.tight_layout() return fig Decisiones Técnicas Críticas 1. La Métrica: RMSE de Reconstrucción ¿Por qué RMSE y no MAE?\nMAE trata todos los errores igual. RMSE penaliza errores grandes más fuertemente.\nSi un método imputa 100 bedrooms cuando la verdad es 3, eso es problemático. RMSE lo castiga más que MAE. En imputación, errores grandes distorsionan el dataset más que muchos errores pequeños.\n2. El Validation Set Masked train_set, val_set = train_test_split(housing_known, test_size=0.2) val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan y_val_true = val_set[self.target_column].copy() Este trick es crítico. No puedes evaluar imputation strategies en los missing values reales—no sabes la verdad. Entonces:\nTomas filas donde el target NO falta Splits en train/val Artificialmente maskeas el target en val Comparas qué tan bien cada imputer reconstruye los valores que conocías Es validación cruzada para preprocesamiento, no solo para modelos.\n3. Por Qué KNN Necesita Scaling scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) KNN calcula distancias euclidianas entre observaciones. Si una feature está en rango [0, 1] y otra en [0, 10000], la segunda domina completamente.\nStandardScaler normaliza todo a media 0, std 1. Ahora todas las features contribuyen equitativamente.\nIterativeImputer con RandomForest NO necesita scaling—los árboles son invariantes a escala.\n4. El Imputer Como Tuple if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer # ... apply both Si KNN ganó, necesitas guardar tanto el scaler como el imputer. En producción, cuando llegan datos nuevos:\nEscalar con el mismo scaler fitted en training Aplicar KNN imputer Inverse transform para volver a escala original Guardar solo el imputer sin el scaler rompería todo.\nUso en el Pipeline # En main.py del Step 02 import wandb import mlflow analyzer = ImputationAnalyzer(df, target_column=\"total_bedrooms\") results = analyzer.compare_all_methods() # Log a W\u0026B comparison_plot = analyzer.create_comparison_plot() wandb.log({ \"imputation/comparison\": wandb.Image(comparison_plot), \"imputation/best_method\": analyzer.best_method, \"imputation/best_rmse\": results[analyzer.best_method].rmse, }) # Aplicar al dataset completo housing_clean = analyzer.apply_best_imputer(housing_df) # Guardar imputer import joblib joblib.dump(analyzer.best_imputer, \"artifacts/imputer.pkl\") mlflow.log_artifact(\"artifacts/imputer.pkl\") Lo Que Esto Logra Sin esto: “Usé median porque es lo que hace todo el mundo.”\nCon esto: “Comparé 4 estrategias. IterativeImputer con RandomForest tuvo 15% menor RMSE que median. Aquí está el plot en W\u0026B dashboard run abc123. El imputer está serializado en MLflow.”\nAhora tienes evidencia cuantificable de por qué elegiste lo que elegiste. Seis meses después, cuando alguien pregunta, los datos están ahí.\n5. Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering El Problema Real California tiene patrones geográficos fuertes. Casas en San Francisco se comportan diferente que casas en el valle central. Pero latitude/longitude como features crudas no capturan esto bien—un modelo lineal no puede aprender “esta área es cara”.\nSolución: Clustering geográfico. Pero no para segmentar datos, sino para crear una feature categórica: cluster_label.\nClusterSimilarity: Custom Transformer from sklearn.base import BaseEstimator, TransformerMixin from sklearn.cluster import KMeans import numpy as np class ClusterSimilarity(BaseEstimator, TransformerMixin): \"\"\" Custom transformer para clustering geográfico. Design: Transformer de scikit-learn para integrarse en Pipeline. \"\"\" def __init__(self, n_clusters=10, gamma=1.0, random_state=None): self.n_clusters = n_clusters self.gamma = gamma # Placeholder para RBF kernel (no usado actualmente) self.random_state = random_state def fit(self, X, y=None, sample_weight=None): \"\"\"Fit KMeans en coordenadas geográficas.\"\"\" self.kmeans_ = KMeans( self.n_clusters, n_init=10, random_state=self.random_state ) self.kmeans_.fit(X, sample_weight=sample_weight) return self def transform(self, X): \"\"\"Transforma coordenadas a cluster labels.\"\"\" cluster_labels = self.kmeans_.predict(X) return np.expand_dims(cluster_labels, axis=1) def get_feature_names_out(self, names=None): \"\"\"Retorna nombres de features para Pipeline.\"\"\" return [\"cluster_label\"] El Pipeline de Preprocessing Completo from sklearn.pipeline import Pipeline from sklearn.compose import ColumnTransformer from sklearn.impute import SimpleImputer from sklearn.preprocessing import OneHotEncoder, StandardScaler def create_preprocessing_pipeline(n_clusters=10): \"\"\" Crea pipeline que procesa: - Numéricas: impute + scale - Categóricas: impute + one-hot - Geo: clustering \"\"\" num_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"median\")), (\"standardize\", StandardScaler()), ]) cat_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")), ]) num_attribs = [ \"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\" ] cat_attribs = [\"ocean_proximity\"] preprocessing = ColumnTransformer([ (\"num\", num_pipeline, num_attribs), (\"cat\", cat_pipeline, cat_attribs), (\"geo\", ClusterSimilarity(n_clusters=n_clusters), [\"latitude\", \"longitude\"]), ]) return preprocessing Optimización Automática de n_clusters from sklearn.metrics import silhouette_score, davies_bouldin_score def optimize_n_clusters( df: pd.DataFrame, min_clusters=2, max_clusters=20 ) -\u003e Tuple[int, Dict]: \"\"\" Busca el mejor K para KMeans usando silhouette score. Métricas: - Silhouette score (0 a 1): Separación de clusters. Maximizar. - Davies-Bouldin index: Dispersión interna vs separación. Minimizar. \"\"\" geo_features = df[[\"latitude\", \"longitude\"]].values cluster_range = range(min_clusters, max_clusters + 1) silhouette_scores = [] davies_bouldin_scores = [] inertias = [] for n in cluster_range: kmeans = KMeans(n_clusters=n, n_init=10, random_state=42) labels = kmeans.fit_predict(geo_features) silhouette_scores.append(silhouette_score(geo_features, labels)) davies_bouldin_scores.append(davies_bouldin_score(geo_features, labels)) inertias.append(kmeans.inertia_) # Seleccionar K con mejor silhouette optimal_n = cluster_range[np.argmax(silhouette_scores)] metrics = { \"optimal_n_clusters\": optimal_n, \"best_silhouette\": max(silhouette_scores), \"cluster_range\": list(cluster_range), \"silhouette_scores\": silhouette_scores, \"davies_bouldin_scores\": davies_bouldin_scores, \"inertias\": inertias, } return optimal_n, metrics Visualización: Elbow Method + Silhouette def create_optimization_plots(metrics: Dict) -\u003e Dict[str, plt.Figure]: \"\"\"Crea plots de optimización de K.\"\"\" # Plot 1: Elbow Method (Inertia) fig1, ax1 = plt.subplots(figsize=(10, 6)) ax1.plot(metrics[\"cluster_range\"], metrics[\"inertias\"], 'bo-') ax1.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--', label=f'Optimal K={metrics[\"optimal_n_clusters\"]}' ) ax1.set_xlabel('Number of Clusters (K)') ax1.set_ylabel('Inertia') ax1.set_title('Elbow Method - KMeans Optimization') ax1.legend() ax1.grid(True) # Plot 2: Silhouette Score fig2, ax2 = plt.subplots(figsize=(10, 6)) ax2.plot(metrics[\"cluster_range\"], metrics[\"silhouette_scores\"], 'go-') ax2.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--' ) ax2.set_xlabel('Number of Clusters (K)') ax2.set_ylabel('Silhouette Score') ax2.set_title('Silhouette Score vs K') ax2.grid(True) return {\"elbow_method\": fig1, \"silhouette_scores\": fig2} Uso en el Pipeline # En main.py del Step 03 import wandb import mlflow import joblib # Descargar datos desde GCS df = download_from_gcs(bucket, \"data/02-processed/housing_processed.parquet\") # Optimizar K optimal_k, metrics = optimize_n_clusters(df, min_clusters=5, max_clusters=15) print(f\"Optimal K: {optimal_k}\") print(f\" Silhouette: {metrics['best_silhouette']:.4f}\") # Crear plots plots = create_optimization_plots(metrics) # Log a W\u0026B wandb.log({ \"optimization/optimal_k\": optimal_k, \"optimization/silhouette\": metrics[\"best_silhouette\"], \"optimization/elbow_plot\": wandb.Image(plots[\"elbow_method\"]), \"optimization/silhouette_plot\": wandb.Image(plots[\"silhouette_scores\"]), }) # Crear pipeline con K óptimo preprocessing_pipeline = create_preprocessing_pipeline(n_clusters=optimal_k) # Fit pipeline target_column = \"median_house_value\" y = df[target_column] X = df.drop(columns=[target_column]) preprocessing_pipeline.fit(X, y) # Transform data X_transformed = preprocessing_pipeline.transform(X) # Reconstruir DataFrame con target df_transformed = pd.DataFrame( X_transformed, columns=preprocessing_pipeline.get_feature_names_out() ) df_transformed[target_column] = y.values # Upload a GCS upload_to_gcs(df_transformed, bucket, \"data/03-features/housing_features.parquet\") # Guardar pipeline joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") mlflow.log_artifact(\"artifacts/preprocessing_pipeline.pkl\") Decisiones Técnicas Críticas 1. Por Qué Silhouette Score Silhouette score (rango 0 a 1) mide qué tan bien separados están los clusters:\n1.0: Clusters perfectamente separados 0.5: Overlap moderado 0.0: Clusters aleatorios Es interpretable y generalmente correlaciona bien con calidad visual de clusters.\nDavies-Bouldin index: También lo calculamos pero no lo usamos para decisión—es más sensible a outliers.\n2. La Crítica Obvia Este código optimiza n_clusters basándose en métricas de clustering, no en performance del modelo final.\nUn approach más riguroso sería:\nfor k in range(5, 15): pipeline = create_preprocessing_pipeline(n_clusters=k) X_train_transformed = pipeline.fit_transform(X_train, y_train) X_test_transformed = pipeline.transform(X_test) model = RandomForestRegressor() model.fit(X_train_transformed, y_train) mape = calculate_mape(model, X_test_transformed, y_test) # Seleccionar K con mejor MAPE Esto tomaría 10x más tiempo pero sería más riguroso.\nTrade-off: Este pipeline prioriza velocidad sobre rigor absoluto. Para California Housing, silhouette score es suficientemente bueno. Para datasets más complejos, considera el approach de cross-validation completo.\n3. handle_unknown=“ignore” en OneHotEncoder OneHotEncoder(handle_unknown=\"ignore\") Crítico para producción. Si en training tienes categorías [\"\u003c1H OCEAN\", \"INLAND\", \"NEAR BAY\"] pero en producción llega \"ISLAND\" (que no viste), el encoder:\nSin handle_unknown: Explota con ValueError Con handle_unknown=\"ignore\": Genera vector de ceros para esa observación Pierdes información de esa observación, pero el API no devuelve HTTP 500.\n4. Por Qué Guardar el Pipeline, No Solo el Modelo joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") En producción, necesitas:\nCargar el pipeline Transform datos nuevos Predecir con el modelo Si solo guardas el modelo, no sabes:\nQué features espera En qué orden Qué transformaciones aplicar El pipeline encapsula todo eso.\nLo Que Esto Logra Sin esto: “Usé KMeans con K=10 porque leí que 10 clusters es bueno.”\nCon esto: “Probé K de 5 a 15. K=8 maximizó silhouette score (0.64). Aquí están los plots de elbow method y silhouette. El pipeline con K=8 está serializado en MLflow.”\nEvidencia cuantificable + artifact reproducible.\n6. Step 06: Hyperparameter Sweep - Optimización Bayesiana con W\u0026B El Problema de Model Selection vs Hyperparameter Tuning La mayoría de los proyectos de ML cometen este error: entrenan un Random Forest en un notebook, ajustan algunos hiperparámetros hasta que R² se ve “bien” y declaran victoria. Tres meses después, cuando alguien pregunta “¿por qué Random Forest y no XGBoost?”, la respuesta es silencio incómodo.\nEste pipeline separa dos fases:\nModel Selection (Step 05): Compara algoritmos con GridSearch rápido (5-10 combos por modelo) Hyperparameter Sweep (Step 06): Optimiza el ganador con Bayesian search exhaustivo (50+ runs) Razón: No tienes tiempo ni cómputo para hacer sweep exhaustivo de 5 algoritmos. Primero decides estrategia (qué algoritmo), luego tácticas (qué hiperparámetros).\nsweep_config.yaml: El Espacio de Búsqueda # ================================================================= # W\u0026B Sweep Configuration for Random Forest # Autor: Carlos Daniel Jiménez # ================================================================= program: main.py method: bayes # Bayesian optimization, no random, no grid metric: name: wmape # Weighted MAPE (menos sesgado que MAPE) goal: minimize parameters: n_estimators: min: 50 max: 500 max_depth: min: 5 max: 30 min_samples_split: min: 2 max: 20 min_samples_leaf: min: 1 max: 10 max_features: values: ['sqrt', 'log2'] # Early stopping: elimina runs pobres temprano early_terminate: type: hyperband min_iter: 10 # Mínimo 10 runs antes de terminar eta: 3 # Elimina 1/3 de runs pobres s: 2 name: housing-rf-sweep-improved description: \"Optimize Random Forest with wmape + feature tracking\" main.py del Step 06: El Sweep Real \"\"\" W\u0026B Sweep for Random Forest Hyperparameter Optimization. Autor: Carlos Daniel Jiménez \"\"\" import argparse import yaml import wandb import logging from pathlib import Path from utils import ( download_data_from_gcs, prepare_data, train_random_forest, evaluate_model, log_feature_importances ) logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) # Module-level data cache (cargado una vez, reusado en todos los runs) _data_cache = { \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None, \"feature_names\": None } def train(): \"\"\" Training function llamada por W\u0026B Sweep agent. Ejecutada para cada combinación de hiperparámetros. Usa module-level cache para evitar recargar datos en cada run. \"\"\" run = wandb.init() config = wandb.config logger.info(\"=\"*70) logger.info(f\"SWEEP RUN: {run.name}\") logger.info(\"=\"*70) try: # Preparar parámetros params = { 'n_estimators': int(config.n_estimators), 'max_depth': int(config.max_depth) if config.max_depth else None, 'min_samples_split': int(config.min_samples_split), 'min_samples_leaf': int(config.min_samples_leaf), 'max_features': config.max_features, 'random_state': 42 } # Train model usando cached data model = train_random_forest( _data_cache[\"X_train\"], _data_cache[\"y_train\"], params ) # Evaluate model metrics = evaluate_model( model, _data_cache[\"X_test\"], _data_cache[\"y_test\"] ) # Log feature importances feature_importances = log_feature_importances( model, _data_cache[\"feature_names\"] ) # Log todo a W\u0026B wandb.log({ **params, **metrics, **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) logger.info(f\"SUCCESS: MAPE={metrics['mape']:.2f}% | \" f\"WMAPE={metrics['wmape']:.2f}%\") except Exception as e: logger.error(f\"ERROR: Run failed: {str(e)}\") wandb.log({ \"error\": str(e), \"mape\": 999.9, \"wmape\": 999.9 }) raise finally: run.finish() def main(): \"\"\"Main function para inicializar y ejecutar el sweep.\"\"\" parser = argparse.ArgumentParser() parser.add_argument(\"--gcs_train_path\", type=str, required=True) parser.add_argument(\"--gcs_test_path\", type=str, required=True) parser.add_argument(\"--bucket_name\", type=str, required=True) parser.add_argument(\"--wandb_project\", type=str, required=True) parser.add_argument(\"--target_column\", type=str, default=\"median_house_value\") parser.add_argument(\"--sweep_count\", type=int, default=50) parser.add_argument(\"--sweep_config\", type=str, default=\"sweep_config.yaml\") args = parser.parse_args() logger.info(\"=\"*70) logger.info(\"W\u0026B SWEEP - HYPERPARAMETER OPTIMIZATION\") logger.info(\"=\"*70) # Cargar datos UNA VEZ en module-level cache logger.info(\"\\nLoading data into cache...\") train_df = download_data_from_gcs(args.bucket_name, args.gcs_train_path) X_train, y_train = prepare_data(train_df, args.target_column) test_df = download_data_from_gcs(args.bucket_name, args.gcs_test_path) X_test, y_test = prepare_data(test_df, args.target_column) # Store in cache _data_cache[\"X_train\"] = X_train _data_cache[\"X_test\"] = X_test _data_cache[\"y_train\"] = y_train _data_cache[\"y_test\"] = y_test _data_cache[\"feature_names\"] = X_train.columns.tolist() logger.info(f\"Data cached: Train {X_train.shape}, Test {X_test.shape}\") # Load sweep configuration sweep_config_path = Path(__file__).parent / args.sweep_config with open(sweep_config_path, 'r') as f: sweep_config = yaml.safe_load(f) logger.info(f\"\\nSweep config:\") logger.info(f\" Method: {sweep_config['method']}\") logger.info(f\" Metric: {sweep_config['metric']['name']} ({sweep_config['metric']['goal']})\") # Initialize sweep sweep_id = wandb.sweep( sweep=sweep_config, project=args.wandb_project ) logger.info(f\"\\nSweep created: {sweep_id}\") logger.info(f\" View at: https://wandb.ai/{args.wandb_project}/sweeps/{sweep_id}\") # Run sweep agent logger.info(f\"\\nStarting sweep agent ({args.sweep_count} runs)...\") wandb.agent( sweep_id, function=train, count=args.sweep_count, project=args.wandb_project ) logger.info(\"\\n\" + \"=\"*70) logger.info(\"SWEEP COMPLETED\") logger.info(\"=\"*70) # Guardar best params api = wandb.Api() sweep = api.sweep(f\"{args.wandb_project}/{sweep_id}\") best_run = sweep.best_run() best_params = { \"hyperparameters\": { \"n_estimators\": int(best_run.config.get('n_estimators')), \"max_depth\": int(best_run.config.get('max_depth')) if best_run.config.get('max_depth') else None, \"min_samples_split\": int(best_run.config.get('min_samples_split')), \"min_samples_leaf\": int(best_run.config.get('min_samples_leaf')), \"max_features\": best_run.config.get('max_features'), }, \"metrics\": { \"mape\": float(best_run.summary.get('mape')), \"wmape\": float(best_run.summary.get('wmape')), \"r2\": float(best_run.summary.get('r2')), }, \"sweep_id\": sweep_id, \"best_run_id\": best_run.id } # Guardar a YAML best_params_path = Path(__file__).parent / \"best_params.yaml\" with open(best_params_path, 'w') as f: yaml.dump(best_params, f) logger.info(f\"\\nBest params saved to: {best_params_path}\") logger.info(f\" MAPE: {best_params['metrics']['mape']:.2f}%\") if __name__ == \"__main__\": main() Decisiones Técnicas Críticas 1. Bayesian Optimization, No Random Search method: bayes # No random, no grid Random search: Prueba combinaciones aleatorias. No aprende de runs anteriores.\nGrid search: Prueba todas las combinaciones. Exhaustivo pero carísimo (5 × 4 × 3 × 3 × 2 = 360 combos).\nBayesian optimization: Construye un modelo probabilístico de la función que optimizas (MAPE en función de hiperparámetros) y usa ese modelo para decidir qué probar siguiente.\nSi detecta que max_depth=None consistentemente da mejor MAPE, explora más en esa región del espacio.\n50 runs es \u003c15% del espacio total, pero capturan el 80% del beneficio posible.\n2. wMAPE, No MAPE metric: name: wmape # Weighted MAPE MAPE estándar: Penaliza errores en casas baratas más que en casas caras.\nSi una casa vale $10,000 y predices $12,000, error = 20%. Si una casa vale $500,000 y predices $510,000, error = 2%.\nAmbos errores son $10,000, pero MAPE los ve radicalmente diferentes.\nwMAPE (Weighted MAPE): Pondera por el valor real. Menos sesgado hacia valores bajos.\nPor qué funciona aquí: California Housing no tiene casas de $0. Rango está entre $15k y $500k—razonablemente acotado.\n3. Variables Globales Para Data Cache _data_cache = { \"X_train\": None, \"X_test\": None, # ... } Las variables globales son generalmente código sucio. Aquí son la decisión correcta.\nCada run del sweep necesita los mismos datos. Sin cache, cargarías desde GCS 50 veces. Con California Housing (20k filas), eso son segundos desperdiciados. Con datasets más grandes, son minutos u horas.\nAlternativa “limpia”: Pasar datos como argumento a cada función. Pero W\u0026B Sweeps tiene interfaz fija—la función que pasas a wandb.agent() no puede recibir argumentos adicionales.\nLas variables globales aquí tienen scope limitado—solo existen durante el proceso del sweep.\n4. Early Stopping con Hyperband early_terminate: type: hyperband min_iter: 10 eta: 3 Hyperband elimina runs pobres temprano. Si después de 10 runs un set de hiperparámetros muestra MAPE de 25% mientras otros están en 8%, Hyperband lo detiene.\neta=3: Elimina el peor tercio de runs en cada iteración.\nBeneficio: Ahorras cómputo en hiperparámetros obviamente malos.\n5. Feature Importances Loggeadas feature_importances = log_feature_importances(model, feature_names) wandb.log({ **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) Random Forest calcula feature importances gratis. Sería valioso loggearlo para entender qué features dominan el modelo.\nEn W\u0026B dashboard, puedes comparar runs y ver “en el mejor run, median_income tuvo importance de 0.45”.\nEl Output Crítico: best_params.yaml hyperparameters: n_estimators: 200 max_depth: 20 min_samples_split: 2 min_samples_leaf: 1 max_features: sqrt metrics: mape: 7.82 wmape: 7.65 r2: 0.87 sweep_id: abc123xyz best_run_id: run_456 Los hiperparámetros óptimos se guardan en YAML, not pickle. Razón:\nYAML es legible y git-friendly. Si en el próximo retraining cambias de n_estimators=200 a n_estimators=300, un git diff lo muestra claramente.\nCon pickle, es un blob binario opaco.\nLo Que Esto Logra Sin esto: “Usé n_estimators=100 porque es el default de scikit-learn.”\nCon esto: “Corrí sweep bayesiano de 50 runs. Optimal config: n_estimators=200, max_depth=20. MAPE mejoró de 8.5% a 7.8%. Aquí está el sweep en W\u0026B: wandb.ai/project/sweeps/abc123.”\nEvidencia cuantificable de por qué elegiste cada hiperparámetro.\n7. Step 07: Model Registry - Versionamiento en MLflow Por Qué No Basta con Guardar el Pickle La tentación es:\nimport joblib joblib.dump(model, \"best_model.pkl\") Esto funciona hasta que necesitas responder:\n¿Qué hiperparámetros usó? ¿Con qué datos se entrenó? ¿Qué métricas logró? ¿Cómo rollback a la versión anterior? MLflow Model Registry resuelve esto.\nregister_model_to_mlflow(): El Core \"\"\" Registro de modelo en MLflow Model Registry. Autor: Carlos Daniel Jiménez \"\"\" import mlflow import mlflow.sklearn from mlflow.tracking import MlflowClient def register_model_to_mlflow( model, model_name: str, model_stage: str, params: dict, metrics: dict, feature_columns: list, target_column: str, gcs_train_path: str, gcs_test_path: str ) -\u003e tuple: \"\"\" Registra modelo en MLflow Model Registry con metadata rica. Args: model: Trained sklearn model model_name: Nombre para registered model model_stage: Stage (Staging/Production) params: Hyperparameters metrics: Métricas de evaluación feature_columns: Lista de features target_column: Target column name gcs_train_path: Path a training data gcs_test_path: Path a test data Returns: (model_uri, model_version, run_id) \"\"\" logger.info(\"=\"*70) logger.info(\"REGISTERING MODEL TO MLFLOW\") logger.info(\"=\"*70) client = MlflowClient() run_id = mlflow.active_run().info.run_id model_uri = f\"runs:/{run_id}/model\" # Log model to MLflow mlflow.sklearn.log_model(model, \"model\") logger.info(f\"Model logged: {model_uri}\") # Create or get registered model try: client.create_registered_model( name=model_name, description=\"Housing price prediction - Random Forest\" ) logger.info(f\"Created new registered model: {model_name}\") except Exception as e: if \"already exists\" in str(e): logger.info(f\"Model already exists: {model_name}\") else: raise # Create model version model_version = client.create_model_version( name=model_name, source=model_uri, run_id=run_id ) logger.info(f\"Version created: {model_version.version}\") # Transition to stage client.transition_model_version_stage( name=model_name, version=model_version.version, stage=model_stage # \"Staging\" or \"Production\" ) logger.info(f\"Transitioned to: {model_stage}\") # Create comprehensive description (MARKDOWN) description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest Regressor ## Hyperparameters - n_estimators: {params['n_estimators']} - max_depth: {params.get('max_depth', 'None')} - min_samples_split: {params['min_samples_split']} - min_samples_leaf: {params['min_samples_leaf']} - max_features: {params.get('max_features', 'sqrt')} ## Performance Metrics - MAPE: {metrics['mape']:.2f}% - Median APE: {metrics['median_ape']:.2f}% - Within 10%: {metrics['within_10pct']:.1f}% - RMSE: {metrics['rmse']:.2f} - R²: {metrics['r2']:.4f} ## Features - Number of features: {len(feature_columns)} - Target: {target_column} ## Data Sources - Training: {gcs_train_path} - Testing: {gcs_test_path} \"\"\" client.update_model_version( name=model_name, version=model_version.version, description=description ) # Add searchable tags tags = { \"algorithm\": \"RandomForest\", \"framework\": \"sklearn\", \"mape\": f\"{metrics['mape']:.2f}\", \"within_10pct\": f\"{metrics['within_10pct']:.1f}\", \"rmse\": f\"{metrics['rmse']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", \"n_features\": str(len(feature_columns)), \"target\": target_column, } for key, value in tags.items(): client.set_model_version_tag( model_name, model_version.version, key, value ) logger.info(\"Tags added to model version\") logger.info(\"=\"*70) return model_uri, model_version.version, run_id Decisiones Técnicas Críticas 1. Artifact vs Registered Model Artifact: Pickle guardado en un run específico. Para usarlo, necesitas el run_id.\nmlflow.sklearn.log_model(model, \"model\") # Solo artifact # Uso: mlflow.sklearn.load_model(f\"runs://{run_id}/model\") Registered Model: Versionado con nombre semántico, stages y metadata.\nclient.create_model_version(name=\"housing_price_model\", source=model_uri) # Uso: mlflow.pyfunc.load_model(\"models:/housing_price_model/Production\") En producción, tu API carga models:/housing_price_model/Production, no runs:/abc123/model.\nCuando registras una nueva versión, la transicionas a Production y el deployment automáticamente toma la nueva versión.\n2. Metadata Rica en Markdown description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest ## Hyperparameters - n_estimators: {params['n_estimators']} ... ## Performance Metrics - MAPE: {metrics['mape']:.2f}% ... \"\"\" Esto guarda markdown en la descripción del modelo. Cuando abres MLflow UI y navegas a housing_price_model v3, ves:\nQué hiperparámetros usó Qué métricas logró De dónde vinieron los datos Por qué es oro: Seis meses después, cuando alguien pregunta “¿por qué el modelo v3 tiene mejor MAPE que v2?”, abres MLflow y la respuesta está ahí.\nNo necesitas buscar en logs ni preguntar a quien lo entrenó.\n3. Tags Para Búsqueda tags = { \"algorithm\": \"RandomForest\", \"mape\": f\"{metrics['mape']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", } for key, value in tags.items(): client.set_model_version_tag(model_name, model_version.version, key, value) En MLflow puedes filtrar modelos por tags. “Muéstrame todos los modelos con MAPE \u003c 8%” es una query que funciona si taggeaste consistentemente.\n4. Model Config File: Single Source of Truth model_config = { 'model': { 'name': model_name, 'version': str(model_version), 'stage': model_stage, 'parameters': params, 'metrics': metrics, 'feature_columns': feature_columns, 'mlflow_run_id': run_id, 'sweep_id': sweep_id } } config_path = Path(\"configs/model_config.yaml\") with open(config_path, 'w') as f: yaml.dump(model_config, f) mlflow.log_artifact(str(config_path), artifact_path=\"config\") Este YAML se loggea a MLflow Y se guarda en el repo (en configs/model_config.yaml).\nPor qué YAML y no solo MLflow: Tu FastAPI app necesita leer configuración al iniciar. Puede hacer mlflow.load_model() para el pickle, pero necesita saber los feature names para validación de input.\nEl YAML es esa single source of truth.\n5. Versionado en Git Cuando commiteas model_config.yaml, el diff muestra:\n- version: 2 + version: 3 - mape: 8.5 + mape: 7.8 - n_estimators: 100 + n_estimators: 200 Es auditable. Sabes exactamente qué cambió entre versiones.\nEl Flujo Completo: Sweep → Registration → Production # 1. Model Selection (Step 05) python src/model/05_model_selection/main.py # Output: \"Best: RandomForestRegressor (MAPE: 8.2%)\" # 2. Hyperparameter Sweep (Step 06) python src/model/06_sweep/main.py --sweep_count=50 # Output: best_params.yaml con hiperparámetros óptimos # 3. Model Registration (Step 07) python src/model/07_registration/main.py --params_file=best_params.yaml # Output: Modelo registrado en MLflow Registry # 4. Transition to Production (manual) mlflow models transition \\ --name housing_price_model \\ --version 3 \\ --stage Production Lo Que Este Approach Soluciona Sin Model Registry:\nPickles en carpetas: model_v3_final_FINAL_2.pkl No sabes qué hiperparámetros usa cada uno Rollback = buscar el pickle correcto en GCS Con Model Registry:\nModelos con versiones semánticas: v1, v2, v3 Metadata embebida: params, metrics, data sources Rollback = transition v3 to Archived + transition v2 to Production 8. CI/CD con GitHub Actions: Automatización del Pipeline Completo Navegación ← Inicio | Parte 2: Deployment e Infraestructura →\nEn la Parte 2 cubriremos:\nCI/CD con GitHub Actions W\u0026B vs MLflow: Estrategias complementarias Containerización completa con Docker Arquitectura FastAPI en producción ","wordCount":"6065","inLanguage":"en","datePublished":"2026-01-13T00:00:00Z","dateModified":"2026-01-13T00:00:00Z","author":{"@type":"Person","name":"Carlos Daniel Jiménez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-1/"},"publisher":{"@type":"Organization","name":"The Probability Engine","logo":{"@type":"ImageObject","url":"https://carlosdanieljimenez.com/img/icon.jpeg"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://carlosdanieljimenez.com/ accesskey=h title="The Probability Engine (Alt + H)">The Probability Engine</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://carlosdanieljimenez.com/mlops/ title=MLOps><span>MLOps</span></a></li><li><a href=https://carlosdanieljimenez.com/agentic-ai/ title="Agentic AI"><span>Agentic AI</span></a></li><li><a href=https://carlosdanieljimenez.com/tidytuesday/ title=TidyTuesday><span>TidyTuesday</span></a></li><li><a href=https://carlosdanieljimenez.com/post/ title=Posts><span>Posts</span></a></li><li><a href=https://carlosdanieljimenez.com/edge-computing/ title="Edge Computing"><span>Edge Computing</span></a></li><li><a href=https://carlosdanieljimenez.com/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://carlosdanieljimenez.com/about/ title=About><span>About</span></a></li><li><a href=https://carlosdanieljimenez.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación</h1><div class=post-description>Parte 1: Filosofía, arquitectura del proyecto y orquestación con Hydra + MLflow. Steps de preprocessing, feature engineering, hyperparameter tuning y model registry.</div><div class=post-meta><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;<span>Carlos Daniel Jiménez</span></div></header><div class=post-content><blockquote><p><strong>Serie MLOps Completo:</strong> <a href=/mlops/anatomia-pipeline-mlops-parte-1/>Parte 1 (actual)</a> | <a href=/mlops/anatomia-pipeline-mlops-parte-2/>Parte 2: Deployment →</a> | <a href=/mlops/anatomia-pipeline-mlops-parte-3/>Parte 3: Producción →</a></p></blockquote><h1 id=anatomía-de-un-pipeline-mlops---parte-1-pipeline-y-orquestación>Anatomía de un Pipeline MLOps - Parte 1: Pipeline y Orquestación<a hidden class=anchor aria-hidden=true href=#anatomía-de-un-pipeline-mlops---parte-1-pipeline-y-orquestación>#</a></h1><h1 id=anatomía-de-un-pipeline-mlops-de-los-datos-crudos-al-deployment-en-producción>Anatomía de un Pipeline MLOps: De los Datos Crudos al Deployment en Producción<a hidden class=anchor aria-hidden=true href=#anatomía-de-un-pipeline-mlops-de-los-datos-crudos-al-deployment-en-producción>#</a></h1><h2 id=por-qué-este-post-no-es-otro-tutorial-de-scikit-learn>Por Qué Este Post No Es Otro Tutorial de Scikit-Learn<a hidden class=anchor aria-hidden=true href=#por-qué-este-post-no-es-otro-tutorial-de-scikit-learn>#</a></h2><p>La mayoría de los posts sobre MLOps te enseñan a entrenar un Random Forest en un notebook y te dicen &ldquo;ahora ponlo en producción&rdquo;. Este post asume que ya sabes entrenar modelos. Lo que probablemente no sabes es cómo construir un sistema donde:</p><ul><li>Un commit a GitHub dispara un pipeline completo de 7 steps</li><li>Cada decisión de preprocesamiento está respaldada por métricas cuantificables</li><li>Los modelos se versionan con metadata rica, no con nombres de archivo tipo <code>model_final_v3_REAL.pkl</code></li><li>El deployment no requiere SSH a un servidor para copiar un pickle</li><li>Rollback de una versión defectuosa toma 30 segundos, no 3 horas de panic debugging</li></ul><p>Este post disecciona un pipeline real que implementa todo eso. No es teoría, es código que corre en producción. Basado en el capítulo 2 de &ldquo;Hands-On Machine Learning&rdquo; de Aurélien Géron, pero con la infraestructura que el libro no cubre.</p><p><strong>Repositorio completo:</strong> <a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github</a></p><hr><h2 id=tabla-de-contenidos>Tabla de Contenidos<a hidden class=anchor aria-hidden=true href=#tabla-de-contenidos>#</a></h2><ol><li><a href=#filosof%C3%ADa>La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente</a></li><li><a href=#estructura>Estructura del Proyecto: Arquitectura Que Escala</a></li><li><a href=#orquestaci%C3%B3n>Orquestación con Hydra + MLflow</a></li><li><a href=#step-02>Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos</a></li><li><a href=#step-03>Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering</a></li><li><a href=#step-06>Step 06: Hyperparameter Sweep - Optimización Bayesiana con W&amp;B</a></li><li><a href=#step-07>Step 07: Model Registry - Versionamiento en MLflow</a></li><li><a href=#github-actions>CI/CD con GitHub Actions: Automatización del Pipeline Completo</a></li><li><a href=#mlops-value-proposition>El Valor de MLOps: Por Qué Esto Importa</a><ul><li>W&amp;B vs MLflow: Por Qué Ambos, No Uno u Otro (#wandb-vs-mlflow)</li></ul></li><li><a href=#docker-mlflow>Docker y MLflow: Containerización del Ecosistema Completo</a><ul><li>Pipeline Container con MLflow Tracking</li><li>API Container para Inference</li><li>Streamlit Container para Frontend</li><li>Docker Compose: Orquestación de los Tres Containers</li><li>Arquitectura del API: FastAPI en Producción (#api-architecture)</li></ul></li><li><a href=#model-strategies>Estrategias de Selección de Modelos y Parámetros</a><ul><li>Model Selection: Comparación de 5 Algoritmos</li><li>Parameter Grids y GridSearch</li><li>Métricas de Evaluación: MAPE, SMAPE, wMAPE</li></ul></li><li><a href=#testing>Testing: Fixtures, Mocking y Coverage Real</a></li><li><a href=#production-patterns>Patrones de Producción Que Nadie Te Cuenta</a><ul><li>El Transform Pattern: El Truco del KMeans Sintético</li><li>Training/Serving Skew: El Asesino Silencioso</li><li>Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea</li><li>Model Monitoring: Más Allá de Accuracy</li><li>The Cascade Pattern: Fallback Resilience</li><li>Feature Store Anti-Pattern: Cuándo NO Necesitas Uno</li><li>Production Readiness: Un Checklist Honesto</li></ul></li><li><a href=#conclusiones>Conclusiones: MLOps Como Disciplina de Ingeniería</a></li></ol><hr><p><a name=filosofía></a></p><h2 id=1-la-filosofía-por-qué-ser-ordenado-es-más-importante-que-ser-inteligente>1. La Filosofía: Por Qué Ser Ordenado Es Más Importante Que Ser Inteligente<a hidden class=anchor aria-hidden=true href=#1-la-filosofía-por-qué-ser-ordenado-es-más-importante-que-ser-inteligente>#</a></h2><h3 id=el-problema-real-del-mlops>El Problema Real del MLOps<a hidden class=anchor aria-hidden=true href=#el-problema-real-del-mlops>#</a></h3><p>Ser un MLOps engineer tiene dos cosas importantes en su quehacer:</p><p><strong>Primero, y lo que siento que es lo más importante: ser ordenado.</strong> Suena redundante, pero cada cosa debe ir en su lugar. Un notebook con 50 celdas ejecutadas en orden aleatorio no es un pipeline—es una bomba de tiempo. Cuando ese modelo necesita reentrenarse a las 3 AM porque el data drift disparó una alerta, ¿quién se acuerda del orden correcto de las celdas?</p><p><strong>Segundo: lo que no se prueba, no deja de ser un mock o un prototipo.</strong> Lejos de pensar en usar solamente patrones de diseño, el foco y lo que intentaré sembrar como idea central de este post es <strong>la usabilidad de los productos y ver esto como software design.</strong></p><h3 id=el-mindset-correcto>El Mindset Correcto<a hidden class=anchor aria-hidden=true href=#el-mindset-correcto>#</a></h3><p>Este proyecto trata Machine Learning como lo que realmente es: <strong>software con componentes probabilísticos</strong>. No es magia, es ingeniería. Y como ingeniería, necesita:</p><ul><li><strong>Versionamiento:</strong> De datos, código, modelos y configuración</li><li><strong>Testing:</strong> Unit, integration y end-to-end</li><li><strong>Observabilidad:</strong> Logs, métricas y traces</li><li><strong>Reproducibilidad:</strong> Ejecutar hoy y en 6 meses debe dar el mismo resultado</li><li><strong>Deployment:</strong> Automatizado, no manual</li></ul><h3 id=referencia-hands-on-machine-learning-de-géron>Referencia: Hands-On Machine Learning de Géron<a hidden class=anchor aria-hidden=true href=#referencia-hands-on-machine-learning-de-géron>#</a></h3><p>Este post se basa en el <strong>Capítulo 2 del libro de Géron</strong>, un clásico que todos deberíamos leer. Pero el libro se enfoca en el modelo—cómo entrenar un buen predictor. Este post se enfoca en el <strong>sistema alrededor del modelo</strong>—cómo hacer que ese predictor llegue a producción de manera confiable.</p><p><strong>Lo que Géron enseña:</strong> Imputación de datos, feature engineering, selección de modelos, evaluación.</p><p><strong>Lo que este post agrega:</strong> GCS para almacenamiento, W&amp;B para experimentación, MLflow para model registry, FastAPI para serving, Docker para deployment, GitHub Actions para CI/CD.</p><hr><p><a name=estructura></a></p><h2 id=2-estructura-del-proyecto-arquitectura-que-escala>2. Estructura del Proyecto: Arquitectura Que Escala<a hidden class=anchor aria-hidden=true href=#2-estructura-del-proyecto-arquitectura-que-escala>#</a></h2><h3 id=el-árbol-completo-200-archivos>El Árbol Completo (200+ Archivos)<a hidden class=anchor aria-hidden=true href=#el-árbol-completo-200-archivos>#</a></h3><pre tabindex=0><code>cap2-end_to_end/
├── main.py                                # Orquestador Hydra + MLflow
├── config.yaml                            # Single source of truth
├── pyproject.toml                         # Dependencias con UV
├── Makefile                               # CLI para operaciones comunes
├── Dockerfile                             # Pipeline containerizado
├── docker-compose.yaml                    # API + Streamlit + MLflow
├── pytest.ini                             # Configuración de tests
├── .env.example                           # Template de secrets
│
├── src/
│   ├── data/                              # Steps de procesamiento (01-04)
│   │   ├── 01_download_data/
│   │   │   ├── main.py                    # Download desde URL → GCS
│   │   │   ├── downloader.py              # Lógica de descarga
│   │   │   ├── models.py                  # Pydantic schemas
│   │   │   ├── MLproject                  # Entry point MLflow
│   │   │   └── conda.yaml                 # Dependencias aisladas
│   │   │
│   │   ├── 02_preprocessing_and_imputation/
│   │   │   ├── main.py
│   │   │   ├── preprocessor.py
│   │   │   ├── imputation_analyzer.py     # (crítico) Comparación de estrategias
│   │   │   └── utils.py
│   │   │
│   │   ├── 03_feature_engineering/
│   │   │   ├── main.py
│   │   │   ├── feature_engineer.py        # (crítico) KMeans clustering
│   │   │   └── utils.py                   # Optimización n_clusters
│   │   │
│   │   └── 04_segregation/
│   │       ├── main.py
│   │       ├── segregator.py              # Train/test split
│   │       └── models.py
│   │
│   ├── model/                             # Steps de modelado (05-07)
│   │   ├── 05_model_selection/
│   │   │   ├── main.py                    # Comparación de 5 algoritmos
│   │   │   ├── model_selector.py          # (crítico) GridSearch por modelo
│   │   │   └── utils.py
│   │   │
│   │   ├── 06_sweep/
│   │   │   ├── main.py                    # (crítico) W&amp;B Bayesian optimization
│   │   │   ├── sweep_config.yaml          # Espacio de búsqueda
│   │   │   └── best_params.yaml           # Output (generado)
│   │   │
│   │   └── 07_registration/
│   │       ├── main.py                    # (crítico) Registro en MLflow
│   │       └── configs/
│   │           └── model_config.yaml      # Metadata (generado)
│   │
│   └── utils/
│       └── colored_logger.py              # Logging estructurado
│
├── api/                                   # FastAPI REST API
│   ├── app/
│   │   ├── main.py                        # FastAPI + lifespan
│   │   ├── core/
│   │   │   ├── config.py                  # Pydantic Settings
│   │   │   ├── model_loader.py            # Load desde MLflow/GCS/Local
│   │   │   └── wandb_logger.py            # Logging predicciones
│   │   ├── models/
│   │   │   └── schemas.py                 # Request/Response schemas
│   │   └── routers/
│   │       └── predict.py                 # POST /api/v1/predict
│   ├── Dockerfile                         # Imagen del API (port 8080)
│   └── requirements.txt
│
├── streamlit_app/                         # Frontend interactivo
│   ├── app.py                             # Aplicación Streamlit (450+ líneas)
│   ├── Dockerfile                         # Imagen Streamlit (port 8501)
│   └── requirements.txt
│
├── tests/                                 # Suite de tests
│   ├── conftest.py                        # Fixtures compartidas
│   ├── fixtures/
│   │   └── test_data_generator.py         # Datos sintéticos
│   ├── test_pipeline.py                   # Test de orquestación
│   ├── test_downloader.py
│   ├── test_preprocessor.py
│   ├── test_imputation_analyzer.py        # (crítico) Tests de imputación
│   ├── test_feature_engineering.py
│   ├── test_segregation.py
│   └── test_integration_simple.py         # End-to-end
│
└── docs/
    ├── API_ARCHITECTURE_POST.md
    ├── QUICKSTART_GUIDE.md
    └── TESTING_IMPROVEMENTS.md
</code></pre><p><strong>Los archivos marcados con (crítico) son los más críticos</strong> para entender la arquitectura.</p><h3 id=decisiones-arquitectónicas-fundamentales>Decisiones Arquitectónicas Fundamentales<a hidden class=anchor aria-hidden=true href=#decisiones-arquitectónicas-fundamentales>#</a></h3><h4 id=1-separación-srcdata-vs-srcmodel>1. Separación <code>src/data</code> vs <code>src/model</code><a hidden class=anchor aria-hidden=true href=#1-separación-srcdata-vs-srcmodel>#</a></h4><p><strong>Por qué:</strong> Los steps de datos (01-04) producen artifacts <strong>reutilizables</strong>—preprocesamiento, features, splits. Los steps de modelo (05-07) los <strong>consumen</strong> pero pueden reentrenarse sin reejecutar todo upstream.</p><p><strong>Beneficio:</strong> Si cambias hiperparámetros, reejecutas solo 06-07. Si cambias feature engineering, reejecutas 03-07. No re-descargas datos cada vez.</p><p><strong>Costo:</strong> Más verbosidad, más archivos. Pero en pipelines reales con múltiples data scientists, el aislamiento vale oro.</p><h4 id=2-mlproject--condayaml-por-step>2. MLproject + conda.yaml por Step<a hidden class=anchor aria-hidden=true href=#2-mlproject--condayaml-por-step>#</a></h4><p>Cada subdirectorio es un proyecto MLflow independiente:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># src/data/02_preprocessing/MLproject</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>preprocessing_and_imputation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>conda_env</span><span class=p>:</span><span class=w> </span><span class=l>conda.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>entry_points</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Ventajas:</strong></p><ul><li>Dependencias aisladas (step 03 usa scikit-learn 1.3, step 06 podría usar 1.4)</li><li>Ejecución independiente: <code>mlflow run src/data/02_preprocessing</code></li><li>Tracking granular: cada step es un run separado</li></ul><p><strong>Desventaja:</strong> Overhead de archivos. Pero es el mismo overhead que tener microservicios—cada uno con su Dockerfile.</p><h4 id=3-api-como-proyecto-separado>3. <code>api/</code> Como Proyecto Separado<a hidden class=anchor aria-hidden=true href=#3-api-como-proyecto-separado>#</a></h4><p>El API no está en <code>src/api/</code>. Es un proyecto hermano con su propio <code>requirements.txt</code>, Dockerfile y tests.</p><p><strong>Razón:</strong> El API se deploya <strong>independientemente</strong> del pipeline. No necesita pandas completo, scikit-learn full o W&amp;B client. Solo FastAPI, pydantic y el pickle del modelo.</p><p><strong>Resultado:</strong> Imagen Docker de 200MB vs 1.5GB si incluyeras todo el pipeline.</p><h4 id=4-tests-en-la-raíz>4. Tests en la Raíz<a hidden class=anchor aria-hidden=true href=#4-tests-en-la-raíz>#</a></h4><p>Los tests prueban el <strong>sistema completo</strong>, no módulos aislados. <code>test_integration_simple.py</code> corre el pipeline end-to-end. No encaja conceptualmente en <code>src/</code>.</p><h4 id=5-ausencia-de-notebooks>5. Ausencia de <code>notebooks/</code><a hidden class=anchor aria-hidden=true href=#5-ausencia-de-notebooks>#</a></h4><p><strong>Decisión deliberada.</strong> Los notebooks son excelentes para exploración, terribles para producción. Este proyecto prioriza <strong>reproducibilidad</strong> sobre iteración rápida.</p><p>Si necesitas explorar, úsalos localmente pero <strong>no los comitees</strong>. Los notebooks en git son:</p><ul><li>Difíciles de revisar (diffs incomprensibles)</li><li>Imposibles de testear</li><li>Propensos a ejecutarse fuera de orden</li></ul><hr><p><a name=orquestación></a></p><h2 id=3-orquestación-con-hydra--mlflow>3. Orquestación con Hydra + MLflow<a hidden class=anchor aria-hidden=true href=#3-orquestación-con-hydra--mlflow>#</a></h2><h3 id=por-qué-no-scripts-bash-simples>Por Qué No Scripts Bash Simples<a hidden class=anchor aria-hidden=true href=#por-qué-no-scripts-bash-simples>#</a></h3><p>Ejecutar comandos Python secuenciales funciona para pipelines simples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python src/data/01_download_data/main.py
</span></span><span class=line><span class=cl>python src/data/02_preprocessing/main.py
</span></span><span class=line><span class=cl>python src/data/03_feature_engineering/main.py
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span></code></pre></div><p><strong>Este enfoque falla cuando necesitas:</strong></p><ul><li>Ejecutar solo steps específicos (debugging)</li><li>Cambiar parámetros sin editar código</li><li>Versionar configuración junto al código</li><li>Logs estructurados de qué corrió con qué params</li><li>Rastrear dependencias entre steps</li></ul><p><strong>Hydra + MLflow resuelve todos estos problemas.</strong></p><h3 id=el-orquestador-mainpy>El Orquestador: main.py<a hidden class=anchor aria-hidden=true href=#el-orquestador-mainpy>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>MLOps Pipeline Orchestrator
</span></span></span><span class=line><span class=cl><span class=s2>Ejecuta steps secuencialmente usando MLflow + Hydra
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>hydra</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>DictConfig</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>validate_environment_variables</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Fail fast si faltan secrets críticos.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>required_vars</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCP_PROJECT_ID&#34;</span><span class=p>:</span> <span class=s2>&#34;Google Cloud Project ID&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCS_BUCKET_NAME&#34;</span><span class=p>:</span> <span class=s2>&#34;GCS Bucket name&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;WANDB_API_KEY&#34;</span><span class=p>:</span> <span class=s2>&#34;Weights &amp; Biases API Key&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>missing</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>var</span><span class=p>,</span> <span class=n>description</span> <span class=ow>in</span> <span class=n>required_vars</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>value</span> <span class=ow>or</span> <span class=n>value</span> <span class=ow>in</span> <span class=p>[</span><span class=s2>&#34;your-project-id&#34;</span><span class=p>,</span> <span class=s2>&#34;your-key&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>missing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  ERROR: </span><span class=si>{</span><span class=n>var</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>description</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>missing</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>missing</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Create .env file with:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCP_PROJECT_ID=your-project-id&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCS_BUCKET_NAME=your-bucket&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  WANDB_API_KEY=your-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sys</span><span class=o>.</span><span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Convierte execute_steps de config a lista.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;execute_steps&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>steps</span><span class=p>,</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>s</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=n>steps</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;,&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_step</span><span class=p>(</span><span class=n>step_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>step_path</span><span class=p>:</span> <span class=n>Path</span><span class=p>,</span> <span class=n>entry_point</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>parameters</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Ejecuta un step como MLflow project.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;EXECUTING: </span><span class=si>{</span><span class=n>step_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>uri</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>step_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>entry_point</span><span class=o>=</span><span class=n>entry_point</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>env_manager</span><span class=o>=</span><span class=s2>&#34;local&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>parameters</span><span class=o>=</span><span class=n>parameters</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@hydra.main</span><span class=p>(</span><span class=n>config_path</span><span class=o>=</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=n>config_name</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>,</span> <span class=n>version_base</span><span class=o>=</span><span class=s2>&#34;1.3&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>go</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Entry point principal del pipeline.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>validate_environment_variables</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_experiment</span><span class=p>(</span><span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;experiment_name&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>steps_to_execute</span> <span class=o>=</span> <span class=n>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>root_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Step 01: Download Data</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;01_download_data&#34;</span> <span class=ow>in</span> <span class=n>steps_to_execute</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>run_step</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;01 - Download Data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>root_path</span> <span class=o>/</span> <span class=s2>&#34;src&#34;</span> <span class=o>/</span> <span class=s2>&#34;data&#34;</span> <span class=o>/</span> <span class=s2>&#34;01_download_data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;file_url&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;file_url&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;gcs_output_path&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;gcs_output_path&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ... Steps 02-07 similar pattern ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>SUCCESS: PIPELINE COMPLETED (</span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>s)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>ERROR: PIPELINE FAILED: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>go</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=configyaml-single-source-of-truth>config.yaml: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#configyaml-single-source-of-truth>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>project_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing-mlops-gcp&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>experiment_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;end_to_end_pipeline&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>execute_steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;01_download_data&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;02_preprocessing_and_imputation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;03_feature_engineering&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;04_segregation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;05_model_selection&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;06_sweep&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;07_registration&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>download_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file_url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>preprocessing</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>imputation_strategy</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;auto&#34;</span><span class=w>  </span><span class=c># Comparará 4 estrategias</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>feature_engineering</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_clusters</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>optimize_hyperparams</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>  </span><span class=c># Busca mejor K</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>segregation</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>test_size</span><span class=p>:</span><span class=w> </span><span class=m>0.2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>target_column</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;median_house_value&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>model_selection</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>sweep_count</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>  </span><span class=c># 50 runs de Bayesian optimization</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;mape&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_goal</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;minimize&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>registration</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>registered_model_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing_price_model&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>model_stage</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Staging&#34;</span><span class=w>  </span><span class=c># O &#34;Production&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=lo-que-este-código-hace-bien>Lo Que Este Código Hace Bien<a hidden class=anchor aria-hidden=true href=#lo-que-este-código-hace-bien>#</a></h3><p><strong>1. Fail Fast con Validación de Environment</strong></p><p>Antes de gastar CPU, verifica que todas las secrets existen. El mensaje de error incluye <strong>instrucciones</strong> de cómo conseguir cada valor.</p><pre tabindex=0><code>ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES
===============================================
  ERROR: WANDB_API_KEY: Weights &amp; Biases API Key

Create .env file with:
  WANDB_API_KEY=your-key
</code></pre><p>Esto ahorra <strong>frustración</strong>—especialmente para nuevos colaboradores.</p><p><strong>2. Ejecución Selectiva Sin Comentar Código</strong></p><p>Cambias <code>config.yaml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>execute_steps</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;03_feature_engineering&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;05_model_selection&#34;</span><span class=p>]</span><span class=w>
</span></span></span></code></pre></div><p>Y solo esos steps corren. No editas Python, no comentas imports.</p><p><strong>3. Separación Entre Orchestration y Logic</strong></p><p><code>main.py</code> no sabe cómo descargar datos o entrenar modelos. Solo sabe cómo <strong>invocar</strong> scripts que lo hacen. Cada step puede desarrollarse/testearse independientemente.</p><p><strong>4. Logging Estructurado con Visual Hierarchy</strong></p><p>Los separadores (<code>"="*70</code>) y emojis no son cosmética—en un pipeline que corre 2 horas, las secciones visuales permiten <strong>escanear rápido</strong> para encontrar qué step falló.</p><hr><p><a name=step-02></a></p><h2 id=4-step-02-imputación-automatizada---decisiones-respaldadas-por-datos>4. Step 02: Imputación Automatizada - Decisiones Respaldadas por Datos<a hidden class=anchor aria-hidden=true href=#4-step-02-imputación-automatizada---decisiones-respaldadas-por-datos>#</a></h2><h3 id=el-problema-real>El Problema Real<a hidden class=anchor aria-hidden=true href=#el-problema-real>#</a></h3><p>California Housing tiene ~1% de <code>total_bedrooms</code> faltantes. Opciones obvias:</p><ol><li><strong>Drop rows</strong> → pierdes datos</li><li><strong>Fill con median</strong> → asumes distribución sin verificar</li><li><strong>Fill con KNN</strong> → asumes similitud en feature space</li><li><strong>Fill con IterativeImputer</strong> → asumes relaciones modelables</li></ol><p><strong>Pregunta:</strong> ¿Cuál es mejor?</p><p><strong>Respuesta incorrecta:</strong> &ldquo;KNN siempre funciona&rdquo;</p><p><strong>Respuesta correcta:</strong> &ldquo;Probé las 4, median tuvo RMSE de 0.8, KNN de 0.6, Iterative de 0.5. Uso Iterative porque minimiza error de reconstrucción. Aquí está el plot en W&amp;B.&rdquo;</p><h3 id=imputation_analyzerpy-el-core>imputation_analyzer.py: El Core<a hidden class=anchor aria-hidden=true href=#imputation_analyzerpy-el-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Imputation Analyzer - Compara estrategias automáticamente
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Tuple</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>mean_squared_error</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span><span class=p>,</span> <span class=n>KNNImputer</span><span class=p>,</span> <span class=n>IterativeImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestRegressor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Resultado de una estrategia de imputación.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>method_name</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=cl>    <span class=n>imputed_values</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
</span></span><span class=line><span class=cl>    <span class=n>imputer</span><span class=p>:</span> <span class=nb>object</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationAnalyzer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Analiza y compara estrategias de imputación.
</span></span></span><span class=line><span class=cl><span class=s2>    Selecciona automáticamente la mejor basándose en RMSE.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>test_size</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>df</span> <span class=o>=</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>target_column</span> <span class=o>=</span> <span class=n>target_column</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>test_size</span> <span class=o>=</span> <span class=n>test_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>:</span> <span class=nb>object</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>prepare_validation_set</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Crea validation set masked para comparar estrategias.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Strategy:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Remove rows con target faltante (no podemos validar contra NaN)
</span></span></span><span class=line><span class=cl><span class=s2>        2. Split en train/val
</span></span></span><span class=line><span class=cl><span class=s2>        3. Maskear target en val set (simular missing values)
</span></span></span><span class=line><span class=cl><span class=s2>        4. Guardar ground truth
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            (train_set, val_set_missing, y_val_true)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_numeric</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>df</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_known</span> <span class=o>=</span> <span class=n>housing_numeric</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>housing_known</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>test_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>test_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Maskear target en val</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Ground truth</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>strategy</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evalúa SimpleImputer con strategy dada.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=n>strategy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Simple Imputer (</span><span class=si>{</span><span class=n>strategy</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>n_neighbors</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Evalúa KNNImputer con scaling.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        CRÍTICO: KNN requiere features escaladas o explota con overflow.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Scale data</span>
</span></span><span class=line><span class=cl>            <span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># KNN imputation</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span> <span class=o>=</span> <span class=n>KNNImputer</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>n_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Inverse scale</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>val_imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;KNN Imputer (k=</span><span class=si>{</span><span class=n>n_neighbors</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=p>(</span><span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span><span class=p>)</span>  <span class=c1># Store tuple!</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evalúa IterativeImputer con RandomForest estimator.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>IterativeImputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>estimator</span><span class=o>=</span><span class=n>estimator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=s2>&#34;Iterative Imputer (RF)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compare_all_methods</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Compara todas las estrategias y selecciona la mejor.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>prepare_validation_set</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluar todos</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_mean&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;mean&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;knn&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;iterative_rf&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Seleccionar mejor</span>
</span></span><span class=line><span class=cl>        <span class=n>best_key</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>k</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span> <span class=o>=</span> <span class=n>best_key</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>best_key</span><span class=p>]</span><span class=o>.</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Print summary</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;IMPUTATION METHODS COMPARISON&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>sorted</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>status</span> <span class=o>=</span> <span class=s2>&#34;[BEST]&#34;</span> <span class=k>if</span> <span class=n>key</span> <span class=o>==</span> <span class=n>best_key</span> <span class=k>else</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>method_name</span><span class=si>:</span><span class=s2>30s</span><span class=si>}</span><span class=s2> RMSE: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>rmse</span><span class=si>:</span><span class=s2>8.4f</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>status</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>apply_best_imputer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Aplica el mejor imputer al dataset completo.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;Run compare_all_methods() first&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>numeric_df</span> <span class=o>=</span> <span class=n>df_out</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Check si es tuple (KNN con scaler)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>                <span class=n>numeric_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>numeric_df</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>imputed_array</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df_out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_comparison_plot</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Crea bar plot comparando RMSE de métodos.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>methods</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>method_name</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>        <span class=n>rmses</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>rmse</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;green&#39;</span> <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>rmses</span><span class=p>)</span> <span class=k>else</span> <span class=s1>&#39;skyblue&#39;</span>
</span></span><span class=line><span class=cl>                  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>rmses</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>        <span class=n>bars</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>methods</span><span class=p>,</span> <span class=n>rmses</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Imputation Method&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;RMSE&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Comparison of Imputation Strategies&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=s1>&#39;y&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Value labels</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>bar</span><span class=p>,</span> <span class=n>rmse</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>bars</span><span class=p>,</span> <span class=n>rmses</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>height</span> <span class=o>=</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_height</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>bar</span><span class=o>.</span><span class=n>get_x</span><span class=p>()</span> <span class=o>+</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_width</span><span class=p>()</span><span class=o>/</span><span class=mf>2.</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>height</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>rmse</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>va</span><span class=o>=</span><span class=s1>&#39;bottom&#39;</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>rotation</span><span class=o>=</span><span class=mi>45</span><span class=p>,</span> <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;right&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>fig</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas>#</a></h3><h4 id=1-la-métrica-rmse-de-reconstrucción>1. La Métrica: RMSE de Reconstrucción<a hidden class=anchor aria-hidden=true href=#1-la-métrica-rmse-de-reconstrucción>#</a></h4><p><strong>¿Por qué RMSE y no MAE?</strong></p><p>MAE trata todos los errores igual. RMSE penaliza errores grandes más fuertemente.</p><p>Si un método imputa 100 bedrooms cuando la verdad es 3, eso es <strong>problemático</strong>. RMSE lo castiga más que MAE. En imputación, errores grandes distorsionan el dataset más que muchos errores pequeños.</p><h4 id=2-el-validation-set-masked>2. El Validation Set Masked<a hidden class=anchor aria-hidden=true href=#2-el-validation-set-masked>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>housing_known</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl><span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span></code></pre></div><p>Este <strong>trick es crítico</strong>. No puedes evaluar imputation strategies en los missing values reales—no sabes la verdad. Entonces:</p><ol><li>Tomas filas donde el target NO falta</li><li>Splits en train/val</li><li>Artificialmente maskeas el target en val</li><li>Comparas qué tan bien cada imputer reconstruye los valores que conocías</li></ol><p>Es <strong>validación cruzada para preprocesamiento</strong>, no solo para modelos.</p><h4 id=3-por-qué-knn-necesita-scaling>3. Por Qué KNN Necesita Scaling<a hidden class=anchor aria-hidden=true href=#3-por-qué-knn-necesita-scaling>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span></code></pre></div><p>KNN calcula distancias euclidianas entre observaciones. Si una feature está en rango [0, 1] y otra en [0, 10000], <strong>la segunda domina completamente</strong>.</p><p>StandardScaler normaliza todo a media 0, std 1. Ahora todas las features contribuyen equitativamente.</p><p><strong>IterativeImputer con RandomForest NO necesita scaling</strong>—los árboles son invariantes a escala.</p><h4 id=4-el-imputer-como-tuple>4. El Imputer Como Tuple<a hidden class=anchor aria-hidden=true href=#4-el-imputer-como-tuple>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... apply both</span>
</span></span></code></pre></div><p>Si KNN ganó, necesitas guardar <strong>tanto el scaler como el imputer</strong>. En producción, cuando llegan datos nuevos:</p><ol><li>Escalar con el mismo scaler fitted en training</li><li>Aplicar KNN imputer</li><li>Inverse transform para volver a escala original</li></ol><p>Guardar solo el imputer sin el scaler <strong>rompería todo</strong>.</p><h3 id=uso-en-el-pipeline>Uso en el Pipeline<a hidden class=anchor aria-hidden=true href=#uso-en-el-pipeline>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En main.py del Step 02</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>analyzer</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>target_column</span><span class=o>=</span><span class=s2>&#34;total_bedrooms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log a W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>comparison_plot</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>create_comparison_plot</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/comparison&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>comparison_plot</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_method&#34;</span><span class=p>:</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_rmse&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Aplicar al dataset completo</span>
</span></span><span class=line><span class=cl><span class=n>housing_clean</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>apply_best_imputer</span><span class=p>(</span><span class=n>housing_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Guardar imputer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=lo-que-esto-logra>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé median porque es lo que hace todo el mundo.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Comparé 4 estrategias. IterativeImputer con RandomForest tuvo 15% menor RMSE que median. Aquí está el plot en W&amp;B dashboard run <code>abc123</code>. El imputer está serializado en MLflow.&rdquo;</p><p>Ahora tienes <strong>evidencia cuantificable</strong> de por qué elegiste lo que elegiste. Seis meses después, cuando alguien pregunta, <strong>los datos están ahí</strong>.</p><hr><p><a name=step-03></a></p><h2 id=5-step-03-feature-engineering---kmeans-como-feature-no-solo-clustering>5. Step 03: Feature Engineering - KMeans Como Feature, No Solo Clustering<a hidden class=anchor aria-hidden=true href=#5-step-03-feature-engineering---kmeans-como-feature-no-solo-clustering>#</a></h2><h3 id=el-problema-real-1>El Problema Real<a hidden class=anchor aria-hidden=true href=#el-problema-real-1>#</a></h3><p>California tiene patrones geográficos fuertes. Casas en San Francisco se comportan diferente que casas en el valle central. Pero latitude/longitude como features crudas no capturan esto bien—un modelo lineal no puede aprender &ldquo;esta área es cara&rdquo;.</p><p><strong>Solución:</strong> Clustering geográfico. Pero no para segmentar datos, sino para <strong>crear una feature categórica</strong>: <code>cluster_label</code>.</p><h3 id=clustersimilarity-custom-transformer>ClusterSimilarity: Custom Transformer<a hidden class=anchor aria-hidden=true href=#clustersimilarity-custom-transformer>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>KMeans</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ClusterSimilarity</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Custom transformer para clustering geográfico.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Design: Transformer de scikit-learn para integrarse en Pipeline.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span> <span class=o>=</span> <span class=n>n_clusters</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>gamma</span>  <span class=c1># Placeholder para RBF kernel (no usado actualmente)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Fit KMeans en coordenadas geográficas.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>sample_weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Transforma coordenadas a cluster labels.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>cluster_labels</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>cluster_labels</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_feature_names_out</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Retorna nombres de features para Pipeline.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=s2>&#34;cluster_label&#34;</span><span class=p>]</span>
</span></span></code></pre></div><h3 id=el-pipeline-de-preprocessing-completo>El Pipeline de Preprocessing Completo<a hidden class=anchor aria-hidden=true href=#el-pipeline-de-preprocessing-completo>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.compose</span> <span class=kn>import</span> <span class=n>ColumnTransformer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span><span class=p>,</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Crea pipeline que procesa:
</span></span></span><span class=line><span class=cl><span class=s2>    - Numéricas: impute + scale
</span></span></span><span class=line><span class=cl><span class=s2>    - Categóricas: impute + one-hot
</span></span></span><span class=line><span class=cl><span class=s2>    - Geo: clustering
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;standardize&#34;</span><span class=p>,</span> <span class=n>StandardScaler</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;most_frequent&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;onehot&#34;</span><span class=p>,</span> <span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_attribs</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;longitude&#34;</span><span class=p>,</span> <span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;housing_median_age&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;total_rooms&#34;</span><span class=p>,</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span> <span class=s2>&#34;population&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;households&#34;</span><span class=p>,</span> <span class=s2>&#34;median_income&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_attribs</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;ocean_proximity&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>preprocessing</span> <span class=o>=</span> <span class=n>ColumnTransformer</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;num&#34;</span><span class=p>,</span> <span class=n>num_pipeline</span><span class=p>,</span> <span class=n>num_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;cat&#34;</span><span class=p>,</span> <span class=n>cat_pipeline</span><span class=p>,</span> <span class=n>cat_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;geo&#34;</span><span class=p>,</span> <span class=n>ClusterSimilarity</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>),</span>
</span></span><span class=line><span class=cl>         <span class=p>[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>preprocessing</span>
</span></span></code></pre></div><h3 id=optimización-automática-de-n_clusters>Optimización Automática de n_clusters<a hidden class=anchor aria-hidden=true href=#optimización-automática-de-n_clusters>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>silhouette_score</span><span class=p>,</span> <span class=n>davies_bouldin_score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>optimize_n_clusters</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_clusters</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_clusters</span><span class=o>=</span><span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=n>Dict</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Busca el mejor K para KMeans usando silhouette score.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Métricas:
</span></span></span><span class=line><span class=cl><span class=s2>    - Silhouette score (0 a 1): Separación de clusters. Maximizar.
</span></span></span><span class=line><span class=cl><span class=s2>    - Davies-Bouldin index: Dispersión interna vs separación. Minimizar.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>geo_features</span> <span class=o>=</span> <span class=n>df</span><span class=p>[[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cluster_range</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=n>min_clusters</span><span class=p>,</span> <span class=n>max_clusters</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>silhouette_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>davies_bouldin_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>inertias</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>cluster_range</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>geo_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>silhouette_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>silhouette_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>davies_bouldin_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>davies_bouldin_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>inertias</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Seleccionar K con mejor silhouette</span>
</span></span><span class=line><span class=cl>    <span class=n>optimal_n</span> <span class=o>=</span> <span class=n>cluster_range</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>:</span> <span class=n>optimal_n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_silhouette&#34;</span><span class=p>:</span> <span class=nb>max</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;cluster_range&#34;</span><span class=p>:</span> <span class=nb>list</span><span class=p>(</span><span class=n>cluster_range</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>silhouette_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;davies_bouldin_scores&#34;</span><span class=p>:</span> <span class=n>davies_bouldin_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;inertias&#34;</span><span class=p>:</span> <span class=n>inertias</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>optimal_n</span><span class=p>,</span> <span class=n>metrics</span>
</span></span></code></pre></div><h3 id=visualización-elbow-method--silhouette>Visualización: Elbow Method + Silhouette<a hidden class=anchor aria-hidden=true href=#visualización-elbow-method--silhouette>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea plots de optimización de K.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 1: Elbow Method (Inertia)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig1</span><span class=p>,</span> <span class=n>ax1</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;inertias&#34;</span><span class=p>],</span> <span class=s1>&#39;bo-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal K=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Inertia&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Elbow Method - KMeans Optimization&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 2: Silhouette Score</span>
</span></span><span class=line><span class=cl>    <span class=n>fig2</span><span class=p>,</span> <span class=n>ax2</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>],</span> <span class=s1>&#39;go-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Silhouette Score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Silhouette Score vs K&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>:</span> <span class=n>fig1</span><span class=p>,</span> <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>fig2</span><span class=p>}</span>
</span></span></code></pre></div><h3 id=uso-en-el-pipeline-1>Uso en el Pipeline<a hidden class=anchor aria-hidden=true href=#uso-en-el-pipeline-1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En main.py del Step 03</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Descargar datos desde GCS</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>download_from_gcs</span><span class=p>(</span><span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Optimizar K</span>
</span></span><span class=line><span class=cl><span class=n>optimal_k</span><span class=p>,</span> <span class=n>metrics</span> <span class=o>=</span> <span class=n>optimize_n_clusters</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>min_clusters</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>max_clusters</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Optimal K: </span><span class=si>{</span><span class=n>optimal_k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   Silhouette: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;best_silhouette&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Crear plots</span>
</span></span><span class=line><span class=cl><span class=n>plots</span> <span class=o>=</span> <span class=n>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log a W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/optimal_k&#34;</span><span class=p>:</span> <span class=n>optimal_k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;best_silhouette&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/elbow_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Crear pipeline con K óptimo</span>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>optimal_k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit pipeline</span>
</span></span><span class=line><span class=cl><span class=n>target_column</span> <span class=o>=</span> <span class=s2>&#34;median_house_value&#34;</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform data</span>
</span></span><span class=line><span class=cl><span class=n>X_transformed</span> <span class=o>=</span> <span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Reconstruir DataFrame con target</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>X_transformed</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>columns</span><span class=o>=</span><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upload a GCS</span>
</span></span><span class=line><span class=cl><span class=n>upload_to_gcs</span><span class=p>(</span><span class=n>df_transformed</span><span class=p>,</span> <span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Guardar pipeline</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-1>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-1>#</a></h3><h4 id=1-por-qué-silhouette-score>1. Por Qué Silhouette Score<a hidden class=anchor aria-hidden=true href=#1-por-qué-silhouette-score>#</a></h4><p><strong>Silhouette score</strong> (rango 0 a 1) mide qué tan bien separados están los clusters:</p><ul><li><strong>1.0:</strong> Clusters perfectamente separados</li><li><strong>0.5:</strong> Overlap moderado</li><li><strong>0.0:</strong> Clusters aleatorios</li></ul><p>Es <strong>interpretable</strong> y generalmente correlaciona bien con calidad visual de clusters.</p><p><strong>Davies-Bouldin index:</strong> También lo calculamos pero no lo usamos para decisión—es más sensible a outliers.</p><h4 id=2-la-crítica-obvia>2. La Crítica Obvia<a hidden class=anchor aria-hidden=true href=#2-la-crítica-obvia>#</a></h4><p>Este código optimiza <code>n_clusters</code> basándose en <strong>métricas de clustering</strong>, no en <strong>performance del modelo final</strong>.</p><p>Un approach más riguroso sería:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_transformed</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mape</span> <span class=o>=</span> <span class=n>calculate_mape</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_test_transformed</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Seleccionar K con mejor MAPE</span>
</span></span></code></pre></div><p>Esto tomaría <strong>10x más tiempo</strong> pero sería más riguroso.</p><p><strong>Trade-off:</strong> Este pipeline prioriza velocidad sobre rigor absoluto. Para California Housing, silhouette score es suficientemente bueno. Para datasets más complejos, considera el approach de cross-validation completo.</p><h4 id=3-handle_unknownignore-en-onehotencoder>3. handle_unknown=&ldquo;ignore&rdquo; en OneHotEncoder<a hidden class=anchor aria-hidden=true href=#3-handle_unknownignore-en-onehotencoder>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Crítico para producción.</strong> Si en training tienes categorías <code>["&lt;1H OCEAN", "INLAND", "NEAR BAY"]</code> pero en producción llega <code>"ISLAND"</code> (que no viste), el encoder:</p><ul><li><strong>Sin <code>handle_unknown</code>:</strong> Explota con ValueError</li><li><strong>Con <code>handle_unknown="ignore"</code>:</strong> Genera vector de ceros para esa observación</li></ul><p>Pierdes información de esa observación, pero el <strong>API no devuelve HTTP 500</strong>.</p><h4 id=4-por-qué-guardar-el-pipeline-no-solo-el-modelo>4. Por Qué Guardar el Pipeline, No Solo el Modelo<a hidden class=anchor aria-hidden=true href=#4-por-qué-guardar-el-pipeline-no-solo-el-modelo>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>En producción, necesitas:</p><ol><li>Cargar el pipeline</li><li>Transform datos nuevos</li><li>Predecir con el modelo</li></ol><p>Si solo guardas el modelo, no sabes:</p><ul><li>Qué features espera</li><li>En qué orden</li><li>Qué transformaciones aplicar</li></ul><p>El pipeline <strong>encapsula todo eso</strong>.</p><h3 id=lo-que-esto-logra-1>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra-1>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé KMeans con K=10 porque leí que 10 clusters es bueno.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Probé K de 5 a 15. K=8 maximizó silhouette score (0.64). Aquí están los plots de elbow method y silhouette. El pipeline con K=8 está serializado en MLflow.&rdquo;</p><p><strong>Evidencia cuantificable + artifact reproducible.</strong></p><hr><p><a name=step-06></a></p><h2 id=6-step-06-hyperparameter-sweep---optimización-bayesiana-con-wb>6. Step 06: Hyperparameter Sweep - Optimización Bayesiana con W&amp;B<a hidden class=anchor aria-hidden=true href=#6-step-06-hyperparameter-sweep---optimización-bayesiana-con-wb>#</a></h2><h3 id=el-problema-de-model-selection-vs-hyperparameter-tuning>El Problema de Model Selection vs Hyperparameter Tuning<a hidden class=anchor aria-hidden=true href=#el-problema-de-model-selection-vs-hyperparameter-tuning>#</a></h3><p>La mayoría de los proyectos de ML cometen este error: entrenan un Random Forest en un notebook, ajustan algunos hiperparámetros hasta que R² se ve &ldquo;bien&rdquo; y declaran victoria. Tres meses después, cuando alguien pregunta &ldquo;¿por qué Random Forest y no XGBoost?&rdquo;, la respuesta es silencio incómodo.</p><p><strong>Este pipeline separa dos fases:</strong></p><ol><li><strong>Model Selection (Step 05):</strong> Compara algoritmos con GridSearch rápido (5-10 combos por modelo)</li><li><strong>Hyperparameter Sweep (Step 06):</strong> Optimiza el ganador con Bayesian search exhaustivo (50+ runs)</li></ol><p><strong>Razón:</strong> No tienes tiempo ni cómputo para hacer sweep exhaustivo de 5 algoritmos. Primero decides <strong>estrategia</strong> (qué algoritmo), luego <strong>tácticas</strong> (qué hiperparámetros).</p><h3 id=sweep_configyaml-el-espacio-de-búsqueda>sweep_config.yaml: El Espacio de Búsqueda<a hidden class=anchor aria-hidden=true href=#sweep_configyaml-el-espacio-de-búsqueda>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># W&amp;B Sweep Configuration for Random Forest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Autor: Carlos Daniel Jiménez</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>program</span><span class=p>:</span><span class=w> </span><span class=l>main.py</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># Bayesian optimization, no random, no grid</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE (menos sesgado que MAPE)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>goal</span><span class=p>:</span><span class=w> </span><span class=l>minimize</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>values</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s1>&#39;sqrt&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;log2&#39;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Early stopping: elimina runs pobres temprano</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>   </span><span class=c># Mínimo 10 runs antes de terminar</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>         </span><span class=c># Elimina 1/3 de runs pobres</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>s</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>housing-rf-sweep-improved</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Optimize Random Forest with wmape + feature tracking&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=mainpy-del-step-06-el-sweep-real>main.py del Step 06: El Sweep Real<a hidden class=anchor aria-hidden=true href=#mainpy-del-step-06-el-sweep-real>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>W&amp;B Sweep for Random Forest Hyperparameter Optimization.
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>yaml</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>utils</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>download_data_from_gcs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prepare_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_random_forest</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluate_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>log_feature_importances</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Module-level data cache (cargado una vez, reusado en todos los runs)</span>
</span></span><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;feature_names&#34;</span><span class=p>:</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Training function llamada por W&amp;B Sweep agent.
</span></span></span><span class=line><span class=cl><span class=s2>    Ejecutada para cada combinación de hiperparámetros.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Usa module-level cache para evitar recargar datos en cada run.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SWEEP RUN: </span><span class=si>{</span><span class=n>run</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Preparar parámetros</span>
</span></span><span class=line><span class=cl>        <span class=n>params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;n_estimators&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>n_estimators</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>max_depth</span><span class=p>)</span> <span class=k>if</span> <span class=n>config</span><span class=o>.</span><span class=n>max_depth</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_split</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_leaf</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_features&#39;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>max_features</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;random_state&#39;</span><span class=p>:</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Train model usando cached data</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>train_random_forest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>params</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluate model</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log feature importances</span>
</span></span><span class=line><span class=cl>        <span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log todo a W&amp;B</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>               <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SUCCESS: MAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% | &#34;</span>
</span></span><span class=line><span class=cl>                   <span class=sa>f</span><span class=s2>&#34;WMAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;wmape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ERROR: Run failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=mf>999.9</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=mf>999.9</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>run</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Main function para inicializar y ejecutar el sweep.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_train_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_test_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--bucket_name&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--wandb_project&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--target_column&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;median_house_value&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_count&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_config&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;sweep_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;W&amp;B SWEEP - HYPERPARAMETER OPTIMIZATION&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Cargar datos UNA VEZ en module-level cache</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Loading data into cache...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>train_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_train_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_test_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>test_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Store in cache</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Data cached: Train </span><span class=si>{</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, Test </span><span class=si>{</span><span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Load sweep configuration</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=n>args</span><span class=o>.</span><span class=n>sweep_config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>sweep_config_path</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_config</span> <span class=o>=</span> <span class=n>yaml</span><span class=o>.</span><span class=n>safe_load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep config:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Method: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;method&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Metric: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;goal&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize sweep</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_id</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep</span><span class=o>=</span><span class=n>sweep_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep created: </span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  View at: https://wandb.ai/</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/sweeps/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Run sweep agent</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Starting sweep agent (</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=si>}</span><span class=s2> runs)...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>function</span><span class=o>=</span><span class=n>train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>count</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;SWEEP COMPLETED&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Guardar best params</span>
</span></span><span class=line><span class=cl>    <span class=n>api</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Api</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep</span> <span class=o>=</span> <span class=n>api</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>best_run</span> <span class=o>=</span> <span class=n>sweep</span><span class=o>.</span><span class=n>best_run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;hyperparameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>))</span> <span class=k>if</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>)</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_features&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;mape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;wmape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;r2&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;sweep_id&#34;</span><span class=p>:</span> <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_run_id&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Guardar a YAML</span>
</span></span><span class=line><span class=cl>    <span class=n>best_params_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=s2>&#34;best_params.yaml&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>best_params_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>best_params</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Best params saved to: </span><span class=si>{</span><span class=n>best_params_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   MAPE: </span><span class=si>{</span><span class=n>best_params</span><span class=p>[</span><span class=s1>&#39;metrics&#39;</span><span class=p>][</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-2>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-2>#</a></h3><h4 id=1-bayesian-optimization-no-random-search>1. Bayesian Optimization, No Random Search<a hidden class=anchor aria-hidden=true href=#1-bayesian-optimization-no-random-search>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># No random, no grid</span><span class=w>
</span></span></span></code></pre></div><p><strong>Random search:</strong> Prueba combinaciones aleatorias. No aprende de runs anteriores.</p><p><strong>Grid search:</strong> Prueba todas las combinaciones. Exhaustivo pero <strong>carísimo</strong> (5 × 4 × 3 × 3 × 2 = 360 combos).</p><p><strong>Bayesian optimization:</strong> Construye un modelo probabilístico de la función que optimizas (MAPE en función de hiperparámetros) y usa ese modelo para decidir qué probar siguiente.</p><p>Si detecta que <code>max_depth=None</code> consistentemente da mejor MAPE, <strong>explora más en esa región</strong> del espacio.</p><p><strong>50 runs es &lt;15% del espacio total</strong>, pero capturan el 80% del beneficio posible.</p><h4 id=2-wmape-no-mape>2. wMAPE, No MAPE<a hidden class=anchor aria-hidden=true href=#2-wmape-no-mape>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE</span><span class=w>
</span></span></span></code></pre></div><p><strong>MAPE estándar:</strong> Penaliza errores en casas baratas más que en casas caras.</p><p>Si una casa vale $10,000 y predices $12,000, error = 20%.
Si una casa vale $500,000 y predices $510,000, error = 2%.</p><p>Ambos errores son <strong>$10,000</strong>, pero MAPE los ve radicalmente diferentes.</p><p><strong>wMAPE (Weighted MAPE):</strong> Pondera por el valor real. Menos sesgado hacia valores bajos.</p><p><strong>Por qué funciona aquí:</strong> California Housing no tiene casas de $0. Rango está entre $15k y $500k—razonablemente acotado.</p><h4 id=3-variables-globales-para-data-cache>3. Variables Globales Para Data Cache<a hidden class=anchor aria-hidden=true href=#3-variables-globales-para-data-cache>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Las variables globales son generalmente código sucio. <strong>Aquí son la decisión correcta.</strong></p><p>Cada run del sweep necesita los mismos datos. Sin cache, cargarías desde GCS <strong>50 veces</strong>. Con California Housing (20k filas), eso son segundos desperdiciados. Con datasets más grandes, son <strong>minutos u horas</strong>.</p><p><strong>Alternativa &ldquo;limpia&rdquo;:</strong> Pasar datos como argumento a cada función. Pero W&amp;B Sweeps tiene interfaz fija—la función que pasas a <code>wandb.agent()</code> no puede recibir argumentos adicionales.</p><p>Las variables globales aquí tienen <strong>scope limitado</strong>—solo existen durante el proceso del sweep.</p><h4 id=4-early-stopping-con-hyperband>4. Early Stopping con Hyperband<a hidden class=anchor aria-hidden=true href=#4-early-stopping-con-hyperband>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><p><strong>Hyperband</strong> elimina runs pobres temprano. Si después de 10 runs un set de hiperparámetros muestra MAPE de 25% mientras otros están en 8%, Hyperband lo <strong>detiene</strong>.</p><p><strong>eta=3:</strong> Elimina el peor tercio de runs en cada iteración.</p><p><strong>Beneficio:</strong> Ahorras cómputo en hiperparámetros obviamente malos.</p><h4 id=5-feature-importances-loggeadas>5. Feature Importances Loggeadas<a hidden class=anchor aria-hidden=true href=#5-feature-importances-loggeadas>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>feature_names</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>       <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><p>Random Forest calcula feature importances <strong>gratis</strong>. Sería valioso loggearlo para entender qué features dominan el modelo.</p><p>En W&amp;B dashboard, puedes comparar runs y ver &ldquo;en el mejor run, <code>median_income</code> tuvo importance de 0.45&rdquo;.</p><h3 id=el-output-crítico-best_paramsyaml>El Output Crítico: best_params.yaml<a hidden class=anchor aria-hidden=true href=#el-output-crítico-best_paramsyaml>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>hyperparameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w> </span><span class=m>200</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w> </span><span class=l>sqrt</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mape</span><span class=p>:</span><span class=w> </span><span class=m>7.82</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>wmape</span><span class=p>:</span><span class=w> </span><span class=m>7.65</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>r2</span><span class=p>:</span><span class=w> </span><span class=m>0.87</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep_id</span><span class=p>:</span><span class=w> </span><span class=l>abc123xyz</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>best_run_id</span><span class=p>:</span><span class=w> </span><span class=l>run_456</span><span class=w>
</span></span></span></code></pre></div><p>Los hiperparámetros óptimos se guardan en <strong>YAML</strong>, not pickle. Razón:</p><p><strong>YAML es legible y git-friendly.</strong> Si en el próximo retraining cambias de <code>n_estimators=200</code> a <code>n_estimators=300</code>, un <code>git diff</code> lo muestra claramente.</p><p>Con pickle, es un <strong>blob binario opaco</strong>.</p><h3 id=lo-que-esto-logra-2>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra-2>#</a></h3><p><strong>Sin esto:</strong> &ldquo;Usé <code>n_estimators=100</code> porque es el default de scikit-learn.&rdquo;</p><p><strong>Con esto:</strong> &ldquo;Corrí sweep bayesiano de 50 runs. Optimal config: <code>n_estimators=200, max_depth=20</code>. MAPE mejoró de 8.5% a 7.8%. Aquí está el sweep en W&amp;B: <code>wandb.ai/project/sweeps/abc123</code>.&rdquo;</p><p><strong>Evidencia cuantificable</strong> de por qué elegiste cada hiperparámetro.</p><hr><p><a name=step-07></a></p><h2 id=7-step-07-model-registry---versionamiento-en-mlflow>7. Step 07: Model Registry - Versionamiento en MLflow<a hidden class=anchor aria-hidden=true href=#7-step-07-model-registry---versionamiento-en-mlflow>#</a></h2><h3 id=por-qué-no-basta-con-guardar-el-pickle>Por Qué No Basta con Guardar el Pickle<a hidden class=anchor aria-hidden=true href=#por-qué-no-basta-con-guardar-el-pickle>#</a></h3><p>La tentación es:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;best_model.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Esto funciona hasta que necesitas responder:</p><ul><li>¿Qué hiperparámetros usó?</li><li>¿Con qué datos se entrenó?</li><li>¿Qué métricas logró?</li><li>¿Cómo rollback a la versión anterior?</li></ul><p><strong>MLflow Model Registry</strong> resuelve esto.</p><h3 id=register_model_to_mlflow-el-core>register_model_to_mlflow(): El Core<a hidden class=anchor aria-hidden=true href=#register_model_to_mlflow-el-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Registro de modelo en MLflow Model Registry.
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow.sklearn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mlflow.tracking</span> <span class=kn>import</span> <span class=n>MlflowClient</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>register_model_to_mlflow</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_stage</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_columns</span><span class=p>:</span> <span class=nb>list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_train_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_test_path</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Registra modelo en MLflow Model Registry con metadata rica.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: Trained sklearn model
</span></span></span><span class=line><span class=cl><span class=s2>        model_name: Nombre para registered model
</span></span></span><span class=line><span class=cl><span class=s2>        model_stage: Stage (Staging/Production)
</span></span></span><span class=line><span class=cl><span class=s2>        params: Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>        metrics: Métricas de evaluación
</span></span></span><span class=line><span class=cl><span class=s2>        feature_columns: Lista de features
</span></span></span><span class=line><span class=cl><span class=s2>        target_column: Target column name
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_train_path: Path a training data
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_test_path: Path a test data
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        (model_uri, model_version, run_id)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;REGISTERING MODEL TO MLFLOW&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>run_id</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>active_run</span><span class=p>()</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;runs:/</span><span class=si>{</span><span class=n>run_id</span><span class=si>}</span><span class=s2>/model&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Log model to MLflow</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model logged: </span><span class=si>{</span><span class=n>model_uri</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create or get registered model</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>create_registered_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Housing price prediction - Random Forest&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Created new registered model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;already exists&#34;</span> <span class=ow>in</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model already exists: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create model version</span>
</span></span><span class=line><span class=cl>    <span class=n>model_version</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>run_id</span><span class=o>=</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Version created: </span><span class=si>{</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Transition to stage</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stage</span><span class=o>=</span><span class=n>model_stage</span>  <span class=c1># &#34;Staging&#34; or &#34;Production&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Transitioned to: </span><span class=si>{</span><span class=n>model_stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create comprehensive description (MARKDOWN)</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest Regressor
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_depth: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>,</span> <span class=s1>&#39;None&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_split: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_leaf: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_features: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>,</span> <span class=s1>&#39;sqrt&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Median APE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;median_ape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Within 10%: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- RMSE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- R²: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Features
</span></span></span><span class=line><span class=cl><span class=s2>- Number of features: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Target: </span><span class=si>{</span><span class=n>target_column</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Data Sources
</span></span></span><span class=line><span class=cl><span class=s2>- Training: </span><span class=si>{</span><span class=n>gcs_train_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Testing: </span><span class=si>{</span><span class=n>gcs_test_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>update_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=n>description</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Add searchable tags</span>
</span></span><span class=line><span class=cl>    <span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;framework&#34;</span><span class=p>:</span> <span class=s2>&#34;sklearn&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_10pct&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rmse&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_features&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;target&#34;</span><span class=p>:</span> <span class=n>target_column</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>key</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Tags added to model version&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model_uri</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>run_id</span>
</span></span></code></pre></div><h3 id=decisiones-técnicas-críticas-3>Decisiones Técnicas Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-técnicas-críticas-3>#</a></h3><h4 id=1-artifact-vs-registered-model>1. Artifact vs Registered Model<a hidden class=anchor aria-hidden=true href=#1-artifact-vs-registered-model>#</a></h4><p><strong>Artifact:</strong> Pickle guardado en un run específico. Para usarlo, necesitas el <code>run_id</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>  <span class=c1># Solo artifact</span>
</span></span><span class=line><span class=cl><span class=c1># Uso: mlflow.sklearn.load_model(f&#34;runs://{run_id}/model&#34;)</span>
</span></span></code></pre></div><p><strong>Registered Model:</strong> Versionado con nombre semántico, stages y metadata.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Uso: mlflow.pyfunc.load_model(&#34;models:/housing_price_model/Production&#34;)</span>
</span></span></code></pre></div><p>En producción, tu API carga <code>models:/housing_price_model/Production</code>, <strong>no <code>runs:/abc123/model</code></strong>.</p><p>Cuando registras una nueva versión, la transicionas a Production y el deployment <strong>automáticamente</strong> toma la nueva versión.</p><h4 id=2-metadata-rica-en-markdown>2. Metadata Rica en Markdown<a hidden class=anchor aria-hidden=true href=#2-metadata-rica-en-markdown>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>Esto guarda <strong>markdown en la descripción</strong> del modelo. Cuando abres MLflow UI y navegas a <code>housing_price_model v3</code>, ves:</p><ul><li>Qué hiperparámetros usó</li><li>Qué métricas logró</li><li>De dónde vinieron los datos</li></ul><p><strong>Por qué es oro:</strong> Seis meses después, cuando alguien pregunta &ldquo;¿por qué el modelo v3 tiene mejor MAPE que v2?&rdquo;, abres MLflow y <strong>la respuesta está ahí</strong>.</p><p>No necesitas buscar en logs ni preguntar a quien lo entrenó.</p><h4 id=3-tags-para-búsqueda>3. Tags Para Búsqueda<a hidden class=anchor aria-hidden=true href=#3-tags-para-búsqueda>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span>
</span></span></code></pre></div><p>En MLflow puedes <strong>filtrar modelos por tags</strong>. &ldquo;Muéstrame todos los modelos con MAPE &lt; 8%&rdquo; es una query que funciona si taggeaste consistentemente.</p><h4 id=4-model-config-file-single-source-of-truth>4. Model Config File: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#4-model-config-file-single-source-of-truth>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>model_version</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;stage&#39;</span><span class=p>:</span> <span class=n>model_stage</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;parameters&#39;</span><span class=p>:</span> <span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;feature_columns&#39;</span><span class=p>:</span> <span class=n>feature_columns</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;mlflow_run_id&#39;</span><span class=p>:</span> <span class=n>run_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;sweep_id&#39;</span><span class=p>:</span> <span class=n>sweep_id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;configs/model_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>config_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model_config</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>config_path</span><span class=p>),</span> <span class=n>artifact_path</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Este YAML se loggea a MLflow <strong>Y</strong> se guarda en el repo (en <code>configs/model_config.yaml</code>).</p><p><strong>Por qué YAML y no solo MLflow:</strong> Tu FastAPI app necesita leer configuración al iniciar. Puede hacer <code>mlflow.load_model()</code> para el pickle, pero necesita saber los <strong>feature names</strong> para validación de input.</p><p>El YAML es esa <strong>single source of truth</strong>.</p><h4 id=5-versionado-en-git>5. Versionado en Git<a hidden class=anchor aria-hidden=true href=#5-versionado-en-git>#</a></h4><p>Cuando commiteas <code>model_config.yaml</code>, el diff muestra:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl><span class=gd>- version: 2
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ version: 3
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- mape: 8.5
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ mape: 7.8
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- n_estimators: 100
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ n_estimators: 200
</span></span></span></code></pre></div><p>Es <strong>auditable</strong>. Sabes exactamente qué cambió entre versiones.</p><h3 id=el-flujo-completo-sweep--registration--production>El Flujo Completo: Sweep → Registration → Production<a hidden class=anchor aria-hidden=true href=#el-flujo-completo-sweep--registration--production>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. Model Selection (Step 05)</span>
</span></span><span class=line><span class=cl>python src/model/05_model_selection/main.py
</span></span><span class=line><span class=cl><span class=c1># Output: &#34;Best: RandomForestRegressor (MAPE: 8.2%)&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Hyperparameter Sweep (Step 06)</span>
</span></span><span class=line><span class=cl>python src/model/06_sweep/main.py --sweep_count<span class=o>=</span><span class=m>50</span>
</span></span><span class=line><span class=cl><span class=c1># Output: best_params.yaml con hiperparámetros óptimos</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Model Registration (Step 07)</span>
</span></span><span class=line><span class=cl>python src/model/07_registration/main.py --params_file<span class=o>=</span>best_params.yaml
</span></span><span class=line><span class=cl><span class=c1># Output: Modelo registrado en MLflow Registry</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Transition to Production (manual)</span>
</span></span><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span></code></pre></div><h3 id=lo-que-este-approach-soluciona>Lo Que Este Approach Soluciona<a hidden class=anchor aria-hidden=true href=#lo-que-este-approach-soluciona>#</a></h3><p><strong>Sin Model Registry:</strong></p><ul><li>Pickles en carpetas: <code>model_v3_final_FINAL_2.pkl</code></li><li>No sabes qué hiperparámetros usa cada uno</li><li>Rollback = buscar el pickle correcto en GCS</li></ul><p><strong>Con Model Registry:</strong></p><ul><li>Modelos con versiones semánticas: v1, v2, v3</li><li>Metadata embebida: params, metrics, data sources</li><li>Rollback = <code>transition v3 to Archived</code> + <code>transition v2 to Production</code></li></ul><hr><p><a name=github-actions></a></p><h2 id=8-cicd-con-github-actions-automatización-del-pipeline-completo>8. CI/CD con GitHub Actions: Automatización del Pipeline Completo<a hidden class=anchor aria-hidden=true href=#8-cicd-con-github-actions-automatización-del-pipeline-completo>#</a></h2><hr><h2 id=navegación>Navegación<a hidden class=anchor aria-hidden=true href=#navegación>#</a></h2><p><strong><a href=/mlops/>← Inicio</a></strong> | <strong><a href=/mlops/anatomia-pipeline-mlops-parte-2/>Parte 2: Deployment e Infraestructura →</a></strong></p><p>En la Parte 2 cubriremos:</p><ul><li>CI/CD con GitHub Actions</li><li>W&amp;B vs MLflow: Estrategias complementarias</li><li>Containerización completa con Docker</li><li>Arquitectura FastAPI en producción</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://carlosdanieljimenez.com/tags/mlops/>Mlops</a></li><li><a href=https://carlosdanieljimenez.com/tags/machine-learning/>Machine-Learning</a></li><li><a href=https://carlosdanieljimenez.com/tags/python/>Python</a></li><li><a href=https://carlosdanieljimenez.com/tags/gcp/>Gcp</a></li><li><a href=https://carlosdanieljimenez.com/tags/mlflow/>Mlflow</a></li><li><a href=https://carlosdanieljimenez.com/tags/wandb/>Wandb</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://carlosdanieljimenez.com/>The Probability Engine</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><div class=newsletter-cta><div class=newsletter-content><h3>📬 Did this help?</h3><p>I write about MLOps, Edge AI, and making models work outside the lab.
One email per month, max. No spam, no course pitches, just technical content.</p><form action=https://buttondown.com/api/emails/embed-subscribe/carlosjimenez88m method=post class=newsletter-form target=popupwindow onsubmit='window.open("https://buttondown.com/carlosjimenez88m","popupwindow")'><div class=form-group><input type=email name=email id=bd-email placeholder=your@email.com required aria-label="Email address">
<input type=submit value=Subscribe></div></form><p class=newsletter-stats>Join engineers building ML systems and Edge Computing infrastructure.</p></div></div><style>.newsletter-cta{margin:3rem auto 2rem;padding:2rem;max-width:650px;background:var(--entry);border:1px solid var(--border);border-radius:8px;text-align:center}.newsletter-content h3{margin:0 0 1rem;font-size:1.5rem;color:var(--primary)}.newsletter-content p{margin:0 0 1.5rem;color:var(--secondary);line-height:1.6}.newsletter-form{margin:1.5rem 0}.form-group{display:flex;gap:.5rem;max-width:500px;margin:0 auto;flex-wrap:wrap;justify-content:center}.newsletter-form input[type=email]{flex:1;min-width:250px;padding:.75rem 1rem;font-size:1rem;border:1px solid var(--border);border-radius:6px;background:var(--theme);color:var(--content);transition:border-color .2s ease}.newsletter-form input[type=email]:focus{outline:none;border-color:var(--primary);box-shadow:0 0 0 3px rgba(var(--primary-rgb),.1)}.newsletter-form input[type=submit]{padding:.75rem 2rem;font-size:1rem;font-weight:600;color:#fff;background:var(--primary);border:none;border-radius:6px;cursor:pointer;transition:opacity .2s ease}.newsletter-form input[type=submit]:hover{opacity:.9}.newsletter-stats{font-size:.875rem;color:var(--secondary);margin-top:1rem;font-style:italic}@media screen and (max-width:600px){.newsletter-cta{padding:1.5rem 1rem;margin:2rem .5rem 1rem}.newsletter-content h3{font-size:1.25rem}.form-group{flex-direction:column;width:100%}.newsletter-form input[type=email],.newsletter-form input[type=submit]{width:100%;min-width:100%}}</style><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>