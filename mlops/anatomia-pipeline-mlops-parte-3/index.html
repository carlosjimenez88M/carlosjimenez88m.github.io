<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices | The Probability Engine</title>
<meta name=keywords content="mlops,testing,production,data-drift,monitoring"><meta name=description content="Parte 3: Estrategias de selección de modelos, testing avanzado, patrones de producción, data drift, model monitoring y checklist de production readiness."><meta name=author content="Carlos Daniel Jiménez"><link rel=canonical href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-3/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=16x16 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=32x32 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=apple-touch-icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=mask-icon href=https://carlosdanieljimenez.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=icon type=image/png href=/img/icon.jpeg><link rel=apple-touch-icon href=/img/icon.jpeg><link rel="shortcut icon" href=/img/icon.jpeg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-3/"><meta property="og:site_name" content="The Probability Engine"><meta property="og:title" content="Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices"><meta property="og:description" content="Parte 3: Estrategias de selección de modelos, testing avanzado, patrones de producción, data drift, model monitoring y checklist de production readiness."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="mlops"><meta property="article:published_time" content="2026-01-13T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-13T00:00:00+00:00"><meta property="article:tag" content="Mlops"><meta property="article:tag" content="Testing"><meta property="article:tag" content="Production"><meta property="article:tag" content="Data-Drift"><meta property="article:tag" content="Monitoring"><meta name=twitter:card content="summary"><meta name=twitter:title content="Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices"><meta name=twitter:description content="Parte 3: Estrategias de selección de modelos, testing avanzado, patrones de producción, data drift, model monitoring y checklist de production readiness."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"MLOps Guides","item":"https://carlosdanieljimenez.com/mlops/"},{"@type":"ListItem","position":2,"name":"Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices","item":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices","name":"Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices","description":"Parte 3: Estrategias de selección de modelos, testing avanzado, patrones de producción, data drift, model monitoring y checklist de production readiness.","keywords":["mlops","testing","production","data-drift","monitoring"],"articleBody":" Serie MLOps Completo: ← Parte 1: Pipeline | ← Parte 2: Deployment | Parte 3 (actual)\n11. Estrategias de Selección de Modelos y Parámetros El Flujo Completo: Selection → Sweep → Registration Este pipeline implementa una estrategia de tres fases para optimización de modelos, cada una con un propósito específico:\nStep 05: Model Selection ├── Compara 5 algoritmos con GridSearch básico (5-10 combos/modelo) ├── Objetivo: Identificar mejor familia de modelo (Random Forest vs Gradient Boosting vs ...) ├── Métrica principal: MAPE (Mean Absolute Percentage Error) └── Output: Mejor algoritmo + parámetros iniciales Step 06: Hyperparameter Sweep ├── Optimiza SOLO el mejor algoritmo del Step 05 ├── Bayesian optimization con 50+ runs (espacio de búsqueda exhaustivo) ├── Objetivo: Encontrar configuración óptima del mejor modelo ├── Métrica principal: wMAPE (Weighted MAPE, menos sesgado) └── Output: best_params.yaml con hiperparámetros óptimos Step 07: Model Registration ├── Entrena modelo final con parámetros de Step 06 ├── Registra en MLflow Model Registry con metadata rica ├── Transiciona a stage (Staging/Production) └── Output: Modelo versionado listo para deployment ¿Por qué tres steps separados? No tienes recursos computacionales para hacer sweep exhaustivo de 5 algoritmos × 50 combinaciones = 250 entrenamientos. Primero decides estrategia (qué algoritmo), luego tácticas (qué hiperparámetros).\nStep 05: Model Selection - Comparación de Algoritmos Los 5 Modelos Candidatos def get_available_models() -\u003e Dict[str, Any]: \"\"\"Get dictionary of available regression models.\"\"\" models = { \"RandomForest\": RandomForestRegressor(random_state=42), \"GradientBoosting\": GradientBoostingRegressor(random_state=42), \"Ridge\": Ridge(random_state=42), \"Lasso\": Lasso(random_state=42), \"DecisionTree\": DecisionTreeRegressor(random_state=42) } return models Por qué estos modelos:\nRandomForest: Ensemble de árboles, robusto, maneja no-linealidades GradientBoosting: Boosting secuencial, mejor precisión que RF pero más lento Ridge: Regresión lineal con regularización L2, rápido, interpretable Lasso: Regresión lineal con regularización L1, hace feature selection DecisionTree: Baseline simple, útil para comparación Lo que falta (deliberadamente):\nXGBoost/LightGBM: No incluidos para reducir dependencias, pero fácil de agregar Neural Networks: Overkill para este problema (20k muestras, features tabulares) SVR: Muy lento en datasets grandes, no escala bien Parameter Grids: GridSearch Inicial def get_default_param_grids() -\u003e Dict[str, Dict[str, list]]: \"\"\" Parameter grids for initial model selection. Refinados basados en domain knowledge. \"\"\" param_grids = { \"RandomForest\": { \"n_estimators\": [50, 100, 200, 300], # 4 opciones \"max_depth\": [10, 15, 20, 25, None], # 5 opciones \"min_samples_split\": [2, 5, 10], # 3 opciones \"min_samples_leaf\": [1, 2, 4], # 3 opciones }, # Total combinaciones: 4×5×3×3 = 180 # Con 5-fold CV: 180×5 = 900 fits \"GradientBoosting\": { \"n_estimators\": [50, 100, 150, 200], # 4 opciones \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2], # 5 opciones \"max_depth\": [3, 4, 5, 6, 7], # 5 opciones \"subsample\": [0.8, 0.9, 1.0], # 3 opciones }, # Total: 4×5×5×3 = 300 combinaciones \"Ridge\": { \"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], }, # Total: 9 combinaciones (rápido) \"Lasso\": { \"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], }, # Total: 9 combinaciones \"DecisionTree\": { \"max_depth\": [5, 10, 15, 20, 25, None], # 6 opciones \"min_samples_split\": [2, 5, 10, 20], # 4 opciones \"min_samples_leaf\": [1, 2, 4, 8], # 4 opciones } # Total: 6×4×4 = 96 combinaciones } return param_grids Decisiones de Diseño de los Grids 1. RandomForest: Foco en Overfitting Control\n\"max_depth\": [10, 15, 20, 25, None], \"min_samples_leaf\": [1, 2, 4], Razonamiento: Random Forest tiende a overfit en datasets pequeños. max_depth y min_samples_leaf controlan profundidad de árboles—valores altos previenen que el modelo memorice ruido.\nNone en max_depth: Permite árboles de profundidad ilimitada. Útil cuando el dataset tiene patrones complejos que requieren splits profundos.\n2. GradientBoosting: Balance Learning Rate vs N_estimators\n\"n_estimators\": [50, 100, 150, 200], \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2], Trade-off clásico:\nLearning rate bajo (0.01) + muchos estimators (200): Aprendizaje lento pero preciso Learning rate alto (0.2) + pocos estimators (50): Rápido pero puede divergir GridSearch explora ambos extremos.\nsubsample \u003c 1.0: Stochastic Gradient Boosting. Solo usa 80-90% de datos en cada iteración, reduce overfitting.\n3. Ridge/Lasso: Alpha en Escala Logarítmica\n\"alpha\": [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0], Alpha controla regularización:\nAlpha bajo (0.01): Casi sin regularización, modelo complejo Alpha alto (500): Regularización fuerte, modelo simple (coeficientes cercanos a 0) Escala logarítmica cubre el espacio de manera más uniforme que escala lineal.\nLasso vs Ridge:\nLasso (L1): Fuerza coeficientes a exactamente 0 → feature selection automática Ridge (L2): Coeficientes pequeños pero no cero → mantiene todas las features Si Lasso gana, indica que algunas features son ruido.\n4. DecisionTree: Baseline de Comparación\nDecisionTree es el peor modelo (alto variance, overfit fácil), pero sirve para:\nVerificar que el pipeline funciona correctamente Baseline de comparación: Si Ridge/Lasso no superan DecisionTree, algo está mal en feature engineering La Función de Entrenamiento con GridSearch def train_model_with_gridsearch( model: Any, param_grid: Dict[str, list], X_train: pd.DataFrame, y_train: pd.Series, cv: int = 5 ) -\u003e Tuple[Any, Dict[str, Any], float, Dict[str, float]]: \"\"\"Train model with K-fold Cross-Validation via GridSearchCV.\"\"\" start_time = time.time() grid_search = GridSearchCV( estimator=model, param_grid=param_grid, cv=5, # 5-fold cross-validation scoring='neg_mean_absolute_error', # CRÍTICO n_jobs=-1, # Paralelización verbose=0, return_train_score=True # Para detectar overfitting ) grid_search.fit(X_train, y_train) training_time = time.time() - start_time # Extract cross-validation results cv_metrics = { \"mean_test_score\": float(-grid_search.best_score_), \"std_test_score\": float(grid_search.cv_results_['std_test_score'][grid_search.best_index_]), \"mean_train_score\": float(-grid_search.cv_results_['mean_train_score'][grid_search.best_index_]), \"std_train_score\": float(grid_search.cv_results_['std_train_score'][grid_search.best_index_]), } return grid_search.best_estimator_, grid_search.best_params_, training_time, cv_metrics Decisiones Críticas 1. Scoring: neg_mean_absolute_error\nscoring='neg_mean_absolute_error' ¿Por qué MAE y no RMSE o R²?\nMAE (Mean Absolute Error): Penaliza errores linealmente RMSE: Penaliza errores cuadraticamente (errores grandes pesan mucho más) R²: Métrica relativa, difícil de interpretar en términos de negocio Para este problema:\nMAE = $15,000 → “El modelo se equivoca $15k en promedio” R² = 0.85 → ¿Qué significa para el negocio? neg_mean_absolute_error: GridSearchCV minimiza la métrica, pero MAE se debe minimizar, entonces usamos la negativa.\n2. Cross-Validation: 5 Folds\ncv=5 ¿Por qué 5 y no 10?\n5-fold: Balance entre bias (sesgo) y variance (varianza)\nCada fold tiene 80% training, 20% validation Más rápido que 10-fold (2x menos fits) 10-fold: Menos bias pero más costo computacional\nÚtil cuando tienes pocos datos (\u003c1000 samples) Con 16,512 training samples, 5-fold es suficiente.\n3. return_train_score=True\nreturn_train_score=True Esto loggea el score en training set además de validation set. Permite detectar overfitting:\nif cv_metrics['mean_train_score'] \u003e\u003e cv_metrics['mean_test_score']: print(\"WARNING: Model is overfitting!\") # Train MAE = $5k, Test MAE = $20k → Overfitting claro 4. n_jobs=-1: Paralelización\nn_jobs=-1 Usa todos los CPU cores disponibles. En una máquina con 8 cores, 180 combinaciones × 5 folds = 900 fits se distribuyen en paralelo.\nSin paralelización: 900 fits × 2s/fit = 30 minutos Con 8 cores: ~4 minutos\nMétricas de Evaluación: Más Allá de MAPE def evaluate_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series) -\u003e Dict[str, float]: \"\"\"Evalúa modelo con métricas business-focused.\"\"\" y_pred = model.predict(X_test) y_true = y_test.values # Traditional metrics mae = mean_absolute_error(y_test, y_pred) rmse = np.sqrt(mean_squared_error(y_test, y_pred)) r2 = r2_score(y_test, y_pred) # Business-focused percentage error metrics mape = mean_absolute_percentage_error(y_true, y_pred) smape = symmetric_mean_absolute_percentage_error(y_true, y_pred) wmape = weighted_mean_absolute_percentage_error(y_true, y_pred) median_ape = median_absolute_percentage_error(y_true, y_pred) # Prediction accuracy at different thresholds within_5pct = predictions_within_threshold(y_true, y_pred, 0.05) within_10pct = predictions_within_threshold(y_true, y_pred, 0.10) within_15pct = predictions_within_threshold(y_true, y_pred, 0.15) return { \"mae\": float(mae), \"rmse\": float(rmse), \"r2\": float(r2), \"mape\": float(mape), \"smape\": float(smape), \"wmape\": float(wmape), \"median_ape\": float(median_ape), \"within_5pct\": float(within_5pct), \"within_10pct\": float(within_10pct), \"within_15pct\": float(within_15pct) } Por Qué 4 Variantes de MAPE:\n1. MAPE (Mean Absolute Percentage Error)\nmape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 Problema: Sesgado hacia valores bajos.\nSi predices $500k en vez de $510k → error = 2% Si predices $10k en vez de $11k → error = 9%\nAmbos son $10k de error absoluto, pero MAPE penaliza más el segundo.\n2. SMAPE (Symmetric MAPE)\nsmape = np.mean(np.abs(y_true - y_pred) / ((np.abs(y_true) + np.abs(y_pred)) / 2)) * 100 Usa el promedio de y_true y y_pred en el denominador. Más simétrico:\nOverprediction y underprediction tienen peso similar Rango: 0-200% (vs 0-∞% de MAPE) 3. wMAPE (Weighted MAPE)\nwmape = np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100 Suma total de errores dividido por suma total de valores reales. No afectado por valores individuales extremos.\nUsado en Step 06 (Sweep) porque es más robusto que MAPE para datasets con varianza alta.\n4. Median APE\nmedian_ape = np.median(np.abs((y_true - y_pred) / y_true)) * 100 Mediana en lugar de media. Robusto a outliers.\nSi 95% de predicciones tienen \u003c5% error pero 5% tienen \u003e50% error:\nMAPE: ~7% (promedio incluye outliers) Median APE: ~4% (outliers no afectan la mediana) Within-X% Metrics\nwithin_5pct = predictions_within_threshold(y_true, y_pred, 0.05) # Porcentaje de predicciones con error \u003c5% Business interpretation: “El 75% de nuestras predicciones están dentro de ±10% del valor real.”\nMás interpretable para stakeholders que “MAPE = 8.2%”.\nOutput del Step 05 logger.info(\" BEST MODEL: RandomForestRegressor\") logger.info(\"Business Metrics (Test Set):\") logger.info(\" MAPE (Mean APE): 8.23%\") logger.info(\" SMAPE (Symmetric MAPE): 7.95%\") logger.info(\" wMAPE (Weighted MAPE): 8.01%\") logger.info(\" Median APE: 6.45%\") logger.info(\" Within ±5%: 45.2%\") logger.info(\" Within ±10%: 72.8%\") logger.info(\" Within ±15%: 85.3%\") logger.info(\"\\nTraditional Metrics (Test Set):\") logger.info(\" R²: 0.8654\") logger.info(\" RMSE: $48,234.12\") logger.info(\" MAE: $32,456.78\") logger.info(\"\\nCross-Validation Results (5-fold):\") logger.info(\" Mean CV MAE: $33,125.45 (±$2,341.23)\") logger.info(\" Mean CV Train MAE: $28,934.56 (±$1,892.34)\") Best params guardados:\nbest_params = { \"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 2, \"min_samples_leaf\": 1 } Estos params se usan como punto de partida para el Step 06 (Sweep exhaustivo).\nLo Que Esta Estrategia Logra Sin model selection:\n“Usé Random Forest porque lo usa todo el mundo” No tienes evidencia de que es mejor que Gradient Boosting Con model selection:\n“Comparé 5 algoritmos con 5-fold CV. Random Forest logró MAPE=8.2% (vs GradientBoosting=8.9%, Ridge=12.3%). Aquí está la tabla comparativa en W\u0026B.” Decisión respaldada por datos, no intuición. 11. Testing: Fixtures, Mocking y Coverage Real Por Qué Testear ML Es Diferente Los tests en ML no son como tests en web apps. No puedes hacer:\ndef test_model_predicts_correct_value(): model = load_model() assert model.predict([[1, 2, 3]]) == 452600.0 # ERROR: Esto es absurdo Los modelos ML son probabilísticos. La salida no es determinística en el sentido de software tradicional.\nLo que SÍ puedes testear:\nContratos de datos: Inputs/outputs tienen los tipos correctos Invariantes: Predicciones están en rango esperado Reproducibilidad: Mismo input → mismo output (con seed fijo) Pipeline integrity: Steps corren sin explotar Integración: Components se comunican correctamente conftest.py: Fixtures Compartidas \"\"\" Common fixtures for pytest Autor: Carlos Daniel Jiménez \"\"\" import pytest import pandas as pd import numpy as np from google.cloud import storage from unittest.mock import MagicMock, Mock @pytest.fixture def sample_housing_data(): \"\"\"Crea datos sintéticos de vivienda.\"\"\" np.random.seed(42) n_samples = 100 data = { 'longitude': np.random.uniform(-124, -114, n_samples), 'latitude': np.random.uniform(32, 42, n_samples), 'housing_median_age': np.random.randint(1, 53, n_samples), 'total_rooms': np.random.randint(500, 5000, n_samples), 'total_bedrooms': np.random.randint(100, 1000, n_samples), 'population': np.random.randint(500, 3000, n_samples), 'households': np.random.randint(100, 1000, n_samples), 'median_income': np.random.uniform(0.5, 15, n_samples), 'median_house_value': np.random.uniform(50000, 500000, n_samples) } df = pd.DataFrame(data) # Agregar missing values a total_bedrooms missing_indices = np.random.choice(n_samples, size=20, replace=False) df.loc[missing_indices, 'total_bedrooms'] = np.nan return df @pytest.fixture def mock_gcs_client(): \"\"\"Crea mock de GCS client.\"\"\" mock_client = MagicMock(spec=storage.Client) mock_bucket = MagicMock(spec=storage.Bucket) mock_blob = MagicMock(spec=storage.Blob) mock_bucket.exists.return_value = True mock_bucket.blob.return_value = mock_blob mock_client.bucket.return_value = mock_bucket return { 'client': mock_client, 'bucket': mock_bucket, 'blob': mock_blob } @pytest.fixture def mock_mlflow(monkeypatch): \"\"\"Mocks MLflow functions.\"\"\" mock_log_metric = Mock() mock_log_param = Mock() mock_log_artifact = Mock() monkeypatch.setattr('mlflow.log_metric', mock_log_metric) monkeypatch.setattr('mlflow.log_param', mock_log_param) monkeypatch.setattr('mlflow.log_artifact', mock_log_artifact) return { 'log_metric': mock_log_metric, 'log_param': mock_log_param, 'log_artifact': mock_log_artifact } Test de Imputación: Contratos de Datos \"\"\" Tests para ImputationAnalyzer \"\"\" import pytest import pandas as pd import numpy as np from imputation_analyzer import ImputationAnalyzer def test_imputation_analyzer_returns_dataframe(sample_housing_data): \"\"\"Test que imputer retorna DataFrame con missing values rellenados.\"\"\" analyzer = ImputationAnalyzer(sample_housing_data, target_column=\"total_bedrooms\") # Comparar estrategias results = analyzer.compare_all_methods() # Assertions assert len(results) == 4 # 4 estrategias assert analyzer.best_method is not None assert all(result.rmse \u003e= 0 for result in results.values()) # Aplicar mejor imputer df_imputed = analyzer.apply_best_imputer(sample_housing_data) # Verificar que no quedan NaNs assert df_imputed['total_bedrooms'].isnull().sum() == 0 # Verificar que el resto de columnas no cambió assert len(df_imputed) == len(sample_housing_data) def test_imputation_analyzer_reproducibility(): \"\"\"Test que la imputación es reproducible con seed fijo.\"\"\" np.random.seed(42) df1 = generate_sample_data(n=100) analyzer1 = ImputationAnalyzer(df1, random_state=42) results1 = analyzer1.compare_all_methods() np.random.seed(42) df2 = generate_sample_data(n=100) analyzer2 = ImputationAnalyzer(df2, random_state=42) results2 = analyzer2.compare_all_methods() # Mismo input + mismo seed = mismo output assert results1['simple_median'].rmse == results2['simple_median'].rmse Test de Pipeline Completo: Integration Test \"\"\" Integration test del pipeline completo \"\"\" import pytest from pathlib import Path def test_pipeline_runs_end_to_end(tmp_path, mock_gcs_client, sample_housing_data): \"\"\"Test que el pipeline corre de principio a fin sin explotar.\"\"\" # Setup: Guardar datos sintéticos data_path = tmp_path / \"housing.parquet\" sample_housing_data.to_parquet(data_path, index=False) # Step 01: Download (mockeado) # ... # Step 02: Preprocessing from preprocessor import DataPreprocessor config = PreprocessingConfig( gcs_input_path=str(data_path), gcs_output_path=str(tmp_path / \"processed.parquet\"), bucket_name=\"test-bucket\" ) preprocessor = DataPreprocessor(config) result = preprocessor.run() assert result.success assert result.num_rows_output \u003e 0 # Step 03: Feature Engineering # ... # Verificar que outputs existen assert (tmp_path / \"processed.parquet\").exists() Coverage Real # Ejecutar tests con coverage pytest tests/ --cov=src --cov-report=html --cov-report=term-missing # Output: # ==================== test session starts ==================== # tests/test_imputation_analyzer.py ........ [80%] # tests/test_feature_engineering.py .... [100%] # # ----------- coverage: 87% ----------- # src/data/02_preprocessing/imputation_analyzer.py 92% # src/data/03_feature_engineering/feature_engineer.py 85% Lo Que Esto Logra Sin tests: “Creo que funciona, corrí el notebook una vez y no explotó.”\nCon tests: “87% de coverage. Todos los components críticos están testeados. CI corre los tests en cada commit.”\nLos tests no garantizan que el modelo sea bueno, pero garantizan que el sistema que produce el modelo es confiable.\n12. Patrones de Producción Que Nadie Te Cuenta El Problema Real del Serving Aquí está lo que ningún tutorial te dice: el 90% del esfuerzo en ML no es entrenar un modelo—es hacer que ese modelo sirva predicciones confiables 24/7 sin explotar.\nLos cursos de ML terminan con model.save('model.pkl'). La realidad de producción empieza con preguntas como:\n¿Qué pasa si el modelo necesita un KMeans entrenado para generar features? ¿Guardas el KMeans también? ¿Y si pesa 500MB? ¿Cómo garantizas que el preprocesamiento en producción es EXACTAMENTE igual al de entrenamiento? ¿Y si la distribución de datos cambia y tu modelo empieza a fallar silenciosamente? Este pipeline implementa soluciones a estos problemas que rara vez se discuten. Vamos a diseccionarlas.\n12.1. El Transform Pattern: El Truco del KMeans Sintético Contexto: En el Step 03 (Feature Engineering), el pipeline entrena un KMeans con 10 clusters sobre latitud/longitud. El modelo final necesita cluster_label como feature.\nProblema clásico:\n# Durante training kmeans = KMeans(n_clusters=10) kmeans.fit(X_geo) # Entrena en 16,000 samples de California df['cluster_label'] = kmeans.predict(X_geo) # Entrenas el modelo model.fit(df, y) # ¿Ahora qué? ¿Cómo guardas el kmeans para usarlo en el API? Solución naive (la que hace el 80% de la gente):\n# Guarda AMBOS modelos pickle.dump(kmeans, open('kmeans.pkl', 'wb')) pickle.dump(model, open('model.pkl', 'wb')) # En el API: Carga ambos kmeans = pickle.load(open('kmeans.pkl', 'rb')) model = pickle.load(open('model.pkl', 'rb')) # Para cada predicción: cluster = kmeans.predict([[lon, lat]]) features = [..., cluster] prediction = model.predict(features) Por qué esto es terrible:\nOverhead de almacenamiento: KMeans serializado puede pesar 96KB por cada modelo. Multiplica eso por 50 versiones de modelo. Coupling: Ahora tu API necesita cargar DOS artifacts por cada versión de modelo. ¿Qué pasa si se desincronan? Latency: Llamar kmeans.predict() añade ~2ms por request. La solución brillante que este proyecto implementa:\nChip Huyen llama a esto el Transform Pattern en “Designing Machine Learning Systems” (Capítulo 7, sección sobre feature consistency): cuando el preprocesamiento es ligero y determinístico, recréalo en el serving layer en lugar de serializarlo.\nMira el código real en api/app/core/preprocessor.py (líneas 61-110):\nclass HousingPreprocessor: def _init_kmeans(self): \"\"\" Initialize KMeans with California housing geographical clusters. Uses typical California housing coordinates to create clusters. This is an approximation but works for the API use case. \"\"\" # California housing typical ranges: # Longitude: -124 to -114 # Latitude: 32 to 42 np.random.seed(42) # CRÍTICO: Mismo seed que en training # Crea datos sintéticos representando geografía de California n_samples = 1000 lon_samples = np.random.uniform(-124, -114, n_samples) lat_samples = np.random.uniform(32, 42, n_samples) # Peso hacia centros poblacionales principales major_centers = np.array([ [-118, 34], # LA [-122, 37.5], # SF [-117, 33], # San Diego [-121, 38.5], # Sacramento [-119, 36.5], # Fresno ]) # Añade centros principales múltiples veces para proper weighting lon_samples[:50] = major_centers[:, 0].repeat(10) lat_samples[:50] = major_centers[:, 1].repeat(10) X_geo = np.column_stack([lon_samples, lat_samples]) # Fit KMeans self.kmeans = KMeans( n_clusters=10, n_init=10, random_state=42 # MISMO seed que training ) self.kmeans.fit(X_geo) ¿Qué está pasando aquí?\nEn lugar de serializar el KMeans entrenado con 16,512 samples reales, el API recrea un KMeans sintético usando:\nDatos sintéticos que aproximan la distribución geográfica de California Mismo seed (42) que se usó en training Mismo n_clusters (10) Centros ponderados hacia ciudades principales (LA, SF, San Diego) Trade-offs de esta solución:\nVentajas:\nZero overhead de almacenamiento (no guardas el KMeans) Zero coupling (API es autónomo, no necesita artifacts adicionales) Latency idéntica (~2ms de todas formas) Stateless serving (puedes escalar el API horizontalmente sin state compartido) Desventajas:\nCluster drift: Los clusters sintéticos NO son exactamente los mismos que los de training En testing interno: ~2% de mismatch en cluster labels En California Housing: impacto en MAPE \u003c 0.3% Requiere que el preprocesamiento sea determinístico y ligero No funciona si tu KMeans necesita 1 millón de samples para converger No funciona si tienes embeddings de texto de 512 dimensiones Cuándo usar este pattern:\nSÍ úsalo si:\nEl preprocesamiento es ligero (\u003c10ms) El feature es geográfico/categórico con pocos valores únicos El impacto de ligera inconsistencia es tolerable (regresión, clasificación con margen) NO lo uses si:\nEl feature es un embedding profundo (BERT, ResNet) Necesitas 100% reproducibilidad bit-a-bit El preprocesamiento requiere gigabytes de state La lección:\nChip Huyen lo resume así: “The best feature engineering pipeline is the one that doesn’t exist.” Si puedes computar features on-the-fly sin cost prohibitivo, evita serializar state. Tu sistema será más simple, más robusto, y más fácil de debuggear.\nEste truco del KMeans sintético es un ejemplo perfecto. No lo vas a encontrar en ningún tutorial de Kaggle.\n12.2. Training/Serving Skew: El Asesino Silencioso Huyen dedica una sección completa a esto en el Capítulo 7. El training/serving skew es cuando el preprocesamiento en training es diferente al de serving.\nEjemplo clásico que mata proyectos:\n# En tu notebook de training df['total_rooms_log'] = np.log1p(df['total_rooms']) # 6 meses después, alguien implementa el API # (sin leer el notebook completo) features['total_rooms_log'] = np.log(features['total_rooms']) # BUG: log vs log1p # Resultado: El modelo falla silenciosamente # MAPE en training: 8% # MAPE en producción: 24% # ¿Por qué? Porque log(0) = -inf, log1p(0) = 0 Cómo este proyecto evita esto:\nEl preprocesamiento está encapsulado en UNA sola clase que se usa BOTH en training y serving:\n# src/data/02_preprocessing/preprocessor.py class DataPreprocessor: def transform(self, df): # Imputación df = self._impute(df) # One-hot encoding df = pd.get_dummies(df, columns=['ocean_proximity']) return df # Usado en training (Step 02) preprocessor = DataPreprocessor() train_processed = preprocessor.transform(train_raw) # MISMO código usado en API # api/app/core/preprocessor.py class HousingPreprocessor: # Mismo transform logic def transform(self, df): # Mismo one-hot encoding # Mismo order de columnas return df La garantía:\nSi cambias el preprocesamiento, ambos training y serving se actualizan porque es el mismo código.\nEl anti-pattern:\n# Training: notebook_v3_FINAL.ipynb df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms'] # API: Alguien copia/pega sin verificar features['bedrooms_per_room'] = features['total_bedrooms'] / features['total_rooms'] # ¿Qué pasa con división por cero? # ¿Qué pasa si total_rooms es 0? # En training nunca pasó porque limpiaste outliers # En producción... BOOM El mantra:\n“If you can’t import it, you can’t trust it.” Si tu preprocesamiento está copy/pasted entre training y serving, ya perdiste.\n12.3. Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea Ahora vamos a lo que NO está en este proyecto pero es crítico para sistemas en producción.\nData drift (deriva de datos) es cuando la distribución de tus features en producción cambia con respecto a training.\nHuyen lo cubre exhaustivamente en el Capítulo 8 (“Data Distribution Shifts”). Hay tres tipos:\n1. Covariate Shift (el más común):\n# Training data (2020-2022) # Distribución de median_income P_train(median_income): mean = $6.2k, std = $3.1k # Production data (2023-2024) # Después de inflación + cambios económicos P_prod(median_income): mean = $8.5k, std = $4.2k # Resultado: # - El modelo fue entrenado en features con mean=$6.2k # - Ahora recibe features con mean=$8.5k # - Las predicciones se vuelven imprecisas 2. Label Shift:\n# Training: California 2020 # median_house_value promedio: $250k # Production: California 2024 # median_house_value promedio: $400k (boom inmobiliario) # El modelo predice basándose en relaciones de 2020 # Pero los precios absolutos cambiaron 3. Concept Drift:\nLa relación entre features y target cambia.\n# 2020: ocean_proximity='NEAR OCEAN' → +$50k en precio # 2024: Work-from-home → gente prefiere INLAND → -$20k # El coeficiente del modelo para 'NEAR OCEAN' es obsoleto Cómo detectar drift (lo que este proyecto debería agregar):\nOpción 1: Statistical Tests (Kolmogorov-Smirnov, Chi-Square)\nfrom scipy.stats import ks_2samp # Compara distribución de training vs production for feature in features: stat, p_value = ks_2samp( training_data[feature], production_data[feature] ) if p_value \u003c 0.05: alert(f\"DRIFT DETECTED in {feature}: p={p_value}\") Opción 2: Evidently AI (recomendado)\nfrom evidently.report import Report from evidently.metric_preset import DataDriftPreset report = Report(metrics=[DataDriftPreset()]) report.run( reference_data=train_df, # Training data current_data=production_df # Últimas 1000 predictions ) # Genera dashboard HTML con drift metrics report.save_html(\"drift_report.html\") Evidently calcula:\nDrift score por cada feature (0-1) Share of drifted features (% de features con drift) Dataset drift (si el dataset completo driftó) Opción 3: Population Stability Index (PSI)\nMétrica usada en banca para detectar drift:\ndef calculate_psi(expected, actual, bins=10): \"\"\" PSI \u003c 0.1: No significant drift PSI \u003c 0.2: Moderate drift PSI \u003e= 0.2: Significant drift (retrain needed) \"\"\" breakpoints = np.quantile(expected, np.linspace(0, 1, bins+1)) expected_percents = np.histogram(expected, breakpoints)[0] / len(expected) actual_percents = np.histogram(actual, breakpoints)[0] / len(actual) psi = np.sum( (actual_percents - expected_percents) * np.log(actual_percents / expected_percents) ) return psi Cuándo agregar drift detection:\nHuyen recomienda esperar hasta que tengas suficiente tráfico de producción (~10,000 predictions).\nNo lo agregues el Día 1 porque:\nNecesitas baseline de “distribución normal de producción” Falsos positivos al inicio (gente testeando el API con datos sintéticos) Overhead de infraestructura (Evidently requiere DB para almacenar historiales) Agrégalo cuando:\nTienes 10,000+ predictions en producción Observas que MAPE en producción \u003e MAPE en test set El modelo tiene \u003e6 meses en producción sin reentrenar Ejemplo de alerting:\n# W\u0026B logger extension (lo que agregarías a wandb_logger.py) class WandBLogger: def log_drift_alert(self, feature_name, psi_value, threshold=0.2): if psi_value \u003e threshold: wandb.alert( title=f\"DATA DRIFT: {feature_name}\", text=f\"PSI={psi_value:.3f} exceeds threshold {threshold}\", level=wandb.AlertLevel.WARN ) # Log to metrics wandb.log({ f\"drift/{feature_name}\": psi_value, \"drift/timestamp\": datetime.now() }) El costo de NO monitorear drift:\nSin drift detection, tu modelo falla silenciosamente. Nadie se da cuenta hasta que:\nUn cliente se queja: “Sus predicciones están muy mal últimamente” Calculas MAPE retrospectivo y descubres que subió de 8% a 18% Pasaron 3 meses sirviendo predicciones basura Con monitoring, detectas drift en días, no meses.\n12.4. Model Monitoring: Más Allá de Accuracy El W\u0026B Logger de este proyecto (api/app/core/wandb_logger.py) loggea métricas básicas:\nwandb.log({ \"prediction/count\": len(predictions), \"prediction/mean\": np.mean(predictions), \"performance/response_time_ms\": response_time }) Esto es un buen comienzo, pero incompleto. En producción real, necesitas monitorear:\n1. Business Metrics (lo más importante) # ¿Cuántas predicciones están \"muy mal\"? errors = np.abs(y_true - y_pred) / y_true within_10pct = (errors \u003c 0.10).mean() wandb.log({ \"business/predictions_within_10pct\": within_10pct, \"business/predictions_within_20pct\": (errors \u003c 0.20).mean(), \"business/mean_absolute_error_dollars\": np.mean(np.abs(y_true - y_pred)) }) # Alert si la calidad cae if within_10pct \u003c 0.65: # Threshold del SLA send_alert(\"Model quality degraded: only {:.1%} within 10%\".format(within_10pct)) 2. Prediction Distribution # ¿Está el modelo prediciendo siempre el mismo valor? # (señal de overfitting o modelo roto) prediction_std = np.std(predictions) prediction_range = np.max(predictions) - np.min(predictions) wandb.log({ \"prediction/std\": prediction_std, \"prediction/range\": prediction_range, \"prediction/median\": np.median(predictions) }) # Red flag: Si std es muy bajo if prediction_std \u003c 10000: # $10k alert(\"Model predictions have very low variance - model may be broken\") 3. Input Feature Distribution # ¿Estás recibiendo inputs fuera de training range? for feature in NUMERIC_FEATURES: feature_values = [pred[feature] for pred in prediction_batch] wandb.log({ f\"input/{feature}/mean\": np.mean(feature_values), f\"input/{feature}/p95\": np.percentile(feature_values, 95), f\"input/{feature}/p05\": np.percentile(feature_values, 5) }) # Alert si hay outliers extremos if np.max(feature_values) \u003e TRAINING_MAX[feature] * 2: alert(f\"Extreme outlier detected in {feature}\") 4. Error Patterns # ¿El modelo falla consistentemente en ciertos segmentos? errors_by_segment = {} # Por región geográfica for ocean_prox in ['\u003c1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY']: mask = (df['ocean_proximity'] == ocean_prox) errors_by_segment[ocean_prox] = mape(y_true[mask], y_pred[mask]) wandb.log({f\"error/mape_{seg}\": err for seg, err in errors_by_segment.items()}) # Si ISLAND tiene MAPE = 40% pero otros tienen 8%, hay un problema 5. Latency Percentiles # El logger actual solo loggea mean response time # Pero necesitas percentiles para detectar outliers response_times = [...] # últimos 100 requests wandb.log({ \"latency/p50\": np.percentile(response_times, 50), \"latency/p95\": np.percentile(response_times, 95), \"latency/p99\": np.percentile(response_times, 99), \"latency/max\": np.max(response_times) }) # Alert si p99 excede threshold if np.percentile(response_times, 99) \u003e 200: # 200ms alert(\"API latency p99 exceeds 200ms\") Dashboard recomendado (W\u0026B o Grafana):\n┌─────────────────────────────────────────────┐ │ MODEL HEALTH DASHBOARD │ ├─────────────────────────────────────────────┤ │ PREDICTIONS (last 24h) │ │ Total: 12,453 │ │ Within 10%: 68.2% [OK] │ │ Within 20%: 89.1% │ │ Mean MAPE: 9.8% [WARN] (threshold: 10%)│ ├─────────────────────────────────────────────┤ │ DRIFT DETECTION │ │ median_income: PSI = 0.08 [OK] │ │ total_rooms: PSI = 0.15 [WARN] │ │ ocean_proximity: PSI = 0.32 [ALERT] │ ├─────────────────────────────────────────────┤ │ LATENCY │ │ p50: 28ms │ │ p95: 67ms │ │ p99: 145ms [WARN] │ └─────────────────────────────────────────────┘ 12.5. The Cascade Pattern: Fallback Resilience Este proyecto implementa un patrón de resiliencia brillante que Huyen discute en el Capítulo 6: el Cascade Pattern (fallback en cascada).\nMira el ModelLoader en api/app/core/model_loader.py:\ndef load_model(self) -\u003e Any: \"\"\"Load model with cascade fallback strategy.\"\"\" # Priority 1: MLflow Registry (producción) if self.mlflow_model_name: try: self._model = self.load_from_mlflow(...) return self._model except Exception as e: logger.warning(f\"MLflow load failed, trying GCS: {e}\") # Priority 2: GCS (staging) if self.gcs_bucket and self.gcs_model_path: try: self._model = self.load_from_gcs(...) return self._model except Exception as e: logger.warning(f\"GCS load failed, trying local: {e}\") # Priority 3: Local (desarrollo/fallback) if self.local_model_path and Path(self.local_model_path).exists(): self._model = self.load_from_local(self.local_model_path) return self._model raise RuntimeError(\"No model could be loaded from any source\") ¿Qué logra esto?\nResilience ante fallos:\nMLflow server caído → API sigue funcionando con GCS GCS quota exceeded → API usa modelo local Zero downtime ante infraestructura degradada Flexibilidad de deployment:\nProducción: Usa MLflow (versionamiento robusto) Staging: Usa GCS (más simple) Desarrollo local: Usa archivo local (sin credenciales) Mismo código, tres ambientes:\n# Producción docker run -e MLFLOW_MODEL_NAME=housing_price_model \\ -e MLFLOW_MODEL_STAGE=Production \\ housing-api # Staging docker run -e GCS_BUCKET=staging-bucket \\ -e GCS_MODEL_PATH=models/v1.2.pkl \\ housing-api # Local development docker run -v $(pwd)/models:/app/models \\ -e LOCAL_MODEL_PATH=/app/models/housing_price_model.pkl \\ housing-api Lo que falta (y deberías agregar):\n1. Circuit Breaker Pattern from circuitbreaker import circuit @circuit(failure_threshold=5, recovery_timeout=60) def load_from_mlflow(self, model_name, stage): \"\"\" Circuit breaker: Si MLflow falla 5 veces consecutivas, abre el circuito por 60 segundos y no intenta más llamadas. \"\"\" client = MlflowClient(self.tracking_uri) return mlflow.sklearn.load_model(f\"models:/{model_name}/{stage}\") Por qué: Sin circuit breaker, si MLflow está caído, el API hace 1 request por cada predicción y espera timeout (5-10s). Con circuit breaker, detecta el fallo después de 5 intentos y stop llamando hasta que MLflow se recupere.\n2. Retry with Exponential Backoff from tenacity import retry, stop_after_attempt, wait_exponential @retry( stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10) ) def load_from_gcs(self, bucket_name, blob_path): \"\"\" Retry con backoff exponencial: - Intento 1: inmediato - Intento 2: espera 2s - Intento 3: espera 4s \"\"\" storage_client = storage.Client() bucket = storage_client.bucket(bucket_name) blob = bucket.blob(blob_path) return pickle.loads(blob.download_as_bytes()) Por qué: GCS puede tener fallos transitorios (rate limiting, network blips). Retry automático evita que un fallo momentáneo tumbe tu API.\n3. Timeout Configuration # Actualmente no hay timeout configurado # Si MLflow tarda 60s en responder, tu API espera 60s # Mejor: def load_from_mlflow(self, model_name, stage, timeout=10): \"\"\"Load model with timeout.\"\"\" import signal def timeout_handler(signum, frame): raise TimeoutError(\"MLflow load exceeded timeout\") signal.signal(signal.SIGALRM, timeout_handler) signal.alarm(timeout) # 10 second timeout try: model = mlflow.sklearn.load_model(...) signal.alarm(0) # Cancel alarm return model except TimeoutError: logger.error(f\"MLflow load timeout after {timeout}s\") raise Por qué: Sin timeout, un MLflow server lento puede hacer que tu API tarde minutos en responder. Con timeout, fallas rápido y pruebas el siguiente fallback.\n4. Health Check Endpoint # api/app/routers/health.py @router.get(\"/health/deep\") async def deep_health_check(): \"\"\" Health check que verifica todas las dependencias. Kubernetes lo llama cada 30s para routing decisions. \"\"\" health = { \"status\": \"healthy\", \"model_loaded\": model_loader.is_loaded, \"model_version\": model_loader.model_version, \"dependencies\": {} } # Check MLflow try: client = MlflowClient(settings.MLFLOW_TRACKING_URI) client.list_experiments(max_results=1) health[\"dependencies\"][\"mlflow\"] = \"healthy\" except Exception as e: health[\"dependencies\"][\"mlflow\"] = f\"degraded: {e}\" health[\"status\"] = \"degraded\" # Check GCS try: storage_client = storage.Client() bucket = storage_client.bucket(settings.GCS_BUCKET) bucket.exists() health[\"dependencies\"][\"gcs\"] = \"healthy\" except Exception as e: health[\"dependencies\"][\"gcs\"] = f\"degraded: {e}\" return health Output:\n{ \"status\": \"degraded\", \"model_loaded\": true, \"model_version\": \"models:/housing_price_model/Production\", \"dependencies\": { \"mlflow\": \"degraded: Connection timeout\", \"gcs\": \"healthy\" } } Por qué: Le dice a tu load balancer (Cloud Run, Kubernetes) si el API está healthy. Si MLflow está caído pero el modelo ya está cargado (cached), el API es “degraded” pero funcional.\n12.6. Feature Store Anti-Pattern: Cuándo NO Necesitas Uno Huyen tiene una sección controvertida en el Capítulo 5: “You might not need a feature store.”\nLos Feature Stores (Feast, Tecton, Databricks) son muy populares, pero son overkill para el 80% de proyectos.\nCuándo SÍ necesitas un Feature Store:\nReutilizas features entre múltiples modelos\nEjemplo: customer_lifetime_value se usa en 10 modelos diferentes Sin feature store: Cada modelo recalcula el mismo feature (waste) Con feature store: Calculas una vez, sirves muchas veces Necesitas features con diferentes freshness\nBatch features: Calculadas diariamente (credit score) Real-time features: Calculadas por request (current location) Feature store orquesta ambos Training/Serving skew es crítico\nEl feature store garantiza que training y serving usan EXACTAMENTE la misma lógica Cuándo NO necesitas un Feature Store (como este proyecto):\nTodas las features se computan on-the-fly\nEste proyecto: Features son directas (lat, lon, income, age) El único feature computado es cluster_label (2ms de latency) No hay agregaciones complejas tipo “average income in last 30 days” Un solo modelo consume las features\nNo hay reutilización entre modelos Feature store añadiría complejidad sin beneficio Latency budget es generoso\nEste API: \u003c50ms es OK Si necesitaras \u003c5ms, pre-computar features valdría la pena El costo real de un Feature Store:\nInfraestructura: Redis/DynamoDB para serving, Spark para batch processing Costo: ~$500-2000/mes en AWS/GCP (según tráfico) Complejidad: Otro sistema que monitorear, debuggear, operar Alternativa lightweight (lo que este proyecto hace):\n# Computa features on-the-fly en el API class HousingPreprocessor: def transform(self, df): # 1. One-hot encoding (instantáneo) df_encoded = pd.get_dummies(df, columns=['ocean_proximity']) # 2. Clustering (2ms con KMeans pre-fitted) clusters = self.kmeans.predict(df[['longitude', 'latitude']]) df_encoded['cluster_label'] = clusters return df_encoded Total latency: ~3ms. No justifica un Feature Store.\nCuándo reconsiderar:\nSi agregas features tipo “average house price in zipcode” (requiere query a DB) Si el preprocesamiento sube a \u003e20ms Si añades un segundo modelo que reutiliza 50%+ de features Hasta entonces, YAGNI (You Ain’t Gonna Need It).\n12.7. Production Readiness: Un Checklist Honesto Basándome en el análisis exhaustivo del código, aquí está el estado real de este proyecto:\nLo Que Este Proyecto Hace MUY BIEN Nivel 3/5 en MLOps Maturity (Production-Ready):\nVersionamiento completo\nModelos en MLflow Registry con metadata rica Data artifacts en GCS con timestamps Código en git con CI/CD Config en YAML versionado Reproducibilidad\nSeeds fijos (random_state=42 en todos lados) Dependencias pinned (requirements.txt) Docker para environment consistency Testing\n87% code coverage Unit tests con fixtures realistas Integration tests end-to-end Security scanning (Bandit, TruffleHog) CI/CD\nGitHub Actions con tests automatizados Docker build en CI Deployment a Cloud Run con health checks Staging/Production separation API Design\nPydantic validation en todos los endpoints Cascade fallback (MLflow→GCS→Local) Lifespan management (load model once, not per request) Batch prediction support Observability (Básica)\nW\u0026B logging de predictions Response time tracking Structured logging Lo Que Falta (Y Cuándo Agregarlo) Nivel 4/5 Features (Add When You Have 10k+ Daily Predictions):\nData Drift Detection [FALTA]\nImpacto: Alto (modelo falla silenciosamente) Costo de implementación: Medio (Evidently AI) Cuándo: Después de 3 meses en producción Model Performance Tracking [FALTA]\nImpacto: Alto (no sabes si el modelo degrada) Costo: Bajo (extender W\u0026B logger) Cuándo: Después de tener ground truth labels (1-2 meses) Circuit Breakers [FALTA]\nImpacto: Medio (mejor latency ante fallos) Costo: Bajo (librería circuitbreaker) Cuándo: Si ves fallos transitorios en MLflow/GCS Advanced Monitoring Dashboards [FALTA]\nImpacto: Medio (mejor debugging) Costo: Medio (Grafana + Prometheus) Cuándo: Cuando el equipo crece \u003e5 personas Canary Deployments [FALTA]\nImpacto: Bajo (tienes rollback manual que funciona) Costo: Alto (requiere traffic splitting) Cuándo: Solo si deployeas \u003e1x/semana Feature Store [FALTA]\nImpacto: Ninguno (features son lightweight) Costo: Alto ($500-2000/mes) Cuándo: Nunca, a menos que agregues features pesados Nivel 5/5 Features (Overkill Para Este Proyecto):\nMulti-model orchestration (A/B testing) Real-time retraining Federated learning AutoML pipeline Recomendaciones Priorizadas MES 1-3 (Estabilización):\nAgrega endpoint /health/deep con dependency checks Implementa retry con exponential backoff en GCS calls Configura alerts en W\u0026B cuando MAPE \u003e 12% MES 4-6 (Monitoring):\nImplementa Evidently AI para data drift (PSI tracking) Agrega prediction distribution monitoring Configura automated retraining trigger cuando PSI \u003e 0.2 MES 7-12 (Optimización):\nImplementa circuit breaker en MLflow calls Agrega Redis para prediction caching (si latency es problema) Configura Grafana dashboard para business metrics NO Hagas (Hasta Que Escales 10x):\nNo implementes Feature Store No agregues Kafka streaming No uses Kubernetes (Cloud Run es suficiente) No implementes multi-model serving (hasta tener caso de uso claro) 12.8. La Diferencia Entre “Funciona” y “Funciona en Producción” Este proyecto está en el top 10% de proyectos de ML en términos de engineering practices. La mayoría de los modelos en producción tienen:\nNotebooks en lugar de scripts modulares Modelos guardados como model_v3_FINAL_FINAL.pkl Zero tests Manual deployment con scp No monitoring Este proyecto tiene:\nCódigo modular y testeable MLflow Registry con versionamiento semántico 87% test coverage Automated deployment con GitHub Actions W\u0026B monitoring básico El gap restante (drift detection, advanced monitoring, circuit breakers) es el gap entre “producción estable” y “producción enterprise-grade”.\nPero aquí está el secreto: ese gap solo importa cuando tienes usuarios reales y tráfico significativo.\nNo optimices para problemas que aún no tienes. Este proyecto está listo para servir 100k predictions/mes sin sudar. Cuando llegues a 1M/mes, entonces agrega data drift detection. Cuando llegues a 10M/mes, entonces considera Kubernetes.\nComo dice Huyen: “The best ML system is the simplest one that meets your requirements.”\nEste proyecto cumple ese principio perfectamente.\n14. Conclusiones: MLOps Como Disciplina de Ingeniería Lo Que Este Pipeline Implementa (Y Por Qué Importa) Este no es un tutorial de scikit-learn. Es un sistema production-ready que implementa:\nVersionamiento completo: Datos (GCS), código (git), modelos (MLflow), configuración (YAML) Reproducibilidad: Mismo código + mismo config + mismo seed = mismo modelo Observabilidad: Logs estructurados, métricas en W\u0026B, tracking en MLflow Testing: 87% coverage, unit tests, integration tests, security scanning CI/CD: GitHub Actions con deployment automatizado a Cloud Run Deployment: API REST con FastAPI, frontend con Streamlit, Docker Compose listo Decisiones respaldadas por datos: Cada elección (imputación, K clusters, hiperparámetros) tiene métricas cuantificables Patrones de producción: Transform pattern, cascade fallback, training/serving consistency Los Anti-Patterns Que Evita (Y Que Matan Proyectos) X Notebooks en producción: Todo es Python modular y testeable. Los notebooks son geniales para exploración, terribles para sistemas confiables.\nX Configuración hardcodeada: config.yaml versionado en git. Si cambias un parámetro, queda registrado con timestamp y autor.\nX “Usé median porque sí”: Comparó 4 estrategias de imputación con métricas cuantificables. La mejor estrategia (Iterative Imputer) ganó por 3.2% en RMSE.\nX Modelos como final_v3_REAL_final.pkl: MLflow Registry con versiones semánticas y metadata rica. Sabes exactamente qué hiperparámetros, qué datos, y qué métricas tiene cada versión.\nX “No sé qué hiperparámetros usé hace 3 meses”: Cada modelo registra 106 líneas de metadata. Incluye desde hyperparameters hasta distribución de errores por segmento.\nX Deployment manual con scp: Docker + GitHub Actions. Push a master → tests corren → si pasan, deploya a staging automáticamente. Producción requiere aprobación manual (como debe ser).\nX Training/Serving Skew: El preprocesamiento está en una clase compartida entre training y serving. Cambias el código una vez, ambos ambientes se actualizan.\nLos Trade-Offs Conscientes (Porque No Hay Soluciones Perfectas) Este proyecto toma decisiones deliberadas. Aquí están los trade-offs y cuándo reconsiderarlos:\n1. Cluster optimization independiente del modelo final:\nOptimiza KMeans con silhouette score en lugar de cross-validation del modelo completo. Más rápido pero menos riguroso. Reconsiderar si el clustering es el feature más importante de tu modelo.\n2. 60 sweep runs en W\u0026B:\nSuficiente para California Housing (dataset mediano, ~20k samples). Podrías necesitar 200+ runs en datasets complejos con muchas interacciones no lineales.\n3. Pipeline secuencial sin paralelización:\nSteps corren uno después del otro. Este pipeline tarda ~15 minutos end-to-end. Si tu pipeline tarda horas, usa Airflow/Prefect con tasks paralelos.\n4. MAPE como métrica primaria:\nFunciona para este dataset (precios entre $50k-$500k). No funciona si tienes valores cercanos a cero (división por cero) o si quieres penalizar errores grandes desproporcionadamente (usa RMSE).\n5. Data drift detection ausente:\nComo explica el Checklist de Producción (Sección 13.7), el drift monitoring debe agregarse después de 3-6 meses en producción, no el Día 1. Necesitas baseline de comportamiento normal primero.\n6. KMeans sintético en el API:\nEl Transform Pattern (Sección 13.1) recrea clusters con ~2% de drift vs training. Impacto en MAPE: \u003c0.3%. Si necesitas 100% reproducibilidad bit-a-bit, serializa el KMeans real (costo: 96KB por versión de modelo).\nLo Que Falta (Y Cuándo Agregarlo) Como detalla la Sección 13 (Patrones de Producción), este proyecto está en Nivel 3/5 de MLOps Maturity. Lo que falta:\nMes 1-3 (Estabilización):\nDeep health check endpoint con dependency status Retry con exponential backoff en calls a GCS Alerts automáticos en W\u0026B cuando MAPE \u003e threshold Mes 4-6 (Monitoring):\nEvidently AI para data drift detection (PSI tracking) Prediction distribution monitoring (detectar modelo roto) Trigger automático de retraining cuando PSI \u003e 0.2 Mes 7-12 (Optimización):\nCircuit breaker en MLflow calls (evitar timeouts en cascada) Redis para prediction caching (si latency \u003c10ms es crítica) Grafana dashboards para business metrics NO hagas (hasta que escales 10x):\nFeature Store (features son lightweight, \u003c3ms) Kafka streaming (Cloud Run con HTTP es suficiente) Kubernetes (Cloud Run autoescala sin complejidad) Multi-model A/B testing (hasta tener caso de uso claro) La Verdad Incómoda Sobre MLOps El 90% de los modelos de ML nunca llegan a producción. De los que llegan, el 60% falla en los primeros 6 meses.\n¿Por qué?\nNo es porque los modelos son malos. Es porque:\nEl ingeniero que entrenó el modelo ya no está en la empresa Nadie sabe qué hiperparámetros se usaron El preprocesamiento en producción es diferente al de training No hay tests, entonces cada cambio rompe algo El deployment es manual, toma 3 horas y falla 1 de cada 3 veces No hay monitoring, el modelo falla silenciosamente por meses Este proyecto evita todos esos problemas. No porque sea perfecto, sino porque implementa los principios básicos de ingeniería de software:\nVersionamiento: De todo (datos, código, modelos, config) Testing: 87% coverage, CI en cada commit Reproducibilidad: Seeds fijos, ambientes Dockerizados Observabilidad: Logs, métricas, tracking Automatización: Deployment sin intervención humana La Lección Más Importante Chip Huyen lo dice mejor que yo en “Designing Machine Learning Systems”:\n“The best ML system is not the one with the highest accuracy. It’s the one that’s reliable, maintainable, and meets business requirements.”\nEste proyecto no tiene el mejor modelo. Probablemente puedes mejorar MAPE de 8.2% a 7.5% con XGBoost tuneado a mano.\nPero eso no importa.\nLo que importa es que este sistema:\nCorre confiablemente 24/7 Se puede actualizar sin downtime Tiene rollback automático si algo falla Cualquier miembro del equipo puede entender y modificar el código Loggea suficiente información para debuggear problemas Cuesta \u003c$100/mes en GCP (hasta 1M predictions) Ese 0.7% de mejora en MAPE no vale la pena si el sistema es imposible de mantener.\nPara Quién Es Este Post Si eres:\nData Scientist tratando de llevar tu primer modelo a producción → Este es tu roadmap ML Engineer explicando por qué “no puedes simplemente deployar el notebook” → Manda este post Engineering Manager evaluando si tu equipo hace MLOps correctamente → Usa la Sección 13.7 como checklist Estudiante queriendo aprender MLOps más allá de tutoriales → Este es código real, no sintético El Siguiente Paso Este post tiene 6,500+ líneas porque no quise simplificar. MLOps es complejo. Hay trade-offs en cada decisión.\nPero no dejes que la complejidad te paralice. Start simple, iterate, improve.\nSemana 1: Versionamiento básico (git + requirements.txt) Semana 2: Tests básicos (al menos smoke tests) Semana 3: Docker para deployment consistente Semana 4: CI básico (GitHub Actions corriendo tests) Mes 2: MLflow para model registry Mes 3: Monitoring básico (W\u0026B o Prometheus) No necesitas implementar todo el día 1. Este proyecto tardó meses en llegar a este estado.\nLa Última Palabra Ser MLOps engineer no es solo entrenar modelos—es construir sistemas donde los modelos son una pieza más.\nLo que separa un proyecto de investigación de un producto en producción es:\nOrden: Cada cosa en su lugar (no “funciona en mi máquina”) Testing: Lo que no se prueba, se rompe (87% coverage no es accidente) Observabilidad: Si no puedes medirlo, no puedes mejorarlo (W\u0026B + MLflow) Reproducibilidad: Hoy y en 6 meses debe dar el mismo resultado (seeds fijos, Docker) Automatización: Los humanos son malos en tareas repetitivas (CI/CD) Humildad: Reconocer lo que falta y cuándo agregarlo (Sección 13.7) Este post no te enseña a ser mejor en machine learning.\nTe enseña a ser mejor en machine learning engineering.\nY esa diferencia es la que separa modelos en notebooks de modelos en producción creando valor real.\nSi implementas aunque sea el 50% de lo que está en este post, tu pipeline estará en el top 10% de proyectos de ML en términos de engineering practices.\nSi implementas el 80%, estarás listo para escalar a millones de predictions sin reestructurar todo.\nEl 100% es overkill para la mayoría de proyectos. Usa el Checklist de Producción (Sección 13.7) para priorizar qué necesitas y cuándo.\nReferencias y Recursos Libros fundamentales:\nGéron, A. (2022). Hands-On Machine Learning with Scikit-Learn, Keras \u0026 TensorFlow (3rd ed.). O’Reilly. Capítulo 2: Base de este proyecto (California Housing dataset, feature engineering, model selection) Enfoque en ML, este post agrega la infraestructura de producción Huyen, C. (2022). Designing Machine Learning Systems. O’Reilly. Capítulo 5: Feature stores y cuándo no necesitas uno Capítulo 6: Deployment patterns (Cascade, Circuit Breaker) Capítulo 7: Transform Pattern y Training/Serving Skew (Secciones 13.1 y 13.2 de este post) Capítulo 8: Data Distribution Shifts y drift detection (Sección 13.3) Libro completo: Si solo lees un libro sobre MLOps, que sea este Herramientas (con enlaces a docs):\nMLflow: Model registry y experiment tracking Weights \u0026 Biases: Sweep y visualización de experimentos Hydra: Configuration management con composable configs FastAPI: REST API framework con validación Pydantic Streamlit: Frontend interactivo para ML apps Google Cloud Storage: Almacenamiento de artifacts Evidently AI: Data drift detection (recomendado para producción) Docker: Containerización y reproducibilidad Repositorio completo:\ngithub.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch /api: FastAPI con cascade fallback y Transform Pattern /src: Pipeline modular (01-07) con MLflow tracking /tests: 87% coverage con fixtures realistas /.github/workflows: CI/CD completo con security scanning Autor: Carlos Daniel Jiménez Email: danieljimenez88m@gmail.com LinkedIn: linkedin.com/in/carlosdanieljimenez Fecha: Enero 2026\nNavegación ← Parte 2: Deployment e Infraestructura | ← Parte 1: Pipeline y Orquestación\nSerie completa:\nParte 1: Pipeline y Orquestación Parte 2: Deployment e Infraestructura Parte 3: Producción y Best Practices (actual) Repositorio: github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch\n","wordCount":"7068","inLanguage":"en","datePublished":"2026-01-13T00:00:00Z","dateModified":"2026-01-13T00:00:00Z","author":{"@type":"Person","name":"Carlos Daniel Jiménez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-parte-3/"},"publisher":{"@type":"Organization","name":"The Probability Engine","logo":{"@type":"ImageObject","url":"https://carlosdanieljimenez.com/img/icon.jpeg"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://carlosdanieljimenez.com/ accesskey=h title="The Probability Engine (Alt + H)">The Probability Engine</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://carlosdanieljimenez.com/mlops/ title=MLOps><span>MLOps</span></a></li><li><a href=https://carlosdanieljimenez.com/agentic-ai/ title="Agentic AI"><span>Agentic AI</span></a></li><li><a href=https://carlosdanieljimenez.com/tidytuesday/ title=TidyTuesday><span>TidyTuesday</span></a></li><li><a href=https://carlosdanieljimenez.com/post/ title=Posts><span>Posts</span></a></li><li><a href=https://carlosdanieljimenez.com/edge-computing/ title="Edge Computing"><span>Edge Computing</span></a></li><li><a href=https://carlosdanieljimenez.com/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://carlosdanieljimenez.com/about/ title=About><span>About</span></a></li><li><a href=https://carlosdanieljimenez.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Anatomía de un Pipeline MLOps - Parte 3: Producción y Best Practices</h1><div class=post-description>Parte 3: Estrategias de selección de modelos, testing avanzado, patrones de producción, data drift, model monitoring y checklist de production readiness.</div><div class=post-meta><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;<span>Carlos Daniel Jiménez</span></div></header><div class=post-content><blockquote><p><strong>Serie MLOps Completo:</strong> <a href=/mlops/anatomia-pipeline-mlops-parte-1/>← Parte 1: Pipeline</a> | <a href=/mlops/anatomia-pipeline-mlops-parte-2/>← Parte 2: Deployment</a> | <strong>Parte 3 (actual)</strong></p></blockquote><p><a name=model-strategies></a></p><h2 id=11-estrategias-de-selección-de-modelos-y-parámetros>11. Estrategias de Selección de Modelos y Parámetros<a hidden class=anchor aria-hidden=true href=#11-estrategias-de-selección-de-modelos-y-parámetros>#</a></h2><h3 id=el-flujo-completo-selection--sweep--registration>El Flujo Completo: Selection → Sweep → Registration<a hidden class=anchor aria-hidden=true href=#el-flujo-completo-selection--sweep--registration>#</a></h3><p>Este pipeline implementa una <strong>estrategia de tres fases</strong> para optimización de modelos, cada una con un propósito específico:</p><pre tabindex=0><code>Step 05: Model Selection
├── Compara 5 algoritmos con GridSearch básico (5-10 combos/modelo)
├── Objetivo: Identificar mejor familia de modelo (Random Forest vs Gradient Boosting vs ...)
├── Métrica principal: MAPE (Mean Absolute Percentage Error)
└── Output: Mejor algoritmo + parámetros iniciales

Step 06: Hyperparameter Sweep
├── Optimiza SOLO el mejor algoritmo del Step 05
├── Bayesian optimization con 50+ runs (espacio de búsqueda exhaustivo)
├── Objetivo: Encontrar configuración óptima del mejor modelo
├── Métrica principal: wMAPE (Weighted MAPE, menos sesgado)
└── Output: best_params.yaml con hiperparámetros óptimos

Step 07: Model Registration
├── Entrena modelo final con parámetros de Step 06
├── Registra en MLflow Model Registry con metadata rica
├── Transiciona a stage (Staging/Production)
└── Output: Modelo versionado listo para deployment
</code></pre><p><strong>¿Por qué tres steps separados?</strong> No tienes recursos computacionales para hacer sweep exhaustivo de 5 algoritmos × 50 combinaciones = 250 entrenamientos. Primero decides <strong>estrategia</strong> (qué algoritmo), luego <strong>tácticas</strong> (qué hiperparámetros).</p><hr><h3 id=step-05-model-selection---comparación-de-algoritmos>Step 05: Model Selection - Comparación de Algoritmos<a hidden class=anchor aria-hidden=true href=#step-05-model-selection---comparación-de-algoritmos>#</a></h3><h4 id=los-5-modelos-candidatos>Los 5 Modelos Candidatos<a hidden class=anchor aria-hidden=true href=#los-5-modelos-candidatos>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_available_models</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Get dictionary of available regression models.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>models</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;RandomForest&#34;</span><span class=p>:</span> <span class=n>RandomForestRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GradientBoosting&#34;</span><span class=p>:</span> <span class=n>GradientBoostingRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ridge&#34;</span><span class=p>:</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Lasso&#34;</span><span class=p>:</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;DecisionTree&#34;</span><span class=p>:</span> <span class=n>DecisionTreeRegressor</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>models</span>
</span></span></code></pre></div><p><strong>Por qué estos modelos:</strong></p><ol><li><strong>RandomForest</strong>: Ensemble de árboles, robusto, maneja no-linealidades</li><li><strong>GradientBoosting</strong>: Boosting secuencial, mejor precisión que RF pero más lento</li><li><strong>Ridge</strong>: Regresión lineal con regularización L2, rápido, interpretable</li><li><strong>Lasso</strong>: Regresión lineal con regularización L1, hace feature selection</li><li><strong>DecisionTree</strong>: Baseline simple, útil para comparación</li></ol><p><strong>Lo que falta (deliberadamente):</strong></p><ul><li><strong>XGBoost/LightGBM</strong>: No incluidos para reducir dependencias, pero fácil de agregar</li><li><strong>Neural Networks</strong>: Overkill para este problema (20k muestras, features tabulares)</li><li><strong>SVR</strong>: Muy lento en datasets grandes, no escala bien</li></ul><h4 id=parameter-grids-gridsearch-inicial>Parameter Grids: GridSearch Inicial<a hidden class=anchor aria-hidden=true href=#parameter-grids-gridsearch-inicial>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_default_param_grids</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Parameter grids for initial model selection.
</span></span></span><span class=line><span class=cl><span class=s2>    Refinados basados en domain knowledge.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>param_grids</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;RandomForest&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>200</span><span class=p>,</span> <span class=mi>300</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>         <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>             <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>               <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total combinaciones: 4×5×3×3 = 180</span>
</span></span><span class=line><span class=cl>        <span class=c1># Con 5-fold CV: 180×5 = 900 fits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GradientBoosting&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>150</span><span class=p>,</span> <span class=mi>200</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;learning_rate&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span> <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span>                <span class=c1># 5 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;subsample&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.9</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>],</span>                <span class=c1># 3 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 4×5×5×3 = 300 combinaciones</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ridge&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 9 combinaciones (rápido)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Lasso&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 9 combinaciones</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;DecisionTree&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>      <span class=c1># 6 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span>         <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span>            <span class=c1># 4 opciones</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=c1># Total: 6×4×4 = 96 combinaciones</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>param_grids</span>
</span></span></code></pre></div><h4 id=decisiones-de-diseño-de-los-grids>Decisiones de Diseño de los Grids<a hidden class=anchor aria-hidden=true href=#decisiones-de-diseño-de-los-grids>#</a></h4><p><strong>1. RandomForest: Foco en Overfitting Control</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span></span></code></pre></div><p><strong>Razonamiento:</strong> Random Forest tiende a overfit en datasets pequeños. <code>max_depth</code> y <code>min_samples_leaf</code> controlan profundidad de árboles—valores altos previenen que el modelo memorice ruido.</p><p><strong>None en max_depth:</strong> Permite árboles de profundidad ilimitada. Útil cuando el dataset tiene patrones complejos que requieren splits profundos.</p><p><strong>2. GradientBoosting: Balance Learning Rate vs N_estimators</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>150</span><span class=p>,</span> <span class=mi>200</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;learning_rate&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span>
</span></span></code></pre></div><p><strong>Trade-off clásico:</strong></p><ul><li><strong>Learning rate bajo (0.01) + muchos estimators (200):</strong> Aprendizaje lento pero preciso</li><li><strong>Learning rate alto (0.2) + pocos estimators (50):</strong> Rápido pero puede divergir</li></ul><p>GridSearch explora ambos extremos.</p><p><strong>subsample &lt; 1.0:</strong> Stochastic Gradient Boosting. Solo usa 80-90% de datos en cada iteración, reduce overfitting.</p><p><strong>3. Ridge/Lasso: Alpha en Escala Logarítmica</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;alpha&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>,</span> <span class=mf>500.0</span><span class=p>],</span>
</span></span></code></pre></div><p>Alpha controla regularización:</p><ul><li><strong>Alpha bajo (0.01):</strong> Casi sin regularización, modelo complejo</li><li><strong>Alpha alto (500):</strong> Regularización fuerte, modelo simple (coeficientes cercanos a 0)</li></ul><p>Escala logarítmica cubre el espacio de manera más uniforme que escala lineal.</p><p><strong>Lasso vs Ridge:</strong></p><ul><li><strong>Lasso (L1):</strong> Fuerza coeficientes a <strong>exactamente 0</strong> → feature selection automática</li><li><strong>Ridge (L2):</strong> Coeficientes pequeños pero <strong>no cero</strong> → mantiene todas las features</li></ul><p>Si Lasso gana, indica que algunas features son ruido.</p><p><strong>4. DecisionTree: Baseline de Comparación</strong></p><p>DecisionTree es el peor modelo (alto variance, overfit fácil), pero sirve para:</p><ul><li>Verificar que el pipeline funciona correctamente</li><li>Baseline de comparación: Si Ridge/Lasso no superan DecisionTree, algo está mal en feature engineering</li></ul><h4 id=la-función-de-entrenamiento-con-gridsearch>La Función de Entrenamiento con GridSearch<a hidden class=anchor aria-hidden=true href=#la-función-de-entrenamiento-con-gridsearch>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model_with_gridsearch</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>param_grid</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>y_train</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>cv</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>Any</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=nb>float</span><span class=p>,</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Train model with K-fold Cross-Validation via GridSearchCV.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>param_grid</span><span class=o>=</span><span class=n>param_grid</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>  <span class=c1># 5-fold cross-validation</span>
</span></span><span class=line><span class=cl>        <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;neg_mean_absolute_error&#39;</span><span class=p>,</span>  <span class=c1># CRÍTICO</span>
</span></span><span class=line><span class=cl>        <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># Paralelización</span>
</span></span><span class=line><span class=cl>        <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># Para detectar overfitting</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>training_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Extract cross-validation results</span>
</span></span><span class=line><span class=cl>    <span class=n>cv_metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mean_test_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=o>-</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;std_test_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;std_test_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mean_train_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=o>-</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;mean_train_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;std_train_score&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>[</span><span class=s1>&#39;std_train_score&#39;</span><span class=p>][</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_index_</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>,</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=p>,</span> <span class=n>training_time</span><span class=p>,</span> <span class=n>cv_metrics</span>
</span></span></code></pre></div><h4 id=decisiones-críticas>Decisiones Críticas<a hidden class=anchor aria-hidden=true href=#decisiones-críticas>#</a></h4><p><strong>1. Scoring: neg_mean_absolute_error</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;neg_mean_absolute_error&#39;</span>
</span></span></code></pre></div><p><strong>¿Por qué MAE y no RMSE o R²?</strong></p><ul><li><strong>MAE (Mean Absolute Error)</strong>: Penaliza errores linealmente</li><li><strong>RMSE</strong>: Penaliza errores cuadraticamente (errores grandes pesan mucho más)</li><li><strong>R²</strong>: Métrica relativa, difícil de interpretar en términos de negocio</li></ul><p>Para este problema:</p><ul><li>MAE = $15,000 → &ldquo;El modelo se equivoca $15k en promedio&rdquo;</li><li>R² = 0.85 → ¿Qué significa para el negocio?</li></ul><p><strong>neg_mean_absolute_error:</strong> GridSearchCV minimiza la métrica, pero MAE se debe minimizar, entonces usamos la negativa.</p><p><strong>2. Cross-Validation: 5 Folds</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>cv</span><span class=o>=</span><span class=mi>5</span>
</span></span></code></pre></div><p><strong>¿Por qué 5 y no 10?</strong></p><ul><li><p><strong>5-fold:</strong> Balance entre bias (sesgo) y variance (varianza)</p><ul><li>Cada fold tiene 80% training, 20% validation</li><li>Más rápido que 10-fold (2x menos fits)</li></ul></li><li><p><strong>10-fold:</strong> Menos bias pero más costo computacional</p><ul><li>Útil cuando tienes pocos datos (&lt;1000 samples)</li></ul></li></ul><p>Con 16,512 training samples, 5-fold es suficiente.</p><p><strong>3. return_train_score=True</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>return_train_score</span><span class=o>=</span><span class=kc>True</span>
</span></span></code></pre></div><p>Esto loggea el score en <strong>training set</strong> además de validation set. Permite detectar overfitting:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=n>cv_metrics</span><span class=p>[</span><span class=s1>&#39;mean_train_score&#39;</span><span class=p>]</span> <span class=o>&gt;&gt;</span> <span class=n>cv_metrics</span><span class=p>[</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;WARNING: Model is overfitting!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Train MAE = $5k, Test MAE = $20k → Overfitting claro</span>
</span></span></code></pre></div><p><strong>4. n_jobs=-1: Paralelización</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span>
</span></span></code></pre></div><p>Usa todos los CPU cores disponibles. En una máquina con 8 cores, 180 combinaciones × 5 folds = 900 fits se distribuyen en paralelo.</p><p><strong>Sin paralelización:</strong> 900 fits × 2s/fit = 30 minutos
<strong>Con 8 cores:</strong> ~4 minutos</p><h4 id=métricas-de-evaluación-más-allá-de-mape>Métricas de Evaluación: Más Allá de MAPE<a hidden class=anchor aria-hidden=true href=#métricas-de-evaluación-más-allá-de-mape>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span> <span class=n>X_test</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>y_test</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Evalúa modelo con métricas business-focused.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y_true</span> <span class=o>=</span> <span class=n>y_test</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Traditional metrics</span>
</span></span><span class=line><span class=cl>    <span class=n>mae</span> <span class=o>=</span> <span class=n>mean_absolute_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Business-focused percentage error metrics</span>
</span></span><span class=line><span class=cl>    <span class=n>mape</span> <span class=o>=</span> <span class=n>mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>smape</span> <span class=o>=</span> <span class=n>symmetric_mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wmape</span> <span class=o>=</span> <span class=n>weighted_mean_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>median_ape</span> <span class=o>=</span> <span class=n>median_absolute_percentage_error</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Prediction accuracy at different thresholds</span>
</span></span><span class=line><span class=cl>    <span class=n>within_5pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>within_10pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>within_15pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mae&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>mae</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rmse&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>rmse</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>r2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>mape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;smape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>smape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>wmape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;median_ape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>median_ape</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_5pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_5pct</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_10pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_10pct</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_15pct&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>within_15pct</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p><strong>Por Qué 4 Variantes de MAPE:</strong></p><p><strong>1. MAPE (Mean Absolute Percentage Error)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>((</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p><strong>Problema:</strong> Sesgado hacia valores bajos.</p><p>Si predices $500k en vez de $510k → error = 2%
Si predices $10k en vez de $11k → error = 9%</p><p>Ambos son $10k de error absoluto, pero MAPE penaliza más el segundo.</p><p><strong>2. SMAPE (Symmetric MAPE)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>smape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=p>((</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span><span class=p>)</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_pred</span><span class=p>))</span> <span class=o>/</span> <span class=mi>2</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Usa el promedio de <code>y_true</code> y <code>y_pred</code> en el denominador. Más simétrico:</p><ul><li>Overprediction y underprediction tienen peso similar</li><li>Rango: 0-200% (vs 0-∞% de MAPE)</li></ul><p><strong>3. wMAPE (Weighted MAPE)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wmape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>))</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Suma total de errores dividido por suma total de valores reales. No afectado por valores individuales extremos.</p><p><strong>Usado en Step 06 (Sweep)</strong> porque es más robusto que MAPE para datasets con varianza alta.</p><p><strong>4. Median APE</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>median_ape</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>((</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span><span class=p>))</span> <span class=o>*</span> <span class=mi>100</span>
</span></span></code></pre></div><p>Mediana en lugar de media. Robusto a outliers.</p><p>Si 95% de predicciones tienen &lt;5% error pero 5% tienen >50% error:</p><ul><li><strong>MAPE:</strong> ~7% (promedio incluye outliers)</li><li><strong>Median APE:</strong> ~4% (outliers no afectan la mediana)</li></ul><p><strong>Within-X% Metrics</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>within_5pct</span> <span class=o>=</span> <span class=n>predictions_within_threshold</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Porcentaje de predicciones con error &lt;5%</span>
</span></span></code></pre></div><p><strong>Business interpretation:</strong> &ldquo;El 75% de nuestras predicciones están dentro de ±10% del valor real.&rdquo;</p><p>Más interpretable para stakeholders que &ldquo;MAPE = 8.2%&rdquo;.</p><h4 id=output-del-step-05>Output del Step 05<a hidden class=anchor aria-hidden=true href=#output-del-step-05>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34; BEST MODEL: RandomForestRegressor&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Business Metrics (Test Set):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  MAPE (Mean APE): 8.23%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  SMAPE (Symmetric MAPE): 7.95%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  wMAPE (Weighted MAPE): 8.01%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Median APE: 6.45%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±5%: 45.2%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±10%: 72.8%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Within ±15%: 85.3%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Traditional Metrics (Test Set):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  R²: 0.8654&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  RMSE: $48,234.12&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  MAE: $32,456.78&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Cross-Validation Results (5-fold):&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Mean CV MAE: $33,125.45 (±$2,341.23)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;  Mean CV Train MAE: $28,934.56 (±$1,892.34)&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Best params guardados:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Estos params se usan como <strong>punto de partida</strong> para el Step 06 (Sweep exhaustivo).</p><hr><h3 id=lo-que-esta-estrategia-logra>Lo Que Esta Estrategia Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esta-estrategia-logra>#</a></h3><p><strong>Sin model selection:</strong></p><ul><li>&ldquo;Usé Random Forest porque lo usa todo el mundo&rdquo;</li><li>No tienes evidencia de que es mejor que Gradient Boosting</li></ul><p><strong>Con model selection:</strong></p><ul><li>&ldquo;Comparé 5 algoritmos con 5-fold CV. Random Forest logró MAPE=8.2% (vs GradientBoosting=8.9%, Ridge=12.3%). Aquí está la tabla comparativa en W&amp;B.&rdquo;</li><li><strong>Decisión respaldada por datos, no intuición.</strong></li></ul><hr><p><a name=testing></a></p><h2 id=11-testing-fixtures-mocking-y-coverage-real>11. Testing: Fixtures, Mocking y Coverage Real<a hidden class=anchor aria-hidden=true href=#11-testing-fixtures-mocking-y-coverage-real>#</a></h2><h3 id=por-qué-testear-ml-es-diferente>Por Qué Testear ML Es Diferente<a hidden class=anchor aria-hidden=true href=#por-qué-testear-ml-es-diferente>#</a></h3><p>Los tests en ML no son como tests en web apps. No puedes hacer:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_model_predicts_correct_value</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>load_model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>]])</span> <span class=o>==</span> <span class=mf>452600.0</span>  <span class=c1># ERROR: Esto es absurdo</span>
</span></span></code></pre></div><p>Los modelos ML son <strong>probabilísticos</strong>. La salida no es determinística en el sentido de software tradicional.</p><p><strong>Lo que SÍ puedes testear:</strong></p><ol><li><strong>Contratos de datos:</strong> Inputs/outputs tienen los tipos correctos</li><li><strong>Invariantes:</strong> Predicciones están en rango esperado</li><li><strong>Reproducibilidad:</strong> Mismo input → mismo output (con seed fijo)</li><li><strong>Pipeline integrity:</strong> Steps corren sin explotar</li><li><strong>Integración:</strong> Components se comunican correctamente</li></ol><h3 id=conftestpy-fixtures-compartidas>conftest.py: Fixtures Compartidas<a hidden class=anchor aria-hidden=true href=#conftestpy-fixtures-compartidas>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Common fixtures for pytest
</span></span></span><span class=line><span class=cl><span class=s2>Autor: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>google.cloud</span> <span class=kn>import</span> <span class=n>storage</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>unittest.mock</span> <span class=kn>import</span> <span class=n>MagicMock</span><span class=p>,</span> <span class=n>Mock</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sample_housing_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea datos sintéticos de vivienda.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;longitude&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>124</span><span class=p>,</span> <span class=o>-</span><span class=mi>114</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;latitude&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;housing_median_age&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>53</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;total_rooms&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>500</span><span class=p>,</span> <span class=mi>5000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;total_bedrooms&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;population&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>500</span><span class=p>,</span> <span class=mi>3000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;households&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;median_income&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;median_house_value&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>50000</span><span class=p>,</span> <span class=mi>500000</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Agregar missing values a total_bedrooms</span>
</span></span><span class=line><span class=cl>    <span class=n>missing_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>n_samples</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>loc</span><span class=p>[</span><span class=n>missing_indices</span><span class=p>,</span> <span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mock_gcs_client</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Crea mock de GCS client.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_client</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Bucket</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_blob</span> <span class=o>=</span> <span class=n>MagicMock</span><span class=p>(</span><span class=n>spec</span><span class=o>=</span><span class=n>storage</span><span class=o>.</span><span class=n>Blob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span><span class=o>.</span><span class=n>exists</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_bucket</span><span class=o>.</span><span class=n>blob</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=n>mock_blob</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_client</span><span class=o>.</span><span class=n>bucket</span><span class=o>.</span><span class=n>return_value</span> <span class=o>=</span> <span class=n>mock_bucket</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;client&#39;</span><span class=p>:</span> <span class=n>mock_client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;bucket&#39;</span><span class=p>:</span> <span class=n>mock_bucket</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;blob&#39;</span><span class=p>:</span> <span class=n>mock_blob</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@pytest.fixture</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mock_mlflow</span><span class=p>(</span><span class=n>monkeypatch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Mocks MLflow functions.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_metric</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_param</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>mock_log_artifact</span> <span class=o>=</span> <span class=n>Mock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_metric&#39;</span><span class=p>,</span> <span class=n>mock_log_metric</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_param&#39;</span><span class=p>,</span> <span class=n>mock_log_param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>monkeypatch</span><span class=o>.</span><span class=n>setattr</span><span class=p>(</span><span class=s1>&#39;mlflow.log_artifact&#39;</span><span class=p>,</span> <span class=n>mock_log_artifact</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_metric&#39;</span><span class=p>:</span> <span class=n>mock_log_metric</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_param&#39;</span><span class=p>:</span> <span class=n>mock_log_param</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;log_artifact&#39;</span><span class=p>:</span> <span class=n>mock_log_artifact</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><h3 id=test-de-imputación-contratos-de-datos>Test de Imputación: Contratos de Datos<a hidden class=anchor aria-hidden=true href=#test-de-imputación-contratos-de-datos>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Tests para ImputationAnalyzer
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>imputation_analyzer</span> <span class=kn>import</span> <span class=n>ImputationAnalyzer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_imputation_analyzer_returns_dataframe</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que imputer retorna DataFrame con missing values rellenados.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>analyzer</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>,</span> <span class=n>target_column</span><span class=o>=</span><span class=s2>&#34;total_bedrooms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Comparar estrategias</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Assertions</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span>  <span class=c1># 4 estrategias</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>all</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>rmse</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=k>for</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Aplicar mejor imputer</span>
</span></span><span class=line><span class=cl>    <span class=n>df_imputed</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>apply_best_imputer</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que no quedan NaNs</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>df_imputed</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que el resto de columnas no cambió</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>df_imputed</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample_housing_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_imputation_analyzer_reproducibility</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que la imputación es reproducible con seed fijo.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df1</span> <span class=o>=</span> <span class=n>generate_sample_data</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>analyzer1</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results1</span> <span class=o>=</span> <span class=n>analyzer1</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df2</span> <span class=o>=</span> <span class=n>generate_sample_data</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>analyzer2</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results2</span> <span class=o>=</span> <span class=n>analyzer2</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Mismo input + mismo seed = mismo output</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>results1</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span> <span class=o>==</span> <span class=n>results2</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span>
</span></span></code></pre></div><h3 id=test-de-pipeline-completo-integration-test>Test de Pipeline Completo: Integration Test<a hidden class=anchor aria-hidden=true href=#test-de-pipeline-completo-integration-test>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Integration test del pipeline completo
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pytest</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_pipeline_runs_end_to_end</span><span class=p>(</span><span class=n>tmp_path</span><span class=p>,</span> <span class=n>mock_gcs_client</span><span class=p>,</span> <span class=n>sample_housing_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Test que el pipeline corre de principio a fin sin explotar.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Setup: Guardar datos sintéticos</span>
</span></span><span class=line><span class=cl>    <span class=n>data_path</span> <span class=o>=</span> <span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;housing.parquet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>sample_housing_data</span><span class=o>.</span><span class=n>to_parquet</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 01: Download (mockeado)</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 02: Preprocessing</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>preprocessor</span> <span class=kn>import</span> <span class=n>DataPreprocessor</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>PreprocessingConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_input_path</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>data_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>gcs_output_path</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;processed.parquet&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket_name</span><span class=o>=</span><span class=s2>&#34;test-bucket&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>preprocessor</span> <span class=o>=</span> <span class=n>DataPreprocessor</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>preprocessor</span><span class=o>.</span><span class=n>run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>result</span><span class=o>.</span><span class=n>success</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>result</span><span class=o>.</span><span class=n>num_rows_output</span> <span class=o>&gt;</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 03: Feature Engineering</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Verificar que outputs existen</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=p>(</span><span class=n>tmp_path</span> <span class=o>/</span> <span class=s2>&#34;processed.parquet&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=coverage-real>Coverage Real<a hidden class=anchor aria-hidden=true href=#coverage-real>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Ejecutar tests con coverage</span>
</span></span><span class=line><span class=cl>pytest tests/ --cov<span class=o>=</span>src --cov-report<span class=o>=</span>html --cov-report<span class=o>=</span>term-missing
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Output:</span>
</span></span><span class=line><span class=cl><span class=c1># ==================== test session starts ====================</span>
</span></span><span class=line><span class=cl><span class=c1># tests/test_imputation_analyzer.py ........    [80%]</span>
</span></span><span class=line><span class=cl><span class=c1># tests/test_feature_engineering.py ....       [100%]</span>
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl><span class=c1># ----------- coverage: 87% -----------</span>
</span></span><span class=line><span class=cl><span class=c1># src/data/02_preprocessing/imputation_analyzer.py   92%</span>
</span></span><span class=line><span class=cl><span class=c1># src/data/03_feature_engineering/feature_engineer.py   85%</span>
</span></span></code></pre></div><h3 id=lo-que-esto-logra>Lo Que Esto Logra<a hidden class=anchor aria-hidden=true href=#lo-que-esto-logra>#</a></h3><p><strong>Sin tests:</strong> &ldquo;Creo que funciona, corrí el notebook una vez y no explotó.&rdquo;</p><p><strong>Con tests:</strong> &ldquo;87% de coverage. Todos los components críticos están testeados. CI corre los tests en cada commit.&rdquo;</p><p>Los tests <strong>no garantizan que el modelo sea bueno</strong>, pero garantizan que el <strong>sistema que produce el modelo es confiable</strong>.</p><hr><p><a name=production-patterns></a></p><h2 id=12-patrones-de-producción-que-nadie-te-cuenta>12. Patrones de Producción Que Nadie Te Cuenta<a hidden class=anchor aria-hidden=true href=#12-patrones-de-producción-que-nadie-te-cuenta>#</a></h2><h3 id=el-problema-real-del-serving>El Problema Real del Serving<a hidden class=anchor aria-hidden=true href=#el-problema-real-del-serving>#</a></h3><p>Aquí está lo que ningún tutorial te dice: el 90% del esfuerzo en ML no es entrenar un modelo—es hacer que ese modelo sirva predicciones confiables 24/7 sin explotar.</p><p>Los cursos de ML terminan con <code>model.save('model.pkl')</code>. La realidad de producción empieza con preguntas como:</p><ul><li>¿Qué pasa si el modelo necesita un KMeans entrenado para generar features?</li><li>¿Guardas el KMeans también? ¿Y si pesa 500MB?</li><li>¿Cómo garantizas que el preprocesamiento en producción es EXACTAMENTE igual al de entrenamiento?</li><li>¿Y si la distribución de datos cambia y tu modelo empieza a fallar silenciosamente?</li></ul><p>Este pipeline implementa soluciones a estos problemas que rara vez se discuten. Vamos a diseccionarlas.</p><hr><h3 id=121-el-transform-pattern-el-truco-del-kmeans-sintético>12.1. El Transform Pattern: El Truco del KMeans Sintético<a hidden class=anchor aria-hidden=true href=#121-el-transform-pattern-el-truco-del-kmeans-sintético>#</a></h3><p><strong>Contexto:</strong> En el Step 03 (Feature Engineering), el pipeline entrena un KMeans con 10 clusters sobre latitud/longitud. El modelo final necesita <code>cluster_label</code> como feature.</p><p><strong>Problema clásico:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Durante training</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>  <span class=c1># Entrena en 16,000 samples de California</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cluster_label&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Entrenas el modelo</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ¿Ahora qué? ¿Cómo guardas el kmeans para usarlo en el API?</span>
</span></span></code></pre></div><p><strong>Solución naive (la que hace el 80% de la gente):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Guarda AMBOS modelos</span>
</span></span><span class=line><span class=cl><span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>kmeans</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;kmeans.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;model.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># En el API: Carga ambos</span>
</span></span><span class=line><span class=cl><span class=n>kmeans</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s1>&#39;kmeans.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>pickle</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=nb>open</span><span class=p>(</span><span class=s1>&#39;model.pkl&#39;</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Para cada predicción:</span>
</span></span><span class=line><span class=cl><span class=n>cluster</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>([[</span><span class=n>lon</span><span class=p>,</span> <span class=n>lat</span><span class=p>]])</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=n>cluster</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>prediction</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué esto es terrible:</strong></p><ol><li><strong>Overhead de almacenamiento:</strong> KMeans serializado puede pesar 96KB por cada modelo. Multiplica eso por 50 versiones de modelo.</li><li><strong>Coupling:</strong> Ahora tu API necesita cargar DOS artifacts por cada versión de modelo. ¿Qué pasa si se desincronan?</li><li><strong>Latency:</strong> Llamar <code>kmeans.predict()</code> añade ~2ms por request.</li></ol><p><strong>La solución brillante que este proyecto implementa:</strong></p><p>Chip Huyen llama a esto el <strong>Transform Pattern</strong> en &ldquo;Designing Machine Learning Systems&rdquo; (Capítulo 7, sección sobre feature consistency): cuando el preprocesamiento es ligero y determinístico, <strong>recréalo en el serving layer en lugar de serializarlo</strong>.</p><p>Mira el código real en <code>api/app/core/preprocessor.py</code> (líneas 61-110):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_init_kmeans</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Initialize KMeans with California housing geographical clusters.
</span></span></span><span class=line><span class=cl><span class=s2>        Uses typical California housing coordinates to create clusters.
</span></span></span><span class=line><span class=cl><span class=s2>        This is an approximation but works for the API use case.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># California housing typical ranges:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Longitude: -124 to -114</span>
</span></span><span class=line><span class=cl>        <span class=c1># Latitude: 32 to 42</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>  <span class=c1># CRÍTICO: Mismo seed que en training</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Crea datos sintéticos representando geografía de California</span>
</span></span><span class=line><span class=cl>        <span class=n>n_samples</span> <span class=o>=</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl>        <span class=n>lon_samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>124</span><span class=p>,</span> <span class=o>-</span><span class=mi>114</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lat_samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Peso hacia centros poblacionales principales</span>
</span></span><span class=line><span class=cl>        <span class=n>major_centers</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>118</span><span class=p>,</span> <span class=mi>34</span><span class=p>],</span>   <span class=c1># LA</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>122</span><span class=p>,</span> <span class=mf>37.5</span><span class=p>],</span> <span class=c1># SF</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>117</span><span class=p>,</span> <span class=mi>33</span><span class=p>],</span>   <span class=c1># San Diego</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>121</span><span class=p>,</span> <span class=mf>38.5</span><span class=p>],</span> <span class=c1># Sacramento</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=o>-</span><span class=mi>119</span><span class=p>,</span> <span class=mf>36.5</span><span class=p>],</span> <span class=c1># Fresno</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Añade centros principales múltiples veces para proper weighting</span>
</span></span><span class=line><span class=cl>        <span class=n>lon_samples</span><span class=p>[:</span><span class=mi>50</span><span class=p>]</span> <span class=o>=</span> <span class=n>major_centers</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lat_samples</span><span class=p>[:</span><span class=mi>50</span><span class=p>]</span> <span class=o>=</span> <span class=n>major_centers</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>X_geo</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>column_stack</span><span class=p>([</span><span class=n>lon_samples</span><span class=p>,</span> <span class=n>lat_samples</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Fit KMeans</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>  <span class=c1># MISMO seed que training</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_geo</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>¿Qué está pasando aquí?</strong></p><p>En lugar de serializar el KMeans entrenado con 16,512 samples reales, el API <strong>recrea un KMeans sintético</strong> usando:</p><ol><li><strong>Datos sintéticos</strong> que aproximan la distribución geográfica de California</li><li><strong>Mismo seed (42)</strong> que se usó en training</li><li><strong>Mismo n_clusters (10)</strong></li><li><strong>Centros ponderados</strong> hacia ciudades principales (LA, SF, San Diego)</li></ol><p><strong>Trade-offs de esta solución:</strong></p><p><strong>Ventajas:</strong></p><ul><li>Zero overhead de almacenamiento (no guardas el KMeans)</li><li>Zero coupling (API es autónomo, no necesita artifacts adicionales)</li><li>Latency idéntica (~2ms de todas formas)</li><li>Stateless serving (puedes escalar el API horizontalmente sin state compartido)</li></ul><p><strong>Desventajas:</strong></p><ul><li><strong>Cluster drift:</strong> Los clusters sintéticos NO son exactamente los mismos que los de training<ul><li>En testing interno: ~2% de mismatch en cluster labels</li><li>En California Housing: impacto en MAPE &lt; 0.3%</li></ul></li><li>Requiere que el preprocesamiento sea <strong>determinístico y ligero</strong><ul><li>No funciona si tu KMeans necesita 1 millón de samples para converger</li><li>No funciona si tienes embeddings de texto de 512 dimensiones</li></ul></li></ul><p><strong>Cuándo usar este pattern:</strong></p><p><strong>SÍ úsalo si:</strong></p><ul><li>El preprocesamiento es ligero (&lt;10ms)</li><li>El feature es geográfico/categórico con pocos valores únicos</li><li>El impacto de ligera inconsistencia es tolerable (regresión, clasificación con margen)</li></ul><p><strong>NO lo uses si:</strong></p><ul><li>El feature es un embedding profundo (BERT, ResNet)</li><li>Necesitas 100% reproducibilidad bit-a-bit</li><li>El preprocesamiento requiere gigabytes de state</li></ul><p><strong>La lección:</strong></p><p>Chip Huyen lo resume así: &ldquo;The best feature engineering pipeline is the one that doesn&rsquo;t exist.&rdquo; Si puedes computar features on-the-fly sin cost prohibitivo, evita serializar state. Tu sistema será más simple, más robusto, y más fácil de debuggear.</p><p>Este truco del KMeans sintético es un ejemplo perfecto. <strong>No lo vas a encontrar en ningún tutorial de Kaggle.</strong></p><hr><h3 id=122-trainingserving-skew-el-asesino-silencioso>12.2. Training/Serving Skew: El Asesino Silencioso<a hidden class=anchor aria-hidden=true href=#122-trainingserving-skew-el-asesino-silencioso>#</a></h3><p>Huyen dedica una sección completa a esto en el Capítulo 7. El <strong>training/serving skew</strong> es cuando el preprocesamiento en training es diferente al de serving.</p><p><strong>Ejemplo clásico que mata proyectos:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># En tu notebook de training</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms_log&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log1p</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6 meses después, alguien implementa el API</span>
</span></span><span class=line><span class=cl><span class=c1># (sin leer el notebook completo)</span>
</span></span><span class=line><span class=cl><span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms_log&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>])</span>  <span class=c1># BUG: log vs log1p</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Resultado: El modelo falla silenciosamente</span>
</span></span><span class=line><span class=cl><span class=c1># MAPE en training: 8%</span>
</span></span><span class=line><span class=cl><span class=c1># MAPE en producción: 24%</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Por qué? Porque log(0) = -inf, log1p(0) = 0</span>
</span></span></code></pre></div><p><strong>Cómo este proyecto evita esto:</strong></p><p>El preprocesamiento está encapsulado en <strong>UNA sola clase</strong> que se usa BOTH en training y serving:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># src/data/02_preprocessing/preprocessor.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Imputación</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_impute</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># One-hot encoding</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Usado en training (Step 02)</span>
</span></span><span class=line><span class=cl><span class=n>preprocessor</span> <span class=o>=</span> <span class=n>DataPreprocessor</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_processed</span> <span class=o>=</span> <span class=n>preprocessor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>train_raw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MISMO código usado en API</span>
</span></span><span class=line><span class=cl><span class=c1># api/app/core/preprocessor.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>  <span class=c1># Mismo transform logic</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Mismo one-hot encoding</span>
</span></span><span class=line><span class=cl>        <span class=c1># Mismo order de columnas</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df</span>
</span></span></code></pre></div><p><strong>La garantía:</strong></p><p>Si cambias el preprocesamiento, <strong>ambos</strong> training y serving se actualizan porque es <strong>el mismo código</strong>.</p><p><strong>El anti-pattern:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training: notebook_v3_FINAL.ipynb</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;bedrooms_per_room&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API: Alguien copia/pega sin verificar</span>
</span></span><span class=line><span class=cl><span class=n>features</span><span class=p>[</span><span class=s1>&#39;bedrooms_per_room&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_bedrooms&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>features</span><span class=p>[</span><span class=s1>&#39;total_rooms&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Qué pasa con división por cero?</span>
</span></span><span class=line><span class=cl><span class=c1># ¿Qué pasa si total_rooms es 0?</span>
</span></span><span class=line><span class=cl><span class=c1># En training nunca pasó porque limpiaste outliers</span>
</span></span><span class=line><span class=cl><span class=c1># En producción... BOOM</span>
</span></span></code></pre></div><p><strong>El mantra:</strong></p><p>&ldquo;If you can&rsquo;t import it, you can&rsquo;t trust it.&rdquo; Si tu preprocesamiento está copy/pasted entre training y serving, <strong>ya perdiste</strong>.</p><hr><h3 id=123-data-drift-el-enemigo-que-este-proyecto-aún-no-monitorea>12.3. Data Drift: El Enemigo Que Este Proyecto (Aún) No Monitorea<a hidden class=anchor aria-hidden=true href=#123-data-drift-el-enemigo-que-este-proyecto-aún-no-monitorea>#</a></h3><p>Ahora vamos a lo que <strong>NO</strong> está en este proyecto pero es crítico para sistemas en producción.</p><p><strong>Data drift</strong> (deriva de datos) es cuando la distribución de tus features en producción cambia con respecto a training.</p><p>Huyen lo cubre exhaustivamente en el Capítulo 8 (&ldquo;Data Distribution Shifts&rdquo;). Hay tres tipos:</p><p><strong>1. Covariate Shift (el más común):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training data (2020-2022)</span>
</span></span><span class=line><span class=cl><span class=c1># Distribución de median_income</span>
</span></span><span class=line><span class=cl><span class=n>P_train</span><span class=p>(</span><span class=n>median_income</span><span class=p>):</span> <span class=n>mean</span> <span class=o>=</span> <span class=err>$</span><span class=mf>6.2</span><span class=n>k</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=err>$</span><span class=mf>3.1</span><span class=n>k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Production data (2023-2024)</span>
</span></span><span class=line><span class=cl><span class=c1># Después de inflación + cambios económicos</span>
</span></span><span class=line><span class=cl><span class=n>P_prod</span><span class=p>(</span><span class=n>median_income</span><span class=p>):</span> <span class=n>mean</span> <span class=o>=</span> <span class=err>$</span><span class=mf>8.5</span><span class=n>k</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=err>$</span><span class=mf>4.2</span><span class=n>k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Resultado:</span>
</span></span><span class=line><span class=cl><span class=c1># - El modelo fue entrenado en features con mean=$6.2k</span>
</span></span><span class=line><span class=cl><span class=c1># - Ahora recibe features con mean=$8.5k</span>
</span></span><span class=line><span class=cl><span class=c1># - Las predicciones se vuelven imprecisas</span>
</span></span></code></pre></div><p><strong>2. Label Shift:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Training: California 2020</span>
</span></span><span class=line><span class=cl><span class=c1># median_house_value promedio: $250k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Production: California 2024</span>
</span></span><span class=line><span class=cl><span class=c1># median_house_value promedio: $400k (boom inmobiliario)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># El modelo predice basándose en relaciones de 2020</span>
</span></span><span class=line><span class=cl><span class=c1># Pero los precios absolutos cambiaron</span>
</span></span></code></pre></div><p><strong>3. Concept Drift:</strong></p><p>La relación entre features y target cambia.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 2020: ocean_proximity=&#39;NEAR OCEAN&#39; → +$50k en precio</span>
</span></span><span class=line><span class=cl><span class=c1># 2024: Work-from-home → gente prefiere INLAND → -$20k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># El coeficiente del modelo para &#39;NEAR OCEAN&#39; es obsoleto</span>
</span></span></code></pre></div><p><strong>Cómo detectar drift (lo que este proyecto debería agregar):</strong></p><p><strong>Opción 1: Statistical Tests (Kolmogorov-Smirnov, Chi-Square)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>ks_2samp</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Compara distribución de training vs production</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>features</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ks_2samp</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>training_data</span><span class=p>[</span><span class=n>feature</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>production_data</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>alert</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;DRIFT DETECTED in </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>: p=</span><span class=si>{</span><span class=n>p_value</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Opción 2: Evidently AI (recomendado)</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>evidently.report</span> <span class=kn>import</span> <span class=n>Report</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>evidently.metric_preset</span> <span class=kn>import</span> <span class=n>DataDriftPreset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>report</span> <span class=o>=</span> <span class=n>Report</span><span class=p>(</span><span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=n>DataDriftPreset</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>report</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>reference_data</span><span class=o>=</span><span class=n>train_df</span><span class=p>,</span>  <span class=c1># Training data</span>
</span></span><span class=line><span class=cl>    <span class=n>current_data</span><span class=o>=</span><span class=n>production_df</span>  <span class=c1># Últimas 1000 predictions</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Genera dashboard HTML con drift metrics</span>
</span></span><span class=line><span class=cl><span class=n>report</span><span class=o>.</span><span class=n>save_html</span><span class=p>(</span><span class=s2>&#34;drift_report.html&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Evidently calcula:</strong></p><ul><li><strong>Drift score</strong> por cada feature (0-1)</li><li><strong>Share of drifted features</strong> (% de features con drift)</li><li><strong>Dataset drift</strong> (si el dataset completo driftó)</li></ul><p><strong>Opción 3: Population Stability Index (PSI)</strong></p><p>Métrica usada en banca para detectar drift:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calculate_psi</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>actual</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &lt; 0.1: No significant drift
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &lt; 0.2: Moderate drift
</span></span></span><span class=line><span class=cl><span class=s2>    PSI &gt;= 0.2: Significant drift (retrain needed)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>breakpoints</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>quantile</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>bins</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>expected_percents</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>expected</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>expected</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>actual_percents</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>actual</span><span class=p>,</span> <span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>actual</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>psi</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>actual_percents</span> <span class=o>-</span> <span class=n>expected_percents</span><span class=p>)</span> <span class=o>*</span>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>actual_percents</span> <span class=o>/</span> <span class=n>expected_percents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>psi</span>
</span></span></code></pre></div><p><strong>Cuándo agregar drift detection:</strong></p><p>Huyen recomienda esperar hasta que tengas <strong>suficiente tráfico de producción</strong> (~10,000 predictions).</p><p><strong>No lo agregues el Día 1</strong> porque:</p><ul><li>Necesitas baseline de &ldquo;distribución normal de producción&rdquo;</li><li>Falsos positivos al inicio (gente testeando el API con datos sintéticos)</li><li>Overhead de infraestructura (Evidently requiere DB para almacenar historiales)</li></ul><p><strong>Agrégalo cuando:</strong></p><ul><li>Tienes 10,000+ predictions en producción</li><li>Observas que MAPE en producción > MAPE en test set</li><li>El modelo tiene >6 meses en producción sin reentrenar</li></ul><p><strong>Ejemplo de alerting:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># W&amp;B logger extension (lo que agregarías a wandb_logger.py)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>WandBLogger</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>log_drift_alert</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>feature_name</span><span class=p>,</span> <span class=n>psi_value</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>psi_value</span> <span class=o>&gt;</span> <span class=n>threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb</span><span class=o>.</span><span class=n>alert</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>title</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;DATA DRIFT: </span><span class=si>{</span><span class=n>feature_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>text</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;PSI=</span><span class=si>{</span><span class=n>psi_value</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> exceeds threshold </span><span class=si>{</span><span class=n>threshold</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>level</span><span class=o>=</span><span class=n>wandb</span><span class=o>.</span><span class=n>AlertLevel</span><span class=o>.</span><span class=n>WARN</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Log to metrics</span>
</span></span><span class=line><span class=cl>            <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;drift/</span><span class=si>{</span><span class=n>feature_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>psi_value</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;drift/timestamp&#34;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span></code></pre></div><p><strong>El costo de NO monitorear drift:</strong></p><p>Sin drift detection, tu modelo <strong>falla silenciosamente</strong>. Nadie se da cuenta hasta que:</p><ul><li>Un cliente se queja: &ldquo;Sus predicciones están muy mal últimamente&rdquo;</li><li>Calculas MAPE retrospectivo y descubres que subió de 8% a 18%</li><li>Pasaron 3 meses sirviendo predicciones basura</li></ul><p>Con monitoring, detectas drift <strong>en días</strong>, no meses.</p><hr><h3 id=124-model-monitoring-más-allá-de-accuracy>12.4. Model Monitoring: Más Allá de Accuracy<a hidden class=anchor aria-hidden=true href=#124-model-monitoring-más-allá-de-accuracy>#</a></h3><p>El W&amp;B Logger de este proyecto (<code>api/app/core/wandb_logger.py</code>) loggea métricas básicas:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/count&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/mean&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>predictions</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;performance/response_time_ms&#34;</span><span class=p>:</span> <span class=n>response_time</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><p><strong>Esto es un buen comienzo, pero incompleto.</strong> En producción real, necesitas monitorear:</p><h4 id=1-business-metrics-lo-más-importante>1. Business Metrics (lo más importante)<a hidden class=anchor aria-hidden=true href=#1-business-metrics-lo-más-importante>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Cuántas predicciones están &#34;muy mal&#34;?</span>
</span></span><span class=line><span class=cl><span class=n>errors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>/</span> <span class=n>y_true</span>
</span></span><span class=line><span class=cl><span class=n>within_10pct</span> <span class=o>=</span> <span class=p>(</span><span class=n>errors</span> <span class=o>&lt;</span> <span class=mf>0.10</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/predictions_within_10pct&#34;</span><span class=p>:</span> <span class=n>within_10pct</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/predictions_within_20pct&#34;</span><span class=p>:</span> <span class=p>(</span><span class=n>errors</span> <span class=o>&lt;</span> <span class=mf>0.20</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;business/mean_absolute_error_dollars&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Alert si la calidad cae</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>within_10pct</span> <span class=o>&lt;</span> <span class=mf>0.65</span><span class=p>:</span>  <span class=c1># Threshold del SLA</span>
</span></span><span class=line><span class=cl>    <span class=n>send_alert</span><span class=p>(</span><span class=s2>&#34;Model quality degraded: only </span><span class=si>{:.1%}</span><span class=s2> within 10%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>within_10pct</span><span class=p>))</span>
</span></span></code></pre></div><h4 id=2-prediction-distribution>2. Prediction Distribution<a hidden class=anchor aria-hidden=true href=#2-prediction-distribution>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Está el modelo prediciendo siempre el mismo valor?</span>
</span></span><span class=line><span class=cl><span class=c1># (señal de overfitting o modelo roto)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prediction_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>prediction_range</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/std&#34;</span><span class=p>:</span> <span class=n>prediction_std</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/range&#34;</span><span class=p>:</span> <span class=n>prediction_range</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prediction/median&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Red flag: Si std es muy bajo</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>prediction_std</span> <span class=o>&lt;</span> <span class=mi>10000</span><span class=p>:</span>  <span class=c1># $10k</span>
</span></span><span class=line><span class=cl>    <span class=n>alert</span><span class=p>(</span><span class=s2>&#34;Model predictions have very low variance - model may be broken&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=3-input-feature-distribution>3. Input Feature Distribution<a hidden class=anchor aria-hidden=true href=#3-input-feature-distribution>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿Estás recibiendo inputs fuera de training range?</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>NUMERIC_FEATURES</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>pred</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>prediction_batch</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/mean&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>feature_values</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/p95&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>feature_values</span><span class=p>,</span> <span class=mi>95</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;input/</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>/p05&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>feature_values</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Alert si hay outliers extremos</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>feature_values</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>TRAINING_MAX</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=o>*</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>alert</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Extreme outlier detected in </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=4-error-patterns>4. Error Patterns<a hidden class=anchor aria-hidden=true href=#4-error-patterns>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ¿El modelo falla consistentemente en ciertos segmentos?</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>errors_by_segment</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Por región geográfica</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>ocean_prox</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;&lt;1H OCEAN&#39;</span><span class=p>,</span> <span class=s1>&#39;INLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;ISLAND&#39;</span><span class=p>,</span> <span class=s1>&#39;NEAR BAY&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=n>mask</span> <span class=o>=</span> <span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=n>ocean_prox</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>errors_by_segment</span><span class=p>[</span><span class=n>ocean_prox</span><span class=p>]</span> <span class=o>=</span> <span class=n>mape</span><span class=p>(</span><span class=n>y_true</span><span class=p>[</span><span class=n>mask</span><span class=p>],</span> <span class=n>y_pred</span><span class=p>[</span><span class=n>mask</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span><span class=sa>f</span><span class=s2>&#34;error/mape_</span><span class=si>{</span><span class=n>seg</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>err</span> <span class=k>for</span> <span class=n>seg</span><span class=p>,</span> <span class=n>err</span> <span class=ow>in</span> <span class=n>errors_by_segment</span><span class=o>.</span><span class=n>items</span><span class=p>()})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Si ISLAND tiene MAPE = 40% pero otros tienen 8%, hay un problema</span>
</span></span></code></pre></div><h4 id=5-latency-percentiles>5. Latency Percentiles<a hidden class=anchor aria-hidden=true href=#5-latency-percentiles>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># El logger actual solo loggea mean response time</span>
</span></span><span class=line><span class=cl><span class=c1># Pero necesitas percentiles para detectar outliers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response_times</span> <span class=o>=</span> <span class=p>[</span><span class=o>...</span><span class=p>]</span>  <span class=c1># últimos 100 requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p50&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>50</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p95&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>95</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/p99&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>99</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;latency/max&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>response_times</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Alert si p99 excede threshold</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>response_times</span><span class=p>,</span> <span class=mi>99</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>200</span><span class=p>:</span>  <span class=c1># 200ms</span>
</span></span><span class=line><span class=cl>    <span class=n>alert</span><span class=p>(</span><span class=s2>&#34;API latency p99 exceeds 200ms&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Dashboard recomendado (W&amp;B o Grafana):</strong></p><pre tabindex=0><code>┌─────────────────────────────────────────────┐
│ MODEL HEALTH DASHBOARD                       │
├─────────────────────────────────────────────┤
│ PREDICTIONS (last 24h)                       │
│   Total:        12,453                       │
│   Within 10%:   68.2% [OK]                   │
│   Within 20%:   89.1%                        │
│   Mean MAPE:    9.8%  [WARN] (threshold: 10%)│
├─────────────────────────────────────────────┤
│ DRIFT DETECTION                              │
│   median_income:     PSI = 0.08 [OK]        │
│   total_rooms:       PSI = 0.15 [WARN]      │
│   ocean_proximity:   PSI = 0.32 [ALERT]     │
├─────────────────────────────────────────────┤
│ LATENCY                                      │
│   p50:   28ms                                │
│   p95:   67ms                                │
│   p99:   145ms [WARN]                        │
└─────────────────────────────────────────────┘
</code></pre><hr><h3 id=125-the-cascade-pattern-fallback-resilience>12.5. The Cascade Pattern: Fallback Resilience<a hidden class=anchor aria-hidden=true href=#125-the-cascade-pattern-fallback-resilience>#</a></h3><p>Este proyecto implementa un patrón de resiliencia brillante que Huyen discute en el Capítulo 6: el <strong>Cascade Pattern</strong> (fallback en cascada).</p><p>Mira el <code>ModelLoader</code> en <code>api/app/core/model_loader.py</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Any</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Load model with cascade fallback strategy.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 1: MLflow Registry (producción)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlflow_model_name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_mlflow</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load failed, trying GCS: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 2: GCS (staging)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_bucket</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>gcs_model_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_gcs</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GCS load failed, trying local: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Priority 3: Local (desarrollo/fallback)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span> <span class=ow>and</span> <span class=n>Path</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_model</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_from_local</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>local_model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;No model could be loaded from any source&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>¿Qué logra esto?</strong></p><p><strong>Resilience ante fallos:</strong></p><ul><li>MLflow server caído → API sigue funcionando con GCS</li><li>GCS quota exceeded → API usa modelo local</li><li>Zero downtime ante infraestructura degradada</li></ul><p><strong>Flexibilidad de deployment:</strong></p><ul><li><strong>Producción:</strong> Usa MLflow (versionamiento robusto)</li><li><strong>Staging:</strong> Usa GCS (más simple)</li><li><strong>Desarrollo local:</strong> Usa archivo local (sin credenciales)</li></ul><p><strong>Mismo código, tres ambientes:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Producción</span>
</span></span><span class=line><span class=cl>docker run -e <span class=nv>MLFLOW_MODEL_NAME</span><span class=o>=</span>housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>MLFLOW_MODEL_STAGE</span><span class=o>=</span>Production <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Staging</span>
</span></span><span class=line><span class=cl>docker run -e <span class=nv>GCS_BUCKET</span><span class=o>=</span>staging-bucket <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>GCS_MODEL_PATH</span><span class=o>=</span>models/v1.2.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Local development</span>
</span></span><span class=line><span class=cl>docker run -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/models:/app/models <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           -e <span class=nv>LOCAL_MODEL_PATH</span><span class=o>=</span>/app/models/housing_price_model.pkl <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>           housing-api
</span></span></code></pre></div><p><strong>Lo que falta (y deberías agregar):</strong></p><h4 id=1-circuit-breaker-pattern>1. Circuit Breaker Pattern<a hidden class=anchor aria-hidden=true href=#1-circuit-breaker-pattern>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>circuitbreaker</span> <span class=kn>import</span> <span class=n>circuit</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@circuit</span><span class=p>(</span><span class=n>failure_threshold</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>recovery_timeout</span><span class=o>=</span><span class=mi>60</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_mlflow</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>,</span> <span class=n>stage</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Circuit breaker: Si MLflow falla 5 veces consecutivas,
</span></span></span><span class=line><span class=cl><span class=s2>    abre el circuito por 60 segundos y no intenta más llamadas.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tracking_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;models:/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Sin circuit breaker, si MLflow está caído, el API hace 1 request por cada predicción y espera timeout (5-10s). Con circuit breaker, detecta el fallo después de 5 intentos y stop llamando hasta que MLflow se recupere.</p><h4 id=2-retry-with-exponential-backoff>2. Retry with Exponential Backoff<a hidden class=anchor aria-hidden=true href=#2-retry-with-exponential-backoff>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tenacity</span> <span class=kn>import</span> <span class=n>retry</span><span class=p>,</span> <span class=n>stop_after_attempt</span><span class=p>,</span> <span class=n>wait_exponential</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@retry</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>stop</span><span class=o>=</span><span class=n>stop_after_attempt</span><span class=p>(</span><span class=mi>3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>wait</span><span class=o>=</span><span class=n>wait_exponential</span><span class=p>(</span><span class=n>multiplier</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=nb>min</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=nb>max</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_gcs</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bucket_name</span><span class=p>,</span> <span class=n>blob_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Retry con backoff exponencial:
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 1: inmediato
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 2: espera 2s
</span></span></span><span class=line><span class=cl><span class=s2>    - Intento 3: espera 4s
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>storage_client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>bucket</span> <span class=o>=</span> <span class=n>storage_client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=n>bucket_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>blob</span> <span class=o>=</span> <span class=n>bucket</span><span class=o>.</span><span class=n>blob</span><span class=p>(</span><span class=n>blob_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pickle</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>blob</span><span class=o>.</span><span class=n>download_as_bytes</span><span class=p>())</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> GCS puede tener fallos transitorios (rate limiting, network blips). Retry automático evita que un fallo momentáneo tumbe tu API.</p><h4 id=3-timeout-configuration>3. Timeout Configuration<a hidden class=anchor aria-hidden=true href=#3-timeout-configuration>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Actualmente no hay timeout configurado</span>
</span></span><span class=line><span class=cl><span class=c1># Si MLflow tarda 60s en responder, tu API espera 60s</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Mejor:</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_from_mlflow</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>,</span> <span class=n>stage</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Load model with timeout.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>signal</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>timeout_handler</span><span class=p>(</span><span class=n>signum</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>TimeoutError</span><span class=p>(</span><span class=s2>&#34;MLflow load exceeded timeout&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>signal</span><span class=o>.</span><span class=n>signal</span><span class=p>(</span><span class=n>signal</span><span class=o>.</span><span class=n>SIGALRM</span><span class=p>,</span> <span class=n>timeout_handler</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>signal</span><span class=o>.</span><span class=n>alarm</span><span class=p>(</span><span class=n>timeout</span><span class=p>)</span>  <span class=c1># 10 second timeout</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>signal</span><span class=o>.</span><span class=n>alarm</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Cancel alarm</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>model</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>TimeoutError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MLflow load timeout after </span><span class=si>{</span><span class=n>timeout</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Sin timeout, un MLflow server lento puede hacer que tu API tarde minutos en responder. Con timeout, fallas rápido y pruebas el siguiente fallback.</p><h4 id=4-health-check-endpoint>4. Health Check Endpoint<a hidden class=anchor aria-hidden=true href=#4-health-check-endpoint>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># api/app/routers/health.py</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@router.get</span><span class=p>(</span><span class=s2>&#34;/health/deep&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>deep_health_check</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Health check que verifica todas las dependencias.
</span></span></span><span class=line><span class=cl><span class=s2>    Kubernetes lo llama cada 30s para routing decisions.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>health</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;healthy&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_loaded&#34;</span><span class=p>:</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>is_loaded</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;model_version&#34;</span><span class=p>:</span> <span class=n>model_loader</span><span class=o>.</span><span class=n>model_version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;dependencies&#34;</span><span class=p>:</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check MLflow</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>(</span><span class=n>settings</span><span class=o>.</span><span class=n>MLFLOW_TRACKING_URI</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>list_experiments</span><span class=p>(</span><span class=n>max_results</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;mlflow&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;mlflow&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;degraded: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;status&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;degraded&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check GCS</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>storage_client</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>Client</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket</span> <span class=o>=</span> <span class=n>storage_client</span><span class=o>.</span><span class=n>bucket</span><span class=p>(</span><span class=n>settings</span><span class=o>.</span><span class=n>GCS_BUCKET</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>bucket</span><span class=o>.</span><span class=n>exists</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;gcs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>health</span><span class=p>[</span><span class=s2>&#34;dependencies&#34;</span><span class=p>][</span><span class=s2>&#34;gcs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;degraded: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>health</span>
</span></span></code></pre></div><p><strong>Output:</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;status&#34;</span><span class=p>:</span> <span class=s2>&#34;degraded&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;model_loaded&#34;</span><span class=p>:</span> <span class=kc>true</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;model_version&#34;</span><span class=p>:</span> <span class=s2>&#34;models:/housing_price_model/Production&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;dependencies&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;mlflow&#34;</span><span class=p>:</span> <span class=s2>&#34;degraded: Connection timeout&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;gcs&#34;</span><span class=p>:</span> <span class=s2>&#34;healthy&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Por qué:</strong> Le dice a tu load balancer (Cloud Run, Kubernetes) si el API está healthy. Si MLflow está caído pero el modelo ya está cargado (cached), el API es &ldquo;degraded&rdquo; pero funcional.</p><hr><h3 id=126-feature-store-anti-pattern-cuándo-no-necesitas-uno>12.6. Feature Store Anti-Pattern: Cuándo NO Necesitas Uno<a hidden class=anchor aria-hidden=true href=#126-feature-store-anti-pattern-cuándo-no-necesitas-uno>#</a></h3><p>Huyen tiene una sección controvertida en el Capítulo 5: &ldquo;You might not need a feature store.&rdquo;</p><p>Los Feature Stores (Feast, Tecton, Databricks) son muy populares, pero son <strong>overkill</strong> para el 80% de proyectos.</p><p><strong>Cuándo SÍ necesitas un Feature Store:</strong></p><ol><li><p><strong>Reutilizas features entre múltiples modelos</strong></p><ul><li>Ejemplo: <code>customer_lifetime_value</code> se usa en 10 modelos diferentes</li><li>Sin feature store: Cada modelo recalcula el mismo feature (waste)</li><li>Con feature store: Calculas una vez, sirves muchas veces</li></ul></li><li><p><strong>Necesitas features con diferentes freshness</strong></p><ul><li>Batch features: Calculadas diariamente (credit score)</li><li>Real-time features: Calculadas por request (current location)</li><li>Feature store orquesta ambos</li></ul></li><li><p><strong>Training/Serving skew es crítico</strong></p><ul><li>El feature store garantiza que training y serving usan EXACTAMENTE la misma lógica</li></ul></li></ol><p><strong>Cuándo NO necesitas un Feature Store (como este proyecto):</strong></p><ol><li><p><strong>Todas las features se computan on-the-fly</strong></p><ul><li>Este proyecto: Features son directas (lat, lon, income, age)</li><li>El único feature computado es <code>cluster_label</code> (2ms de latency)</li><li>No hay agregaciones complejas tipo &ldquo;average income in last 30 days&rdquo;</li></ul></li><li><p><strong>Un solo modelo consume las features</strong></p><ul><li>No hay reutilización entre modelos</li><li>Feature store añadiría complejidad sin beneficio</li></ul></li><li><p><strong>Latency budget es generoso</strong></p><ul><li>Este API: &lt;50ms es OK</li><li>Si necesitaras &lt;5ms, pre-computar features valdría la pena</li></ul></li></ol><p><strong>El costo real de un Feature Store:</strong></p><ul><li><strong>Infraestructura:</strong> Redis/DynamoDB para serving, Spark para batch processing</li><li><strong>Costo:</strong> ~$500-2000/mes en AWS/GCP (según tráfico)</li><li><strong>Complejidad:</strong> Otro sistema que monitorear, debuggear, operar</li></ul><p><strong>Alternativa lightweight (lo que este proyecto hace):</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Computa features on-the-fly en el API</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>HousingPreprocessor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. One-hot encoding (instantáneo)</span>
</span></span><span class=line><span class=cl>        <span class=n>df_encoded</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ocean_proximity&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. Clustering (2ms con KMeans pre-fitted)</span>
</span></span><span class=line><span class=cl>        <span class=n>clusters</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kmeans</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>df</span><span class=p>[[</span><span class=s1>&#39;longitude&#39;</span><span class=p>,</span> <span class=s1>&#39;latitude&#39;</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>df_encoded</span><span class=p>[</span><span class=s1>&#39;cluster_label&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>clusters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df_encoded</span>
</span></span></code></pre></div><p><strong>Total latency:</strong> ~3ms. No justifica un Feature Store.</p><p><strong>Cuándo reconsiderar:</strong></p><ul><li>Si agregas features tipo &ldquo;average house price in zipcode&rdquo; (requiere query a DB)</li><li>Si el preprocesamiento sube a >20ms</li><li>Si añades un segundo modelo que reutiliza 50%+ de features</li></ul><p>Hasta entonces, YAGNI (You Ain&rsquo;t Gonna Need It).</p><hr><h3 id=127-production-readiness-un-checklist-honesto>12.7. Production Readiness: Un Checklist Honesto<a hidden class=anchor aria-hidden=true href=#127-production-readiness-un-checklist-honesto>#</a></h3><p>Basándome en el análisis exhaustivo del código, aquí está el estado <strong>real</strong> de este proyecto:</p><h4 id=lo-que-este-proyecto-hace-muy-bien>Lo Que Este Proyecto Hace MUY BIEN<a hidden class=anchor aria-hidden=true href=#lo-que-este-proyecto-hace-muy-bien>#</a></h4><p><strong>Nivel 3/5 en MLOps Maturity (Production-Ready):</strong></p><ol><li><p><strong>Versionamiento completo</strong></p><ul><li>Modelos en MLflow Registry con metadata rica</li><li>Data artifacts en GCS con timestamps</li><li>Código en git con CI/CD</li><li>Config en YAML versionado</li></ul></li><li><p><strong>Reproducibilidad</strong></p><ul><li>Seeds fijos (random_state=42 en todos lados)</li><li>Dependencias pinned (requirements.txt)</li><li>Docker para environment consistency</li></ul></li><li><p><strong>Testing</strong></p><ul><li>87% code coverage</li><li>Unit tests con fixtures realistas</li><li>Integration tests end-to-end</li><li>Security scanning (Bandit, TruffleHog)</li></ul></li><li><p><strong>CI/CD</strong></p><ul><li>GitHub Actions con tests automatizados</li><li>Docker build en CI</li><li>Deployment a Cloud Run con health checks</li><li>Staging/Production separation</li></ul></li><li><p><strong>API Design</strong></p><ul><li>Pydantic validation en todos los endpoints</li><li>Cascade fallback (MLflow→GCS→Local)</li><li>Lifespan management (load model once, not per request)</li><li>Batch prediction support</li></ul></li><li><p><strong>Observability (Básica)</strong></p><ul><li>W&amp;B logging de predictions</li><li>Response time tracking</li><li>Structured logging</li></ul></li></ol><h4 id=lo-que-falta-y-cuándo-agregarlo>Lo Que Falta (Y Cuándo Agregarlo)<a hidden class=anchor aria-hidden=true href=#lo-que-falta-y-cuándo-agregarlo>#</a></h4><p><strong>Nivel 4/5 Features (Add When You Have 10k+ Daily Predictions):</strong></p><ol><li><p><strong>Data Drift Detection</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Alto (modelo falla silenciosamente)</li><li><strong>Costo de implementación:</strong> Medio (Evidently AI)</li><li><strong>Cuándo:</strong> Después de 3 meses en producción</li></ul></li><li><p><strong>Model Performance Tracking</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Alto (no sabes si el modelo degrada)</li><li><strong>Costo:</strong> Bajo (extender W&amp;B logger)</li><li><strong>Cuándo:</strong> Después de tener ground truth labels (1-2 meses)</li></ul></li><li><p><strong>Circuit Breakers</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Medio (mejor latency ante fallos)</li><li><strong>Costo:</strong> Bajo (librería <code>circuitbreaker</code>)</li><li><strong>Cuándo:</strong> Si ves fallos transitorios en MLflow/GCS</li></ul></li><li><p><strong>Advanced Monitoring Dashboards</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Medio (mejor debugging)</li><li><strong>Costo:</strong> Medio (Grafana + Prometheus)</li><li><strong>Cuándo:</strong> Cuando el equipo crece >5 personas</li></ul></li><li><p><strong>Canary Deployments</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Bajo (tienes rollback manual que funciona)</li><li><strong>Costo:</strong> Alto (requiere traffic splitting)</li><li><strong>Cuándo:</strong> Solo si deployeas >1x/semana</li></ul></li><li><p><strong>Feature Store</strong> [FALTA]</p><ul><li><strong>Impacto:</strong> Ninguno (features son lightweight)</li><li><strong>Costo:</strong> Alto ($500-2000/mes)</li><li><strong>Cuándo:</strong> Nunca, a menos que agregues features pesados</li></ul></li></ol><p><strong>Nivel 5/5 Features (Overkill Para Este Proyecto):</strong></p><ul><li>Multi-model orchestration (A/B testing)</li><li>Real-time retraining</li><li>Federated learning</li><li>AutoML pipeline</li></ul><h4 id=recomendaciones-priorizadas>Recomendaciones Priorizadas<a hidden class=anchor aria-hidden=true href=#recomendaciones-priorizadas>#</a></h4><p><strong>MES 1-3 (Estabilización):</strong></p><ol><li>Agrega endpoint <code>/health/deep</code> con dependency checks</li><li>Implementa retry con exponential backoff en GCS calls</li><li>Configura alerts en W&amp;B cuando MAPE > 12%</li></ol><p><strong>MES 4-6 (Monitoring):</strong></p><ol start=4><li>Implementa Evidently AI para data drift (PSI tracking)</li><li>Agrega prediction distribution monitoring</li><li>Configura automated retraining trigger cuando PSI > 0.2</li></ol><p><strong>MES 7-12 (Optimización):</strong></p><ol start=7><li>Implementa circuit breaker en MLflow calls</li><li>Agrega Redis para prediction caching (si latency es problema)</li><li>Configura Grafana dashboard para business metrics</li></ol><p><strong>NO Hagas (Hasta Que Escales 10x):</strong></p><ul><li>No implementes Feature Store</li><li>No agregues Kafka streaming</li><li>No uses Kubernetes (Cloud Run es suficiente)</li><li>No implementes multi-model serving (hasta tener caso de uso claro)</li></ul><hr><h3 id=128-la-diferencia-entre-funciona-y-funciona-en-producción>12.8. La Diferencia Entre &ldquo;Funciona&rdquo; y &ldquo;Funciona en Producción&rdquo;<a hidden class=anchor aria-hidden=true href=#128-la-diferencia-entre-funciona-y-funciona-en-producción>#</a></h3><p>Este proyecto está en el top 10% de proyectos de ML en términos de engineering practices. La mayoría de los modelos en producción tienen:</p><ul><li>Notebooks en lugar de scripts modulares</li><li>Modelos guardados como <code>model_v3_FINAL_FINAL.pkl</code></li><li>Zero tests</li><li>Manual deployment con <code>scp</code></li><li>No monitoring</li></ul><p>Este proyecto tiene:</p><ul><li>Código modular y testeable</li><li>MLflow Registry con versionamiento semántico</li><li>87% test coverage</li><li>Automated deployment con GitHub Actions</li><li>W&amp;B monitoring básico</li></ul><p><strong>El gap restante</strong> (drift detection, advanced monitoring, circuit breakers) es el gap entre &ldquo;producción estable&rdquo; y &ldquo;producción enterprise-grade&rdquo;.</p><p>Pero aquí está el secreto: <strong>ese gap solo importa cuando tienes usuarios reales y tráfico significativo.</strong></p><p>No optimices para problemas que aún no tienes. Este proyecto está listo para servir 100k predictions/mes sin sudar. Cuando llegues a 1M/mes, entonces agrega data drift detection. Cuando llegues a 10M/mes, entonces considera Kubernetes.</p><p>Como dice Huyen: <strong>&ldquo;The best ML system is the simplest one that meets your requirements.&rdquo;</strong></p><p>Este proyecto cumple ese principio perfectamente.</p><hr><p><a name=conclusiones></a></p><h2 id=14-conclusiones-mlops-como-disciplina-de-ingeniería>14. Conclusiones: MLOps Como Disciplina de Ingeniería<a hidden class=anchor aria-hidden=true href=#14-conclusiones-mlops-como-disciplina-de-ingeniería>#</a></h2><h3 id=lo-que-este-pipeline-implementa-y-por-qué-importa>Lo Que Este Pipeline Implementa (Y Por Qué Importa)<a hidden class=anchor aria-hidden=true href=#lo-que-este-pipeline-implementa-y-por-qué-importa>#</a></h3><p>Este no es un tutorial de scikit-learn. Es un <strong>sistema production-ready</strong> que implementa:</p><ol><li><strong>Versionamiento completo:</strong> Datos (GCS), código (git), modelos (MLflow), configuración (YAML)</li><li><strong>Reproducibilidad:</strong> Mismo código + mismo config + mismo seed = mismo modelo</li><li><strong>Observabilidad:</strong> Logs estructurados, métricas en W&amp;B, tracking en MLflow</li><li><strong>Testing:</strong> 87% coverage, unit tests, integration tests, security scanning</li><li><strong>CI/CD:</strong> GitHub Actions con deployment automatizado a Cloud Run</li><li><strong>Deployment:</strong> API REST con FastAPI, frontend con Streamlit, Docker Compose listo</li><li><strong>Decisiones respaldadas por datos:</strong> Cada elección (imputación, K clusters, hiperparámetros) tiene métricas cuantificables</li><li><strong>Patrones de producción:</strong> Transform pattern, cascade fallback, training/serving consistency</li></ol><h3 id=los-anti-patterns-que-evita-y-que-matan-proyectos>Los Anti-Patterns Que Evita (Y Que Matan Proyectos)<a hidden class=anchor aria-hidden=true href=#los-anti-patterns-que-evita-y-que-matan-proyectos>#</a></h3><p><strong>X Notebooks en producción:</strong> Todo es Python modular y testeable. Los notebooks son geniales para exploración, terribles para sistemas confiables.</p><p><strong>X Configuración hardcodeada:</strong> config.yaml versionado en git. Si cambias un parámetro, queda registrado con timestamp y autor.</p><p><strong>X &ldquo;Usé median porque sí&rdquo;:</strong> Comparó 4 estrategias de imputación con métricas cuantificables. La mejor estrategia (Iterative Imputer) ganó por 3.2% en RMSE.</p><p><strong>X Modelos como <code>final_v3_REAL_final.pkl</code>:</strong> MLflow Registry con versiones semánticas y metadata rica. Sabes exactamente qué hiperparámetros, qué datos, y qué métricas tiene cada versión.</p><p><strong>X &ldquo;No sé qué hiperparámetros usé hace 3 meses&rdquo;:</strong> Cada modelo registra 106 líneas de metadata. Incluye desde hyperparameters hasta distribución de errores por segmento.</p><p><strong>X Deployment manual con scp:</strong> Docker + GitHub Actions. Push a master → tests corren → si pasan, deploya a staging automáticamente. Producción requiere aprobación manual (como debe ser).</p><p><strong>X Training/Serving Skew:</strong> El preprocesamiento está en una clase compartida entre training y serving. Cambias el código una vez, ambos ambientes se actualizan.</p><h3 id=los-trade-offs-conscientes-porque-no-hay-soluciones-perfectas>Los Trade-Offs Conscientes (Porque No Hay Soluciones Perfectas)<a hidden class=anchor aria-hidden=true href=#los-trade-offs-conscientes-porque-no-hay-soluciones-perfectas>#</a></h3><p>Este proyecto toma decisiones deliberadas. Aquí están los trade-offs y cuándo reconsiderarlos:</p><p><strong>1. Cluster optimization independiente del modelo final:</strong></p><p>Optimiza KMeans con silhouette score en lugar de cross-validation del modelo completo. <strong>Más rápido pero menos riguroso.</strong> Reconsiderar si el clustering es el feature más importante de tu modelo.</p><p><strong>2. 60 sweep runs en W&amp;B:</strong></p><p>Suficiente para California Housing (dataset mediano, ~20k samples). <strong>Podrías necesitar 200+ runs</strong> en datasets complejos con muchas interacciones no lineales.</p><p><strong>3. Pipeline secuencial sin paralelización:</strong></p><p>Steps corren uno después del otro. Este pipeline tarda ~15 minutos end-to-end. Si tu pipeline tarda horas, usa Airflow/Prefect con tasks paralelos.</p><p><strong>4. MAPE como métrica primaria:</strong></p><p>Funciona para este dataset (precios entre $50k-$500k). <strong>No funciona</strong> si tienes valores cercanos a cero (división por cero) o si quieres penalizar errores grandes desproporcionadamente (usa RMSE).</p><p><strong>5. Data drift detection ausente:</strong></p><p>Como explica el Checklist de Producción (Sección 13.7), el drift monitoring debe agregarse <strong>después de 3-6 meses en producción</strong>, no el Día 1. Necesitas baseline de comportamiento normal primero.</p><p><strong>6. KMeans sintético en el API:</strong></p><p>El Transform Pattern (Sección 13.1) recrea clusters con ~2% de drift vs training. <strong>Impacto en MAPE: &lt;0.3%.</strong> Si necesitas 100% reproducibilidad bit-a-bit, serializa el KMeans real (costo: 96KB por versión de modelo).</p><h3 id=lo-que-falta-y-cuándo-agregarlo-1>Lo Que Falta (Y Cuándo Agregarlo)<a hidden class=anchor aria-hidden=true href=#lo-que-falta-y-cuándo-agregarlo-1>#</a></h3><p>Como detalla la Sección 13 (Patrones de Producción), este proyecto está en <strong>Nivel 3/5 de MLOps Maturity</strong>. Lo que falta:</p><p><strong>Mes 1-3 (Estabilización):</strong></p><ul><li>Deep health check endpoint con dependency status</li><li>Retry con exponential backoff en calls a GCS</li><li>Alerts automáticos en W&amp;B cuando MAPE > threshold</li></ul><p><strong>Mes 4-6 (Monitoring):</strong></p><ul><li>Evidently AI para data drift detection (PSI tracking)</li><li>Prediction distribution monitoring (detectar modelo roto)</li><li>Trigger automático de retraining cuando PSI > 0.2</li></ul><p><strong>Mes 7-12 (Optimización):</strong></p><ul><li>Circuit breaker en MLflow calls (evitar timeouts en cascada)</li><li>Redis para prediction caching (si latency &lt;10ms es crítica)</li><li>Grafana dashboards para business metrics</li></ul><p><strong>NO hagas (hasta que escales 10x):</strong></p><ul><li>Feature Store (features son lightweight, &lt;3ms)</li><li>Kafka streaming (Cloud Run con HTTP es suficiente)</li><li>Kubernetes (Cloud Run autoescala sin complejidad)</li><li>Multi-model A/B testing (hasta tener caso de uso claro)</li></ul><h3 id=la-verdad-incómoda-sobre-mlops>La Verdad Incómoda Sobre MLOps<a hidden class=anchor aria-hidden=true href=#la-verdad-incómoda-sobre-mlops>#</a></h3><p>El 90% de los modelos de ML nunca llegan a producción. De los que llegan, el 60% falla en los primeros 6 meses.</p><p><strong>¿Por qué?</strong></p><p>No es porque los modelos son malos. Es porque:</p><ul><li>El ingeniero que entrenó el modelo ya no está en la empresa</li><li>Nadie sabe qué hiperparámetros se usaron</li><li>El preprocesamiento en producción es diferente al de training</li><li>No hay tests, entonces cada cambio rompe algo</li><li>El deployment es manual, toma 3 horas y falla 1 de cada 3 veces</li><li>No hay monitoring, el modelo falla silenciosamente por meses</li></ul><p>Este proyecto evita todos esos problemas. <strong>No porque sea perfecto</strong>, sino porque implementa los principios básicos de ingeniería de software:</p><ul><li><strong>Versionamiento:</strong> De todo (datos, código, modelos, config)</li><li><strong>Testing:</strong> 87% coverage, CI en cada commit</li><li><strong>Reproducibilidad:</strong> Seeds fijos, ambientes Dockerizados</li><li><strong>Observabilidad:</strong> Logs, métricas, tracking</li><li><strong>Automatización:</strong> Deployment sin intervención humana</li></ul><h3 id=la-lección-más-importante>La Lección Más Importante<a hidden class=anchor aria-hidden=true href=#la-lección-más-importante>#</a></h3><p>Chip Huyen lo dice mejor que yo en &ldquo;Designing Machine Learning Systems&rdquo;:</p><blockquote><p>&ldquo;The best ML system is not the one with the highest accuracy. It&rsquo;s the one that&rsquo;s reliable, maintainable, and meets business requirements.&rdquo;</p></blockquote><p>Este proyecto no tiene el mejor modelo. Probablemente puedes mejorar MAPE de 8.2% a 7.5% con XGBoost tuneado a mano.</p><p><strong>Pero eso no importa.</strong></p><p>Lo que importa es que este sistema:</p><ul><li>Corre confiablemente 24/7</li><li>Se puede actualizar sin downtime</li><li>Tiene rollback automático si algo falla</li><li>Cualquier miembro del equipo puede entender y modificar el código</li><li>Loggea suficiente información para debuggear problemas</li><li>Cuesta &lt;$100/mes en GCP (hasta 1M predictions)</li></ul><p><strong>Ese 0.7% de mejora en MAPE no vale la pena si el sistema es imposible de mantener.</strong></p><h3 id=para-quién-es-este-post>Para Quién Es Este Post<a hidden class=anchor aria-hidden=true href=#para-quién-es-este-post>#</a></h3><p>Si eres:</p><ul><li><strong>Data Scientist</strong> tratando de llevar tu primer modelo a producción → Este es tu roadmap</li><li><strong>ML Engineer</strong> explicando por qué &ldquo;no puedes simplemente deployar el notebook&rdquo; → Manda este post</li><li><strong>Engineering Manager</strong> evaluando si tu equipo hace MLOps correctamente → Usa la Sección 13.7 como checklist</li><li><strong>Estudiante</strong> queriendo aprender MLOps más allá de tutoriales → Este es código real, no sintético</li></ul><h3 id=el-siguiente-paso>El Siguiente Paso<a hidden class=anchor aria-hidden=true href=#el-siguiente-paso>#</a></h3><p>Este post tiene 6,500+ líneas porque no quise simplificar. MLOps es complejo. Hay trade-offs en cada decisión.</p><p>Pero no dejes que la complejidad te paralice. <strong>Start simple, iterate, improve.</strong></p><ol><li><strong>Semana 1:</strong> Versionamiento básico (git + requirements.txt)</li><li><strong>Semana 2:</strong> Tests básicos (al menos smoke tests)</li><li><strong>Semana 3:</strong> Docker para deployment consistente</li><li><strong>Semana 4:</strong> CI básico (GitHub Actions corriendo tests)</li><li><strong>Mes 2:</strong> MLflow para model registry</li><li><strong>Mes 3:</strong> Monitoring básico (W&amp;B o Prometheus)</li></ol><p><strong>No necesitas implementar todo el día 1.</strong> Este proyecto tardó meses en llegar a este estado.</p><h3 id=la-última-palabra>La Última Palabra<a hidden class=anchor aria-hidden=true href=#la-última-palabra>#</a></h3><p><strong>Ser MLOps engineer no es solo entrenar modelos—es construir sistemas donde los modelos son una pieza más.</strong></p><p>Lo que separa un proyecto de investigación de un producto en producción es:</p><ul><li><strong>Orden:</strong> Cada cosa en su lugar (no &ldquo;funciona en mi máquina&rdquo;)</li><li><strong>Testing:</strong> Lo que no se prueba, se rompe (87% coverage no es accidente)</li><li><strong>Observabilidad:</strong> Si no puedes medirlo, no puedes mejorarlo (W&amp;B + MLflow)</li><li><strong>Reproducibilidad:</strong> Hoy y en 6 meses debe dar el mismo resultado (seeds fijos, Docker)</li><li><strong>Automatización:</strong> Los humanos son malos en tareas repetitivas (CI/CD)</li><li><strong>Humildad:</strong> Reconocer lo que falta y cuándo agregarlo (Sección 13.7)</li></ul><p>Este post no te enseña a ser mejor en machine learning.</p><p><strong>Te enseña a ser mejor en machine learning engineering.</strong></p><p>Y esa diferencia es la que separa modelos en notebooks de modelos en producción creando valor real.</p><hr><p>Si implementas aunque sea el 50% de lo que está en este post, tu pipeline estará en el top 10% de proyectos de ML en términos de engineering practices.</p><p>Si implementas el 80%, estarás listo para escalar a millones de predictions sin reestructurar todo.</p><p>El 100% es overkill para la mayoría de proyectos. Usa el Checklist de Producción (Sección 13.7) para priorizar qué necesitas y cuándo.</p><hr><h2 id=referencias-y-recursos>Referencias y Recursos<a hidden class=anchor aria-hidden=true href=#referencias-y-recursos>#</a></h2><p><strong>Libros fundamentales:</strong></p><ul><li>Géron, A. (2022). <em>Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow</em> (3rd ed.). O&rsquo;Reilly.<ul><li><strong>Capítulo 2:</strong> Base de este proyecto (California Housing dataset, feature engineering, model selection)</li><li>Enfoque en ML, este post agrega la infraestructura de producción</li></ul></li><li>Huyen, C. (2022). <em>Designing Machine Learning Systems</em>. O&rsquo;Reilly.<ul><li><strong>Capítulo 5:</strong> Feature stores y cuándo no necesitas uno</li><li><strong>Capítulo 6:</strong> Deployment patterns (Cascade, Circuit Breaker)</li><li><strong>Capítulo 7:</strong> Transform Pattern y Training/Serving Skew (Secciones 13.1 y 13.2 de este post)</li><li><strong>Capítulo 8:</strong> Data Distribution Shifts y drift detection (Sección 13.3)</li><li><strong>Libro completo:</strong> Si solo lees un libro sobre MLOps, que sea este</li></ul></li></ul><p><strong>Herramientas (con enlaces a docs):</strong></p><ul><li><a href=https://mlflow.org/>MLflow</a>: Model registry y experiment tracking</li><li><a href=https://wandb.ai/>Weights & Biases</a>: Sweep y visualización de experimentos</li><li><a href=https://hydra.cc/>Hydra</a>: Configuration management con composable configs</li><li><a href=https://fastapi.tiangolo.com/>FastAPI</a>: REST API framework con validación Pydantic</li><li><a href=https://streamlit.io/>Streamlit</a>: Frontend interactivo para ML apps</li><li><a href=https://cloud.google.com/storage>Google Cloud Storage</a>: Almacenamiento de artifacts</li><li><a href=https://evidentlyai.com/>Evidently AI</a>: Data drift detection (recomendado para producción)</li><li><a href=https://www.docker.com/>Docker</a>: Containerización y reproducibilidad</li></ul><p><strong>Repositorio completo:</strong></p><ul><li><a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch</a><ul><li><code>/api</code>: FastAPI con cascade fallback y Transform Pattern</li><li><code>/src</code>: Pipeline modular (01-07) con MLflow tracking</li><li><code>/tests</code>: 87% coverage con fixtures realistas</li><li><code>/.github/workflows</code>: CI/CD completo con security scanning</li></ul></li></ul><hr><p><strong>Autor:</strong> Carlos Daniel Jiménez
<strong>Email:</strong> <a href=mailto:danieljimenez88m@gmail.com>danieljimenez88m@gmail.com</a>
<strong>LinkedIn:</strong> <a href=https://linkedin.com/in/carlosdanieljimenez>linkedin.com/in/carlosdanieljimenez</a>
<strong>Fecha:</strong> Enero 2026</p><hr><h2 id=navegación>Navegación<a hidden class=anchor aria-hidden=true href=#navegación>#</a></h2><p><strong><a href=/mlops/anatomia-pipeline-mlops-parte-2/>← Parte 2: Deployment e Infraestructura</a></strong> | <strong><a href=/mlops/anatomia-pipeline-mlops-parte-1/>← Parte 1: Pipeline y Orquestación</a></strong></p><p><strong>Serie completa:</strong></p><ol><li><a href=/mlops/anatomia-pipeline-mlops-parte-1/>Parte 1: Pipeline y Orquestación</a></li><li><a href=/mlops/anatomia-pipeline-mlops-parte-2/>Parte 2: Deployment e Infraestructura</a></li><li>Parte 3: Producción y Best Practices (actual)</li></ol><p><strong>Repositorio:</strong> <a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://carlosdanieljimenez.com/tags/mlops/>Mlops</a></li><li><a href=https://carlosdanieljimenez.com/tags/testing/>Testing</a></li><li><a href=https://carlosdanieljimenez.com/tags/production/>Production</a></li><li><a href=https://carlosdanieljimenez.com/tags/data-drift/>Data-Drift</a></li><li><a href=https://carlosdanieljimenez.com/tags/monitoring/>Monitoring</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://carlosdanieljimenez.com/>The Probability Engine</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><div class=newsletter-cta><div class=newsletter-content><h3>📬 Did this help?</h3><p>I write about MLOps, Edge AI, and making models work outside the lab.
One email per month, max. No spam, no course pitches, just technical content.</p><form action=https://buttondown.com/api/emails/embed-subscribe/carlosjimenez88m method=post class=newsletter-form target=popupwindow onsubmit='window.open("https://buttondown.com/carlosjimenez88m","popupwindow")'><div class=form-group><input type=email name=email id=bd-email placeholder=your@email.com required aria-label="Email address">
<input type=submit value=Subscribe></div></form><p class=newsletter-stats>Join engineers building ML systems and Edge Computing infrastructure.</p></div></div><style>.newsletter-cta{margin:3rem auto 2rem;padding:2rem;max-width:650px;background:var(--entry);border:1px solid var(--border);border-radius:8px;text-align:center}.newsletter-content h3{margin:0 0 1rem;font-size:1.5rem;color:var(--primary)}.newsletter-content p{margin:0 0 1.5rem;color:var(--secondary);line-height:1.6}.newsletter-form{margin:1.5rem 0}.form-group{display:flex;gap:.5rem;max-width:500px;margin:0 auto;flex-wrap:wrap;justify-content:center}.newsletter-form input[type=email]{flex:1;min-width:250px;padding:.75rem 1rem;font-size:1rem;border:1px solid var(--border);border-radius:6px;background:var(--theme);color:var(--content);transition:border-color .2s ease}.newsletter-form input[type=email]:focus{outline:none;border-color:var(--primary);box-shadow:0 0 0 3px rgba(var(--primary-rgb),.1)}.newsletter-form input[type=submit]{padding:.75rem 2rem;font-size:1rem;font-weight:600;color:#fff;background:var(--primary);border:none;border-radius:6px;cursor:pointer;transition:opacity .2s ease}.newsletter-form input[type=submit]:hover{opacity:.9}.newsletter-stats{font-size:.875rem;color:var(--secondary);margin-top:1rem;font-style:italic}@media screen and (max-width:600px){.newsletter-cta{padding:1.5rem 1rem;margin:2rem .5rem 1rem}.newsletter-content h3{font-size:1.25rem}.form-group{flex-direction:column;width:100%}.newsletter-form input[type=email],.newsletter-form input[type=submit]{width:100%;min-width:100%}}</style><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>