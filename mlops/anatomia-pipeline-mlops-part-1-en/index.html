<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration | The Probability Engine</title>
<meta name=keywords content="mlops,machine-learning,python,gcp,mlflow,wandb"><meta name=description content="Part 1: Philosophy, project architecture and orchestration with Hydra + MLflow. Steps for preprocessing, feature engineering, hyperparameter tuning and model registry."><meta name=author content="Carlos Daniel Jiménez"><link rel=canonical href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-part-1-en/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=16x16 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=icon type=image/png sizes=32x32 href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=apple-touch-icon href=https://carlosdanieljimenez.com/img/icon.jpeg><link rel=mask-icon href=https://carlosdanieljimenez.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-part-1-en/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=icon type=image/png href=/img/icon.jpeg><link rel=apple-touch-icon href=/img/icon.jpeg><link rel="shortcut icon" href=/img/icon.jpeg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-part-1-en/"><meta property="og:site_name" content="The Probability Engine"><meta property="og:title" content="Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration"><meta property="og:description" content="Part 1: Philosophy, project architecture and orchestration with Hydra + MLflow. Steps for preprocessing, feature engineering, hyperparameter tuning and model registry."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="mlops"><meta property="article:published_time" content="2026-01-13T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-13T00:00:00+00:00"><meta property="article:tag" content="Mlops"><meta property="article:tag" content="Machine-Learning"><meta property="article:tag" content="Python"><meta property="article:tag" content="Gcp"><meta property="article:tag" content="Mlflow"><meta property="article:tag" content="Wandb"><meta name=twitter:card content="summary"><meta name=twitter:title content="Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration"><meta name=twitter:description content="Part 1: Philosophy, project architecture and orchestration with Hydra + MLflow. Steps for preprocessing, feature engineering, hyperparameter tuning and model registry."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"MLOps Guides","item":"https://carlosdanieljimenez.com/mlops/"},{"@type":"ListItem","position":2,"name":"Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration","item":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-part-1-en/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration","name":"Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration","description":"Part 1: Philosophy, project architecture and orchestration with Hydra + MLflow. Steps for preprocessing, feature engineering, hyperparameter tuning and model registry.","keywords":["mlops","machine-learning","python","gcp","mlflow","wandb"],"articleBody":" Complete MLOps Series: Part 1 (current) | Part 2: Deployment → | Part 3: Production →\nAnatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration Why This Post Is Not Another Scikit-Learn Tutorial Most MLOps posts teach you how to train a Random Forest in a notebook and tell you “now put it in production.” This post assumes you already know how to train models. What you probably don’t know is how to build a system where:\nA GitHub commit triggers a complete 7-step pipeline Every preprocessing decision is backed by quantifiable metrics Models are versioned with rich metadata, not with filenames like model_final_v3_REAL.pkl Deployment doesn’t require SSH to a server to copy a pickle Rollback from a defective version takes 30 seconds, not 3 hours of panic debugging This post dissects a real pipeline that implements all of that. It’s not theory, it’s code running in production. Based on Chapter 2 of “Hands-On Machine Learning” by Aurélien Géron, but with the infrastructure the book doesn’t cover.\nComplete repository: github\nTable of Contents The Philosophy: Why Being Organized Is More Important Than Being Smart Project Structure: Architecture That Scales Orchestration with Hydra + MLflow Step 02: Automated Imputation - Data-Backed Decisions Step 03: Feature Engineering - KMeans As Feature, Not Just Clustering Step 06: Hyperparameter Sweep - Bayesian Optimization with W\u0026B Step 07: Model Registry - Versioning in MLflow CI/CD with GitHub Actions: Complete Pipeline Automation The Value of MLOps: Why This Matters W\u0026B vs MLflow: Why Both, Not One or the Other (#wandb-vs-mlflow) Docker and MLflow: Complete Ecosystem Containerization Pipeline Container with MLflow Tracking API Container for Inference Streamlit Container for Frontend Docker Compose: Orchestration of Three Containers API Architecture: FastAPI in Production (#api-architecture) Model and Parameter Selection Strategies Model Selection: Comparison of 5 Algorithms Parameter Grids and GridSearch Evaluation Metrics: MAPE, SMAPE, wMAPE Testing: Fixtures, Mocking and Real Coverage Production Patterns Nobody Tells You About The Transform Pattern: The Synthetic KMeans Trick Training/Serving Skew: The Silent Killer Data Drift: The Enemy This Project (Still) Doesn’t Monitor Model Monitoring: Beyond Accuracy The Cascade Pattern: Fallback Resilience Feature Store Anti-Pattern: When You DON’T Need One Production Readiness: An Honest Checklist Conclusions: MLOps As Engineering Discipline 1. The Philosophy: Why Being Organized Is More Important Than Being Smart The Real Problem of MLOps Being an MLOps engineer has two important things in its work:\nFirst, and what I feel is most important: being organized. It sounds redundant, but everything must go in its place. A notebook with 50 cells executed in random order is not a pipeline—it’s a time bomb. When that model needs to be retrained at 3 AM because data drift triggered an alert, who remembers the correct order of cells?\nSecond: what is not tested, remains a mock or a prototype. Far from thinking about using only design patterns, the focus and what I will try to plant as a central idea of this post is the usability of products and seeing this as software design.\nThe Right Mindset This project treats Machine Learning as what it really is: software with probabilistic components. It’s not magic, it’s engineering. And as engineering, it needs:\nVersioning: Of data, code, models and configuration Testing: Unit, integration and end-to-end Observability: Logs, metrics and traces Reproducibility: Running today and in 6 months should give the same result Deployment: Automated, not manual Reference: Hands-On Machine Learning by Géron This post is based on Chapter 2 of Géron’s book, a classic we should all read. But the book focuses on the model—how to train a good predictor. This post focuses on the system around the model—how to get that predictor into production reliably.\nWhat Géron teaches: Data imputation, feature engineering, model selection, evaluation.\nWhat this post adds: GCS for storage, W\u0026B for experimentation, MLflow for model registry, FastAPI for serving, Docker for deployment, GitHub Actions for CI/CD.\n2. Project Structure: Architecture That Scales The Complete Tree (200+ Files) cap2-end_to_end/ ├── main.py # Hydra + MLflow orchestrator ├── config.yaml # Single source of truth ├── pyproject.toml # Dependencies with UV ├── Makefile # CLI for common operations ├── Dockerfile # Containerized pipeline ├── docker-compose.yaml # API + Streamlit + MLflow ├── pytest.ini # Test configuration ├── .env.example # Secrets template │ ├── src/ │ ├── data/ # Processing steps (01-04) │ │ ├── 01_download_data/ │ │ │ ├── main.py # Download from URL → GCS │ │ │ ├── downloader.py # Download logic │ │ │ ├── models.py # Pydantic schemas │ │ │ ├── MLproject # MLflow entry point │ │ │ └── conda.yaml # Isolated dependencies │ │ │ │ │ ├── 02_preprocessing_and_imputation/ │ │ │ ├── main.py │ │ │ ├── preprocessor.py │ │ │ ├── imputation_analyzer.py # (critical) Strategy comparison │ │ │ └── utils.py │ │ │ │ │ ├── 03_feature_engineering/ │ │ │ ├── main.py │ │ │ ├── feature_engineer.py # (critical) KMeans clustering │ │ │ └── utils.py # Optimize n_clusters │ │ │ │ │ └── 04_segregation/ │ │ ├── main.py │ │ ├── segregator.py # Train/test split │ │ └── models.py │ │ │ ├── model/ # Modeling steps (05-07) │ │ ├── 05_model_selection/ │ │ │ ├── main.py # Comparison of 5 algorithms │ │ │ ├── model_selector.py # (critical) GridSearch per model │ │ │ └── utils.py │ │ │ │ │ ├── 06_sweep/ │ │ │ ├── main.py # (critical) W\u0026B Bayesian optimization │ │ │ ├── sweep_config.yaml # Search space │ │ │ └── best_params.yaml # Output (generated) │ │ │ │ │ └── 07_registration/ │ │ ├── main.py # (critical) MLflow registration │ │ └── configs/ │ │ └── model_config.yaml # Metadata (generated) │ │ │ └── utils/ │ └── colored_logger.py # Structured logging │ ├── api/ # FastAPI REST API │ ├── app/ │ │ ├── main.py # FastAPI + lifespan │ │ ├── core/ │ │ │ ├── config.py # Pydantic Settings │ │ │ ├── model_loader.py # Load from MLflow/GCS/Local │ │ │ └── wandb_logger.py # Log predictions │ │ ├── models/ │ │ │ └── schemas.py # Request/Response schemas │ │ └── routers/ │ │ └── predict.py # POST /api/v1/predict │ ├── Dockerfile # API image (port 8080) │ └── requirements.txt │ ├── streamlit_app/ # Interactive frontend │ ├── app.py # Streamlit application (450+ lines) │ ├── Dockerfile # Streamlit image (port 8501) │ └── requirements.txt │ ├── tests/ # Test suite │ ├── conftest.py # Shared fixtures │ ├── fixtures/ │ │ └── test_data_generator.py # Synthetic data │ ├── test_pipeline.py # Orchestration test │ ├── test_downloader.py │ ├── test_preprocessor.py │ ├── test_imputation_analyzer.py # (critical) Imputation tests │ ├── test_feature_engineering.py │ ├── test_segregation.py │ └── test_integration_simple.py # End-to-end │ └── docs/ ├── API_ARCHITECTURE_POST.md ├── QUICKSTART_GUIDE.md └── TESTING_IMPROVEMENTS.md Files marked with (critical) are the most critical to understand the architecture.\nFundamental Architectural Decisions 1. Separation src/data vs src/model Why: Data steps (01-04) produce reusable artifacts—preprocessing, features, splits. Model steps (05-07) consume them but can be retrained without rerunning everything upstream.\nBenefit: If you change hyperparameters, you only rerun 06-07. If you change feature engineering, you rerun 03-07. You don’t re-download data every time.\nCost: More verbosity, more files. But in real pipelines with multiple data scientists, isolation is worth gold.\n2. MLproject + conda.yaml per Step Each subdirectory is an independent MLflow project:\n# src/data/02_preprocessing/MLproject name: preprocessing_and_imputation conda_env: conda.yaml entry_points: main: parameters: gcs_input_path: {type: string} gcs_output_path: {type: string} command: \"python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}\" Advantages:\nIsolated dependencies (step 03 uses scikit-learn 1.3, step 06 could use 1.4) Independent execution: mlflow run src/data/02_preprocessing Granular tracking: each step is a separate run Disadvantage: File overhead. But it’s the same overhead as having microservices—each with its own Dockerfile.\n3. api/ As Separate Project The API is not in src/api/. It’s a sibling project with its own requirements.txt, Dockerfile and tests.\nReason: The API is deployed independently from the pipeline. It doesn’t need full pandas, full scikit-learn or W\u0026B client. Only FastAPI, pydantic and the model pickle.\nResult: Docker image of 200MB vs 1.5GB if you included the entire pipeline.\n4. Tests at Root Tests test the complete system, not isolated modules. test_integration_simple.py runs the pipeline end-to-end. It doesn’t fit conceptually in src/.\n5. Absence of notebooks/ Deliberate decision. Notebooks are excellent for exploration, terrible for production. This project prioritizes reproducibility over rapid iteration.\nIf you need to explore, use them locally but don’t commit them. Notebooks in git are:\nHard to review (incomprehensible diffs) Impossible to test Prone to out-of-order execution 3. Orchestration with Hydra + MLflow Why Not Simple Bash Scripts Running sequential Python commands works for simple pipelines:\npython src/data/01_download_data/main.py python src/data/02_preprocessing/main.py python src/data/03_feature_engineering/main.py # ... This approach fails when you need to:\nRun only specific steps (debugging) Change parameters without editing code Version configuration alongside code Structured logs of what ran with what params Track dependencies between steps Hydra + MLflow solves all these problems.\nThe Orchestrator: main.py \"\"\" MLOps Pipeline Orchestrator Executes steps sequentially using MLflow + Hydra \"\"\" import os import sys import mlflow import hydra from omegaconf import DictConfig from pathlib import Path import time def validate_environment_variables() -\u003e None: \"\"\"Fail fast if critical secrets are missing.\"\"\" required_vars = { \"GCP_PROJECT_ID\": \"Google Cloud Project ID\", \"GCS_BUCKET_NAME\": \"GCS Bucket name\", \"WANDB_API_KEY\": \"Weights \u0026 Biases API Key\", } missing = [] for var, description in required_vars.items(): value = os.getenv(var) if not value or value in [\"your-project-id\", \"your-key\"]: missing.append(f\" ERROR: {var}: {description}\") if missing: print(\"\\n\" + \"=\"*70) print(\"ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES\") print(\"=\"*70) print(\"\\n\".join(missing)) print(\"\\nCreate .env file with:\") print(\" GCP_PROJECT_ID=your-project-id\") print(\" GCS_BUCKET_NAME=your-bucket\") print(\" WANDB_API_KEY=your-key\") sys.exit(1) def get_steps_to_execute(config: DictConfig) -\u003e list[str]: \"\"\"Converts execute_steps from config to list.\"\"\" steps = config['main']['execute_steps'] if isinstance(steps, str): return [s.strip() for s in steps.split(',')] return list(steps) def run_step(step_name: str, step_path: Path, entry_point: str, parameters: dict): \"\"\"Executes a step as MLflow project.\"\"\" print(f\"\\n{'='*70}\") print(f\"EXECUTING: {step_name}\") print(f\"{'='*70}\") mlflow.run( uri=str(step_path), entry_point=entry_point, env_manager=\"local\", parameters=parameters ) @hydra.main(config_path='.', config_name=\"config\", version_base=\"1.3\") def go(config: DictConfig) -\u003e None: \"\"\"Main pipeline entry point.\"\"\" validate_environment_variables() mlflow.set_experiment(config['main']['experiment_name']) steps_to_execute = get_steps_to_execute(config) root_path = Path(__file__).parent start_time = time.time() try: # Step 01: Download Data if \"01_download_data\" in steps_to_execute: run_step( \"01 - Download Data\", root_path / \"src\" / \"data\" / \"01_download_data\", \"main\", { \"file_url\": config[\"download_data\"][\"file_url\"], \"gcs_output_path\": config[\"download_data\"][\"gcs_output_path\"], } ) # ... Steps 02-07 similar pattern ... elapsed = time.time() - start_time print(f\"\\nSUCCESS: PIPELINE COMPLETED ({elapsed:.1f}s)\") except Exception as e: print(f\"\\nERROR: PIPELINE FAILED: {e}\") raise if __name__ == \"__main__\": go() config.yaml: Single Source of Truth main: project_name: \"housing-mlops-gcp\" experiment_name: \"end_to_end_pipeline\" execute_steps: - \"01_download_data\" - \"02_preprocessing_and_imputation\" - \"03_feature_engineering\" - \"04_segregation\" - \"05_model_selection\" - \"06_sweep\" - \"07_registration\" download_data: file_url: \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz\" gcs_output_path: \"data/01-raw/housing.parquet\" preprocessing: gcs_input_path: \"data/01-raw/housing.parquet\" gcs_output_path: \"data/02-processed/housing_processed.parquet\" imputation_strategy: \"auto\" # Will compare 4 strategies feature_engineering: gcs_input_path: \"data/02-processed/housing_processed.parquet\" gcs_output_path: \"data/03-features/housing_features.parquet\" n_clusters: 10 optimize_hyperparams: true # Find best K segregation: gcs_input_path: \"data/03-features/housing_features.parquet\" gcs_train_output_path: \"data/04-split/train/train.parquet\" gcs_test_output_path: \"data/04-split/test/test.parquet\" test_size: 0.2 target_column: \"median_house_value\" model_selection: gcs_train_path: \"data/04-split/train/train.parquet\" gcs_test_path: \"data/04-split/test/test.parquet\" sweep: sweep_count: 50 # 50 Bayesian optimization runs metric_name: \"mape\" metric_goal: \"minimize\" registration: registered_model_name: \"housing_price_model\" model_stage: \"Staging\" # Or \"Production\" What This Code Does Well 1. Fail Fast with Environment Validation\nBefore spending CPU, verify all secrets exist. The error message includes instructions on how to get each value.\nERROR: MISSING REQUIRED ENVIRONMENT VARIABLES =============================================== ERROR: WANDB_API_KEY: Weights \u0026 Biases API Key Create .env file with: WANDB_API_KEY=your-key This saves frustration—especially for new contributors.\n2. Selective Execution Without Commenting Code\nYou change config.yaml:\nexecute_steps: [\"03_feature_engineering\", \"05_model_selection\"] And only those steps run. You don’t edit Python, you don’t comment imports.\n3. Separation Between Orchestration and Logic\nmain.py doesn’t know how to download data or train models. It only knows how to invoke scripts that do. Each step can be developed/tested independently.\n4. Structured Logging with Visual Hierarchy\nThe separators (\"=\"*70) and emojis aren’t cosmetic—in a pipeline that runs 2 hours, visual sections allow you to quickly scan to find which step failed.\n4. Step 02: Automated Imputation - Data-Backed Decisions The Real Problem California Housing has ~1% of total_bedrooms missing. Obvious options:\nDrop rows → lose data Fill with median → assume distribution without verification Fill with KNN → assume similarity in feature space Fill with IterativeImputer → assume modelable relationships Question: Which is better?\nIncorrect answer: “KNN always works”\nCorrect answer: “I tested all 4, median had RMSE of 0.8, KNN of 0.6, Iterative of 0.5. I use Iterative because it minimizes reconstruction error. Here’s the plot in W\u0026B.”\nimputation_analyzer.py: The Core \"\"\" Imputation Analyzer - Automatically compares strategies Author: Carlos Daniel Jiménez \"\"\" from dataclasses import dataclass from typing import Dict, Tuple import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer from sklearn.ensemble import RandomForestRegressor from sklearn.preprocessing import StandardScaler import matplotlib.pyplot as plt @dataclass class ImputationResult: \"\"\"Result of an imputation strategy.\"\"\" method_name: str rmse: float imputed_values: np.ndarray imputer: object class ImputationAnalyzer: \"\"\" Analyzes and compares imputation strategies. Automatically selects the best based on RMSE. \"\"\" def __init__( self, df: pd.DataFrame, target_column: str = \"total_bedrooms\", test_size: float = 0.2, random_state: int = 42 ): self.df = df self.target_column = target_column self.test_size = test_size self.random_state = random_state self.results: Dict[str, ImputationResult] = {} self.best_method: str = None self.best_imputer: object = None def prepare_validation_set(self) -\u003e Tuple[pd.DataFrame, pd.DataFrame, pd.Series]: \"\"\" Creates masked validation set to compare strategies. Strategy: 1. Remove rows with missing target (can't validate against NaN) 2. Split into train/val 3. Mask target in val set (simulate missing values) 4. Save ground truth Returns: (train_set, val_set_missing, y_val_true) \"\"\" housing_numeric = self.df.select_dtypes(include=[np.number]) housing_known = housing_numeric.dropna(subset=[self.target_column]) train_set, val_set = train_test_split( housing_known, test_size=self.test_size, random_state=self.random_state ) # Mask target in val val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan # Ground truth y_val_true = val_set[self.target_column].copy() return train_set, val_set_missing, y_val_true def evaluate_simple_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, strategy: str = \"median\" ) -\u003e ImputationResult: \"\"\"Evaluates SimpleImputer with given strategy.\"\"\" imputer = SimpleImputer(strategy=strategy) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"Simple Imputer ({strategy})\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def evaluate_knn_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series, n_neighbors: int = 5 ) -\u003e ImputationResult: \"\"\" Evaluates KNNImputer with scaling. CRITICAL: KNN requires scaled features or explodes with overflow. \"\"\" import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Scale data scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) val_scaled = scaler.transform(val_set_missing) # KNN imputation imputer = KNNImputer(n_neighbors=n_neighbors) imputer.fit(train_scaled) val_imputed_scaled = imputer.transform(val_scaled) # Inverse scale val_imputed = scaler.inverse_transform(val_imputed_scaled) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=f\"KNN Imputer (k={n_neighbors})\", rmse=rmse, imputed_values=y_val_pred, imputer=(scaler, imputer) # Store tuple! ) def evaluate_iterative_imputer( self, train_set: pd.DataFrame, val_set_missing: pd.DataFrame, y_val_true: pd.Series ) -\u003e ImputationResult: \"\"\"Evaluates IterativeImputer with RandomForest estimator.\"\"\" estimator = RandomForestRegressor( n_jobs=-1, random_state=self.random_state ) imputer = IterativeImputer( estimator=estimator, random_state=self.random_state ) imputer.fit(train_set) val_imputed = imputer.transform(val_set_missing) target_col_idx = train_set.columns.get_loc(self.target_column) y_val_pred = val_imputed[:, target_col_idx] rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred)) return ImputationResult( method_name=\"Iterative Imputer (RF)\", rmse=rmse, imputed_values=y_val_pred, imputer=imputer ) def compare_all_methods(self) -\u003e Dict[str, ImputationResult]: \"\"\"Compares all strategies and selects the best.\"\"\" train_set, val_set_missing, y_val_true = self.prepare_validation_set() # Evaluate all self.results['simple_median'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"median\" ) self.results['simple_mean'] = self.evaluate_simple_imputer( train_set, val_set_missing, y_val_true, strategy=\"mean\" ) self.results['knn'] = self.evaluate_knn_imputer( train_set, val_set_missing, y_val_true, n_neighbors=5 ) self.results['iterative_rf'] = self.evaluate_iterative_imputer( train_set, val_set_missing, y_val_true ) # Select best best_key = min(self.results, key=lambda k: self.results[k].rmse) self.best_method = best_key self.best_imputer = self.results[best_key].imputer # Print summary print(\"\\n\" + \"=\"*70) print(\"IMPUTATION METHODS COMPARISON\") print(\"=\"*70) for key, result in sorted(self.results.items(), key=lambda x: x[1].rmse): status = \"[BEST]\" if key == best_key else \"\" print(f\" {result.method_name:30s} RMSE: {result.rmse:8.4f} {status}\") print(\"=\"*70) return self.results def apply_best_imputer(self, df: pd.DataFrame) -\u003e pd.DataFrame: \"\"\"Applies the best imputer to the complete dataset.\"\"\" if self.best_imputer is None: raise ValueError(\"Run compare_all_methods() first\") df_out = df.copy() numeric_df = df_out.select_dtypes(include=[np.number]) import warnings with warnings.catch_warnings(): warnings.filterwarnings('ignore', category=RuntimeWarning) # Check if it's a tuple (KNN with scaler) if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer numeric_scaled = scaler.transform(numeric_df) imputed_scaled = imputer.transform(numeric_scaled) imputed_array = scaler.inverse_transform(imputed_scaled) else: imputed_array = self.best_imputer.transform(numeric_df) target_col_idx = numeric_df.columns.get_loc(self.target_column) df_out[self.target_column] = imputed_array[:, target_col_idx] return df_out def create_comparison_plot(self) -\u003e plt.Figure: \"\"\"Creates bar plot comparing RMSE of methods.\"\"\" methods = [r.method_name for r in self.results.values()] rmses = [r.rmse for r in self.results.values()] fig, ax = plt.subplots(figsize=(10, 6)) colors = ['green' if i == np.argmin(rmses) else 'skyblue' for i in range(len(rmses))] bars = ax.bar(methods, rmses, color=colors) ax.set_xlabel('Imputation Method', fontweight='bold') ax.set_ylabel('RMSE', fontweight='bold') ax.set_title('Comparison of Imputation Strategies', fontsize=14) ax.grid(axis='y', alpha=0.3) # Value labels for bar, rmse in zip(bars, rmses): height = bar.get_height() ax.text( bar.get_x() + bar.get_width()/2., height, f'{rmse:.4f}', ha='center', va='bottom' ) plt.xticks(rotation=45, ha='right') plt.tight_layout() return fig Critical Technical Decisions 1. The Metric: Reconstruction RMSE Why RMSE and not MAE?\nMAE treats all errors equally. RMSE penalizes large errors more strongly.\nIf a method imputes 100 bedrooms when the truth is 3, that’s problematic. RMSE punishes it more than MAE. In imputation, large errors distort the dataset more than many small errors.\n2. The Masked Validation Set train_set, val_set = train_test_split(housing_known, test_size=0.2) val_set_missing = val_set.copy() val_set_missing[self.target_column] = np.nan y_val_true = val_set[self.target_column].copy() This trick is critical. You can’t evaluate imputation strategies on real missing values—you don’t know the truth. So:\nTake rows where the target is NOT missing Split into train/val Artificially mask the target in val Compare how well each imputer reconstructs the values you knew It’s cross-validation for preprocessing, not just for models.\n3. Why KNN Needs Scaling scaler = StandardScaler() train_scaled = scaler.fit_transform(train_set) KNN calculates euclidean distances between observations. If one feature is in range [0, 1] and another in [0, 10000], the second dominates completely.\nStandardScaler normalizes everything to mean 0, std 1. Now all features contribute equally.\nIterativeImputer with RandomForest does NOT need scaling—trees are scale-invariant.\n4. The Imputer As Tuple if isinstance(self.best_imputer, tuple): scaler, imputer = self.best_imputer # ... apply both If KNN won, you need to save both the scaler and the imputer. In production, when new data arrives:\nScale with the same scaler fitted in training Apply KNN imputer Inverse transform to return to original scale Saving only the imputer without the scaler would break everything.\nUsage in the Pipeline # In Step 02 main.py import wandb import mlflow analyzer = ImputationAnalyzer(df, target_column=\"total_bedrooms\") results = analyzer.compare_all_methods() # Log to W\u0026B comparison_plot = analyzer.create_comparison_plot() wandb.log({ \"imputation/comparison\": wandb.Image(comparison_plot), \"imputation/best_method\": analyzer.best_method, \"imputation/best_rmse\": results[analyzer.best_method].rmse, }) # Apply to complete dataset housing_clean = analyzer.apply_best_imputer(housing_df) # Save imputer import joblib joblib.dump(analyzer.best_imputer, \"artifacts/imputer.pkl\") mlflow.log_artifact(\"artifacts/imputer.pkl\") What This Achieves Without this: “I used median because that’s what everyone does.”\nWith this: “I compared 4 strategies. IterativeImputer with RandomForest had 15% lower RMSE than median. Here’s the plot in W\u0026B dashboard run abc123. The imputer is serialized in MLflow.”\nNow you have quantifiable evidence of why you chose what you chose. Six months later, when someone asks, the data is there.\n5. Step 03: Feature Engineering - KMeans As Feature, Not Just Clustering The Real Problem California has strong geographic patterns. Houses in San Francisco behave differently than houses in the central valley. But latitude/longitude as raw features don’t capture this well—a linear model can’t learn “this area is expensive”.\nSolution: Geographic clustering. But not to segment data, rather to create a categorical feature: cluster_label.\nClusterSimilarity: Custom Transformer from sklearn.base import BaseEstimator, TransformerMixin from sklearn.cluster import KMeans import numpy as np class ClusterSimilarity(BaseEstimator, TransformerMixin): \"\"\" Custom transformer for geographic clustering. Design: Scikit-learn transformer to integrate into Pipeline. \"\"\" def __init__(self, n_clusters=10, gamma=1.0, random_state=None): self.n_clusters = n_clusters self.gamma = gamma # Placeholder for RBF kernel (not currently used) self.random_state = random_state def fit(self, X, y=None, sample_weight=None): \"\"\"Fit KMeans on geographic coordinates.\"\"\" self.kmeans_ = KMeans( self.n_clusters, n_init=10, random_state=self.random_state ) self.kmeans_.fit(X, sample_weight=sample_weight) return self def transform(self, X): \"\"\"Transform coordinates to cluster labels.\"\"\" cluster_labels = self.kmeans_.predict(X) return np.expand_dims(cluster_labels, axis=1) def get_feature_names_out(self, names=None): \"\"\"Returns feature names for Pipeline.\"\"\" return [\"cluster_label\"] The Complete Preprocessing Pipeline from sklearn.pipeline import Pipeline from sklearn.compose import ColumnTransformer from sklearn.impute import SimpleImputer from sklearn.preprocessing import OneHotEncoder, StandardScaler def create_preprocessing_pipeline(n_clusters=10): \"\"\" Creates pipeline that processes: - Numeric: impute + scale - Categorical: impute + one-hot - Geo: clustering \"\"\" num_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"median\")), (\"standardize\", StandardScaler()), ]) cat_pipeline = Pipeline([ (\"impute\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")), ]) num_attribs = [ \"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\" ] cat_attribs = [\"ocean_proximity\"] preprocessing = ColumnTransformer([ (\"num\", num_pipeline, num_attribs), (\"cat\", cat_pipeline, cat_attribs), (\"geo\", ClusterSimilarity(n_clusters=n_clusters), [\"latitude\", \"longitude\"]), ]) return preprocessing Automatic Optimization of n_clusters from sklearn.metrics import silhouette_score, davies_bouldin_score def optimize_n_clusters( df: pd.DataFrame, min_clusters=2, max_clusters=20 ) -\u003e Tuple[int, Dict]: \"\"\" Finds the best K for KMeans using silhouette score. Metrics: - Silhouette score (0 to 1): Cluster separation. Maximize. - Davies-Bouldin index: Internal dispersion vs separation. Minimize. \"\"\" geo_features = df[[\"latitude\", \"longitude\"]].values cluster_range = range(min_clusters, max_clusters + 1) silhouette_scores = [] davies_bouldin_scores = [] inertias = [] for n in cluster_range: kmeans = KMeans(n_clusters=n, n_init=10, random_state=42) labels = kmeans.fit_predict(geo_features) silhouette_scores.append(silhouette_score(geo_features, labels)) davies_bouldin_scores.append(davies_bouldin_score(geo_features, labels)) inertias.append(kmeans.inertia_) # Select K with best silhouette optimal_n = cluster_range[np.argmax(silhouette_scores)] metrics = { \"optimal_n_clusters\": optimal_n, \"best_silhouette\": max(silhouette_scores), \"cluster_range\": list(cluster_range), \"silhouette_scores\": silhouette_scores, \"davies_bouldin_scores\": davies_bouldin_scores, \"inertias\": inertias, } return optimal_n, metrics Visualization: Elbow Method + Silhouette def create_optimization_plots(metrics: Dict) -\u003e Dict[str, plt.Figure]: \"\"\"Creates K optimization plots.\"\"\" # Plot 1: Elbow Method (Inertia) fig1, ax1 = plt.subplots(figsize=(10, 6)) ax1.plot(metrics[\"cluster_range\"], metrics[\"inertias\"], 'bo-') ax1.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--', label=f'Optimal K={metrics[\"optimal_n_clusters\"]}' ) ax1.set_xlabel('Number of Clusters (K)') ax1.set_ylabel('Inertia') ax1.set_title('Elbow Method - KMeans Optimization') ax1.legend() ax1.grid(True) # Plot 2: Silhouette Score fig2, ax2 = plt.subplots(figsize=(10, 6)) ax2.plot(metrics[\"cluster_range\"], metrics[\"silhouette_scores\"], 'go-') ax2.axvline( metrics[\"optimal_n_clusters\"], color='r', linestyle='--' ) ax2.set_xlabel('Number of Clusters (K)') ax2.set_ylabel('Silhouette Score') ax2.set_title('Silhouette Score vs K') ax2.grid(True) return {\"elbow_method\": fig1, \"silhouette_scores\": fig2} Usage in the Pipeline # In Step 03 main.py import wandb import mlflow import joblib # Download data from GCS df = download_from_gcs(bucket, \"data/02-processed/housing_processed.parquet\") # Optimize K optimal_k, metrics = optimize_n_clusters(df, min_clusters=5, max_clusters=15) print(f\"Optimal K: {optimal_k}\") print(f\" Silhouette: {metrics['best_silhouette']:.4f}\") # Create plots plots = create_optimization_plots(metrics) # Log to W\u0026B wandb.log({ \"optimization/optimal_k\": optimal_k, \"optimization/silhouette\": metrics[\"best_silhouette\"], \"optimization/elbow_plot\": wandb.Image(plots[\"elbow_method\"]), \"optimization/silhouette_plot\": wandb.Image(plots[\"silhouette_scores\"]), }) # Create pipeline with optimal K preprocessing_pipeline = create_preprocessing_pipeline(n_clusters=optimal_k) # Fit pipeline target_column = \"median_house_value\" y = df[target_column] X = df.drop(columns=[target_column]) preprocessing_pipeline.fit(X, y) # Transform data X_transformed = preprocessing_pipeline.transform(X) # Reconstruct DataFrame with target df_transformed = pd.DataFrame( X_transformed, columns=preprocessing_pipeline.get_feature_names_out() ) df_transformed[target_column] = y.values # Upload to GCS upload_to_gcs(df_transformed, bucket, \"data/03-features/housing_features.parquet\") # Save pipeline joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") mlflow.log_artifact(\"artifacts/preprocessing_pipeline.pkl\") Critical Technical Decisions 1. Why Silhouette Score Silhouette score (range 0 to 1) measures how well separated the clusters are:\n1.0: Perfectly separated clusters 0.5: Moderate overlap 0.0: Random clusters It’s interpretable and generally correlates well with visual quality of clusters.\nDavies-Bouldin index: We also calculate it but don’t use it for decision—it’s more sensitive to outliers.\n2. The Obvious Criticism This code optimizes n_clusters based on clustering metrics, not on final model performance.\nA more rigorous approach would be:\nfor k in range(5, 15): pipeline = create_preprocessing_pipeline(n_clusters=k) X_train_transformed = pipeline.fit_transform(X_train, y_train) X_test_transformed = pipeline.transform(X_test) model = RandomForestRegressor() model.fit(X_train_transformed, y_train) mape = calculate_mape(model, X_test_transformed, y_test) # Select K with best MAPE This would take 10x more time but would be more rigorous.\nTrade-off: This pipeline prioritizes speed over absolute rigor. For California Housing, silhouette score is good enough. For more complex datasets, consider the full cross-validation approach.\n3. handle_unknown=“ignore” in OneHotEncoder OneHotEncoder(handle_unknown=\"ignore\") Critical for production. If in training you have categories [\"\u003c1H OCEAN\", \"INLAND\", \"NEAR BAY\"] but in production \"ISLAND\" arrives (which you didn’t see), the encoder:\nWithout handle_unknown: Explodes with ValueError With handle_unknown=\"ignore\": Generates zero vector for that observation You lose information for that observation, but the API doesn’t return HTTP 500.\n4. Why Save the Pipeline, Not Just the Model joblib.dump(preprocessing_pipeline, \"artifacts/preprocessing_pipeline.pkl\") In production, you need to:\nLoad the pipeline Transform new data Predict with the model If you only save the model, you don’t know:\nWhat features it expects In what order What transformations to apply The pipeline encapsulates all that.\nWhat This Achieves Without this: “I used KMeans with K=10 because I read that 10 clusters is good.”\nWith this: “I tested K from 5 to 15. K=8 maximized silhouette score (0.64). Here are the elbow method and silhouette plots. The pipeline with K=8 is serialized in MLflow.”\nQuantifiable evidence + reproducible artifact.\n6. Step 06: Hyperparameter Sweep - Bayesian Optimization with W\u0026B The Problem of Model Selection vs Hyperparameter Tuning Most ML projects make this mistake: they train a Random Forest in a notebook, adjust some hyperparameters until R² looks “good” and declare victory. Three months later, when someone asks “why Random Forest and not XGBoost?”, the answer is awkward silence.\nThis pipeline separates two phases:\nModel Selection (Step 05): Compares algorithms with fast GridSearch (5-10 combos per model) Hyperparameter Sweep (Step 06): Optimizes the winner with exhaustive Bayesian search (50+ runs) Reason: You don’t have time or compute to do exhaustive sweep of 5 algorithms. First you decide strategy (which algorithm), then tactics (which hyperparameters).\nsweep_config.yaml: The Search Space # ================================================================= # W\u0026B Sweep Configuration for Random Forest # Author: Carlos Daniel Jiménez # ================================================================= program: main.py method: bayes # Bayesian optimization, not random, not grid metric: name: wmape # Weighted MAPE (less biased than MAPE) goal: minimize parameters: n_estimators: min: 50 max: 500 max_depth: min: 5 max: 30 min_samples_split: min: 2 max: 20 min_samples_leaf: min: 1 max: 10 max_features: values: ['sqrt', 'log2'] # Early stopping: eliminates poor runs early early_terminate: type: hyperband min_iter: 10 # Minimum 10 runs before terminating eta: 3 # Eliminates 1/3 of poor runs s: 2 name: housing-rf-sweep-improved description: \"Optimize Random Forest with wmape + feature tracking\" main.py from Step 06: The Real Sweep \"\"\" W\u0026B Sweep for Random Forest Hyperparameter Optimization. Author: Carlos Daniel Jiménez \"\"\" import argparse import yaml import wandb import logging from pathlib import Path from utils import ( download_data_from_gcs, prepare_data, train_random_forest, evaluate_model, log_feature_importances ) logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) # Module-level data cache (loaded once, reused in all runs) _data_cache = { \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None, \"feature_names\": None } def train(): \"\"\" Training function called by W\u0026B Sweep agent. Executed for each hyperparameter combination. Uses module-level cache to avoid reloading data on each run. \"\"\" run = wandb.init() config = wandb.config logger.info(\"=\"*70) logger.info(f\"SWEEP RUN: {run.name}\") logger.info(\"=\"*70) try: # Prepare parameters params = { 'n_estimators': int(config.n_estimators), 'max_depth': int(config.max_depth) if config.max_depth else None, 'min_samples_split': int(config.min_samples_split), 'min_samples_leaf': int(config.min_samples_leaf), 'max_features': config.max_features, 'random_state': 42 } # Train model using cached data model = train_random_forest( _data_cache[\"X_train\"], _data_cache[\"y_train\"], params ) # Evaluate model metrics = evaluate_model( model, _data_cache[\"X_test\"], _data_cache[\"y_test\"] ) # Log feature importances feature_importances = log_feature_importances( model, _data_cache[\"feature_names\"] ) # Log everything to W\u0026B wandb.log({ **params, **metrics, **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) logger.info(f\"SUCCESS: MAPE={metrics['mape']:.2f}% | \" f\"WMAPE={metrics['wmape']:.2f}%\") except Exception as e: logger.error(f\"ERROR: Run failed: {str(e)}\") wandb.log({ \"error\": str(e), \"mape\": 999.9, \"wmape\": 999.9 }) raise finally: run.finish() def main(): \"\"\"Main function to initialize and run the sweep.\"\"\" parser = argparse.ArgumentParser() parser.add_argument(\"--gcs_train_path\", type=str, required=True) parser.add_argument(\"--gcs_test_path\", type=str, required=True) parser.add_argument(\"--bucket_name\", type=str, required=True) parser.add_argument(\"--wandb_project\", type=str, required=True) parser.add_argument(\"--target_column\", type=str, default=\"median_house_value\") parser.add_argument(\"--sweep_count\", type=int, default=50) parser.add_argument(\"--sweep_config\", type=str, default=\"sweep_config.yaml\") args = parser.parse_args() logger.info(\"=\"*70) logger.info(\"W\u0026B SWEEP - HYPERPARAMETER OPTIMIZATION\") logger.info(\"=\"*70) # Load data ONCE into module-level cache logger.info(\"\\nLoading data into cache...\") train_df = download_data_from_gcs(args.bucket_name, args.gcs_train_path) X_train, y_train = prepare_data(train_df, args.target_column) test_df = download_data_from_gcs(args.bucket_name, args.gcs_test_path) X_test, y_test = prepare_data(test_df, args.target_column) # Store in cache _data_cache[\"X_train\"] = X_train _data_cache[\"X_test\"] = X_test _data_cache[\"y_train\"] = y_train _data_cache[\"y_test\"] = y_test _data_cache[\"feature_names\"] = X_train.columns.tolist() logger.info(f\"Data cached: Train {X_train.shape}, Test {X_test.shape}\") # Load sweep configuration sweep_config_path = Path(__file__).parent / args.sweep_config with open(sweep_config_path, 'r') as f: sweep_config = yaml.safe_load(f) logger.info(f\"\\nSweep config:\") logger.info(f\" Method: {sweep_config['method']}\") logger.info(f\" Metric: {sweep_config['metric']['name']} ({sweep_config['metric']['goal']})\") # Initialize sweep sweep_id = wandb.sweep( sweep=sweep_config, project=args.wandb_project ) logger.info(f\"\\nSweep created: {sweep_id}\") logger.info(f\" View at: https://wandb.ai/{args.wandb_project}/sweeps/{sweep_id}\") # Run sweep agent logger.info(f\"\\nStarting sweep agent ({args.sweep_count} runs)...\") wandb.agent( sweep_id, function=train, count=args.sweep_count, project=args.wandb_project ) logger.info(\"\\n\" + \"=\"*70) logger.info(\"SWEEP COMPLETED\") logger.info(\"=\"*70) # Save best params api = wandb.Api() sweep = api.sweep(f\"{args.wandb_project}/{sweep_id}\") best_run = sweep.best_run() best_params = { \"hyperparameters\": { \"n_estimators\": int(best_run.config.get('n_estimators')), \"max_depth\": int(best_run.config.get('max_depth')) if best_run.config.get('max_depth') else None, \"min_samples_split\": int(best_run.config.get('min_samples_split')), \"min_samples_leaf\": int(best_run.config.get('min_samples_leaf')), \"max_features\": best_run.config.get('max_features'), }, \"metrics\": { \"mape\": float(best_run.summary.get('mape')), \"wmape\": float(best_run.summary.get('wmape')), \"r2\": float(best_run.summary.get('r2')), }, \"sweep_id\": sweep_id, \"best_run_id\": best_run.id } # Save to YAML best_params_path = Path(__file__).parent / \"best_params.yaml\" with open(best_params_path, 'w') as f: yaml.dump(best_params, f) logger.info(f\"\\nBest params saved to: {best_params_path}\") logger.info(f\" MAPE: {best_params['metrics']['mape']:.2f}%\") if __name__ == \"__main__\": main() Critical Technical Decisions 1. Bayesian Optimization, Not Random Search method: bayes # Not random, not grid Random search: Tests random combinations. Doesn’t learn from previous runs.\nGrid search: Tests all combinations. Exhaustive but expensive (5 × 4 × 3 × 3 × 2 = 360 combos).\nBayesian optimization: Builds a probabilistic model of the function you’re optimizing (MAPE as a function of hyperparameters) and uses that model to decide what to test next.\nIf it detects that max_depth=None consistently gives better MAPE, it explores more in that region of the space.\n50 runs is \u003c15% of the total space, but captures 80% of the possible benefit.\n2. wMAPE, Not MAPE metric: name: wmape # Weighted MAPE Standard MAPE: Penalizes errors on cheap houses more than on expensive houses.\nIf a house is worth $10,000 and you predict $12,000, error = 20%. If a house is worth $500,000 and you predict $510,000, error = 2%.\nBoth errors are $10,000, but MAPE sees them radically different.\nwMAPE (Weighted MAPE): Weights by actual value. Less biased toward low values.\nWhy it works here: California Housing doesn’t have $0 houses. Range is between $15k and $500k—reasonably bounded.\n3. Global Variables For Data Cache _data_cache = { \"X_train\": None, \"X_test\": None, # ... } Global variables are generally dirty code. Here they’re the right decision.\nEach sweep run needs the same data. Without cache, you’d load from GCS 50 times. With California Housing (20k rows), that’s wasted seconds. With larger datasets, it’s minutes or hours.\n“Clean” alternative: Pass data as argument to each function. But W\u0026B Sweeps has a fixed interface—the function you pass to wandb.agent() can’t receive additional arguments.\nGlobal variables here have limited scope—they only exist during the sweep process.\n4. Early Stopping with Hyperband early_terminate: type: hyperband min_iter: 10 eta: 3 Hyperband eliminates poor runs early. If after 10 runs a set of hyperparameters shows MAPE of 25% while others are at 8%, Hyperband stops it.\neta=3: Eliminates the worst third of runs in each iteration.\nBenefit: You save compute on obviously bad hyperparameters.\n5. Logged Feature Importances feature_importances = log_feature_importances(model, feature_names) wandb.log({ **{f\"feature_importance_{k}\": v for k, v in list(feature_importances.items())[:10]} }) Random Forest calculates feature importances for free. It would be valuable to log it to understand which features dominate the model.\nIn W\u0026B dashboard, you can compare runs and see “in the best run, median_income had importance of 0.45”.\nThe Critical Output: best_params.yaml Note: Below are the real values from the actual production sweep, not example values:\nsweep_id: f73ao31m best_run_id: 5q1840qa best_run_name: dry-sweep-5 hyperparameters: n_estimators: 128 max_depth: 23 min_samples_split: 9 min_samples_leaf: 9 max_features: log2 random_state: 42 metrics: # Primary metrics mae: 38901.45 rmse: 53277.02 r2: 0.78339 # Percentage error metrics mape: 20.4002 smape: 18.85 wmape: 19.12 median_ape: 16.73 # Accuracy within thresholds within_5pct: 12.4 within_10pct: 36.2 within_15pct: 52.8 sweep_url: https://wandb.ai/danieljimenez88m-carlosdanieljimenez-com/housing-mlops-gcp/sweeps/f73ao31m Key insights from these real metrics:\nMAPE of 20.4% indicates the model predicts prices within ±20% on average 36.2% of predictions are within 10% - acceptable for real estate valuation R² of 0.78 means the model explains 78% of variance in house prices The optimal configuration found by Bayesian optimization used: Moderate tree depth (max_depth=23) to balance bias/variance Higher leaf requirements (min_samples_leaf=9) to prevent overfitting log2 feature sampling for better generalization than sqrt Optimal hyperparameters are saved in YAML, not pickle. Reason:\nYAML is readable and git-friendly. If in the next retraining you change from n_estimators=128 to n_estimators=150, a git diff shows it clearly.\nWith pickle, it’s an opaque binary blob.\nWhat This Achieves Without this: “I used n_estimators=100 because it’s scikit-learn’s default.”\nWith this: “I ran Bayesian sweep of 50 runs. Optimal config: n_estimators=128, max_depth=23, max_features=log2. Final MAPE: 20.4% with 36.2% of predictions within 10%. Here’s the sweep in W\u0026B: f73ao31m.”\nQuantifiable evidence of why you chose each hyperparameter.\n7. Step 07: Model Registry - Versioning in MLflow Why Just Saving the Pickle Isn’t Enough The temptation is:\nimport joblib joblib.dump(model, \"best_model.pkl\") This works until you need to answer:\nWhat hyperparameters did it use? What data was it trained on? What metrics did it achieve? How do I rollback to the previous version? MLflow Model Registry solves this.\nregister_model_to_mlflow(): The Core \"\"\" Model registration in MLflow Model Registry. Author: Carlos Daniel Jiménez \"\"\" import mlflow import mlflow.sklearn from mlflow.tracking import MlflowClient def register_model_to_mlflow( model, model_name: str, model_stage: str, params: dict, metrics: dict, feature_columns: list, target_column: str, gcs_train_path: str, gcs_test_path: str ) -\u003e tuple: \"\"\" Registers model in MLflow Model Registry with rich metadata. Args: model: Trained sklearn model model_name: Name for registered model model_stage: Stage (Staging/Production) params: Hyperparameters metrics: Evaluation metrics feature_columns: List of features target_column: Target column name gcs_train_path: Path to training data gcs_test_path: Path to test data Returns: (model_uri, model_version, run_id) \"\"\" logger.info(\"=\"*70) logger.info(\"REGISTERING MODEL TO MLFLOW\") logger.info(\"=\"*70) client = MlflowClient() run_id = mlflow.active_run().info.run_id model_uri = f\"runs:/{run_id}/model\" # Log model to MLflow mlflow.sklearn.log_model(model, \"model\") logger.info(f\"Model logged: {model_uri}\") # Create or get registered model try: client.create_registered_model( name=model_name, description=\"Housing price prediction - Random Forest\" ) logger.info(f\"Created new registered model: {model_name}\") except Exception as e: if \"already exists\" in str(e): logger.info(f\"Model already exists: {model_name}\") else: raise # Create model version model_version = client.create_model_version( name=model_name, source=model_uri, run_id=run_id ) logger.info(f\"Version created: {model_version.version}\") # Transition to stage client.transition_model_version_stage( name=model_name, version=model_version.version, stage=model_stage # \"Staging\" or \"Production\" ) logger.info(f\"Transitioned to: {model_stage}\") # Create comprehensive description (MARKDOWN) description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest Regressor ## Hyperparameters - n_estimators: {params['n_estimators']} - max_depth: {params.get('max_depth', 'None')} - min_samples_split: {params['min_samples_split']} - min_samples_leaf: {params['min_samples_leaf']} - max_features: {params.get('max_features', 'sqrt')} ## Performance Metrics - MAPE: {metrics['mape']:.2f}% - Median APE: {metrics['median_ape']:.2f}% - Within 10%: {metrics['within_10pct']:.1f}% - RMSE: {metrics['rmse']:.2f} - R²: {metrics['r2']:.4f} ## Features - Number of features: {len(feature_columns)} - Target: {target_column} ## Data Sources - Training: {gcs_train_path} - Testing: {gcs_test_path} \"\"\" client.update_model_version( name=model_name, version=model_version.version, description=description ) # Add searchable tags tags = { \"algorithm\": \"RandomForest\", \"framework\": \"sklearn\", \"mape\": f\"{metrics['mape']:.2f}\", \"within_10pct\": f\"{metrics['within_10pct']:.1f}\", \"rmse\": f\"{metrics['rmse']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", \"n_features\": str(len(feature_columns)), \"target\": target_column, } for key, value in tags.items(): client.set_model_version_tag( model_name, model_version.version, key, value ) logger.info(\"Tags added to model version\") logger.info(\"=\"*70) return model_uri, model_version.version, run_id Critical Technical Decisions 1. Artifact vs Registered Model Artifact: Pickle saved in a specific run. To use it, you need the run_id.\nmlflow.sklearn.log_model(model, \"model\") # Only artifact # Usage: mlflow.sklearn.load_model(f\"runs://{run_id}/model\") Registered Model: Versioned with semantic name, stages and metadata.\nclient.create_model_version(name=\"housing_price_model\", source=model_uri) # Usage: mlflow.pyfunc.load_model(\"models:/housing_price_model/Production\") In production, your API loads models:/housing_price_model/Production, not runs:/abc123/model.\nWhen you register a new version, you transition it to Production and the deployment automatically takes the new version.\n2. Rich Metadata in Markdown description = f\"\"\" # Housing Price Prediction Model **Algorithm:** Random Forest ## Hyperparameters - n_estimators: {params['n_estimators']} ... ## Performance Metrics - MAPE: {metrics['mape']:.2f}% ... \"\"\" This saves markdown in the model description. When you open MLflow UI and navigate to housing_price_model v3, you see:\nWhat hyperparameters it used What metrics it achieved Where the data came from Why it’s gold: Six months later, when someone asks “why does model v3 have better MAPE than v2?”, you open MLflow and the answer is there.\nYou don’t need to search in logs or ask who trained it.\n3. Tags For Search tags = { \"algorithm\": \"RandomForest\", \"mape\": f\"{metrics['mape']:.2f}\", \"r2\": f\"{metrics['r2']:.4f}\", } for key, value in tags.items(): client.set_model_version_tag(model_name, model_version.version, key, value) In MLflow you can filter models by tags. “Show me all models with MAPE \u003c 8%” is a query that works if you tagged consistently.\n4. Model Config File: Single Source of Truth model_config = { 'model': { 'name': model_name, 'version': str(model_version), 'stage': model_stage, 'parameters': params, 'metrics': metrics, 'feature_columns': feature_columns, 'mlflow_run_id': run_id, 'sweep_id': sweep_id } } config_path = Path(\"configs/model_config.yaml\") with open(config_path, 'w') as f: yaml.dump(model_config, f) mlflow.log_artifact(str(config_path), artifact_path=\"config\") This YAML is logged to MLflow AND saved in the repo (in configs/model_config.yaml).\nWhy YAML and not just MLflow: Your FastAPI app needs to read configuration at startup. It can do mlflow.load_model() for the pickle, but needs to know the feature names for input validation.\nThe YAML is that single source of truth.\n5. Versioning in Git When you commit model_config.yaml, the diff shows:\n- version: 2 + version: 3 - mape: 22.1 + mape: 20.4 - n_estimators: 100 + n_estimators: 128 + max_features: log2 It’s auditable. You know exactly what changed between versions.\nThe Complete Flow: Sweep → Registration → Production # 1. Model Selection (Step 05) python src/model/05_model_selection/main.py # Output: \"Best: RandomForestRegressor (MAPE: 8.2%)\" # 2. Hyperparameter Sweep (Step 06) python src/model/06_sweep/main.py --sweep_count=50 # Output: best_params.yaml with optimal hyperparameters # 3. Model Registration (Step 07) python src/model/07_registration/main.py --params_file=best_params.yaml # Output: Model registered in MLflow Registry # 4. Transition to Production (manual) mlflow models transition \\ --name housing_price_model \\ --version 3 \\ --stage Production What This Approach Solves Without Model Registry:\nPickles in folders: model_v3_final_FINAL_2.pkl You don’t know what hyperparameters each uses Rollback = find the correct pickle in GCS With Model Registry:\nModels with semantic versions: v1, v2, v3 Embedded metadata: params, metrics, data sources Rollback = transition v3 to Archived + transition v2 to Production 8. CI/CD with GitHub Actions: Complete Pipeline Automation Navigation ← Home | Part 2: Deployment and Infrastructure →\nIn Part 2 we will cover:\nCI/CD with GitHub Actions W\u0026B vs MLflow: Complementary strategies Complete containerization with Docker FastAPI architecture in production ","wordCount":"6116","inLanguage":"en","datePublished":"2026-01-13T00:00:00Z","dateModified":"2026-01-13T00:00:00Z","author":{"@type":"Person","name":"Carlos Daniel Jiménez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://carlosdanieljimenez.com/mlops/anatomia-pipeline-mlops-part-1-en/"},"publisher":{"@type":"Organization","name":"The Probability Engine","logo":{"@type":"ImageObject","url":"https://carlosdanieljimenez.com/img/icon.jpeg"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://carlosdanieljimenez.com/ accesskey=h title="The Probability Engine (Alt + H)">The Probability Engine</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://carlosdanieljimenez.com/mlops/ title=MLOps><span>MLOps</span></a></li><li><a href=https://carlosdanieljimenez.com/agentic-ai/ title="Agentic AI"><span>Agentic AI</span></a></li><li><a href=https://carlosdanieljimenez.com/tidytuesday/ title=TidyTuesday><span>TidyTuesday</span></a></li><li><a href=https://carlosdanieljimenez.com/post/ title=Posts><span>Posts</span></a></li><li><a href=https://carlosdanieljimenez.com/edge-computing/ title="Edge Computing"><span>Edge Computing</span></a></li><li><a href=https://carlosdanieljimenez.com/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://carlosdanieljimenez.com/about/ title=About><span>About</span></a></li><li><a href=https://carlosdanieljimenez.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration</h1><div class=post-description>Part 1: Philosophy, project architecture and orchestration with Hydra + MLflow. Steps for preprocessing, feature engineering, hyperparameter tuning and model registry.</div><div class=post-meta><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;<span>Carlos Daniel Jiménez</span></div></header><div class=post-content><blockquote><p><strong>Complete MLOps Series:</strong> <a href=/mlops/anatomia-pipeline-mlops-parte-1/>Part 1 (current)</a> | <a href=/mlops/anatomia-pipeline-mlops-parte-2/>Part 2: Deployment →</a> | <a href=/mlops/anatomia-pipeline-mlops-parte-3/>Part 3: Production →</a></p></blockquote><h1 id=anatomy-of-an-mlops-pipeline---part-1-pipeline-and-orchestration>Anatomy of an MLOps Pipeline - Part 1: Pipeline and Orchestration<a hidden class=anchor aria-hidden=true href=#anatomy-of-an-mlops-pipeline---part-1-pipeline-and-orchestration>#</a></h1><h2 id=why-this-post-is-not-another-scikit-learn-tutorial>Why This Post Is Not Another Scikit-Learn Tutorial<a hidden class=anchor aria-hidden=true href=#why-this-post-is-not-another-scikit-learn-tutorial>#</a></h2><p>Most MLOps posts teach you how to train a Random Forest in a notebook and tell you &ldquo;now put it in production.&rdquo; This post assumes you already know how to train models. What you probably don&rsquo;t know is how to build a system where:</p><ul><li>A GitHub commit triggers a complete 7-step pipeline</li><li>Every preprocessing decision is backed by quantifiable metrics</li><li>Models are versioned with rich metadata, not with filenames like <code>model_final_v3_REAL.pkl</code></li><li>Deployment doesn&rsquo;t require SSH to a server to copy a pickle</li><li>Rollback from a defective version takes 30 seconds, not 3 hours of panic debugging</li></ul><p>This post dissects a real pipeline that implements all of that. It&rsquo;s not theory, it&rsquo;s code running in production. Based on Chapter 2 of &ldquo;Hands-On Machine Learning&rdquo; by Aurélien Géron, but with the infrastructure the book doesn&rsquo;t cover.</p><p><strong>Complete repository:</strong> <a href=https://github.com/carlosjimenez88M/mlops-hand-on-ML-and-pytorch/tree/cap2-end_to_end/cap2-end_to_end>github</a></p><hr><h2 id=table-of-contents>Table of Contents<a hidden class=anchor aria-hidden=true href=#table-of-contents>#</a></h2><ol><li><a href=#philosophy>The Philosophy: Why Being Organized Is More Important Than Being Smart</a></li><li><a href=#structure>Project Structure: Architecture That Scales</a></li><li><a href=#orchestration>Orchestration with Hydra + MLflow</a></li><li><a href=#step-02>Step 02: Automated Imputation - Data-Backed Decisions</a></li><li><a href=#step-03>Step 03: Feature Engineering - KMeans As Feature, Not Just Clustering</a></li><li><a href=#step-06>Step 06: Hyperparameter Sweep - Bayesian Optimization with W&amp;B</a></li><li><a href=#step-07>Step 07: Model Registry - Versioning in MLflow</a></li><li><a href=#github-actions>CI/CD with GitHub Actions: Complete Pipeline Automation</a></li><li><a href=#mlops-value-proposition>The Value of MLOps: Why This Matters</a><ul><li>W&amp;B vs MLflow: Why Both, Not One or the Other (#wandb-vs-mlflow)</li></ul></li><li><a href=#docker-mlflow>Docker and MLflow: Complete Ecosystem Containerization</a><ul><li>Pipeline Container with MLflow Tracking</li><li>API Container for Inference</li><li>Streamlit Container for Frontend</li><li>Docker Compose: Orchestration of Three Containers</li><li>API Architecture: FastAPI in Production (#api-architecture)</li></ul></li><li><a href=#model-strategies>Model and Parameter Selection Strategies</a><ul><li>Model Selection: Comparison of 5 Algorithms</li><li>Parameter Grids and GridSearch</li><li>Evaluation Metrics: MAPE, SMAPE, wMAPE</li></ul></li><li><a href=#testing>Testing: Fixtures, Mocking and Real Coverage</a></li><li><a href=#production-patterns>Production Patterns Nobody Tells You About</a><ul><li>The Transform Pattern: The Synthetic KMeans Trick</li><li>Training/Serving Skew: The Silent Killer</li><li>Data Drift: The Enemy This Project (Still) Doesn&rsquo;t Monitor</li><li>Model Monitoring: Beyond Accuracy</li><li>The Cascade Pattern: Fallback Resilience</li><li>Feature Store Anti-Pattern: When You DON&rsquo;T Need One</li><li>Production Readiness: An Honest Checklist</li></ul></li><li><a href=#conclusions>Conclusions: MLOps As Engineering Discipline</a></li></ol><hr><p><a name=philosophy></a></p><h2 id=1-the-philosophy-why-being-organized-is-more-important-than-being-smart>1. The Philosophy: Why Being Organized Is More Important Than Being Smart<a hidden class=anchor aria-hidden=true href=#1-the-philosophy-why-being-organized-is-more-important-than-being-smart>#</a></h2><h3 id=the-real-problem-of-mlops>The Real Problem of MLOps<a hidden class=anchor aria-hidden=true href=#the-real-problem-of-mlops>#</a></h3><p>Being an MLOps engineer has two important things in its work:</p><p><strong>First, and what I feel is most important: being organized.</strong> It sounds redundant, but everything must go in its place. A notebook with 50 cells executed in random order is not a pipeline—it&rsquo;s a time bomb. When that model needs to be retrained at 3 AM because data drift triggered an alert, who remembers the correct order of cells?</p><p><strong>Second: what is not tested, remains a mock or a prototype.</strong> Far from thinking about using only design patterns, the focus and what I will try to plant as a central idea of this post is <strong>the usability of products and seeing this as software design.</strong></p><h3 id=the-right-mindset>The Right Mindset<a hidden class=anchor aria-hidden=true href=#the-right-mindset>#</a></h3><p>This project treats Machine Learning as what it really is: <strong>software with probabilistic components</strong>. It&rsquo;s not magic, it&rsquo;s engineering. And as engineering, it needs:</p><ul><li><strong>Versioning:</strong> Of data, code, models and configuration</li><li><strong>Testing:</strong> Unit, integration and end-to-end</li><li><strong>Observability:</strong> Logs, metrics and traces</li><li><strong>Reproducibility:</strong> Running today and in 6 months should give the same result</li><li><strong>Deployment:</strong> Automated, not manual</li></ul><h3 id=reference-hands-on-machine-learning-by-géron>Reference: Hands-On Machine Learning by Géron<a hidden class=anchor aria-hidden=true href=#reference-hands-on-machine-learning-by-géron>#</a></h3><p>This post is based on <strong>Chapter 2 of Géron&rsquo;s book</strong>, a classic we should all read. But the book focuses on the model—how to train a good predictor. This post focuses on the <strong>system around the model</strong>—how to get that predictor into production reliably.</p><p><strong>What Géron teaches:</strong> Data imputation, feature engineering, model selection, evaluation.</p><p><strong>What this post adds:</strong> GCS for storage, W&amp;B for experimentation, MLflow for model registry, FastAPI for serving, Docker for deployment, GitHub Actions for CI/CD.</p><hr><p><a name=structure></a></p><h2 id=2-project-structure-architecture-that-scales>2. Project Structure: Architecture That Scales<a hidden class=anchor aria-hidden=true href=#2-project-structure-architecture-that-scales>#</a></h2><h3 id=the-complete-tree-200-files>The Complete Tree (200+ Files)<a hidden class=anchor aria-hidden=true href=#the-complete-tree-200-files>#</a></h3><pre tabindex=0><code>cap2-end_to_end/
├── main.py                                # Hydra + MLflow orchestrator
├── config.yaml                            # Single source of truth
├── pyproject.toml                         # Dependencies with UV
├── Makefile                               # CLI for common operations
├── Dockerfile                             # Containerized pipeline
├── docker-compose.yaml                    # API + Streamlit + MLflow
├── pytest.ini                             # Test configuration
├── .env.example                           # Secrets template
│
├── src/
│   ├── data/                              # Processing steps (01-04)
│   │   ├── 01_download_data/
│   │   │   ├── main.py                    # Download from URL → GCS
│   │   │   ├── downloader.py              # Download logic
│   │   │   ├── models.py                  # Pydantic schemas
│   │   │   ├── MLproject                  # MLflow entry point
│   │   │   └── conda.yaml                 # Isolated dependencies
│   │   │
│   │   ├── 02_preprocessing_and_imputation/
│   │   │   ├── main.py
│   │   │   ├── preprocessor.py
│   │   │   ├── imputation_analyzer.py     # (critical) Strategy comparison
│   │   │   └── utils.py
│   │   │
│   │   ├── 03_feature_engineering/
│   │   │   ├── main.py
│   │   │   ├── feature_engineer.py        # (critical) KMeans clustering
│   │   │   └── utils.py                   # Optimize n_clusters
│   │   │
│   │   └── 04_segregation/
│   │       ├── main.py
│   │       ├── segregator.py              # Train/test split
│   │       └── models.py
│   │
│   ├── model/                             # Modeling steps (05-07)
│   │   ├── 05_model_selection/
│   │   │   ├── main.py                    # Comparison of 5 algorithms
│   │   │   ├── model_selector.py          # (critical) GridSearch per model
│   │   │   └── utils.py
│   │   │
│   │   ├── 06_sweep/
│   │   │   ├── main.py                    # (critical) W&amp;B Bayesian optimization
│   │   │   ├── sweep_config.yaml          # Search space
│   │   │   └── best_params.yaml           # Output (generated)
│   │   │
│   │   └── 07_registration/
│   │       ├── main.py                    # (critical) MLflow registration
│   │       └── configs/
│   │           └── model_config.yaml      # Metadata (generated)
│   │
│   └── utils/
│       └── colored_logger.py              # Structured logging
│
├── api/                                   # FastAPI REST API
│   ├── app/
│   │   ├── main.py                        # FastAPI + lifespan
│   │   ├── core/
│   │   │   ├── config.py                  # Pydantic Settings
│   │   │   ├── model_loader.py            # Load from MLflow/GCS/Local
│   │   │   └── wandb_logger.py            # Log predictions
│   │   ├── models/
│   │   │   └── schemas.py                 # Request/Response schemas
│   │   └── routers/
│   │       └── predict.py                 # POST /api/v1/predict
│   ├── Dockerfile                         # API image (port 8080)
│   └── requirements.txt
│
├── streamlit_app/                         # Interactive frontend
│   ├── app.py                             # Streamlit application (450+ lines)
│   ├── Dockerfile                         # Streamlit image (port 8501)
│   └── requirements.txt
│
├── tests/                                 # Test suite
│   ├── conftest.py                        # Shared fixtures
│   ├── fixtures/
│   │   └── test_data_generator.py         # Synthetic data
│   ├── test_pipeline.py                   # Orchestration test
│   ├── test_downloader.py
│   ├── test_preprocessor.py
│   ├── test_imputation_analyzer.py        # (critical) Imputation tests
│   ├── test_feature_engineering.py
│   ├── test_segregation.py
│   └── test_integration_simple.py         # End-to-end
│
└── docs/
    ├── API_ARCHITECTURE_POST.md
    ├── QUICKSTART_GUIDE.md
    └── TESTING_IMPROVEMENTS.md
</code></pre><p><strong>Files marked with (critical) are the most critical</strong> to understand the architecture.</p><h3 id=fundamental-architectural-decisions>Fundamental Architectural Decisions<a hidden class=anchor aria-hidden=true href=#fundamental-architectural-decisions>#</a></h3><h4 id=1-separation-srcdata-vs-srcmodel>1. Separation <code>src/data</code> vs <code>src/model</code><a hidden class=anchor aria-hidden=true href=#1-separation-srcdata-vs-srcmodel>#</a></h4><p><strong>Why:</strong> Data steps (01-04) produce <strong>reusable</strong> artifacts—preprocessing, features, splits. Model steps (05-07) <strong>consume</strong> them but can be retrained without rerunning everything upstream.</p><p><strong>Benefit:</strong> If you change hyperparameters, you only rerun 06-07. If you change feature engineering, you rerun 03-07. You don&rsquo;t re-download data every time.</p><p><strong>Cost:</strong> More verbosity, more files. But in real pipelines with multiple data scientists, isolation is worth gold.</p><h4 id=2-mlproject--condayaml-per-step>2. MLproject + conda.yaml per Step<a hidden class=anchor aria-hidden=true href=#2-mlproject--condayaml-per-step>#</a></h4><p>Each subdirectory is an independent MLflow project:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># src/data/02_preprocessing/MLproject</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>preprocessing_and_imputation</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>conda_env</span><span class=p>:</span><span class=w> </span><span class=l>conda.yaml</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>entry_points</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span>{<span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>string}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;python main.py --gcs_input_path={gcs_input_path} --gcs_output_path={gcs_output_path}&#34;</span><span class=w>
</span></span></span></code></pre></div><p><strong>Advantages:</strong></p><ul><li>Isolated dependencies (step 03 uses scikit-learn 1.3, step 06 could use 1.4)</li><li>Independent execution: <code>mlflow run src/data/02_preprocessing</code></li><li>Granular tracking: each step is a separate run</li></ul><p><strong>Disadvantage:</strong> File overhead. But it&rsquo;s the same overhead as having microservices—each with its own Dockerfile.</p><h4 id=3-api-as-separate-project>3. <code>api/</code> As Separate Project<a hidden class=anchor aria-hidden=true href=#3-api-as-separate-project>#</a></h4><p>The API is not in <code>src/api/</code>. It&rsquo;s a sibling project with its own <code>requirements.txt</code>, Dockerfile and tests.</p><p><strong>Reason:</strong> The API is deployed <strong>independently</strong> from the pipeline. It doesn&rsquo;t need full pandas, full scikit-learn or W&amp;B client. Only FastAPI, pydantic and the model pickle.</p><p><strong>Result:</strong> Docker image of 200MB vs 1.5GB if you included the entire pipeline.</p><h4 id=4-tests-at-root>4. Tests at Root<a hidden class=anchor aria-hidden=true href=#4-tests-at-root>#</a></h4><p>Tests test the <strong>complete system</strong>, not isolated modules. <code>test_integration_simple.py</code> runs the pipeline end-to-end. It doesn&rsquo;t fit conceptually in <code>src/</code>.</p><h4 id=5-absence-of-notebooks>5. Absence of <code>notebooks/</code><a hidden class=anchor aria-hidden=true href=#5-absence-of-notebooks>#</a></h4><p><strong>Deliberate decision.</strong> Notebooks are excellent for exploration, terrible for production. This project prioritizes <strong>reproducibility</strong> over rapid iteration.</p><p>If you need to explore, use them locally but <strong>don&rsquo;t commit them</strong>. Notebooks in git are:</p><ul><li>Hard to review (incomprehensible diffs)</li><li>Impossible to test</li><li>Prone to out-of-order execution</li></ul><hr><p><a name=orchestration></a></p><h2 id=3-orchestration-with-hydra--mlflow>3. Orchestration with Hydra + MLflow<a hidden class=anchor aria-hidden=true href=#3-orchestration-with-hydra--mlflow>#</a></h2><h3 id=why-not-simple-bash-scripts>Why Not Simple Bash Scripts<a hidden class=anchor aria-hidden=true href=#why-not-simple-bash-scripts>#</a></h3><p>Running sequential Python commands works for simple pipelines:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python src/data/01_download_data/main.py
</span></span><span class=line><span class=cl>python src/data/02_preprocessing/main.py
</span></span><span class=line><span class=cl>python src/data/03_feature_engineering/main.py
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span></code></pre></div><p><strong>This approach fails when you need to:</strong></p><ul><li>Run only specific steps (debugging)</li><li>Change parameters without editing code</li><li>Version configuration alongside code</li><li>Structured logs of what ran with what params</li><li>Track dependencies between steps</li></ul><p><strong>Hydra + MLflow solves all these problems.</strong></p><h3 id=the-orchestrator-mainpy>The Orchestrator: main.py<a hidden class=anchor aria-hidden=true href=#the-orchestrator-mainpy>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>MLOps Pipeline Orchestrator
</span></span></span><span class=line><span class=cl><span class=s2>Executes steps sequentially using MLflow + Hydra
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>hydra</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>DictConfig</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>validate_environment_variables</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Fail fast if critical secrets are missing.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>required_vars</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCP_PROJECT_ID&#34;</span><span class=p>:</span> <span class=s2>&#34;Google Cloud Project ID&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;GCS_BUCKET_NAME&#34;</span><span class=p>:</span> <span class=s2>&#34;GCS Bucket name&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;WANDB_API_KEY&#34;</span><span class=p>:</span> <span class=s2>&#34;Weights &amp; Biases API Key&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>missing</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>var</span><span class=p>,</span> <span class=n>description</span> <span class=ow>in</span> <span class=n>required_vars</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>value</span> <span class=ow>or</span> <span class=n>value</span> <span class=ow>in</span> <span class=p>[</span><span class=s2>&#34;your-project-id&#34;</span><span class=p>,</span> <span class=s2>&#34;your-key&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>missing</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  ERROR: </span><span class=si>{</span><span class=n>var</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>description</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>missing</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>missing</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Create .env file with:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCP_PROJECT_ID=your-project-id&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  GCS_BUCKET_NAME=your-bucket&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  WANDB_API_KEY=your-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sys</span><span class=o>.</span><span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Converts execute_steps from config to list.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;execute_steps&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>steps</span><span class=p>,</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>s</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=n>steps</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;,&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=n>steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_step</span><span class=p>(</span><span class=n>step_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>step_path</span><span class=p>:</span> <span class=n>Path</span><span class=p>,</span> <span class=n>entry_point</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>parameters</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Executes a step as MLflow project.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;EXECUTING: </span><span class=si>{</span><span class=n>step_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>70</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>uri</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>step_path</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>entry_point</span><span class=o>=</span><span class=n>entry_point</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>env_manager</span><span class=o>=</span><span class=s2>&#34;local&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>parameters</span><span class=o>=</span><span class=n>parameters</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@hydra.main</span><span class=p>(</span><span class=n>config_path</span><span class=o>=</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=n>config_name</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>,</span> <span class=n>version_base</span><span class=o>=</span><span class=s2>&#34;1.3&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>go</span><span class=p>(</span><span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Main pipeline entry point.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>validate_environment_variables</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>set_experiment</span><span class=p>(</span><span class=n>config</span><span class=p>[</span><span class=s1>&#39;main&#39;</span><span class=p>][</span><span class=s1>&#39;experiment_name&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>steps_to_execute</span> <span class=o>=</span> <span class=n>get_steps_to_execute</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>root_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Step 01: Download Data</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;01_download_data&#34;</span> <span class=ow>in</span> <span class=n>steps_to_execute</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>run_step</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;01 - Download Data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>root_path</span> <span class=o>/</span> <span class=s2>&#34;src&#34;</span> <span class=o>/</span> <span class=s2>&#34;data&#34;</span> <span class=o>/</span> <span class=s2>&#34;01_download_data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;main&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;file_url&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;file_url&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;gcs_output_path&#34;</span><span class=p>:</span> <span class=n>config</span><span class=p>[</span><span class=s2>&#34;download_data&#34;</span><span class=p>][</span><span class=s2>&#34;gcs_output_path&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ... Steps 02-07 similar pattern ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>SUCCESS: PIPELINE COMPLETED (</span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>s)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>ERROR: PIPELINE FAILED: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>go</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=configyaml-single-source-of-truth>config.yaml: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#configyaml-single-source-of-truth>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>main</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>project_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing-mlops-gcp&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>experiment_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;end_to_end_pipeline&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>execute_steps</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;01_download_data&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;02_preprocessing_and_imputation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;03_feature_engineering&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;04_segregation&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;05_model_selection&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;06_sweep&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=s2>&#34;07_registration&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>download_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file_url</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>preprocessing</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/01-raw/housing.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>imputation_strategy</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;auto&#34;</span><span class=w>  </span><span class=c># Will compare 4 strategies</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>feature_engineering</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_clusters</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>optimize_hyperparams</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>  </span><span class=c># Find best K</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>segregation</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_input_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_output_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>test_size</span><span class=p>:</span><span class=w> </span><span class=m>0.2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>target_column</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;median_house_value&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>model_selection</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_train_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/train/train.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>gcs_test_path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;data/04-split/test/test.parquet&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>sweep_count</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>  </span><span class=c># 50 Bayesian optimization runs</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;mape&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>metric_goal</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;minimize&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>registration</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>registered_model_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;housing_price_model&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>model_stage</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Staging&#34;</span><span class=w>  </span><span class=c># Or &#34;Production&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=what-this-code-does-well>What This Code Does Well<a hidden class=anchor aria-hidden=true href=#what-this-code-does-well>#</a></h3><p><strong>1. Fail Fast with Environment Validation</strong></p><p>Before spending CPU, verify all secrets exist. The error message includes <strong>instructions</strong> on how to get each value.</p><pre tabindex=0><code>ERROR: MISSING REQUIRED ENVIRONMENT VARIABLES
===============================================
  ERROR: WANDB_API_KEY: Weights &amp; Biases API Key

Create .env file with:
  WANDB_API_KEY=your-key
</code></pre><p>This saves <strong>frustration</strong>—especially for new contributors.</p><p><strong>2. Selective Execution Without Commenting Code</strong></p><p>You change <code>config.yaml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>execute_steps</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;03_feature_engineering&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;05_model_selection&#34;</span><span class=p>]</span><span class=w>
</span></span></span></code></pre></div><p>And only those steps run. You don&rsquo;t edit Python, you don&rsquo;t comment imports.</p><p><strong>3. Separation Between Orchestration and Logic</strong></p><p><code>main.py</code> doesn&rsquo;t know how to download data or train models. It only knows how to <strong>invoke</strong> scripts that do. Each step can be developed/tested independently.</p><p><strong>4. Structured Logging with Visual Hierarchy</strong></p><p>The separators (<code>"="*70</code>) and emojis aren&rsquo;t cosmetic—in a pipeline that runs 2 hours, visual sections allow you to <strong>quickly scan</strong> to find which step failed.</p><hr><p><a name=step-02></a></p><h2 id=4-step-02-automated-imputation---data-backed-decisions>4. Step 02: Automated Imputation - Data-Backed Decisions<a hidden class=anchor aria-hidden=true href=#4-step-02-automated-imputation---data-backed-decisions>#</a></h2><h3 id=the-real-problem>The Real Problem<a hidden class=anchor aria-hidden=true href=#the-real-problem>#</a></h3><p>California Housing has ~1% of <code>total_bedrooms</code> missing. Obvious options:</p><ol><li><strong>Drop rows</strong> → lose data</li><li><strong>Fill with median</strong> → assume distribution without verification</li><li><strong>Fill with KNN</strong> → assume similarity in feature space</li><li><strong>Fill with IterativeImputer</strong> → assume modelable relationships</li></ol><p><strong>Question:</strong> Which is better?</p><p><strong>Incorrect answer:</strong> &ldquo;KNN always works&rdquo;</p><p><strong>Correct answer:</strong> &ldquo;I tested all 4, median had RMSE of 0.8, KNN of 0.6, Iterative of 0.5. I use Iterative because it minimizes reconstruction error. Here&rsquo;s the plot in W&amp;B.&rdquo;</p><h3 id=imputation_analyzerpy-the-core>imputation_analyzer.py: The Core<a hidden class=anchor aria-hidden=true href=#imputation_analyzerpy-the-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Imputation Analyzer - Automatically compares strategies
</span></span></span><span class=line><span class=cl><span class=s2>Author: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Tuple</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>mean_squared_error</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span><span class=p>,</span> <span class=n>KNNImputer</span><span class=p>,</span> <span class=n>IterativeImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestRegressor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Result of an imputation strategy.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>method_name</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>rmse</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=cl>    <span class=n>imputed_values</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
</span></span><span class=line><span class=cl>    <span class=n>imputer</span><span class=p>:</span> <span class=nb>object</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImputationAnalyzer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Analyzes and compares imputation strategies.
</span></span></span><span class=line><span class=cl><span class=s2>    Automatically selects the best based on RMSE.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>test_size</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>df</span> <span class=o>=</span> <span class=n>df</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>target_column</span> <span class=o>=</span> <span class=n>target_column</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>test_size</span> <span class=o>=</span> <span class=n>test_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>:</span> <span class=nb>object</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>prepare_validation_set</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Creates masked validation set to compare strategies.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Strategy:
</span></span></span><span class=line><span class=cl><span class=s2>        1. Remove rows with missing target (can&#39;t validate against NaN)
</span></span></span><span class=line><span class=cl><span class=s2>        2. Split into train/val
</span></span></span><span class=line><span class=cl><span class=s2>        3. Mask target in val set (simulate missing values)
</span></span></span><span class=line><span class=cl><span class=s2>        4. Save ground truth
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            (train_set, val_set_missing, y_val_true)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_numeric</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>df</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>housing_known</span> <span class=o>=</span> <span class=n>housing_numeric</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>housing_known</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>test_size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>test_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Mask target in val</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Ground truth</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>strategy</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evaluates SimpleImputer with given strategy.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=n>strategy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Simple Imputer (</span><span class=si>{</span><span class=n>strategy</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>n_neighbors</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Evaluates KNNImputer with scaling.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        CRITICAL: KNN requires scaled features or explodes with overflow.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Scale data</span>
</span></span><span class=line><span class=cl>            <span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># KNN imputation</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span> <span class=o>=</span> <span class=n>KNNImputer</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>n_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Inverse scale</span>
</span></span><span class=line><span class=cl>            <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>val_imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;KNN Imputer (k=</span><span class=si>{</span><span class=n>n_neighbors</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=p>(</span><span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span><span class=p>)</span>  <span class=c1># Store tuple!</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_set_missing</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_true</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>Series</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ImputationResult</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Evaluates IterativeImputer with RandomForest estimator.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span> <span class=o>=</span> <span class=n>IterativeImputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>estimator</span><span class=o>=</span><span class=n>estimator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>imputer</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>val_imputed</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>val_set_missing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>train_set</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>val_imputed</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_val_true</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ImputationResult</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>method_name</span><span class=o>=</span><span class=s2>&#34;Iterative Imputer (RF)&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rmse</span><span class=o>=</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputed_values</span><span class=o>=</span><span class=n>y_val_pred</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>imputer</span><span class=o>=</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compare_all_methods</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>ImputationResult</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Compares all strategies and selects the best.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>prepare_validation_set</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluate all</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_median&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;simple_mean&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_simple_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;mean&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;knn&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_knn_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span><span class=p>,</span> <span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;iterative_rf&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>evaluate_iterative_imputer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>train_set</span><span class=p>,</span> <span class=n>val_set_missing</span><span class=p>,</span> <span class=n>y_val_true</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Select best</span>
</span></span><span class=line><span class=cl>        <span class=n>best_key</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>k</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_method</span> <span class=o>=</span> <span class=n>best_key</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=p>[</span><span class=n>best_key</span><span class=p>]</span><span class=o>.</span><span class=n>imputer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Print summary</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;IMPUTATION METHODS COMPARISON&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>sorted</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>status</span> <span class=o>=</span> <span class=s2>&#34;[BEST]&#34;</span> <span class=k>if</span> <span class=n>key</span> <span class=o>==</span> <span class=n>best_key</span> <span class=k>else</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>method_name</span><span class=si>:</span><span class=s2>30s</span><span class=si>}</span><span class=s2> RMSE: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>rmse</span><span class=si>:</span><span class=s2>8.4f</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>status</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>apply_best_imputer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Applies the best imputer to the complete dataset.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;Run compare_all_methods() first&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>numeric_df</span> <span class=o>=</span> <span class=n>df_out</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s1>&#39;ignore&#39;</span><span class=p>,</span> <span class=n>category</span><span class=o>=</span><span class=ne>RuntimeWarning</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Check if it&#39;s a tuple (KNN with scaler)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>                <span class=n>numeric_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_scaled</span> <span class=o>=</span> <span class=n>imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>inverse_transform</span><span class=p>(</span><span class=n>imputed_scaled</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>imputed_array</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>numeric_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>target_col_idx</span> <span class=o>=</span> <span class=n>numeric_df</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>get_loc</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>df_out</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>imputed_array</span><span class=p>[:,</span> <span class=n>target_col_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>df_out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_comparison_plot</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Creates bar plot comparing RMSE of methods.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>methods</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>method_name</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>        <span class=n>rmses</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=o>.</span><span class=n>rmse</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>results</span><span class=o>.</span><span class=n>values</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;green&#39;</span> <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>rmses</span><span class=p>)</span> <span class=k>else</span> <span class=s1>&#39;skyblue&#39;</span>
</span></span><span class=line><span class=cl>                  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>rmses</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>        <span class=n>bars</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>methods</span><span class=p>,</span> <span class=n>rmses</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=n>colors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Imputation Method&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;RMSE&#39;</span><span class=p>,</span> <span class=n>fontweight</span><span class=o>=</span><span class=s1>&#39;bold&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Comparison of Imputation Strategies&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=s1>&#39;y&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Value labels</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>bar</span><span class=p>,</span> <span class=n>rmse</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>bars</span><span class=p>,</span> <span class=n>rmses</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>height</span> <span class=o>=</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_height</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>bar</span><span class=o>.</span><span class=n>get_x</span><span class=p>()</span> <span class=o>+</span> <span class=n>bar</span><span class=o>.</span><span class=n>get_width</span><span class=p>()</span><span class=o>/</span><span class=mf>2.</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>height</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>rmse</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>va</span><span class=o>=</span><span class=s1>&#39;bottom&#39;</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>rotation</span><span class=o>=</span><span class=mi>45</span><span class=p>,</span> <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;right&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>fig</span>
</span></span></code></pre></div><h3 id=critical-technical-decisions>Critical Technical Decisions<a hidden class=anchor aria-hidden=true href=#critical-technical-decisions>#</a></h3><h4 id=1-the-metric-reconstruction-rmse>1. The Metric: Reconstruction RMSE<a hidden class=anchor aria-hidden=true href=#1-the-metric-reconstruction-rmse>#</a></h4><p><strong>Why RMSE and not MAE?</strong></p><p>MAE treats all errors equally. RMSE penalizes large errors more strongly.</p><p>If a method imputes 100 bedrooms when the truth is 3, that&rsquo;s <strong>problematic</strong>. RMSE punishes it more than MAE. In imputation, large errors distort the dataset more than many small errors.</p><h4 id=2-the-masked-validation-set>2. The Masked Validation Set<a hidden class=anchor aria-hidden=true href=#2-the-masked-validation-set>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>train_set</span><span class=p>,</span> <span class=n>val_set</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>housing_known</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span> <span class=o>=</span> <span class=n>val_set</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>val_set_missing</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl><span class=n>y_val_true</span> <span class=o>=</span> <span class=n>val_set</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>target_column</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span></code></pre></div><p>This <strong>trick is critical</strong>. You can&rsquo;t evaluate imputation strategies on real missing values—you don&rsquo;t know the truth. So:</p><ol><li>Take rows where the target is NOT missing</li><li>Split into train/val</li><li>Artificially mask the target in val</li><li>Compare how well each imputer reconstructs the values you knew</li></ol><p>It&rsquo;s <strong>cross-validation for preprocessing</strong>, not just for models.</p><h4 id=3-why-knn-needs-scaling>3. Why KNN Needs Scaling<a hidden class=anchor aria-hidden=true href=#3-why-knn-needs-scaling>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>train_set</span><span class=p>)</span>
</span></span></code></pre></div><p>KNN calculates euclidean distances between observations. If one feature is in range [0, 1] and another in [0, 10000], <strong>the second dominates completely</strong>.</p><p>StandardScaler normalizes everything to mean 0, std 1. Now all features contribute equally.</p><p><strong>IterativeImputer with RandomForest does NOT need scaling</strong>—trees are scale-invariant.</p><h4 id=4-the-imputer-as-tuple>4. The Imputer As Tuple<a hidden class=anchor aria-hidden=true href=#4-the-imputer-as-tuple>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=p>,</span> <span class=n>imputer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_imputer</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... apply both</span>
</span></span></code></pre></div><p>If KNN won, you need to save <strong>both the scaler and the imputer</strong>. In production, when new data arrives:</p><ol><li>Scale with the same scaler fitted in training</li><li>Apply KNN imputer</li><li>Inverse transform to return to original scale</li></ol><p>Saving only the imputer without the scaler <strong>would break everything</strong>.</p><h3 id=usage-in-the-pipeline>Usage in the Pipeline<a hidden class=anchor aria-hidden=true href=#usage-in-the-pipeline>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># In Step 02 main.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>analyzer</span> <span class=o>=</span> <span class=n>ImputationAnalyzer</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>target_column</span><span class=o>=</span><span class=s2>&#34;total_bedrooms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>compare_all_methods</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log to W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>comparison_plot</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>create_comparison_plot</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/comparison&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>comparison_plot</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_method&#34;</span><span class=p>:</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;imputation/best_rmse&#34;</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_method</span><span class=p>]</span><span class=o>.</span><span class=n>rmse</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply to complete dataset</span>
</span></span><span class=line><span class=cl><span class=n>housing_clean</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>apply_best_imputer</span><span class=p>(</span><span class=n>housing_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Save imputer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>analyzer</span><span class=o>.</span><span class=n>best_imputer</span><span class=p>,</span> <span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/imputer.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=what-this-achieves>What This Achieves<a hidden class=anchor aria-hidden=true href=#what-this-achieves>#</a></h3><p><strong>Without this:</strong> &ldquo;I used median because that&rsquo;s what everyone does.&rdquo;</p><p><strong>With this:</strong> &ldquo;I compared 4 strategies. IterativeImputer with RandomForest had 15% lower RMSE than median. Here&rsquo;s the plot in W&amp;B dashboard run <code>abc123</code>. The imputer is serialized in MLflow.&rdquo;</p><p>Now you have <strong>quantifiable evidence</strong> of why you chose what you chose. Six months later, when someone asks, <strong>the data is there</strong>.</p><hr><p><a name=step-03></a></p><h2 id=5-step-03-feature-engineering---kmeans-as-feature-not-just-clustering>5. Step 03: Feature Engineering - KMeans As Feature, Not Just Clustering<a hidden class=anchor aria-hidden=true href=#5-step-03-feature-engineering---kmeans-as-feature-not-just-clustering>#</a></h2><h3 id=the-real-problem-1>The Real Problem<a hidden class=anchor aria-hidden=true href=#the-real-problem-1>#</a></h3><p>California has strong geographic patterns. Houses in San Francisco behave differently than houses in the central valley. But latitude/longitude as raw features don&rsquo;t capture this well—a linear model can&rsquo;t learn &ldquo;this area is expensive&rdquo;.</p><p><strong>Solution:</strong> Geographic clustering. But not to segment data, rather to <strong>create a categorical feature</strong>: <code>cluster_label</code>.</p><h3 id=clustersimilarity-custom-transformer>ClusterSimilarity: Custom Transformer<a hidden class=anchor aria-hidden=true href=#clustersimilarity-custom-transformer>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>KMeans</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ClusterSimilarity</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>TransformerMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Custom transformer for geographic clustering.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Design: Scikit-learn transformer to integrate into Pipeline.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span> <span class=o>=</span> <span class=n>n_clusters</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>gamma</span>  <span class=c1># Placeholder for RBF kernel (not currently used)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>random_state</span> <span class=o>=</span> <span class=n>random_state</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Fit KMeans on geographic coordinates.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>random_state</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>random_state</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>sample_weight</span><span class=o>=</span><span class=n>sample_weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Transform coordinates to cluster labels.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>cluster_labels</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>kmeans_</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>cluster_labels</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_feature_names_out</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Returns feature names for Pipeline.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=s2>&#34;cluster_label&#34;</span><span class=p>]</span>
</span></span></code></pre></div><h3 id=the-complete-preprocessing-pipeline>The Complete Preprocessing Pipeline<a hidden class=anchor aria-hidden=true href=#the-complete-preprocessing-pipeline>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.compose</span> <span class=kn>import</span> <span class=n>ColumnTransformer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.impute</span> <span class=kn>import</span> <span class=n>SimpleImputer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span><span class=p>,</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Creates pipeline that processes:
</span></span></span><span class=line><span class=cl><span class=s2>    - Numeric: impute + scale
</span></span></span><span class=line><span class=cl><span class=s2>    - Categorical: impute + one-hot
</span></span></span><span class=line><span class=cl><span class=s2>    - Geo: clustering
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;median&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;standardize&#34;</span><span class=p>,</span> <span class=n>StandardScaler</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;impute&#34;</span><span class=p>,</span> <span class=n>SimpleImputer</span><span class=p>(</span><span class=n>strategy</span><span class=o>=</span><span class=s2>&#34;most_frequent&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;onehot&#34;</span><span class=p>,</span> <span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_attribs</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;longitude&#34;</span><span class=p>,</span> <span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;housing_median_age&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;total_rooms&#34;</span><span class=p>,</span> <span class=s2>&#34;total_bedrooms&#34;</span><span class=p>,</span> <span class=s2>&#34;population&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;households&#34;</span><span class=p>,</span> <span class=s2>&#34;median_income&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cat_attribs</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;ocean_proximity&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>preprocessing</span> <span class=o>=</span> <span class=n>ColumnTransformer</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;num&#34;</span><span class=p>,</span> <span class=n>num_pipeline</span><span class=p>,</span> <span class=n>num_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;cat&#34;</span><span class=p>,</span> <span class=n>cat_pipeline</span><span class=p>,</span> <span class=n>cat_attribs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=s2>&#34;geo&#34;</span><span class=p>,</span> <span class=n>ClusterSimilarity</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>),</span>
</span></span><span class=line><span class=cl>         <span class=p>[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>preprocessing</span>
</span></span></code></pre></div><h3 id=automatic-optimization-of-n_clusters>Automatic Optimization of n_clusters<a hidden class=anchor aria-hidden=true href=#automatic-optimization-of-n_clusters>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>silhouette_score</span><span class=p>,</span> <span class=n>davies_bouldin_score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>optimize_n_clusters</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_clusters</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_clusters</span><span class=o>=</span><span class=mi>20</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=n>Dict</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Finds the best K for KMeans using silhouette score.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Metrics:
</span></span></span><span class=line><span class=cl><span class=s2>    - Silhouette score (0 to 1): Cluster separation. Maximize.
</span></span></span><span class=line><span class=cl><span class=s2>    - Davies-Bouldin index: Internal dispersion vs separation. Minimize.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>geo_features</span> <span class=o>=</span> <span class=n>df</span><span class=p>[[</span><span class=s2>&#34;latitude&#34;</span><span class=p>,</span> <span class=s2>&#34;longitude&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cluster_range</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=n>min_clusters</span><span class=p>,</span> <span class=n>max_clusters</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>silhouette_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>davies_bouldin_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>inertias</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>cluster_range</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>geo_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>silhouette_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>silhouette_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>davies_bouldin_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>davies_bouldin_score</span><span class=p>(</span><span class=n>geo_features</span><span class=p>,</span> <span class=n>labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>inertias</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Select K with best silhouette</span>
</span></span><span class=line><span class=cl>    <span class=n>optimal_n</span> <span class=o>=</span> <span class=n>cluster_range</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>:</span> <span class=n>optimal_n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_silhouette&#34;</span><span class=p>:</span> <span class=nb>max</span><span class=p>(</span><span class=n>silhouette_scores</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;cluster_range&#34;</span><span class=p>:</span> <span class=nb>list</span><span class=p>(</span><span class=n>cluster_range</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>silhouette_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;davies_bouldin_scores&#34;</span><span class=p>:</span> <span class=n>davies_bouldin_scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;inertias&#34;</span><span class=p>:</span> <span class=n>inertias</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>optimal_n</span><span class=p>,</span> <span class=n>metrics</span>
</span></span></code></pre></div><h3 id=visualization-elbow-method--silhouette>Visualization: Elbow Method + Silhouette<a hidden class=anchor aria-hidden=true href=#visualization-elbow-method--silhouette>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>plt</span><span class=o>.</span><span class=n>Figure</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Creates K optimization plots.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 1: Elbow Method (Inertia)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig1</span><span class=p>,</span> <span class=n>ax1</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;inertias&#34;</span><span class=p>],</span> <span class=s1>&#39;bo-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal K=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Inertia&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Elbow Method - KMeans Optimization&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>ax1</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Plot 2: Silhouette Score</span>
</span></span><span class=line><span class=cl>    <span class=n>fig2</span><span class=p>,</span> <span class=n>ax2</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;cluster_range&#34;</span><span class=p>],</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>],</span> <span class=s1>&#39;go-&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;optimal_n_clusters&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Clusters (K)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Silhouette Score&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Silhouette Score vs K&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax2</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>:</span> <span class=n>fig1</span><span class=p>,</span> <span class=s2>&#34;silhouette_scores&#34;</span><span class=p>:</span> <span class=n>fig2</span><span class=p>}</span>
</span></span></code></pre></div><h3 id=usage-in-the-pipeline-1>Usage in the Pipeline<a hidden class=anchor aria-hidden=true href=#usage-in-the-pipeline-1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># In Step 03 main.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Download data from GCS</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>download_from_gcs</span><span class=p>(</span><span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/02-processed/housing_processed.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Optimize K</span>
</span></span><span class=line><span class=cl><span class=n>optimal_k</span><span class=p>,</span> <span class=n>metrics</span> <span class=o>=</span> <span class=n>optimize_n_clusters</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>min_clusters</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>max_clusters</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Optimal K: </span><span class=si>{</span><span class=n>optimal_k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   Silhouette: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;best_silhouette&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create plots</span>
</span></span><span class=line><span class=cl><span class=n>plots</span> <span class=o>=</span> <span class=n>create_optimization_plots</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Log to W&amp;B</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/optimal_k&#34;</span><span class=p>:</span> <span class=n>optimal_k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s2>&#34;best_silhouette&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/elbow_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;elbow_method&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;optimization/silhouette_plot&#34;</span><span class=p>:</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Image</span><span class=p>(</span><span class=n>plots</span><span class=p>[</span><span class=s2>&#34;silhouette_scores&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create pipeline with optimal K</span>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>optimal_k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit pipeline</span>
</span></span><span class=line><span class=cl><span class=n>target_column</span> <span class=o>=</span> <span class=s2>&#34;median_house_value&#34;</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=n>target_column</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform data</span>
</span></span><span class=line><span class=cl><span class=n>X_transformed</span> <span class=o>=</span> <span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Reconstruct DataFrame with target</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>X_transformed</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>columns</span><span class=o>=</span><span class=n>preprocessing_pipeline</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_transformed</span><span class=p>[</span><span class=n>target_column</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Upload to GCS</span>
</span></span><span class=line><span class=cl><span class=n>upload_to_gcs</span><span class=p>(</span><span class=n>df_transformed</span><span class=p>,</span> <span class=n>bucket</span><span class=p>,</span> <span class=s2>&#34;data/03-features/housing_features.parquet&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Save pipeline</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=critical-technical-decisions-1>Critical Technical Decisions<a hidden class=anchor aria-hidden=true href=#critical-technical-decisions-1>#</a></h3><h4 id=1-why-silhouette-score>1. Why Silhouette Score<a hidden class=anchor aria-hidden=true href=#1-why-silhouette-score>#</a></h4><p><strong>Silhouette score</strong> (range 0 to 1) measures how well separated the clusters are:</p><ul><li><strong>1.0:</strong> Perfectly separated clusters</li><li><strong>0.5:</strong> Moderate overlap</li><li><strong>0.0:</strong> Random clusters</li></ul><p>It&rsquo;s <strong>interpretable</strong> and generally correlates well with visual quality of clusters.</p><p><strong>Davies-Bouldin index:</strong> We also calculate it but don&rsquo;t use it for decision—it&rsquo;s more sensitive to outliers.</p><h4 id=2-the-obvious-criticism>2. The Obvious Criticism<a hidden class=anchor aria-hidden=true href=#2-the-obvious-criticism>#</a></h4><p>This code optimizes <code>n_clusters</code> based on <strong>clustering metrics</strong>, not on <strong>final model performance</strong>.</p><p>A more rigorous approach would be:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>create_preprocessing_pipeline</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test_transformed</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestRegressor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_transformed</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mape</span> <span class=o>=</span> <span class=n>calculate_mape</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_test_transformed</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Select K with best MAPE</span>
</span></span></code></pre></div><p>This would take <strong>10x more time</strong> but would be more rigorous.</p><p><strong>Trade-off:</strong> This pipeline prioritizes speed over absolute rigor. For California Housing, silhouette score is good enough. For more complex datasets, consider the full cross-validation approach.</p><h4 id=3-handle_unknownignore-in-onehotencoder>3. handle_unknown=&ldquo;ignore&rdquo; in OneHotEncoder<a hidden class=anchor aria-hidden=true href=#3-handle_unknownignore-in-onehotencoder>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>OneHotEncoder</span><span class=p>(</span><span class=n>handle_unknown</span><span class=o>=</span><span class=s2>&#34;ignore&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>Critical for production.</strong> If in training you have categories <code>["&lt;1H OCEAN", "INLAND", "NEAR BAY"]</code> but in production <code>"ISLAND"</code> arrives (which you didn&rsquo;t see), the encoder:</p><ul><li><strong>Without <code>handle_unknown</code>:</strong> Explodes with ValueError</li><li><strong>With <code>handle_unknown="ignore"</code>:</strong> Generates zero vector for that observation</li></ul><p>You lose information for that observation, but the <strong>API doesn&rsquo;t return HTTP 500</strong>.</p><h4 id=4-why-save-the-pipeline-not-just-the-model>4. Why Save the Pipeline, Not Just the Model<a hidden class=anchor aria-hidden=true href=#4-why-save-the-pipeline-not-just-the-model>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>preprocessing_pipeline</span><span class=p>,</span> <span class=s2>&#34;artifacts/preprocessing_pipeline.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>In production, you need to:</p><ol><li>Load the pipeline</li><li>Transform new data</li><li>Predict with the model</li></ol><p>If you only save the model, you don&rsquo;t know:</p><ul><li>What features it expects</li><li>In what order</li><li>What transformations to apply</li></ul><p>The pipeline <strong>encapsulates all that</strong>.</p><h3 id=what-this-achieves-1>What This Achieves<a hidden class=anchor aria-hidden=true href=#what-this-achieves-1>#</a></h3><p><strong>Without this:</strong> &ldquo;I used KMeans with K=10 because I read that 10 clusters is good.&rdquo;</p><p><strong>With this:</strong> &ldquo;I tested K from 5 to 15. K=8 maximized silhouette score (0.64). Here are the elbow method and silhouette plots. The pipeline with K=8 is serialized in MLflow.&rdquo;</p><p><strong>Quantifiable evidence + reproducible artifact.</strong></p><hr><p><a name=step-06></a></p><h2 id=6-step-06-hyperparameter-sweep---bayesian-optimization-with-wb>6. Step 06: Hyperparameter Sweep - Bayesian Optimization with W&amp;B<a hidden class=anchor aria-hidden=true href=#6-step-06-hyperparameter-sweep---bayesian-optimization-with-wb>#</a></h2><h3 id=the-problem-of-model-selection-vs-hyperparameter-tuning>The Problem of Model Selection vs Hyperparameter Tuning<a hidden class=anchor aria-hidden=true href=#the-problem-of-model-selection-vs-hyperparameter-tuning>#</a></h3><p>Most ML projects make this mistake: they train a Random Forest in a notebook, adjust some hyperparameters until R² looks &ldquo;good&rdquo; and declare victory. Three months later, when someone asks &ldquo;why Random Forest and not XGBoost?&rdquo;, the answer is awkward silence.</p><p><strong>This pipeline separates two phases:</strong></p><ol><li><strong>Model Selection (Step 05):</strong> Compares algorithms with fast GridSearch (5-10 combos per model)</li><li><strong>Hyperparameter Sweep (Step 06):</strong> Optimizes the winner with exhaustive Bayesian search (50+ runs)</li></ol><p><strong>Reason:</strong> You don&rsquo;t have time or compute to do exhaustive sweep of 5 algorithms. First you decide <strong>strategy</strong> (which algorithm), then <strong>tactics</strong> (which hyperparameters).</p><h3 id=sweep_configyaml-the-search-space>sweep_config.yaml: The Search Space<a hidden class=anchor aria-hidden=true href=#sweep_configyaml-the-search-space>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># W&amp;B Sweep Configuration for Random Forest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Author: Carlos Daniel Jiménez</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># =================================================================</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>program</span><span class=p>:</span><span class=w> </span><span class=l>main.py</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># Bayesian optimization, not random, not grid</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE (less biased than MAPE)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>goal</span><span class=p>:</span><span class=w> </span><span class=l>minimize</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>50</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>30</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>20</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>min</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>max</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>values</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s1>&#39;sqrt&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;log2&#39;</span><span class=p>]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c># Early stopping: eliminates poor runs early</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>   </span><span class=c># Minimum 10 runs before terminating</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>         </span><span class=c># Eliminates 1/3 of poor runs</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>s</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>housing-rf-sweep-improved</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Optimize Random Forest with wmape + feature tracking&#34;</span><span class=w>
</span></span></span></code></pre></div><h3 id=mainpy-from-step-06-the-real-sweep>main.py from Step 06: The Real Sweep<a hidden class=anchor aria-hidden=true href=#mainpy-from-step-06-the-real-sweep>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>W&amp;B Sweep for Random Forest Hyperparameter Optimization.
</span></span></span><span class=line><span class=cl><span class=s2>Author: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>yaml</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>utils</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>download_data_from_gcs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prepare_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_random_forest</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluate_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>log_feature_importances</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Module-level data cache (loaded once, reused in all runs)</span>
</span></span><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;y_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;feature_names&#34;</span><span class=p>:</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Training function called by W&amp;B Sweep agent.
</span></span></span><span class=line><span class=cl><span class=s2>    Executed for each hyperparameter combination.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Uses module-level cache to avoid reloading data on each run.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>run</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>init</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SWEEP RUN: </span><span class=si>{</span><span class=n>run</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Prepare parameters</span>
</span></span><span class=line><span class=cl>        <span class=n>params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;n_estimators&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>n_estimators</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>max_depth</span><span class=p>)</span> <span class=k>if</span> <span class=n>config</span><span class=o>.</span><span class=n>max_depth</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_split</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>min_samples_leaf</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;max_features&#39;</span><span class=p>:</span> <span class=n>config</span><span class=o>.</span><span class=n>max_features</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;random_state&#39;</span><span class=p>:</span> <span class=mi>42</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Train model using cached data</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>train_random_forest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>params</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Evaluate model</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span> <span class=o>=</span> <span class=n>evaluate_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log feature importances</span>
</span></span><span class=line><span class=cl>        <span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Log everything to W&amp;B</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>               <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;SUCCESS: MAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>% | &#34;</span>
</span></span><span class=line><span class=cl>                   <span class=sa>f</span><span class=s2>&#34;WMAPE=</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;wmape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;ERROR: Run failed: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=mf>999.9</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=mf>999.9</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>run</span><span class=o>.</span><span class=n>finish</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Main function to initialize and run the sweep.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_train_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--gcs_test_path&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--bucket_name&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--wandb_project&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--target_column&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;median_house_value&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_count&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--sweep_config&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;sweep_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;W&amp;B SWEEP - HYPERPARAMETER OPTIMIZATION&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Load data ONCE into module-level cache</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Loading data into cache...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>train_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_train_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>train_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_df</span> <span class=o>=</span> <span class=n>download_data_from_gcs</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>bucket_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>gcs_test_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>prepare_data</span><span class=p>(</span><span class=n>test_df</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>target_column</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Store in cache</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;X_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_train&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_train</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;y_test&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_test</span>
</span></span><span class=line><span class=cl>    <span class=n>_data_cache</span><span class=p>[</span><span class=s2>&#34;feature_names&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_train</span><span class=o>.</span><span class=n>columns</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Data cached: Train </span><span class=si>{</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, Test </span><span class=si>{</span><span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Load sweep configuration</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=n>args</span><span class=o>.</span><span class=n>sweep_config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>sweep_config_path</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_config</span> <span class=o>=</span> <span class=n>yaml</span><span class=o>.</span><span class=n>safe_load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep config:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Method: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;method&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Metric: </span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>sweep_config</span><span class=p>[</span><span class=s1>&#39;metric&#39;</span><span class=p>][</span><span class=s1>&#39;goal&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize sweep</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep_id</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep</span><span class=o>=</span><span class=n>sweep_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Sweep created: </span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  View at: https://wandb.ai/</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/sweeps/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Run sweep agent</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Starting sweep agent (</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=si>}</span><span class=s2> runs)...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>wandb</span><span class=o>.</span><span class=n>agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>function</span><span class=o>=</span><span class=n>train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>count</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>sweep_count</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>project</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span> <span class=o>+</span> <span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;SWEEP COMPLETED&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Save best params</span>
</span></span><span class=line><span class=cl>    <span class=n>api</span> <span class=o>=</span> <span class=n>wandb</span><span class=o>.</span><span class=n>Api</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>sweep</span> <span class=o>=</span> <span class=n>api</span><span class=o>.</span><span class=n>sweep</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>sweep_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>best_run</span> <span class=o>=</span> <span class=n>sweep</span><span class=o>.</span><span class=n>best_run</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;hyperparameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_depth&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>))</span> <span class=k>if</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>)</span> <span class=k>else</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_split&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=nb>int</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_features&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;metrics&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;mape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;wmape&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;wmape&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>best_run</span><span class=o>.</span><span class=n>summary</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;r2&#39;</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;sweep_id&#34;</span><span class=p>:</span> <span class=n>sweep_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;best_run_id&#34;</span><span class=p>:</span> <span class=n>best_run</span><span class=o>.</span><span class=n>id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Save to YAML</span>
</span></span><span class=line><span class=cl>    <span class=n>best_params_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)</span><span class=o>.</span><span class=n>parent</span> <span class=o>/</span> <span class=s2>&#34;best_params.yaml&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>best_params_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>best_params</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Best params saved to: </span><span class=si>{</span><span class=n>best_params_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;   MAPE: </span><span class=si>{</span><span class=n>best_params</span><span class=p>[</span><span class=s1>&#39;metrics&#39;</span><span class=p>][</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=critical-technical-decisions-2>Critical Technical Decisions<a hidden class=anchor aria-hidden=true href=#critical-technical-decisions-2>#</a></h3><h4 id=1-bayesian-optimization-not-random-search>1. Bayesian Optimization, Not Random Search<a hidden class=anchor aria-hidden=true href=#1-bayesian-optimization-not-random-search>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>method</span><span class=p>:</span><span class=w> </span><span class=l>bayes </span><span class=w> </span><span class=c># Not random, not grid</span><span class=w>
</span></span></span></code></pre></div><p><strong>Random search:</strong> Tests random combinations. Doesn&rsquo;t learn from previous runs.</p><p><strong>Grid search:</strong> Tests all combinations. Exhaustive but <strong>expensive</strong> (5 × 4 × 3 × 3 × 2 = 360 combos).</p><p><strong>Bayesian optimization:</strong> Builds a probabilistic model of the function you&rsquo;re optimizing (MAPE as a function of hyperparameters) and uses that model to decide what to test next.</p><p>If it detects that <code>max_depth=None</code> consistently gives better MAPE, <strong>it explores more in that region</strong> of the space.</p><p><strong>50 runs is &lt;15% of the total space</strong>, but captures 80% of the possible benefit.</p><h4 id=2-wmape-not-mape>2. wMAPE, Not MAPE<a hidden class=anchor aria-hidden=true href=#2-wmape-not-mape>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>metric</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>wmape </span><span class=w> </span><span class=c># Weighted MAPE</span><span class=w>
</span></span></span></code></pre></div><p><strong>Standard MAPE:</strong> Penalizes errors on cheap houses more than on expensive houses.</p><p>If a house is worth $10,000 and you predict $12,000, error = 20%.
If a house is worth $500,000 and you predict $510,000, error = 2%.</p><p>Both errors are <strong>$10,000</strong>, but MAPE sees them radically different.</p><p><strong>wMAPE (Weighted MAPE):</strong> Weights by actual value. Less biased toward low values.</p><p><strong>Why it works here:</strong> California Housing doesn&rsquo;t have $0 houses. Range is between $15k and $500k—reasonably bounded.</p><h4 id=3-global-variables-for-data-cache>3. Global Variables For Data Cache<a hidden class=anchor aria-hidden=true href=#3-global-variables-for-data-cache>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>_data_cache</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_train&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;X_test&#34;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Global variables are generally dirty code. <strong>Here they&rsquo;re the right decision.</strong></p><p>Each sweep run needs the same data. Without cache, you&rsquo;d load from GCS <strong>50 times</strong>. With California Housing (20k rows), that&rsquo;s wasted seconds. With larger datasets, it&rsquo;s <strong>minutes or hours</strong>.</p><p><strong>&ldquo;Clean&rdquo; alternative:</strong> Pass data as argument to each function. But W&amp;B Sweeps has a fixed interface—the function you pass to <code>wandb.agent()</code> can&rsquo;t receive additional arguments.</p><p>Global variables here have <strong>limited scope</strong>—they only exist during the sweep process.</p><h4 id=4-early-stopping-with-hyperband>4. Early Stopping with Hyperband<a hidden class=anchor aria-hidden=true href=#4-early-stopping-with-hyperband>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>early_terminate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>hyperband</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_iter</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>eta</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>
</span></span></span></code></pre></div><p><strong>Hyperband</strong> eliminates poor runs early. If after 10 runs a set of hyperparameters shows MAPE of 25% while others are at 8%, Hyperband <strong>stops it</strong>.</p><p><strong>eta=3:</strong> Eliminates the worst third of runs in each iteration.</p><p><strong>Benefit:</strong> You save compute on obviously bad hyperparameters.</p><h4 id=5-logged-feature-importances>5. Logged Feature Importances<a hidden class=anchor aria-hidden=true href=#5-logged-feature-importances>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>feature_importances</span> <span class=o>=</span> <span class=n>log_feature_importances</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>feature_names</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&#34;feature_importance_</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>:</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>       <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=nb>list</span><span class=p>(</span><span class=n>feature_importances</span><span class=o>.</span><span class=n>items</span><span class=p>())[:</span><span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><p>Random Forest calculates feature importances <strong>for free</strong>. It would be valuable to log it to understand which features dominate the model.</p><p>In W&amp;B dashboard, you can compare runs and see &ldquo;in the best run, <code>median_income</code> had importance of 0.45&rdquo;.</p><h3 id=the-critical-output-best_paramsyaml>The Critical Output: best_params.yaml<a hidden class=anchor aria-hidden=true href=#the-critical-output-best_paramsyaml>#</a></h3><p><strong>Note:</strong> Below are the <strong>real values</strong> from the actual production sweep, not example values:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>sweep_id</span><span class=p>:</span><span class=w> </span><span class=l>f73ao31m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>best_run_id</span><span class=p>:</span><span class=w> </span><span class=l>5q1840qa</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>best_run_name</span><span class=p>:</span><span class=w> </span><span class=l>dry-sweep-5</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>hyperparameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>n_estimators</span><span class=p>:</span><span class=w> </span><span class=m>128</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_depth</span><span class=p>:</span><span class=w> </span><span class=m>23</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_split</span><span class=p>:</span><span class=w> </span><span class=m>9</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>min_samples_leaf</span><span class=p>:</span><span class=w> </span><span class=m>9</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>max_features</span><span class=p>:</span><span class=w> </span><span class=l>log2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>random_state</span><span class=p>:</span><span class=w> </span><span class=m>42</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c># Primary metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mae</span><span class=p>:</span><span class=w> </span><span class=m>38901.45</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>rmse</span><span class=p>:</span><span class=w> </span><span class=m>53277.02</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>r2</span><span class=p>:</span><span class=w> </span><span class=m>0.78339</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c># Percentage error metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>mape</span><span class=p>:</span><span class=w> </span><span class=m>20.4002</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>smape</span><span class=p>:</span><span class=w> </span><span class=m>18.85</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>wmape</span><span class=p>:</span><span class=w> </span><span class=m>19.12</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>median_ape</span><span class=p>:</span><span class=w> </span><span class=m>16.73</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=c># Accuracy within thresholds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>within_5pct</span><span class=p>:</span><span class=w> </span><span class=m>12.4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>within_10pct</span><span class=p>:</span><span class=w> </span><span class=m>36.2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>within_15pct</span><span class=p>:</span><span class=w> </span><span class=m>52.8</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>sweep_url</span><span class=p>:</span><span class=w> </span><span class=l>https://wandb.ai/danieljimenez88m-carlosdanieljimenez-com/housing-mlops-gcp/sweeps/f73ao31m</span><span class=w>
</span></span></span></code></pre></div><p><strong>Key insights from these real metrics:</strong></p><ul><li><strong>MAPE of 20.4%</strong> indicates the model predicts prices within ±20% on average</li><li><strong>36.2% of predictions are within 10%</strong> - acceptable for real estate valuation</li><li><strong>R² of 0.78</strong> means the model explains 78% of variance in house prices</li><li>The optimal configuration found by Bayesian optimization used:<ul><li>Moderate tree depth (<code>max_depth=23</code>) to balance bias/variance</li><li>Higher leaf requirements (<code>min_samples_leaf=9</code>) to prevent overfitting</li><li><code>log2</code> feature sampling for better generalization than <code>sqrt</code></li></ul></li></ul><p>Optimal hyperparameters are saved in <strong>YAML</strong>, not pickle. Reason:</p><p><strong>YAML is readable and git-friendly.</strong> If in the next retraining you change from <code>n_estimators=128</code> to <code>n_estimators=150</code>, a <code>git diff</code> shows it clearly.</p><p>With pickle, it&rsquo;s an <strong>opaque binary blob</strong>.</p><h3 id=what-this-achieves-2>What This Achieves<a hidden class=anchor aria-hidden=true href=#what-this-achieves-2>#</a></h3><p><strong>Without this:</strong> &ldquo;I used <code>n_estimators=100</code> because it&rsquo;s scikit-learn&rsquo;s default.&rdquo;</p><p><strong>With this:</strong> &ldquo;I ran Bayesian sweep of 50 runs. Optimal config: <code>n_estimators=128, max_depth=23, max_features=log2</code>. Final MAPE: 20.4% with 36.2% of predictions within 10%. Here&rsquo;s the sweep in W&amp;B: <a href=https://wandb.ai/danieljimenez88m-carlosdanieljimenez-com/housing-mlops-gcp/sweeps/f73ao31m>f73ao31m</a>.&rdquo;</p><p><strong>Quantifiable evidence</strong> of why you chose each hyperparameter.</p><hr><p><a name=step-07></a></p><h2 id=7-step-07-model-registry---versioning-in-mlflow>7. Step 07: Model Registry - Versioning in MLflow<a hidden class=anchor aria-hidden=true href=#7-step-07-model-registry---versioning-in-mlflow>#</a></h2><h3 id=why-just-saving-the-pickle-isnt-enough>Why Just Saving the Pickle Isn&rsquo;t Enough<a hidden class=anchor aria-hidden=true href=#why-just-saving-the-pickle-isnt-enough>#</a></h3><p>The temptation is:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>joblib</span>
</span></span><span class=line><span class=cl><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;best_model.pkl&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>This works until you need to answer:</p><ul><li>What hyperparameters did it use?</li><li>What data was it trained on?</li><li>What metrics did it achieve?</li><li>How do I rollback to the previous version?</li></ul><p><strong>MLflow Model Registry</strong> solves this.</p><h3 id=register_model_to_mlflow-the-core>register_model_to_mlflow(): The Core<a hidden class=anchor aria-hidden=true href=#register_model_to_mlflow-the-core>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>Model registration in MLflow Model Registry.
</span></span></span><span class=line><span class=cl><span class=s2>Author: Carlos Daniel Jiménez
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>mlflow.sklearn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>mlflow.tracking</span> <span class=kn>import</span> <span class=n>MlflowClient</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>register_model_to_mlflow</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model_stage</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_columns</span><span class=p>:</span> <span class=nb>list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>target_column</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_train_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>gcs_test_path</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>tuple</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Registers model in MLflow Model Registry with rich metadata.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: Trained sklearn model
</span></span></span><span class=line><span class=cl><span class=s2>        model_name: Name for registered model
</span></span></span><span class=line><span class=cl><span class=s2>        model_stage: Stage (Staging/Production)
</span></span></span><span class=line><span class=cl><span class=s2>        params: Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>        metrics: Evaluation metrics
</span></span></span><span class=line><span class=cl><span class=s2>        feature_columns: List of features
</span></span></span><span class=line><span class=cl><span class=s2>        target_column: Target column name
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_train_path: Path to training data
</span></span></span><span class=line><span class=cl><span class=s2>        gcs_test_path: Path to test data
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        (model_uri, model_version, run_id)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;REGISTERING MODEL TO MLFLOW&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>run_id</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>active_run</span><span class=p>()</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;runs:/</span><span class=si>{</span><span class=n>run_id</span><span class=si>}</span><span class=s2>/model&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Log model to MLflow</span>
</span></span><span class=line><span class=cl>    <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model logged: </span><span class=si>{</span><span class=n>model_uri</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create or get registered model</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>create_registered_model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Housing price prediction - Random Forest&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Created new registered model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;already exists&#34;</span> <span class=ow>in</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model already exists: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create model version</span>
</span></span><span class=line><span class=cl>    <span class=n>model_version</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>run_id</span><span class=o>=</span><span class=n>run_id</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Version created: </span><span class=si>{</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Transition to stage</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stage</span><span class=o>=</span><span class=n>model_stage</span>  <span class=c1># &#34;Staging&#34; or &#34;Production&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Transitioned to: </span><span class=si>{</span><span class=n>model_stage</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Create comprehensive description (MARKDOWN)</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest Regressor
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_depth: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_depth&#39;</span><span class=p>,</span> <span class=s1>&#39;None&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_split: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_split&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- min_samples_leaf: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- max_features: </span><span class=si>{</span><span class=n>params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;max_features&#39;</span><span class=p>,</span> <span class=s1>&#39;sqrt&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Median APE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;median_ape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- Within 10%: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>- RMSE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- R²: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Features
</span></span></span><span class=line><span class=cl><span class=s2>- Number of features: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Target: </span><span class=si>{</span><span class=n>target_column</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Data Sources
</span></span></span><span class=line><span class=cl><span class=s2>- Training: </span><span class=si>{</span><span class=n>gcs_train_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>- Testing: </span><span class=si>{</span><span class=n>gcs_test_path</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>update_model_version</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=n>description</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Add searchable tags</span>
</span></span><span class=line><span class=cl>    <span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;framework&#34;</span><span class=p>:</span> <span class=s2>&#34;sklearn&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;within_10pct&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;within_10pct&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;rmse&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;rmse&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_features&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_columns</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;target&#34;</span><span class=p>:</span> <span class=n>target_column</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>key</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Tags added to model version&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;=&#34;</span><span class=o>*</span><span class=mi>70</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>model_uri</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>run_id</span>
</span></span></code></pre></div><h3 id=critical-technical-decisions-3>Critical Technical Decisions<a hidden class=anchor aria-hidden=true href=#critical-technical-decisions-3>#</a></h3><h4 id=1-artifact-vs-registered-model>1. Artifact vs Registered Model<a hidden class=anchor aria-hidden=true href=#1-artifact-vs-registered-model>#</a></h4><p><strong>Artifact:</strong> Pickle saved in a specific run. To use it, you need the <code>run_id</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>  <span class=c1># Only artifact</span>
</span></span><span class=line><span class=cl><span class=c1># Usage: mlflow.sklearn.load_model(f&#34;runs://{run_id}/model&#34;)</span>
</span></span></code></pre></div><p><strong>Registered Model:</strong> Versioned with semantic name, stages and metadata.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>client</span><span class=o>.</span><span class=n>create_model_version</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;housing_price_model&#34;</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=n>model_uri</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Usage: mlflow.pyfunc.load_model(&#34;models:/housing_price_model/Production&#34;)</span>
</span></span></code></pre></div><p>In production, your API loads <code>models:/housing_price_model/Production</code>, <strong>not <code>runs:/abc123/model</code></strong>.</p><p>When you register a new version, you transition it to Production and the deployment <strong>automatically</strong> takes the new version.</p><h4 id=2-rich-metadata-in-markdown>2. Rich Metadata in Markdown<a hidden class=anchor aria-hidden=true href=#2-rich-metadata-in-markdown>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>description</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2># Housing Price Prediction Model
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>**Algorithm:** Random Forest
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Hyperparameters
</span></span></span><span class=line><span class=cl><span class=s2>- n_estimators: </span><span class=si>{</span><span class=n>params</span><span class=p>[</span><span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>## Performance Metrics
</span></span></span><span class=line><span class=cl><span class=s2>- MAPE: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%
</span></span></span><span class=line><span class=cl><span class=s2>...
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span></code></pre></div><p>This saves <strong>markdown in the model description</strong>. When you open MLflow UI and navigate to <code>housing_price_model v3</code>, you see:</p><ul><li>What hyperparameters it used</li><li>What metrics it achieved</li><li>Where the data came from</li></ul><p><strong>Why it&rsquo;s gold:</strong> Six months later, when someone asks &ldquo;why does model v3 have better MAPE than v2?&rdquo;, you open MLflow and <strong>the answer is there</strong>.</p><p>You don&rsquo;t need to search in logs or ask who trained it.</p><h4 id=3-tags-for-search>3. Tags For Search<a hidden class=anchor aria-hidden=true href=#3-tags-for-search>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tags</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;algorithm&#34;</span><span class=p>:</span> <span class=s2>&#34;RandomForest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;mape&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mape&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;r2&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;r2&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>tags</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span><span class=o>.</span><span class=n>set_model_version_tag</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>model_version</span><span class=o>.</span><span class=n>version</span><span class=p>,</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span>
</span></span></code></pre></div><p>In MLflow you can <strong>filter models by tags</strong>. &ldquo;Show me all models with MAPE &lt; 8%&rdquo; is a query that works if you tagged consistently.</p><h4 id=4-model-config-file-single-source-of-truth>4. Model Config File: Single Source of Truth<a hidden class=anchor aria-hidden=true href=#4-model-config-file-single-source-of-truth>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>model_version</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;stage&#39;</span><span class=p>:</span> <span class=n>model_stage</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;parameters&#39;</span><span class=p>:</span> <span class=n>params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;feature_columns&#39;</span><span class=p>:</span> <span class=n>feature_columns</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;mlflow_run_id&#39;</span><span class=p>:</span> <span class=n>run_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;sweep_id&#39;</span><span class=p>:</span> <span class=n>sweep_id</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>config_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;configs/model_config.yaml&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>config_path</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>yaml</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>model_config</span><span class=p>,</span> <span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>config_path</span><span class=p>),</span> <span class=n>artifact_path</span><span class=o>=</span><span class=s2>&#34;config&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>This YAML is logged to MLflow <strong>AND</strong> saved in the repo (in <code>configs/model_config.yaml</code>).</p><p><strong>Why YAML and not just MLflow:</strong> Your FastAPI app needs to read configuration at startup. It can do <code>mlflow.load_model()</code> for the pickle, but needs to know the <strong>feature names</strong> for input validation.</p><p>The YAML is that <strong>single source of truth</strong>.</p><h4 id=5-versioning-in-git>5. Versioning in Git<a hidden class=anchor aria-hidden=true href=#5-versioning-in-git>#</a></h4><p>When you commit <code>model_config.yaml</code>, the diff shows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-diff data-lang=diff><span class=line><span class=cl><span class=gd>- version: 2
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ version: 3
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- mape: 22.1
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ mape: 20.4
</span></span></span><span class=line><span class=cl><span class=gi></span><span class=gd>- n_estimators: 100
</span></span></span><span class=line><span class=cl><span class=gd></span><span class=gi>+ n_estimators: 128
</span></span></span><span class=line><span class=cl><span class=gi>+ max_features: log2
</span></span></span></code></pre></div><p>It&rsquo;s <strong>auditable</strong>. You know exactly what changed between versions.</p><h3 id=the-complete-flow-sweep--registration--production>The Complete Flow: Sweep → Registration → Production<a hidden class=anchor aria-hidden=true href=#the-complete-flow-sweep--registration--production>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. Model Selection (Step 05)</span>
</span></span><span class=line><span class=cl>python src/model/05_model_selection/main.py
</span></span><span class=line><span class=cl><span class=c1># Output: &#34;Best: RandomForestRegressor (MAPE: 8.2%)&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Hyperparameter Sweep (Step 06)</span>
</span></span><span class=line><span class=cl>python src/model/06_sweep/main.py --sweep_count<span class=o>=</span><span class=m>50</span>
</span></span><span class=line><span class=cl><span class=c1># Output: best_params.yaml with optimal hyperparameters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Model Registration (Step 07)</span>
</span></span><span class=line><span class=cl>python src/model/07_registration/main.py --params_file<span class=o>=</span>best_params.yaml
</span></span><span class=line><span class=cl><span class=c1># Output: Model registered in MLflow Registry</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Transition to Production (manual)</span>
</span></span><span class=line><span class=cl>mlflow models transition <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --name housing_price_model <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --version <span class=m>3</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --stage Production
</span></span></code></pre></div><h3 id=what-this-approach-solves>What This Approach Solves<a hidden class=anchor aria-hidden=true href=#what-this-approach-solves>#</a></h3><p><strong>Without Model Registry:</strong></p><ul><li>Pickles in folders: <code>model_v3_final_FINAL_2.pkl</code></li><li>You don&rsquo;t know what hyperparameters each uses</li><li>Rollback = find the correct pickle in GCS</li></ul><p><strong>With Model Registry:</strong></p><ul><li>Models with semantic versions: v1, v2, v3</li><li>Embedded metadata: params, metrics, data sources</li><li>Rollback = <code>transition v3 to Archived</code> + <code>transition v2 to Production</code></li></ul><hr><p><a name=github-actions></a></p><h2 id=8-cicd-with-github-actions-complete-pipeline-automation>8. CI/CD with GitHub Actions: Complete Pipeline Automation<a hidden class=anchor aria-hidden=true href=#8-cicd-with-github-actions-complete-pipeline-automation>#</a></h2><hr><h2 id=navigation>Navigation<a hidden class=anchor aria-hidden=true href=#navigation>#</a></h2><p><strong><a href=/mlops/>← Home</a></strong> | <strong><a href=/mlops/anatomia-pipeline-mlops-parte-2/>Part 2: Deployment and Infrastructure →</a></strong></p><p>In Part 2 we will cover:</p><ul><li>CI/CD with GitHub Actions</li><li>W&amp;B vs MLflow: Complementary strategies</li><li>Complete containerization with Docker</li><li>FastAPI architecture in production</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://carlosdanieljimenez.com/tags/mlops/>Mlops</a></li><li><a href=https://carlosdanieljimenez.com/tags/machine-learning/>Machine-Learning</a></li><li><a href=https://carlosdanieljimenez.com/tags/python/>Python</a></li><li><a href=https://carlosdanieljimenez.com/tags/gcp/>Gcp</a></li><li><a href=https://carlosdanieljimenez.com/tags/mlflow/>Mlflow</a></li><li><a href=https://carlosdanieljimenez.com/tags/wandb/>Wandb</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://carlosdanieljimenez.com/>The Probability Engine</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><div class=newsletter-cta><div class=newsletter-content><h3>📬 Did this help?</h3><p>I write about MLOps, Edge AI, and making models work outside the lab.
One email per month, max. No spam, no course pitches, just technical content.</p><form action=https://buttondown.com/api/emails/embed-subscribe/carlosjimenez88m method=post class=newsletter-form target=popupwindow onsubmit='window.open("https://buttondown.com/carlosjimenez88m","popupwindow")'><div class=form-group><input type=email name=email id=bd-email placeholder=your@email.com required aria-label="Email address">
<input type=submit value=Subscribe></div></form><p class=newsletter-stats>Join engineers building ML systems and Edge Computing infrastructure.</p></div></div><style>.newsletter-cta{margin:3rem auto 2rem;padding:2rem;max-width:650px;background:var(--entry);border:1px solid var(--border);border-radius:8px;text-align:center}.newsletter-content h3{margin:0 0 1rem;font-size:1.5rem;color:var(--primary)}.newsletter-content p{margin:0 0 1.5rem;color:var(--secondary);line-height:1.6}.newsletter-form{margin:1.5rem 0}.form-group{display:flex;gap:.5rem;max-width:500px;margin:0 auto;flex-wrap:wrap;justify-content:center}.newsletter-form input[type=email]{flex:1;min-width:250px;padding:.75rem 1rem;font-size:1rem;border:1px solid var(--border);border-radius:6px;background:var(--theme);color:var(--content);transition:border-color .2s ease}.newsletter-form input[type=email]:focus{outline:none;border-color:var(--primary);box-shadow:0 0 0 3px rgba(var(--primary-rgb),.1)}.newsletter-form input[type=submit]{padding:.75rem 2rem;font-size:1rem;font-weight:600;color:#fff;background:var(--primary);border:none;border-radius:6px;cursor:pointer;transition:opacity .2s ease}.newsletter-form input[type=submit]:hover{opacity:.9}.newsletter-stats{font-size:.875rem;color:var(--secondary);margin-top:1rem;font-style:italic}@media screen and (max-width:600px){.newsletter-cta{padding:1.5rem 1rem;margin:2rem .5rem 1rem}.newsletter-content h3{font-size:1.25rem}.form-group{flex-direction:column;width:100%}.newsletter-form input[type=email],.newsletter-form input[type=submit]{width:100%;min-width:100%}}</style><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>